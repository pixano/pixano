{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"api_reference/","title":"Pixano API reference","text":"<p>Here you will find the documentation for all of our Python API.</p> <ul> <li>The app module contains the Pixano app and the REST API.</li> <li>The datasets module contains the backend to construct and manipulate datasets.</li> <li>The features module contains the backend to manipulate schemas and data stored in datasets.</li> <li>The utils module contains the utilities functions at the library level.</li> </ul>"},{"location":"api_reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>index</li> <li>app<ul> <li>display</li> <li>main</li> <li>models<ul> <li>annotations</li> <li>base_schema</li> <li>dataset_info</li> <li>dataset_items</li> <li>datasets</li> <li>embeddings</li> <li>entities</li> <li>item_info</li> <li>items</li> <li>sources</li> <li>table_info</li> <li>utils</li> <li>views</li> </ul> </li> <li>routers<ul> <li>annotations</li> <li>browser</li> <li>dataset_items</li> <li>datasets</li> <li>embeddings</li> <li>entities</li> <li>items</li> <li>items_info</li> <li>models</li> <li>sources</li> <li>utils</li> <li>views</li> </ul> </li> <li>serve</li> <li>settings</li> </ul> </li> <li>datasets<ul> <li>builders<ul> <li>dataset_builder</li> <li>folders<ul> <li>base</li> <li>image</li> <li>video</li> </ul> </li> </ul> </li> <li>dataset</li> <li>dataset_features_values</li> <li>dataset_info</li> <li>dataset_schema</li> <li>dataset_stat</li> <li>queries<ul> <li>table</li> </ul> </li> <li>utils<ul> <li>errors</li> <li>integrity</li> <li>labels</li> <li>video</li> </ul> </li> </ul> </li> <li>features<ul> <li>pyarrow_utils</li> <li>schemas<ul> <li>annotations<ul> <li>annotation</li> <li>bbox</li> <li>camcalibration</li> <li>classification</li> <li>compressed_rle</li> <li>info_extraction</li> <li>keypoints</li> <li>text_generation</li> <li>tracklet</li> </ul> </li> <li>base_schema</li> <li>embeddings<ul> <li>embedding</li> </ul> </li> <li>entities<ul> <li>entity</li> <li>track</li> </ul> </li> <li>items<ul> <li>item</li> </ul> </li> <li>registry</li> <li>schema_group</li> <li>source</li> <li>views<ul> <li>image</li> <li>point_cloud</li> <li>sequence_frame</li> <li>text</li> <li>video</li> <li>view</li> </ul> </li> </ul> </li> <li>types<ul> <li>base_type</li> <li>nd_array_float</li> <li>registry</li> <li>schema_reference</li> </ul> </li> <li>utils<ul> <li>boxes</li> <li>creators</li> <li>image</li> </ul> </li> </ul> </li> <li>utils<ul> <li>python</li> <li>validation</li> </ul> </li> </ul>"},{"location":"api_reference/app/display/","title":"display","text":""},{"location":"api_reference/app/display/#pixano.app.display","title":"<code>pixano.app.display</code>","text":""},{"location":"api_reference/app/display/#pixano.app.display.display_cli","title":"<code>display_cli(url, port)</code>","text":"<p>Display a Pixano app inside a command line interface.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Pixano app URL.</p> required <code>port</code> <code>int</code> <p>Pixano app port.</p> required Source code in <code>pixano/app/display.py</code> <pre><code>def display_cli(url: str, port: int):\n    \"\"\"Display a Pixano app inside a command line interface.\n\n    Args:\n        url: Pixano app URL.\n        port: Pixano app port.\n    \"\"\"\n    print(f\"Please visit {url}:{port} in a web browser.\")\n</code></pre>"},{"location":"api_reference/app/display/#pixano.app.display.display_colab","title":"<code>display_colab(url, port, height)</code>","text":"<p>Display a Pixano app inside a Google Colab.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Pixano app URL.</p> required <code>port</code> <code>int</code> <p>Pixano app port.</p> required <code>height</code> <code>int</code> <p>Frame height.</p> required Source code in <code>pixano/app/display.py</code> <pre><code>def display_colab(url: str, port: int, height: int):\n    \"\"\"Display a Pixano app inside a Google Colab.\n\n    Args:\n        url: Pixano app URL.\n        port: Pixano app port.\n        height: Frame height.\n    \"\"\"\n    # Define frame template\n    shell = \"\"\"\n        (() =&gt; {\n            const url = new URL(%URL%);\n            const port = %PORT%;\n            if (port) {\n                url.port = port;\n            }\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '%HEIGHT%');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    \"\"\"\n\n    # Replace variables in template\n    replacements = [\n        (\"%HEIGHT%\", f\"{height}\"),\n        (\"%PORT%\", f\"{port}\"),\n        (\"%URL%\", json.dumps(url)),\n    ]\n    for k, v in replacements:\n        shell = shell.replace(k, v)\n\n    # Display frame\n    script = IPython.display.Javascript(shell)\n    IPython.display.display(script)\n</code></pre>"},{"location":"api_reference/app/display/#pixano.app.display.display_ipython","title":"<code>display_ipython(url, port, height)</code>","text":"<p>Display a Pixano app inside a Jupyter notebook.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Pixano app URL.</p> required <code>port</code> <code>int</code> <p>Pixano app port.</p> required <code>height</code> <code>int</code> <p>Frame height.</p> required Source code in <code>pixano/app/display.py</code> <pre><code>def display_ipython(url: str, port: int, height: int):\n    \"\"\"Display a Pixano app inside a Jupyter notebook.\n\n    Args:\n        url: Pixano app URL.\n        port: Pixano app port.\n        height: Frame height.\n    \"\"\"\n    # Define frame template\n    shell = \"\"\"\n        &lt;iframe id=\"%HTML_ID%\" width=\"100%\" height=\"%HEIGHT%\" frameborder=\"0\"&gt;\n        &lt;/iframe&gt;\n        &lt;script&gt;\n            (function() {\n                const frame = document.getElementById(%JSON_ID%);\n                const url = new URL(%URL%, window.location);\n                const port = %PORT%;\n                if (port) {\n                    url.port = port;\n                }\n                frame.src = url;\n            })();\n        &lt;/script&gt;\n    \"\"\"\n\n    # Replace variables in template\n    frame_id = f\"frame-{shortuuid.uuid()}\"\n    replacements = [\n        (\"%HTML_ID%\", html.escape(frame_id, quote=True)),\n        (\"%JSON_ID%\", json.dumps(frame_id)),\n        (\"%HEIGHT%\", f\"{height}\"),\n        (\"%PORT%\", f\"{port}\"),\n        (\"%URL%\", json.dumps(url)),\n    ]\n    for k, v in replacements:\n        shell = shell.replace(k, v)\n\n    # Display frame\n    iframe = IPython.display.HTML(shell)\n    IPython.display.display(iframe)\n</code></pre>"},{"location":"api_reference/app/main/","title":"main","text":""},{"location":"api_reference/app/main/#pixano.app.main","title":"<code>pixano.app.main</code>","text":""},{"location":"api_reference/app/main/#pixano.app.main.create_app","title":"<code>create_app(settings=Settings())</code>","text":"<p>Create and configure the Pixano app.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>App settings.</p> <code>Settings()</code> <p>Returns:</p> Type Description <code>FastAPI</code> <p>The Pixano app.</p> Source code in <code>pixano/app/main.py</code> <pre><code>def create_app(settings: Settings = Settings()) -&gt; FastAPI:\n    \"\"\"Create and configure the Pixano app.\n\n    Args:\n        settings: App settings.\n\n    Returns:\n        The Pixano app.\n    \"\"\"\n    # Create app\n    app = FastAPI()\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=[\"*\"],\n        allow_credentials=False,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n\n    # Mount folders\n    if isinstance(settings.media_dir, S3Path):\n        # If S3, mount models folder\n        # Check if folder exists\n        if settings.models_dir is None:\n            raise FileNotFoundError(\"Local model directory not provided\")\n        elif not settings.models_dir.exists():\n            raise FileNotFoundError(f\"Local model directory '{settings.models_dir.absolute()}' not found\")\n        # Mount\n        app.mount(\n            \"/models\",\n            StaticFiles(directory=settings.models_dir),\n            name=\"models\",\n        )\n    else:\n        # If local, mount media folder and models folder\n        # Check if folder exists\n        if not settings.media_dir.exists():\n            raise FileNotFoundError(f\"Media directory '{settings.media_dir.absolute()}' not found\")\n        if settings.models_dir is None:\n            raise FileNotFoundError(\"Model directory not provided\")\n        # Create models folder in case it doesn't exist yet\n        if not settings.models_dir.exists():\n            settings.models_dir.mkdir(exist_ok=True)\n        # Mount\n        app.mount(\n            \"/media\",\n            StaticFiles(directory=settings.media_dir),\n            name=\"media\",\n        )\n        app.mount(\n            \"/app_models\",\n            StaticFiles(directory=settings.models_dir),\n            name=\"models\",\n        )\n\n    # Include routers\n    app.include_router(annotations_router)\n    app.include_router(dataset_items_router)\n    app.include_router(datasets_router)\n    app.include_router(browser_router)\n    app.include_router(embeddings_router)\n    app.include_router(entities_router)\n    app.include_router(items_router)\n    app.include_router(items_info_router)\n    app.include_router(sources_router)\n    app.include_router(views_router)\n    app.include_router(models_router)\n\n    return app\n</code></pre>"},{"location":"api_reference/app/serve/","title":"serve","text":""},{"location":"api_reference/app/serve/#pixano.app.serve","title":"<code>pixano.app.serve</code>","text":""},{"location":"api_reference/app/serve/#pixano.app.serve.App","title":"<code>App(library_dir, media_dir, models_dir=None, aws_endpoint=None, aws_region=None, aws_access_key=None, aws_secret_key=None, host='127.0.0.1', port=8000)</code>","text":"<p>The Pixano app.</p> <p>Attributes:</p> Name Type Description <code>app</code> <code>FastAPI</code> <p>FastAPI App.</p> <code>config</code> <code>Config</code> <p>App config.</p> <code>server</code> <code>Server</code> <p>App server.</p> <p>Parameters:</p> Name Type Description Default <code>library_dir</code> <code>str</code> <p>Local or S3 path to dataset library</p> required <code>media_dir</code> <code>str</code> <p>Local or S3 path to media library</p> required <code>models_dir</code> <code>str | None</code> <p>Path to your models. If not provided, and library_dir is not a S3 path, it is set to library_dir/models.</p> <code>None</code> <code>aws_endpoint</code> <code>str | None</code> <p>S3 endpoint URL, use 'AWS' if not provided. Used if library_dir is an S3 path.</p> <code>None</code> <code>aws_region</code> <code>str | None</code> <p>S3 region name, not always required for private storages. Used if library_dir is an S3 path.</p> <code>None</code> <code>aws_access_key</code> <code>str | None</code> <p>S3 AWS access key. Used if library_dir is an S3 path.</p> <code>None</code> <code>aws_secret_key</code> <code>str | None</code> <p>S3 AWS secret key. Used if library_dir is an S3 path.</p> <code>None</code> <code>host</code> <code>str</code> <p>App host.</p> <code>'127.0.0.1'</code> <code>port</code> <code>int</code> <p>App port.</p> <code>8000</code> Source code in <code>pixano/app/serve.py</code> <pre><code>def __init__(\n    self,\n    library_dir: str,\n    media_dir: str,\n    models_dir: str | None = None,\n    aws_endpoint: str | None = None,\n    aws_region: str | None = None,\n    aws_access_key: str | None = None,\n    aws_secret_key: str | None = None,\n    host: str = \"127.0.0.1\",\n    port: int = 8000,\n):\n    \"\"\"Initialize and serve the Pixano app.\n\n    Args:\n        library_dir: Local or S3 path to dataset library\n        media_dir: Local or S3 path to media library\n        models_dir: Path to your models. If not provided, and\n            library_dir is not a S3 path, it is set to\n            library_dir/models.\n        aws_endpoint: S3 endpoint URL, use 'AWS' if not provided.\n            Used if library_dir is an S3 path.\n        aws_region: S3 region name, not always required for\n            private storages. Used if library_dir is an S3 path.\n        aws_access_key: S3 AWS access key. Used if library_dir is\n            an S3 path.\n        aws_secret_key: S3 AWS secret key. Used if library_dir\n            is an S3 path.\n        host: App host.\n        port: App port.\n    \"\"\"\n\n    # Override app settings\n    @lru_cache\n    def get_settings_override():\n        return Settings(\n            library_dir=library_dir,\n            media_dir=media_dir,\n            models_dir=models_dir,\n            aws_endpoint=aws_endpoint,\n            aws_region=aws_region,\n            aws_access_key=aws_access_key,\n            aws_secret_key=aws_secret_key,\n        )\n\n    # Create app\n    settings = get_settings_override()\n    templates = Jinja2Templates(directory=TEMPLATE_PATH)\n    self.app = create_app(settings=settings)\n    self.app.dependency_overrides[get_settings] = get_settings_override\n\n    @self.app.get(\"/\", response_class=HTMLResponse)\n    def main_page(request: fastapi.Request):\n        return templates.TemplateResponse(\"index.html\", {\"request\": request})\n\n    @self.app.get(\"/{ds_id}/dataset\", response_class=HTMLResponse)\n    async def dataset_page(request: fastapi.Request):\n        return templates.TemplateResponse(\"index.html\", {\"request\": request})\n\n    @self.app.get(\"/{ds_id}/dashboard\", response_class=HTMLResponse)\n    async def dashboard_page(request: fastapi.Request):\n        return templates.TemplateResponse(\"index.html\", {\"request\": request})\n\n    @self.app.get(\"/{ds_id}/dataset/{item_id}\", response_class=HTMLResponse)\n    async def item_page(request: fastapi.Request):\n        return templates.TemplateResponse(\"index.html\", {\"request\": request})\n\n    try:\n        self.app.mount(\"/_app\", StaticFiles(directory=ASSETS_PATH), name=\"assets\")\n    # TODO: properly define environment variable for production to raise a RuntimeError accordingly\n    except RuntimeError:\n        warnings.warn(\n            \"Pixano app assets not found. If it is a production environment, this is not expected, \"\n            \"check if you have built the assets for the UI.\"\n        )\n    self.config = uvicorn.Config(self.app, host=host, port=port)\n    self.server = uvicorn.Server(self.config)\n\n    # Serve app\n    task_functions[self.get_env()](self.server.serve())  # type: ignore[operator]\n</code></pre>"},{"location":"api_reference/app/serve/#pixano.app.serve.App.display","title":"<code>display(height=1000)</code>","text":"<p>Display the Pixano app.</p> <p>Parameters:</p> Name Type Description Default <code>height</code> <code>int</code> <p>Frame height.</p> <code>1000</code> Source code in <code>pixano/app/serve.py</code> <pre><code>def display(self, height: int = 1000) -&gt; None:\n    \"\"\"Display the Pixano app.\n\n    Args:\n        height: Frame height.\n    \"\"\"\n    # Wait for app to be online\n    while not self.server.started:\n        task_functions[self.get_env()](asyncio.wait(0.1))  # type: ignore[operator, call-overload]\n\n    # Display app\n    for server in self.server.servers:\n        for socket in server.sockets:\n            address = socket.getsockname()\n            display_functions[self.get_env()](url=f\"http://{address[0]}\", port=address[1], height=height)  # type: ignore[operator]\n</code></pre>"},{"location":"api_reference/app/serve/#pixano.app.serve.App.get_env","title":"<code>get_env()</code>","text":"<p>Get the app's current running environment.</p> <p>Returns:</p> Type Description <code>str</code> <p>Running environment.</p> Source code in <code>pixano/app/serve.py</code> <pre><code>def get_env(self) -&gt; str:\n    \"\"\"Get the app's current running environment.\n\n    Returns:\n        Running environment.\n    \"\"\"\n    # If Google colab import succeeds\n    try:\n        import google.colab  # noqa: F401, I001 #type: ignore\n        import IPython\n    except ImportError:\n        pass\n    else:\n        if IPython.get_ipython() is not None:\n            return \"colab\"\n\n    # If IPython import succeeds\n    try:\n        import IPython\n    except ImportError:\n        pass\n    else:\n        ipython = IPython.get_ipython()\n        if ipython is not None and ipython.has_trait(\"kernel\"):\n            return \"ipython\"\n\n    # Else\n    return \"none\"\n</code></pre>"},{"location":"api_reference/app/serve/#pixano.app.serve.main","title":"<code>main(library_dir, media_dir, models_dir, aws_endpoint, aws_region, aws_access_key, aws_secret_key, host, port)</code>","text":"<p>Launch Pixano App in LIBRARY_DIR.</p> <p>Parameters:</p> Name Type Description Default <code>library_dir</code> <code>str</code> <p>Local or S3 path to dataset library.</p> required <code>media_dir</code> <code>str</code> <p>Local or S3 path to media library.</p> required <code>models_dir</code> <code>str</code> <p>Path to your models. If not provided, and library_dir is not a S3 path, it is set to library_dir/models.</p> required <code>aws_endpoint</code> <code>str</code> <p>S3 endpoint URL, use 'AWS' if not provided.</p> required <code>aws_region</code> <code>str</code> <p>S3 region name, not always required for private storages.</p> required <code>aws_access_key</code> <code>str</code> <p>S3 AWS access key.</p> required <code>aws_secret_key</code> <code>str</code> <p>S3 AWS secret key.</p> required <code>host</code> <code>str</code> <p>App host.</p> required <code>port</code> <code>int</code> <p>App port.</p> required Source code in <code>pixano/app/serve.py</code> <pre><code>@click.command(context_settings={\"auto_envvar_prefix\": \"UVICORN\"})\n@click.argument(\"library_dir\", type=str)\n@click.argument(\"media_dir\", type=str)\n@click.option(\n    \"--models_dir\",\n    type=str,\n    help=\"Path to your models. If not provided, and library_dir is not a S3 path, it is set to library_dir/models\",\n)\n@click.option(\n    \"--aws_endpoint\",\n    type=str,\n    help=(\"S3 endpoint URL, use 'AWS' if not provided. \" \"Used if library_dir or media_dir is an S3 path\"),\n)\n@click.option(\n    \"--aws_region\",\n    type=str,\n    help=(\n        \"S3 region name, not always required for private storages.\" \"Used if library_dir or media_dir is an S3 path\"\n    ),\n)\n@click.option(\n    \"--aws_access_key\",\n    type=str,\n    help=\"S3 AWS access key. Used if library_dir or media_dir is an S3 path\",\n)\n@click.option(\n    \"--aws_secret_key\",\n    type=str,\n    help=\"S3 AWS secret key. Used if library_dir or media_dir is an S3 path\",\n)\n@click.option(\n    \"--host\",\n    type=str,\n    default=\"127.0.0.1\",\n    help=\"Pixano app URL host\",\n    show_default=True,\n)\n@click.option(\n    \"--port\",\n    type=int,\n    default=0,\n    help=\"Pixano app URL port\",\n    show_default=True,\n)\ndef main(\n    library_dir: str,\n    media_dir: str,\n    models_dir: str,\n    aws_endpoint: str,\n    aws_region: str,\n    aws_access_key: str,\n    aws_secret_key: str,\n    host: str,\n    port: int,\n) -&gt; None:\n    \"\"\"Launch Pixano App in LIBRARY_DIR.\n\n    Args:\n        library_dir: Local or S3 path to dataset library.\n        media_dir: Local or S3 path to media library.\n        models_dir: Path to your models. If not provided, and\n            library_dir is not a S3 path, it is set to\n            library_dir/models.\n        aws_endpoint: S3 endpoint URL, use 'AWS' if not provided.\n        aws_region: S3 region name, not always required for private storages.\n        aws_access_key: S3 AWS access key.\n        aws_secret_key: S3 AWS secret key.\n        host: App host.\n        port: App port.\n    \"\"\"\n    App(\n        library_dir,\n        media_dir,\n        models_dir,\n        aws_endpoint,\n        aws_region,\n        aws_access_key,\n        aws_secret_key,\n        host,\n        port,\n    )\n</code></pre>"},{"location":"api_reference/app/settings/","title":"settings","text":""},{"location":"api_reference/app/settings/#pixano.app.settings","title":"<code>pixano.app.settings</code>","text":""},{"location":"api_reference/app/settings/#pixano.app.settings.Settings","title":"<code>Settings</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Pixano app settings.</p> <p>Attributes:</p> Name Type Description <code>library_dir</code> <code>Path | S3Path</code> <p>Local or S3 path to dataset library. If not provided, it is set to <code>'./library/'</code>.</p> <code>media_dir</code> <code>Path | S3Path</code> <p>Local or S3 path to media library. If not provided, it is set to <code>'./media/'</code>.</p> <code>models_dir</code> <code>Path | None</code> <p>Models directory as Path. Must be provided if library_dir is an S3 path else it is set to <code>'library_dir/models'</code></p> <code>aws_endpoint</code> <code>str | None</code> <p>S3 endpoint URL, use 'AWS' if not provided. Used if library_dir is an S3 path.</p> <code>aws_region</code> <code>str | None</code> <p>S3 region name, not always required for private storages. Used if library_dir is an S3 path.</p> <code>aws_access_key</code> <code>str | None</code> <p>S3 AWS access key. Used if library_dir is an S3 path.</p> <code>aws_secret_key</code> <code>str | None</code> <p>S3 AWS secret key. Used if library_dir is an S3 path.</p>"},{"location":"api_reference/app/settings/#pixano.app.settings.get_settings","title":"<code>get_settings()</code>  <code>cached</code>","text":"<p>Get app settings.</p> <p>Returns:</p> Type Description <code>Settings</code> <p>App settings.</p> Source code in <code>pixano/app/settings.py</code> <pre><code>@lru_cache\ndef get_settings() -&gt; Settings:\n    \"\"\"Get app settings.\n\n    Returns:\n        App settings.\n    \"\"\"\n    return Settings()\n</code></pre>"},{"location":"api_reference/app/models/annotations/","title":"annotations","text":""},{"location":"api_reference/app/models/annotations/#pixano.app.models.annotations","title":"<code>pixano.app.models.annotations</code>","text":""},{"location":"api_reference/app/models/annotations/#pixano.app.models.annotations.AnnotationModel","title":"<code>AnnotationModel(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>BaseSchemaModel[Annotation]</code></p> <p>Model for the Annotation schema.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/app/models/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/app/models/annotations/#pixano.app.models.annotations.AnnotationModel.to_row","title":"<code>to_row(schema_type)</code>","text":"<p>Create an Annotation from the model.</p> Source code in <code>pixano/app/models/annotations.py</code> <pre><code>def to_row(self, schema_type: type[T]) -&gt; T:\n    \"\"\"Create an [Annotation][pixano.features.Annotation] from the model.\"\"\"\n    if not issubclass(schema_type, Annotation):\n        raise ValueError(f\"Schema type must be a subclass of {Annotation.__name__}.\")\n    return super().to_row(schema_type)\n</code></pre>"},{"location":"api_reference/app/models/base_schema/","title":"base_schema","text":""},{"location":"api_reference/app/models/base_schema/#pixano.app.models.base_schema","title":"<code>pixano.app.models.base_schema</code>","text":""},{"location":"api_reference/app/models/base_schema/#pixano.app.models.base_schema.BaseSchemaModel","title":"<code>BaseSchemaModel(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[T]</code></p> <p>Base schema model.</p> <p>This class is a base class for all schema models. It provides methods to convert a row to a model and vice versa.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier of the row.</p> <code>created_at</code> <code>datetime</code> <p>The creation date of the row.</p> <code>updated_at</code> <code>datetime</code> <p>The last modification date of the row.</p> <code>table_info</code> <code>TableInfo</code> <p>Information about the table to which the row belongs.</p> <code>data</code> <code>dict[str, Any]</code> <p>Dumped data from the Pixano backend row except the id.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/app/models/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/app/models/base_schema/#pixano.app.models.base_schema.BaseSchemaModel.from_row","title":"<code>from_row(row, table_info)</code>  <code>classmethod</code>","text":"<p>Create a model from a row.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>T</code> <p>The row to create the model from.</p> required <code>table_info</code> <code>TableInfo</code> <p>The table info of the row.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The created model.</p> Source code in <code>pixano/app/models/base_schema.py</code> <pre><code>@classmethod\ndef from_row(cls, row: T, table_info: TableInfo) -&gt; Self:\n    \"\"\"Create a model from a row.\n\n    Args:\n        row: The row to create the model from.\n        table_info: The table info of the row.\n\n    Returns:\n        The created model.\n    \"\"\"\n    model_dict = {}\n    data = {}\n    for key, value in row.model_dump().items():\n        if key in [\"id\", \"created_at\", \"updated_at\"]:\n            model_dict[key] = value\n            continue\n        data[key] = value\n    model_dict[\"data\"] = data\n    model_dict[\"table_info\"] = table_info\n\n    return cls.model_validate(model_dict)\n</code></pre>"},{"location":"api_reference/app/models/base_schema/#pixano.app.models.base_schema.BaseSchemaModel.from_rows","title":"<code>from_rows(rows, table_info)</code>  <code>classmethod</code>","text":"<p>Create a list of models from a list of schemas.</p> <p>Parameters:</p> Name Type Description Default <code>rows</code> <code>list[T]</code> <p>The rows to create the models from.</p> required <code>table_info</code> <code>TableInfo</code> <p>The table info of the rows.</p> required <p>Returns:</p> Type Description <code>list[Self]</code> <p>The list of created models.</p> Source code in <code>pixano/app/models/base_schema.py</code> <pre><code>@classmethod\ndef from_rows(cls, rows: list[T], table_info: TableInfo) -&gt; list[Self]:\n    \"\"\"Create a list of models from a list of schemas.\n\n    Args:\n        rows: The rows to create the models from.\n        table_info: The table info of the rows.\n\n    Returns:\n        The list of created models.\n    \"\"\"\n    return [cls.from_row(row, table_info) for row in rows]\n</code></pre>"},{"location":"api_reference/app/models/base_schema/#pixano.app.models.base_schema.BaseSchemaModel.model_dump","title":"<code>model_dump(exclude_timestamps=False, **kwargs)</code>","text":"<p>Dump the model to a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_timestamps</code> <code>bool</code> <p>Exclude timestamps \"created_at\" and \"updated_at\" from the model dump. Useful for comparing models without timestamps.</p> <code>False</code> <code>kwargs</code> <code>Any</code> <p>Arguments for pydantic <code>BaseModel.model_dump()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The model dump.</p> Source code in <code>pixano/app/models/base_schema.py</code> <pre><code>def model_dump(self, exclude_timestamps: bool = False, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Dump the model to a dictionary.\n\n    Args:\n        exclude_timestamps: Exclude timestamps \"created_at\" and \"updated_at\" from the model dump. Useful for\n            comparing models without timestamps.\n        kwargs: Arguments for pydantic `BaseModel.model_dump()`.\n\n    Returns:\n        The model dump.\n    \"\"\"\n    model_dump = super().model_dump(**kwargs)\n    if exclude_timestamps:\n        model_dump.pop(\"created_at\", None)\n        model_dump.pop(\"updated_at\", None)\n    return model_dump\n</code></pre>"},{"location":"api_reference/app/models/base_schema/#pixano.app.models.base_schema.BaseSchemaModel.to_row","title":"<code>to_row(schema)</code>","text":"<p>Create a row from the model.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>type[SUB_T]</code> <p>The schema type of the row.</p> required <p>Returns:</p> Type Description <code>SUB_T</code> <p>The created row.</p> Source code in <code>pixano/app/models/base_schema.py</code> <pre><code>def to_row(self, schema: type[SUB_T]) -&gt; SUB_T:\n    \"\"\"Create a row from the model.\n\n    Args:\n        schema: The schema type of the row.\n\n    Returns:\n        The created row.\n    \"\"\"\n    schema_dict = self.model_dump()\n    return schema.model_validate(\n        {\n            \"id\": schema_dict[\"id\"],\n            \"created_at\": schema_dict[\"created_at\"],\n            \"updated_at\": schema_dict[\"updated_at\"],\n            **schema_dict[\"data\"],\n        }\n    )\n</code></pre>"},{"location":"api_reference/app/models/base_schema/#pixano.app.models.base_schema.BaseSchemaModel.to_rows","title":"<code>to_rows(models, schema)</code>  <code>staticmethod</code>","text":"<p>Create a list of rows from a list of models.</p> <p>Parameters:</p> Name Type Description Default <code>models</code> <code>list[BaseSchemaModel]</code> <p>The models to create the rows from.</p> required <code>schema</code> <code>type[SUB_T]</code> <p>The schema type of the rows.</p> required <p>Returns:</p> Type Description <code>list[SUB_T]</code> <p>The list of created rows.</p> Source code in <code>pixano/app/models/base_schema.py</code> <pre><code>@staticmethod\ndef to_rows(models: list[\"BaseSchemaModel\"], schema: type[SUB_T]) -&gt; list[SUB_T]:\n    \"\"\"Create a list of rows from a list of models.\n\n    Args:\n        models: The models to create the rows from.\n        schema: The schema type of the rows.\n\n    Returns:\n        The list of created rows.\n    \"\"\"\n    return [model.to_row(schema) for model in models]\n</code></pre>"},{"location":"api_reference/app/models/dataset_info/","title":"dataset_info","text":""},{"location":"api_reference/app/models/dataset_info/#pixano.app.models.dataset_info","title":"<code>pixano.app.models.dataset_info</code>","text":""},{"location":"api_reference/app/models/dataset_info/#pixano.app.models.dataset_info.DatasetInfoModel","title":"<code>DatasetInfoModel(**data)</code>","text":"<p>               Bases: <code>DatasetInfo</code></p> <p>Dataset info model.</p> <p>It contains all the information as a DatasetInfo and the number of items in the dataset.</p> <p>Attributes:</p> Name Type Description <code>num_items</code> <code>int</code> <p>Number of items in the dataset.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            stacklevel=2,\n        )\n</code></pre>"},{"location":"api_reference/app/models/dataset_info/#pixano.app.models.dataset_info.DatasetInfoModel.from_dataset_info","title":"<code>from_dataset_info(dataset_info, dataset_dir)</code>  <code>staticmethod</code>","text":"<p>Create a dataset info model from a dataset info.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_info</code> <code>DatasetInfo</code> <p>Dataset info.</p> required <code>dataset_dir</code> <code>Path</code> <p>Dataset directory.</p> required <p>Returns:</p> Type Description <code>DatasetInfoModel</code> <p>Dataset info model.</p> Source code in <code>pixano/app/models/dataset_info.py</code> <pre><code>@staticmethod\ndef from_dataset_info(dataset_info: DatasetInfo, dataset_dir: Path) -&gt; \"DatasetInfoModel\":\n    \"\"\"Create a dataset info model from a dataset info.\n\n    Args:\n        dataset_info: Dataset info.\n        dataset_dir: Dataset directory.\n\n    Returns:\n        Dataset info model.\n    \"\"\"\n    db = lancedb.connect(dataset_dir / Dataset._DB_PATH)\n    item_table = db.open_table(SchemaGroup.ITEM.value)\n    num_items = item_table.count_rows()\n    return DatasetInfoModel(\n        num_items=num_items,\n        **dataset_info.model_dump(),\n    )\n</code></pre>"},{"location":"api_reference/app/models/dataset_items/","title":"dataset_items","text":""},{"location":"api_reference/app/models/dataset_items/#pixano.app.models.dataset_items","title":"<code>pixano.app.models.dataset_items</code>","text":""},{"location":"api_reference/app/models/dataset_items/#pixano.app.models.dataset_items.DatasetItemModel","title":"<code>DatasetItemModel(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>DatasetItem model.</p> <p>It represents a dataset item with its associated entities, annotations and views.</p> <p>The mappings consist of the table name as key and the corresponding model or list of models as value.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>The dataset item id.</p> <code>item</code> <code>ItemModel</code> <p>The item model.</p> <code>entities</code> <code>dict[str, list[EntityModel] | EntityModel | None]</code> <p>The entities models mapping.</p> <code>annotations</code> <code>dict[str, list[AnnotationModel] | AnnotationModel | None]</code> <p>The annotations models mapping.</p> <code>views</code> <code>dict[str, list[ViewModel] | ViewModel | None]</code> <p>The views models mapping.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            stacklevel=2,\n        )\n</code></pre>"},{"location":"api_reference/app/models/dataset_items/#pixano.app.models.dataset_items.DatasetItemModel.from_dataset_item","title":"<code>from_dataset_item(dataset_item, dataset_schema)</code>  <code>classmethod</code>","text":"<p>Create a model from a DatasetItem.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_item</code> <code>DatasetItem</code> <p>The dataset item to create the model from.</p> required <code>dataset_schema</code> <code>DatasetSchema</code> <p>The schema of the dataset containing the dataset item.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The created model.</p> Source code in <code>pixano/app/models/dataset_items.py</code> <pre><code>@classmethod\ndef from_dataset_item(cls, dataset_item: DatasetItem, dataset_schema: DatasetSchema) -&gt; Self:\n    \"\"\"Create a model from a [DatasetItem][pixano.datasets.DatasetItem].\n\n    Args:\n        dataset_item: The dataset item to create the model from.\n        dataset_schema: The schema of the dataset containing the dataset item.\n\n    Returns:\n        The created model.\n    \"\"\"\n\n    def _row_or_rows_to_model_or_models(\n        row_or_rows: BaseSchema | list[BaseSchema], name: str, group: SchemaGroup, model: type[BaseSchemaModel]\n    ) -&gt; BaseSchemaModel | list[BaseSchemaModel]:\n        base_schema = get_super_type_from_dict(\n            type(row_or_rows[0]) if isinstance(row_or_rows, list) else type(row_or_rows), _PIXANO_SCHEMA_REGISTRY\n        )\n        if base_schema is None:\n            raise ValueError(f\"Unsupported schema type {type(row_or_rows)}\")\n        table_info = TableInfo(name=name, group=group.value, base_schema=base_schema.__name__)\n        if isinstance(row_or_rows, list):\n            return model.from_rows(row_or_rows, table_info=table_info)\n        else:\n            return model.from_row(row_or_rows, table_info=table_info)\n\n    model_dict: dict[str, Any] = {\n        \"entities\": {},\n        \"annotations\": {},\n        \"views\": {},\n    }\n    for key, value in dataset_item.to_schemas_data(dataset_schema).items():\n        if value is None or value == []:\n            if issubclass(dataset_schema.schemas[key], View):\n                model_dict[\"views\"][key] = None if value is None else []\n            elif issubclass(dataset_schema.schemas[key], Entity):\n                model_dict[\"entities\"][key] = None if value is None else []\n            elif issubclass(dataset_schema.schemas[key], Annotation):\n                model_dict[\"annotations\"][key] = None if value is None else []\n            else:\n                raise ValueError(f\"Unsupported schema type {type(value)}\")\n        elif isinstance(value, Item) or isinstance(value, list) and isinstance(value[0], Item):\n            model_dict[key] = _row_or_rows_to_model_or_models(value, key, SchemaGroup.ITEM, ItemModel)\n        elif isinstance(value, Annotation) or isinstance(value, list) and isinstance(value[0], Annotation):\n            model_dict[\"annotations\"][key] = _row_or_rows_to_model_or_models(\n                value, key, SchemaGroup.ANNOTATION, AnnotationModel\n            )\n        elif isinstance(value, Entity) or isinstance(value, list) and isinstance(value[0], Entity):\n            model_dict[\"entities\"][key] = _row_or_rows_to_model_or_models(\n                value, key, SchemaGroup.ENTITY, EntityModel\n            )\n        elif isinstance(value, View) or isinstance(value, list) and isinstance(value[0], View):\n            model_dict[\"views\"][key] = _row_or_rows_to_model_or_models(value, key, SchemaGroup.VIEW, ViewModel)\n        else:\n            raise ValueError(f\"Unsupported schema type {type(value)}\")\n    model_dict[\"id\"] = dataset_item.id\n    return cls.model_validate(model_dict)\n</code></pre>"},{"location":"api_reference/app/models/dataset_items/#pixano.app.models.dataset_items.DatasetItemModel.from_dataset_items","title":"<code>from_dataset_items(dataset_items, dataset_schema)</code>  <code>classmethod</code>","text":"<p>Create a list of models from a list of DatasetItems.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_items</code> <code>list[DatasetItem]</code> <p>The dataset items to create the models from.</p> required <code>dataset_schema</code> <code>DatasetSchema</code> <p>The schema of the dataset containing the dataset item.</p> required <p>Returns:</p> Type Description <code>list[Self]</code> <p>The list of created models.</p> Source code in <code>pixano/app/models/dataset_items.py</code> <pre><code>@classmethod\ndef from_dataset_items(cls, dataset_items: list[DatasetItem], dataset_schema: DatasetSchema) -&gt; list[Self]:\n    \"\"\"Create a list of models from a list of [DatasetItem][pixano.datasets.DatasetItem]s.\n\n    Args:\n        dataset_items: The dataset items to create the models from.\n        dataset_schema: The schema of the dataset containing the dataset item.\n\n    Returns:\n        The list of created models.\n    \"\"\"\n    return [cls.from_dataset_item(dataset_item, dataset_schema) for dataset_item in dataset_items]\n</code></pre>"},{"location":"api_reference/app/models/dataset_items/#pixano.app.models.dataset_items.DatasetItemModel.model_dump","title":"<code>model_dump(exclude_timestamps=False, **kwargs)</code>","text":"<p>Dump the model to a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_timestamps</code> <code>bool</code> <p>Exclude timestamps \"created_at\" and \"updated_at\" from the model dump. Useful for comparing models without timestamps.</p> <code>False</code> <code>kwargs</code> <code>Any</code> <p>Arguments for pydantic <code>BaseModel.model_dump()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The model dump.</p> Source code in <code>pixano/app/models/dataset_items.py</code> <pre><code>def model_dump(self, exclude_timestamps: bool = False, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Dump the model to a dictionary.\n\n    Args:\n        exclude_timestamps: Exclude timestamps \"created_at\" and \"updated_at\" from the model dump. Useful for\n            comparing models without timestamps.\n        kwargs: Arguments for pydantic `BaseModel.model_dump()`.\n\n    Returns:\n        The model dump.\n    \"\"\"\n    model_dump = super().model_dump(**kwargs)\n    if exclude_timestamps:\n        model_dump[\"item\"].pop(\"created_at\", None)\n        model_dump[\"item\"].pop(\"updated_at\", None)\n        for k in [\"entities\", \"annotations\", \"views\"]:\n            for model in model_dump[k].values():\n                if model is None:\n                    continue\n                elif isinstance(model, list):  # Only one level deep.\n                    for item in model:\n                        item.pop(\"created_at\", None)\n                        item.pop(\"updated_at\", None)\n                else:\n                    model.pop(\"created_at\", None)\n                    model.pop(\"updated_at\", None)\n    return model_dump\n</code></pre>"},{"location":"api_reference/app/models/dataset_items/#pixano.app.models.dataset_items.DatasetItemModel.to_dataset_item","title":"<code>to_dataset_item(dataset_schema)</code>","text":"<p>Create a DatasetItem from a model.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_schema</code> <code>DatasetSchema</code> <p>The schema of the dataset containing the dataset item.</p> required <p>Returns:</p> Type Description <code>DatasetItem</code> <p>The created dataset item.</p> Source code in <code>pixano/app/models/dataset_items.py</code> <pre><code>def to_dataset_item(self, dataset_schema: DatasetSchema) -&gt; DatasetItem:\n    \"\"\"Create a [DatasetItem][pixano.datasets.DatasetItem] from a model.\n\n    Args:\n        dataset_schema: The schema of the dataset containing the dataset item.\n\n    Returns:\n        The created dataset item.\n    \"\"\"\n    schema_dict = {}\n\n    item = self.item\n    schema_dict.update(item.to_row(dataset_schema.schemas[\"item\"]).model_dump())\n\n    for group in [self.annotations, self.entities, self.views]:\n        for key, value in group.items():\n            schema = dataset_schema.schemas[key]\n            if isinstance(value, list):\n                schema_dict[key] = [v.to_row(schema) for v in value]\n            elif value is None:\n                schema_dict[key] = None\n            else:\n                schema_dict[key] = value.to_row(schema)\n\n    return DatasetItem.from_dataset_schema(dataset_schema, exclude_embeddings=True).model_validate(schema_dict)\n</code></pre>"},{"location":"api_reference/app/models/dataset_items/#pixano.app.models.dataset_items.DatasetItemModel.to_dataset_items","title":"<code>to_dataset_items(models, dataset_schema)</code>  <code>staticmethod</code>","text":"<p>Create a list of DatasetItems from a list of models.</p> <p>Parameters:</p> Name Type Description Default <code>models</code> <code>list[DatasetItemModel]</code> <p>The models to create the dataset items from.</p> required <code>dataset_schema</code> <code>DatasetSchema</code> <p>The schema of the dataset containing the dataset items.</p> required <p>Returns:</p> Type Description <code>list[DatasetItem]</code> <p>The list of created dataset items.</p> Source code in <code>pixano/app/models/dataset_items.py</code> <pre><code>@staticmethod\ndef to_dataset_items(models: list[\"DatasetItemModel\"], dataset_schema: DatasetSchema) -&gt; list[DatasetItem]:\n    \"\"\"Create a list of [DatasetItem][pixano.datasets.DatasetItem]s from a list of models.\n\n    Args:\n        models: The models to create the dataset items from.\n        dataset_schema: The schema of the dataset containing the dataset items.\n\n    Returns:\n        The list of created dataset items.\n    \"\"\"\n    return [model.to_dataset_item(dataset_schema) for model in models]\n</code></pre>"},{"location":"api_reference/app/models/datasets/","title":"datasets","text":""},{"location":"api_reference/app/models/datasets/#pixano.app.models.datasets","title":"<code>pixano.app.models.datasets</code>","text":""},{"location":"api_reference/app/models/datasets/#pixano.app.models.datasets.DatasetBrowser","title":"<code>DatasetBrowser(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Data for Dataset Browser page.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>dataset id</p> <code>name</code> <code>str</code> <p>dataset name</p> <code>table_data</code> <code>TableData</code> <p>table data</p> <code>pagination</code> <code>PaginationInfo</code> <p>pagination infos</p> <code>semantic_search</code> <code>list[str]</code> <p>list of semantic search available models</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            stacklevel=2,\n        )\n</code></pre>"},{"location":"api_reference/app/models/datasets/#pixano.app.models.datasets.DatasetModel","title":"<code>DatasetModel(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The model of a dataset.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Dataset ID.</p> <code>path</code> <code>Path</code> <p>Path to the dataset.</p> <code>previews_path</code> <code>Path</code> <p>Path to the previews.</p> <code>media_dir</code> <code>Path</code> <p>Path to the media directory.</p> <code>thumbnail</code> <code>Path</code> <p>Path to the thumbnail.</p> <code>dataset_schema</code> <code>DatasetSchema</code> <p>The dataset schema.</p> <code>feature_values</code> <code>DatasetFeaturesValues</code> <p>The feature values of the dataset.</p> <code>info</code> <code>DatasetInfoModel</code> <p>The dataset info.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            stacklevel=2,\n        )\n</code></pre>"},{"location":"api_reference/app/models/datasets/#pixano.app.models.datasets.DatasetModel.from_dataset","title":"<code>from_dataset(dataset)</code>  <code>classmethod</code>","text":"<p>Create a dataset model from a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The dataset.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The dataset model.</p> Source code in <code>pixano/app/models/datasets.py</code> <pre><code>@classmethod\ndef from_dataset(cls, dataset: Dataset) -&gt; Self:\n    \"\"\"Create a dataset model from a dataset.\n\n    Args:\n        dataset: The dataset.\n\n    Returns:\n        The dataset model.\n    \"\"\"\n    info = DatasetInfoModel.from_dataset_info(dataset.info, dataset.path)\n    return cls(\n        id=dataset.info.id,\n        path=dataset.path,\n        previews_path=dataset.previews_path,\n        media_dir=dataset.media_dir,\n        thumbnail=dataset.thumbnail,\n        dataset_schema=dataset.schema,\n        feature_values=dataset.features_values,\n        info=info,\n    )\n</code></pre>"},{"location":"api_reference/app/models/datasets/#pixano.app.models.datasets.DatasetModel.from_json","title":"<code>from_json(data)</code>  <code>classmethod</code>","text":"<p>Create a dataset model from a JSON object.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[str, Any]</code> <p>JSON object.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>Dataset model.</p> Source code in <code>pixano/app/models/datasets.py</code> <pre><code>@classmethod\ndef from_json(cls, data: dict[str, Any]) -&gt; Self:\n    \"\"\"Create a dataset model from a JSON object.\n\n    Args:\n        data: JSON object.\n\n    Returns:\n        Dataset model.\n    \"\"\"\n    return cls(\n        id=data[\"id\"],\n        path=Path(data[\"path\"]),\n        previews_path=Path(data[\"previews_path\"]),\n        media_dir=Path(data[\"media_dir\"]),\n        thumbnail=Path(data[\"thumbnail\"]),\n        dataset_schema=DatasetSchema.deserialize(data[\"dataset_schema\"]),\n        feature_values=DatasetFeaturesValues(**data[\"feature_values\"]),\n        info=DatasetInfoModel.from_dataset_info(DatasetInfo(**data[\"info\"]), Path(data[\"path\"])),\n    )\n</code></pre>"},{"location":"api_reference/app/models/datasets/#pixano.app.models.datasets.DatasetModel.to_dataset","title":"<code>to_dataset()</code>","text":"<p>Create a dataset from a dataset model.</p> Source code in <code>pixano/app/models/datasets.py</code> <pre><code>def to_dataset(self) -&gt; Dataset:\n    \"\"\"Create a dataset from a dataset model.\"\"\"\n    return Dataset(self.path, self.media_dir)\n</code></pre>"},{"location":"api_reference/app/models/datasets/#pixano.app.models.datasets.PaginationColumn","title":"<code>PaginationColumn(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Column description.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>column name.</p> <code>type</code> <code>str</code> <p>column type.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            stacklevel=2,\n        )\n</code></pre>"},{"location":"api_reference/app/models/datasets/#pixano.app.models.datasets.PaginationInfo","title":"<code>PaginationInfo(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Pagination info.</p> <p>Attributes:</p> Name Type Description <code>current_page</code> <code>int</code> <p>current page.</p> <code>page_size</code> <code>int</code> <p>number of items per page.</p> <code>total_size</code> <code>int</code> <p>total number of items.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            stacklevel=2,\n        )\n</code></pre>"},{"location":"api_reference/app/models/datasets/#pixano.app.models.datasets.TableData","title":"<code>TableData(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Table data.</p> <p>Attributes:</p> Name Type Description <code>columns</code> <code>list[PaginationColumn]</code> <p>column descriptions.</p> <code>rows</code> <code>list[dict[str, Any]]</code> <p>rows (actual data).</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            stacklevel=2,\n        )\n</code></pre>"},{"location":"api_reference/app/models/embeddings/","title":"embeddings","text":""},{"location":"api_reference/app/models/embeddings/#pixano.app.models.embeddings","title":"<code>pixano.app.models.embeddings</code>","text":""},{"location":"api_reference/app/models/embeddings/#pixano.app.models.embeddings.EmbeddingModel","title":"<code>EmbeddingModel(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>BaseSchemaModel[Embedding]</code></p> <p>Model for the Embedding schema.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/app/models/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/app/models/embeddings/#pixano.app.models.embeddings.EmbeddingModel.to_row","title":"<code>to_row(schema_type)</code>","text":"<p>Create an Embedding from the model.</p> Source code in <code>pixano/app/models/embeddings.py</code> <pre><code>def to_row(self, schema_type: type[T]) -&gt; T:\n    \"\"\"Create an [Embedding][pixano.features.Embedding] from the model.\"\"\"\n    if not issubclass(schema_type, Embedding):\n        raise ValueError(f\"Schema type must be a subclass of {Embedding.__name__}.\")\n    return super().to_row(schema_type)\n</code></pre>"},{"location":"api_reference/app/models/entities/","title":"entities","text":""},{"location":"api_reference/app/models/entities/#pixano.app.models.entities","title":"<code>pixano.app.models.entities</code>","text":""},{"location":"api_reference/app/models/entities/#pixano.app.models.entities.EntityModel","title":"<code>EntityModel(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>BaseSchemaModel[Entity]</code></p> <p>Model for the Entity schema.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/app/models/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/app/models/entities/#pixano.app.models.entities.EntityModel.to_row","title":"<code>to_row(schema_type)</code>","text":"<p>Create an Entity from the model.</p> Source code in <code>pixano/app/models/entities.py</code> <pre><code>def to_row(self, schema_type: type[T]) -&gt; T:\n    \"\"\"Create an [Entity][pixano.features.Entity] from the model.\"\"\"\n    if not issubclass(schema_type, Entity):\n        raise ValueError(f\"Schema type must be a subclass of {Entity.__name__}.\")\n    return super().to_row(schema_type)\n</code></pre>"},{"location":"api_reference/app/models/item_info/","title":"item_info","text":""},{"location":"api_reference/app/models/item_info/#pixano.app.models.item_info","title":"<code>pixano.app.models.item_info</code>","text":""},{"location":"api_reference/app/models/item_info/#pixano.app.models.item_info.ItemInfoModel","title":"<code>ItemInfoModel(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>ItemModel</code></p> <p>Item information.</p> <p>It contains all the information contained in an ItemModel and additional information about the dataset item such as the number of annotations, embeddings, entities and views.</p> <p>Attributes:</p> Name Type Description <code>infos</code> <p>Information about the dataset item. Structure: {info_name: {sub_info_name: {\"count\": int, ...}, ...}, ...}</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/app/models/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/app/models/items/","title":"items","text":""},{"location":"api_reference/app/models/items/#pixano.app.models.items","title":"<code>pixano.app.models.items</code>","text":""},{"location":"api_reference/app/models/items/#pixano.app.models.items.ItemModel","title":"<code>ItemModel(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>BaseSchemaModel[Item]</code></p> <p>Model for the Item schema.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/app/models/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/app/models/items/#pixano.app.models.items.ItemModel.to_row","title":"<code>to_row(schema_type)</code>","text":"<p>Create an Item from the model.</p> Source code in <code>pixano/app/models/items.py</code> <pre><code>def to_row(self, schema_type: type[T]) -&gt; T:\n    \"\"\"Create an [Item][pixano.features.Item] from the model.\"\"\"\n    if not issubclass(schema_type, Item):\n        raise ValueError(f\"Schema type must be a subclass of {Item.__name__}.\")\n    return super().to_row(schema_type)\n</code></pre>"},{"location":"api_reference/app/models/sources/","title":"sources","text":""},{"location":"api_reference/app/models/sources/#pixano.app.models.sources","title":"<code>pixano.app.models.sources</code>","text":""},{"location":"api_reference/app/models/sources/#pixano.app.models.sources.SourceModel","title":"<code>SourceModel(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>BaseSchemaModel[Source]</code></p> <p>Model for the Source schema.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/app/models/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/app/models/sources/#pixano.app.models.sources.SourceModel.to_row","title":"<code>to_row(schema_type)</code>","text":"<p>Create a Source from the model.</p> Source code in <code>pixano/app/models/sources.py</code> <pre><code>def to_row(self, schema_type: type[T]) -&gt; T:\n    \"\"\"Create a [Source][pixano.features.Source] from the model.\"\"\"\n    if not issubclass(schema_type, Source):\n        raise ValueError(f\"Schema type must be a subclass of {Source.__name__}.\")\n    return super().to_row(schema_type)\n</code></pre>"},{"location":"api_reference/app/models/table_info/","title":"table_info","text":""},{"location":"api_reference/app/models/table_info/#pixano.app.models.table_info","title":"<code>pixano.app.models.table_info</code>","text":""},{"location":"api_reference/app/models/table_info/#pixano.app.models.table_info.TableInfo","title":"<code>TableInfo(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The information of a table.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Table name.</p> <code>group</code> <code>str</code> <p>Group of the schema associated with the table.</p> <code>base_schema</code> <code>str</code> <p>Base Pixano schema stored in the registry.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            stacklevel=2,\n        )\n</code></pre>"},{"location":"api_reference/app/models/utils/","title":"utils","text":""},{"location":"api_reference/app/models/utils/#pixano.app.models.utils","title":"<code>pixano.app.models.utils</code>","text":""},{"location":"api_reference/app/models/views/","title":"views","text":""},{"location":"api_reference/app/models/views/#pixano.app.models.views","title":"<code>pixano.app.models.views</code>","text":""},{"location":"api_reference/app/models/views/#pixano.app.models.views.ViewModel","title":"<code>ViewModel(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>BaseSchemaModel[View]</code></p> <p>Model for the View schema.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/app/models/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/app/models/views/#pixano.app.models.views.ViewModel.to_row","title":"<code>to_row(schema_type)</code>","text":"<p>Create a View from the model.</p> Source code in <code>pixano/app/models/views.py</code> <pre><code>def to_row(self, schema_type: type[T]) -&gt; T:\n    \"\"\"Create a [View][pixano.features.View] from the model.\"\"\"\n    if not issubclass(schema_type, View):\n        raise ValueError(f\"Schema type must be a subclass of {View.__name__}.\")\n    return super().to_row(schema_type)\n</code></pre>"},{"location":"api_reference/app/routers/annotations/","title":"annotations","text":""},{"location":"api_reference/app/routers/annotations/#pixano.app.routers.annotations","title":"<code>pixano.app.routers.annotations</code>","text":""},{"location":"api_reference/app/routers/annotations/#pixano.app.routers.annotations.create_annotation","title":"<code>create_annotation(dataset_id, table, id, annotation, settings)</code>  <code>async</code>","text":"<p>Add an annotation in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the annotation.</p> required <code>annotation</code> <code>AnnotationModel</code> <p>Annotation to add.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>AnnotationModel</code> <p>The annotation added.</p> Source code in <code>pixano/app/routers/annotations.py</code> <pre><code>@router.post(\"/{dataset_id}/{table}/{id}\", response_model=AnnotationModel)\nasync def create_annotation(\n    dataset_id: str,\n    table: str,\n    id: str,\n    annotation: AnnotationModel,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; AnnotationModel:\n    \"\"\"Add an annotation in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the annotation.\n        annotation: Annotation to add.\n        settings: App settings.\n\n    Returns:\n        The annotation added.\n    \"\"\"\n    return await create_row_handler(dataset_id, SchemaGroup.ANNOTATION, table, id, annotation, settings)\n</code></pre>"},{"location":"api_reference/app/routers/annotations/#pixano.app.routers.annotations.create_annotations","title":"<code>create_annotations(dataset_id, table, annotations, settings)</code>  <code>async</code>","text":"<p>Add annotations in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>annotations</code> <code>list[AnnotationModel]</code> <p>Annotations to add.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[AnnotationModel]</code> <p>List of annotations added.</p> Source code in <code>pixano/app/routers/annotations.py</code> <pre><code>@router.post(\"/{dataset_id}/{table}/\", response_model=list[AnnotationModel])\nasync def create_annotations(\n    dataset_id: str,\n    table: str,\n    annotations: list[AnnotationModel],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[AnnotationModel]:\n    \"\"\"Add annotations in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        annotations: Annotations to add.\n        settings: App settings.\n\n    Returns:\n        List of annotations added.\n    \"\"\"\n    return await create_rows_handler(dataset_id, SchemaGroup.ANNOTATION, table, annotations, settings)\n</code></pre>"},{"location":"api_reference/app/routers/annotations/#pixano.app.routers.annotations.delete_annotation","title":"<code>delete_annotation(dataset_id, table, id, settings)</code>  <code>async</code>","text":"<p>Delete an annotation from a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the annotation to delete.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/annotations.py</code> <pre><code>@router.delete(\"/{dataset_id}/{table}/{id}\")\nasync def delete_annotation(\n    dataset_id: str, table: str, id: str, settings: Annotated[Settings, Depends(get_settings)]\n) -&gt; None:\n    \"\"\"Delete an annotation from a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the annotation to delete.\n        settings: App settings.\n    \"\"\"\n    return await delete_row_handler(dataset_id, SchemaGroup.ANNOTATION, table, id, settings)\n</code></pre>"},{"location":"api_reference/app/routers/annotations/#pixano.app.routers.annotations.delete_annotations","title":"<code>delete_annotations(dataset_id, table, ids, settings)</code>  <code>async</code>","text":"<p>Delete annotations from a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>ids</code> <code>Annotated[list[str], Query()]</code> <p>IDs of the annotations to delete.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/annotations.py</code> <pre><code>@router.delete(\"/{dataset_id}/{table}/\")\nasync def delete_annotations(\n    dataset_id: str,\n    table: str,\n    ids: Annotated[list[str], Query()],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; None:\n    \"\"\"Delete annotations from a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        ids: IDs of the annotations to delete.\n        settings: App settings.\n    \"\"\"\n    return await delete_rows_handler(dataset_id, SchemaGroup.ANNOTATION, table, ids, settings)\n</code></pre>"},{"location":"api_reference/app/routers/annotations/#pixano.app.routers.annotations.get_annotation","title":"<code>get_annotation(dataset_id, table, id, settings)</code>  <code>async</code>","text":"<p>Get an annotation from a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the annotation.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>AnnotationModel</code> <p>The annotation.</p> Source code in <code>pixano/app/routers/annotations.py</code> <pre><code>@router.get(\"/{dataset_id}/{table}/{id}\", response_model=AnnotationModel)\nasync def get_annotation(\n    dataset_id: str, table: str, id: str, settings: Annotated[Settings, Depends(get_settings)]\n) -&gt; AnnotationModel:\n    \"\"\"Get an annotation from a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the annotation.\n        settings: App settings.\n\n    Returns:\n        The annotation.\n    \"\"\"\n    return await get_row_handler(dataset_id, SchemaGroup.ANNOTATION, table, id, settings)\n</code></pre>"},{"location":"api_reference/app/routers/annotations/#pixano.app.routers.annotations.get_annotations","title":"<code>get_annotations(dataset_id, table, settings, ids=Query(None), limit=None, skip=0, where=None, item_ids=Query(None))</code>  <code>async</code>","text":"<p>Get annotations from a table of a dataset.</p> <p>They can be filtered by IDs, item IDs, a where clause or paginated.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <code>ids</code> <code>list[str] | None</code> <p>IDs of the annotations.</p> <code>Query(None)</code> <code>limit</code> <code>int | None</code> <p>Limit number of annotations.</p> <code>None</code> <code>skip</code> <code>int</code> <p>Skip number of annotations.</p> <code>0</code> <code>where</code> <code>str | None</code> <p>Where clause.</p> <code>None</code> <code>item_ids</code> <code>list[str] | None</code> <p>Item IDs.</p> <code>Query(None)</code> <p>Returns:</p> Type Description <code>list[AnnotationModel]</code> <p>List of annotations.</p> Source code in <code>pixano/app/routers/annotations.py</code> <pre><code>@router.get(\"/{dataset_id}/{table}/\", response_model=list[AnnotationModel])\nasync def get_annotations(\n    dataset_id: str,\n    table: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n    ids: list[str] | None = Query(None),\n    limit: int | None = None,\n    skip: int = 0,\n    where: str | None = None,\n    item_ids: list[str] | None = Query(None),\n) -&gt; list[AnnotationModel]:\n    \"\"\"Get annotations from a table of a dataset.\n\n    They can be filtered by IDs, item IDs, a where clause or paginated.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        settings: App settings.\n        ids: IDs of the annotations.\n        limit: Limit number of annotations.\n        skip: Skip number of annotations.\n        where: Where clause.\n        item_ids: Item IDs.\n\n    Returns:\n        List of annotations.\n    \"\"\"\n    return await get_rows_handler(\n        dataset_id=dataset_id,\n        group=SchemaGroup.ANNOTATION,\n        table=table,\n        settings=settings,\n        where=where,\n        ids=ids,\n        item_ids=item_ids,\n        limit=limit,\n        skip=skip,\n    )\n</code></pre>"},{"location":"api_reference/app/routers/annotations/#pixano.app.routers.annotations.update_annotation","title":"<code>update_annotation(dataset_id, table, id, annotation, settings)</code>  <code>async</code>","text":"<p>Update an annotation in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the annotation.</p> required <code>annotation</code> <code>AnnotationModel</code> <p>Annotation to update.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>AnnotationModel</code> <p>The annotation updated.</p> Source code in <code>pixano/app/routers/annotations.py</code> <pre><code>@router.put(\"/{dataset_id}/{table}/{id}\", response_model=AnnotationModel)\nasync def update_annotation(\n    dataset_id: str,\n    table: str,\n    id: str,\n    annotation: AnnotationModel,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; AnnotationModel:\n    \"\"\"Update an annotation in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the annotation.\n        annotation: Annotation to update.\n        settings: App settings.\n\n    Returns:\n        The annotation updated.\n    \"\"\"\n    return await update_row_handler(dataset_id, SchemaGroup.ANNOTATION, table, id, annotation, settings)\n</code></pre>"},{"location":"api_reference/app/routers/annotations/#pixano.app.routers.annotations.update_annotations","title":"<code>update_annotations(dataset_id, table, annotations, settings)</code>  <code>async</code>","text":"<p>Update annotations in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>annotations</code> <code>list[AnnotationModel]</code> <p>Annotations to update.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[AnnotationModel]</code> <p>List of annotations updated.</p> Source code in <code>pixano/app/routers/annotations.py</code> <pre><code>@router.put(\"/{dataset_id}/{table}/\", response_model=list[AnnotationModel])\nasync def update_annotations(\n    dataset_id: str,\n    table: str,\n    annotations: list[AnnotationModel],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[AnnotationModel]:\n    \"\"\"Update annotations in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        annotations: Annotations to update.\n        settings: App settings.\n\n    Returns:\n        List of annotations updated.\n    \"\"\"\n    return await update_rows_handler(dataset_id, SchemaGroup.ANNOTATION, table, annotations, settings)\n</code></pre>"},{"location":"api_reference/app/routers/browser/","title":"browser","text":""},{"location":"api_reference/app/routers/browser/#pixano.app.routers.browser","title":"<code>pixano.app.routers.browser</code>","text":""},{"location":"api_reference/app/routers/browser/#pixano.app.routers.browser.get_browser","title":"<code>get_browser(id, settings, limit=50, skip=0, query='', embedding_table='')</code>  <code>async</code>","text":"<p>Load dataset items for the explorer page.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Dataset ID containing the items.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <code>limit</code> <code>int</code> <p>Limit number of items.</p> <code>50</code> <code>skip</code> <code>int</code> <p>Skip number of items.</p> <code>0</code> <code>query</code> <code>str</code> <p>Text query for semantic search.</p> <code>''</code> <code>embedding_table</code> <code>str</code> <p>Table name for embeddings.</p> <code>''</code> <p>Returns:</p> Type Description <code>DatasetBrowser</code> <p>Dataset explorer page.</p> Source code in <code>pixano/app/routers/browser.py</code> <pre><code>@router.get(\"/{id}\", response_model=DatasetBrowser)\nasync def get_browser(\n    id: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n    limit: int = 50,\n    skip: int = 0,\n    query: str = \"\",\n    embedding_table: str = \"\",\n) -&gt; DatasetBrowser:  # type: ignore\n    \"\"\"Load dataset items for the explorer page.\n\n    Args:\n        id: Dataset ID containing the items.\n        settings: App settings.\n        limit: Limit number of items.\n        skip: Skip number of items.\n        query: Text query for semantic search.\n        embedding_table: Table name for embeddings.\n\n    Returns:\n        Dataset explorer page.\n    \"\"\"\n    # Load dataset\n    dataset = get_dataset(id, settings.library_dir, settings.media_dir)\n\n    semantic_search = embedding_table != \"\"\n    if query != \"\" or embedding_table != \"\":\n        if query == \"\" or embedding_table == \"\":\n            raise HTTPException(\n                status_code=400,\n                detail=\"Both query and model_name should be provided for semantic search.\",\n            )\n\n    # Get page parameters\n    total = dataset.num_rows\n    original_limit = limit\n    limit = min(limit, total)\n\n    # Get tables\n    table_item = SchemaGroup.ITEM.value\n    tables_view = sorted(dataset.schema.groups[SchemaGroup.VIEW])\n\n    # get data (items and views)\n    if semantic_search:\n        try:\n            item_rows, distances = dataset.semantic_search(query, embedding_table, limit, skip)\n        except DatasetAccessError as e:\n            raise HTTPException(status_code=400, detail=str(e))\n    else:\n        item_rows = get_rows(dataset=dataset, table=table_item, limit=limit, skip=skip)\n\n    item_ids = [item.id for item in item_rows]\n    item_first_media: dict[str, dict] = {}\n    for view in tables_view:\n        try:\n            view_rows = get_rows(dataset=dataset, table=view, item_ids=item_ids)\n        except HTTPException:\n            view_rows = []\n        item_first_media[view] = {}\n        for item_id in item_ids:\n            # store image or first frame\n            item_first_media[view][item_id] = next(filter(lambda v: v.item_ref.id == item_id, view_rows), None)\n\n    # build column headers (PaginationColumn)\n    cols = []\n    for view in tables_view:\n        view_type = \"image\"\n        # NOTE: right now for video we use a frame\n        # (first returned by get_rows for each item. May not be the real first frame)\n        # when we'll have thumbnail clip, use instead:\n        # view_type = \"video\" if isinstance(item_first_media[view][item_ids[0]], SequenceFrame) else \"image\"\n        cols.append(PaginationColumn(name=view, type=view_type))\n    for feat in vars(item_rows[0]).keys():\n        cols.append(PaginationColumn(name=feat, type=type(getattr(item_rows[0], feat)).__name__))\n    if semantic_search:\n        cols.append(PaginationColumn(name=\"distance\", type=\"float\"))\n\n    # build rows\n    rows: list[dict[str, Any]] = []\n    for i, item in enumerate(item_rows):\n        row: dict[str, Any] = {}\n        # VIEWS -&gt; thumbnails previews\n        for view in tables_view:\n            curr_view = item_first_media[view][item.id]\n            if curr_view is not None:\n                try:\n                    row_view = curr_view.open(settings.media_dir, output_type=\"image\")\n                    row_view = get_image_thumbnail(row_view, (128, 128))\n                    row_view_base64 = image_to_base64(row_view, curr_view.format)\n                except ValueError:\n                    row_view_base64 = \"\"\n\n                row[view] = row_view_base64\n\n        # ITEM features\n        for feat in vars(item).keys():\n            row[feat] = getattr(item, feat)\n        # DISTANCE\n        if semantic_search:\n            row[\"distance\"] = distances[i]\n\n        rows.append(row)\n\n    semantic_search_list = sorted(\n        [\n            table_name\n            for table_name in dataset.schema.groups[SchemaGroup.EMBEDDING]\n            if is_view_embedding(dataset.schema.schemas[table_name])\n        ]\n    )\n    # Return dataset items\n    return DatasetBrowser(\n        id=id,\n        name=dataset.info.name,\n        table_data=TableData(columns=cols, rows=rows),\n        pagination=PaginationInfo(current_page=skip, page_size=original_limit, total_size=total),\n        semantic_search=semantic_search_list,\n    )\n</code></pre>"},{"location":"api_reference/app/routers/dataset_items/","title":"dataset_items","text":""},{"location":"api_reference/app/routers/dataset_items/#pixano.app.routers.dataset_items","title":"<code>pixano.app.routers.dataset_items</code>","text":""},{"location":"api_reference/app/routers/dataset_items/#pixano.app.routers.dataset_items.create_dataset_item","title":"<code>create_dataset_item(dataset_id, id, dataset_item, settings)</code>  <code>async</code>","text":"<p>Add a dataset item.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID to add the item.</p> required <code>id</code> <code>str</code> <p>Dataset item ID to add.</p> required <code>dataset_item</code> <code>DatasetItemModel</code> <p>Dataset item.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>DatasetItemModel</code> <p>The dataset item added.</p> Source code in <code>pixano/app/routers/dataset_items.py</code> <pre><code>@router.post(\"/{dataset_id}/{id}\", response_model=DatasetItemModel)\nasync def create_dataset_item(\n    dataset_id: str,\n    id: str,\n    dataset_item: DatasetItemModel,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; DatasetItemModel:\n    \"\"\"Add a dataset item.\n\n    Args:\n        dataset_id: Dataset ID to add the item.\n        id: Dataset item ID to add.\n        dataset_item: Dataset item.\n        settings: App settings.\n\n    Returns:\n        The dataset item added.\n    \"\"\"\n    if id != dataset_item.id:\n        raise HTTPException(status_code=400, detail=\"ID in path and body do not match.\")\n\n    return (await create_dataset_items(dataset_id, [dataset_item], settings))[0]\n</code></pre>"},{"location":"api_reference/app/routers/dataset_items/#pixano.app.routers.dataset_items.create_dataset_items","title":"<code>create_dataset_items(dataset_id, dataset_items, settings)</code>  <code>async</code>","text":"<p>Add dataset items in a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID to add the items.</p> required <code>dataset_items</code> <code>list[DatasetItemModel]</code> <p>Dataset items to add.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[DatasetItemModel]</code> <p>List of dataset items added.</p> Source code in <code>pixano/app/routers/dataset_items.py</code> <pre><code>@router.post(\"/{dataset_id}/\", response_model=list[DatasetItemModel])\nasync def create_dataset_items(\n    dataset_id: str,\n    dataset_items: list[DatasetItemModel],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[DatasetItemModel]:\n    \"\"\"Add dataset items in a dataset.\n\n    Args:\n        dataset_id: Dataset ID to add the items.\n        dataset_items: Dataset items to add.\n        settings: App settings.\n\n    Returns:\n        List of dataset items added.\n    \"\"\"\n    dataset = get_dataset(dataset_id, settings.library_dir, None)\n\n    try:\n        rows = dataset.add_dataset_items(DatasetItemModel.to_dataset_items(dataset_items, dataset.schema))\n    except ValueError:\n        raise HTTPException(status_code=400, detail=\"Invalid dataset items\")\n    return DatasetItemModel.from_dataset_items(rows, dataset.schema)\n</code></pre>"},{"location":"api_reference/app/routers/dataset_items/#pixano.app.routers.dataset_items.delete_dataset_item","title":"<code>delete_dataset_item(dataset_id, id, settings)</code>  <code>async</code>","text":"<p>Delete a dataset item from a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the item.</p> required <code>id</code> <code>str</code> <p>ID of the dataset item to delete.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/dataset_items.py</code> <pre><code>@router.delete(\"/{dataset_id}/{id}\")\nasync def delete_dataset_item(dataset_id: str, id: str, settings: Annotated[Settings, Depends(get_settings)]) -&gt; None:\n    \"\"\"Delete a dataset item from a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the item.\n        id: ID of the dataset item to delete.\n        settings: App settings.\n    \"\"\"\n    return await delete_dataset_items(dataset_id, ids=[id], settings=settings)\n</code></pre>"},{"location":"api_reference/app/routers/dataset_items/#pixano.app.routers.dataset_items.delete_dataset_items","title":"<code>delete_dataset_items(dataset_id, ids, settings)</code>  <code>async</code>","text":"<p>Delete dataset items from a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the items.</p> required <code>ids</code> <code>Annotated[list[str], Query()]</code> <p>IDs of the dataset items to delete.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/dataset_items.py</code> <pre><code>@router.delete(\"/{dataset_id}/\")\nasync def delete_dataset_items(\n    dataset_id: str,\n    ids: Annotated[list[str], Query()],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; None:\n    \"\"\"Delete dataset items from a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the items.\n        ids: IDs of the dataset items to delete.\n        settings: App settings.\n    \"\"\"\n    dataset = get_dataset(dataset_id, settings.library_dir, None)\n\n    dataset.delete_dataset_items(ids)\n    return\n</code></pre>"},{"location":"api_reference/app/routers/dataset_items/#pixano.app.routers.dataset_items.get_dataset_item","title":"<code>get_dataset_item(dataset_id, id, settings)</code>  <code>async</code>","text":"<p>Get dataset item from a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID.</p> required <code>id</code> <code>str</code> <p>Dataset item ID.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>DatasetItemModel</code> <p>The dataset item.</p> Source code in <code>pixano/app/routers/dataset_items.py</code> <pre><code>@router.get(\"/{dataset_id}/{id}\", response_model=DatasetItemModel)\nasync def get_dataset_item(\n    dataset_id: str, id: str, settings: Annotated[Settings, Depends(get_settings)]\n) -&gt; DatasetItemModel:\n    \"\"\"Get dataset item from a dataset.\n\n    Args:\n        dataset_id: Dataset ID.\n        id: Dataset item ID.\n        settings: App settings.\n\n    Returns:\n        The dataset item.\n    \"\"\"\n    return (await get_dataset_items(dataset_id, settings, ids=[id]))[0]\n</code></pre>"},{"location":"api_reference/app/routers/dataset_items/#pixano.app.routers.dataset_items.get_dataset_items","title":"<code>get_dataset_items(dataset_id, settings, ids=Query(None), limit=None, skip=0)</code>  <code>async</code>","text":"<p>Get dataset items from a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the items.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <code>ids</code> <code>list[str] | None</code> <p>IDs of the dataset items.</p> <code>Query(None)</code> <code>limit</code> <code>int | None</code> <p>Limit number of dataset items.</p> <code>None</code> <code>skip</code> <code>int</code> <p>Skip number of dataset items.</p> <code>0</code> <p>Returns:</p> Type Description <code>list[DatasetItemModel]</code> <p>List of dataset items.</p> Source code in <code>pixano/app/routers/dataset_items.py</code> <pre><code>@router.get(\"/{dataset_id}/\", response_model=list[DatasetItemModel])\nasync def get_dataset_items(\n    dataset_id: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n    ids: list[str] | None = Query(None),\n    limit: int | None = None,\n    skip: int = 0,\n) -&gt; list[DatasetItemModel]:\n    \"\"\"Get dataset items from a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the items.\n        settings: App settings.\n        ids: IDs of the dataset items.\n        limit: Limit number of dataset items.\n        skip: Skip number of dataset items.\n\n    Returns:\n        List of dataset items.\n    \"\"\"\n    dataset = get_dataset(dataset_id, settings.library_dir, None)\n\n    try:\n        rows = dataset.get_dataset_items(ids, limit, skip)\n    except DatasetPaginationError as err:\n        raise HTTPException(status_code=400, detail=\"Invalid query parameters. \" + str(err))\n    except DatasetAccessError as err:\n        raise HTTPException(status_code=500, detail=\"Insternal server error. \" + str(err))\n    if rows == []:\n        raise HTTPException(status_code=404, detail=\"Dataset items not found.\")\n\n    return DatasetItemModel.from_dataset_items(rows, dataset.schema)\n</code></pre>"},{"location":"api_reference/app/routers/dataset_items/#pixano.app.routers.dataset_items.update_dataset_item","title":"<code>update_dataset_item(dataset_id, id, dataset_item, settings)</code>  <code>async</code>","text":"<p>Update dataset item in a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the item.</p> required <code>id</code> <code>str</code> <p>Dataset item ID to update.</p> required <code>dataset_item</code> <code>DatasetItemModel</code> <p>Dataset item.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>DatasetItemModel</code> <p>The dataset item updated.</p> Source code in <code>pixano/app/routers/dataset_items.py</code> <pre><code>@router.put(\"/{dataset_id}/{id}\", response_model=DatasetItemModel)\nasync def update_dataset_item(\n    dataset_id: str,\n    id: str,\n    dataset_item: DatasetItemModel,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; DatasetItemModel:\n    \"\"\"Update dataset item in a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the item.\n        id: Dataset item ID to update.\n        dataset_item: Dataset item.\n        settings: App settings.\n\n    Returns:\n        The dataset item updated.\n    \"\"\"\n    if id != dataset_item.id:\n        raise HTTPException(status_code=400, detail=\"ID in path and body do not match.\")\n\n    return (await update_dataset_items(dataset_id, [dataset_item], settings))[0]\n</code></pre>"},{"location":"api_reference/app/routers/dataset_items/#pixano.app.routers.dataset_items.update_dataset_items","title":"<code>update_dataset_items(dataset_id, dataset_items, settings)</code>  <code>async</code>","text":"<p>Update dataset items in a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the items.</p> required <code>dataset_items</code> <code>list[DatasetItemModel]</code> <p>Dataset items to update.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[DatasetItemModel]</code> <p>List of dataset items updated.</p> Source code in <code>pixano/app/routers/dataset_items.py</code> <pre><code>@router.put(\"/{dataset_id}/\", response_model=list[DatasetItemModel])\nasync def update_dataset_items(\n    dataset_id: str,\n    dataset_items: list[DatasetItemModel],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[DatasetItemModel]:\n    \"\"\"Update dataset items in a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the items.\n        dataset_items: Dataset items to update.\n        settings: App settings.\n\n    Returns:\n        List of dataset items updated.\n    \"\"\"\n    dataset = get_dataset(dataset_id, settings.library_dir, None)\n\n    try:\n        rows = dataset.update_dataset_items(DatasetItemModel.to_dataset_items(dataset_items, dataset.schema))\n    except ValueError:\n        raise HTTPException(status_code=400, detail=\"Invalid dataset items\")\n    return DatasetItemModel.from_dataset_items(rows, dataset.schema)\n</code></pre>"},{"location":"api_reference/app/routers/datasets/","title":"datasets","text":""},{"location":"api_reference/app/routers/datasets/#pixano.app.routers.datasets","title":"<code>pixano.app.routers.datasets</code>","text":""},{"location":"api_reference/app/routers/datasets/#pixano.app.routers.datasets.get_dataset","title":"<code>get_dataset(id, settings)</code>  <code>async</code>","text":"<p>Load dataset from ID.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Dataset ID to load.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>DatasetModel</code> <p>Dataset model.</p> Source code in <code>pixano/app/routers/datasets.py</code> <pre><code>@router.get(\"/{id}\", response_model=DatasetModel)\nasync def get_dataset(\n    id: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; DatasetModel:\n    \"\"\"Load dataset from ID.\n\n    Args:\n        id: Dataset ID to load.\n        settings: App settings.\n\n    Returns:\n        Dataset model.\n    \"\"\"\n    return DatasetModel.from_dataset(get_dataset_utils(id, settings.library_dir, settings.media_dir))\n</code></pre>"},{"location":"api_reference/app/routers/datasets/#pixano.app.routers.datasets.get_dataset_info","title":"<code>get_dataset_info(id, settings)</code>  <code>async</code>","text":"<p>Load a single dataset information.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Dataset ID to load info from.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>DatasetInfoModel</code> <p>The dataset info.</p> Source code in <code>pixano/app/routers/datasets.py</code> <pre><code>@router.get(\"/info/{id}\", response_model=DatasetInfoModel)\nasync def get_dataset_info(\n    id: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; DatasetInfoModel:\n    \"\"\"Load a single dataset information.\n\n    Args:\n        id: Dataset ID to load info from.\n        settings: App settings.\n\n    Returns:\n        The dataset info.\n    \"\"\"\n    try:\n        info, path = DatasetInfo.load_id(id, settings.library_dir, return_path=True)\n    except FileNotFoundError:\n        raise HTTPException(\n            status_code=404,\n            detail=f\"Dataset {id} not found in {settings.library_dir.absolute()}.\",\n        )\n\n    return DatasetInfoModel.from_dataset_info(info, path)\n</code></pre>"},{"location":"api_reference/app/routers/datasets/#pixano.app.routers.datasets.get_datasets_info","title":"<code>get_datasets_info(settings)</code>  <code>async</code>","text":"<p>Load a list of dataset information.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[DatasetInfoModel]</code> <p>List of dataset info.</p> Source code in <code>pixano/app/routers/datasets.py</code> <pre><code>@router.get(\"/info\", response_model=list[DatasetInfoModel])\nasync def get_datasets_info(\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[DatasetInfoModel]:\n    \"\"\"Load a list of dataset information.\n\n    Args:\n        settings: App settings.\n\n    Returns:\n        List of dataset info.\n    \"\"\"\n    try:\n        infos_and_paths: list[tuple[DatasetInfo, Path]] = DatasetInfo.load_directory(\n            directory=settings.library_dir, return_path=True\n        )\n    except FileNotFoundError:\n        raise HTTPException(\n            status_code=404,\n            detail=f\"No datasets found in {settings.library_dir.absolute()}.\",\n        )\n\n    if len(infos_and_paths) &gt; 0:\n        return [DatasetInfoModel.from_dataset_info(info, path) for info, path in infos_and_paths]\n    raise HTTPException(\n        status_code=404,\n        detail=f\"No datasets found in {settings.library_dir.absolute()}.\",\n    )\n</code></pre>"},{"location":"api_reference/app/routers/datasets/#pixano.app.routers.datasets.get_table_count","title":"<code>get_table_count(id, table, settings)</code>  <code>async</code>","text":"<p>Get the number of rows in a table.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The number of rows in the table.</p> Source code in <code>pixano/app/routers/datasets.py</code> <pre><code>@router.get(\"/{id}/{table}/count\", response_model=int)\nasync def get_table_count(\n    id: str,\n    table: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; int:\n    \"\"\"Get the number of rows in a table.\n\n    Args:\n        id: Dataset ID containing the table.\n        table: Table name.\n        settings: App settings.\n\n    Returns:\n        The number of rows in the table.\n    \"\"\"\n    dataset = get_dataset_utils(id, settings.library_dir, settings.media_dir)\n    try:\n        db_table = dataset.open_table(table)\n    except DatasetAccessError as e:\n        raise HTTPException(\n            status_code=404,\n            detail=str(e),\n        )\n    return db_table.count_rows()\n</code></pre>"},{"location":"api_reference/app/routers/embeddings/","title":"embeddings","text":""},{"location":"api_reference/app/routers/embeddings/#pixano.app.routers.embeddings","title":"<code>pixano.app.routers.embeddings</code>","text":""},{"location":"api_reference/app/routers/embeddings/#pixano.app.routers.embeddings.create_embedding","title":"<code>create_embedding(dataset_id, table, id, embedding, settings)</code>  <code>async</code>","text":"<p>Update an embedding in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the embedding.</p> required <code>embedding</code> <code>EmbeddingModel</code> <p>Embedding to update.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>EmbeddingModel</code> <p>The embedding updated.</p> Source code in <code>pixano/app/routers/embeddings.py</code> <pre><code>@router.post(\"/{dataset_id}/{table}/{id}\", response_model=EmbeddingModel)\nasync def create_embedding(\n    dataset_id: str,\n    table: str,\n    id: str,\n    embedding: EmbeddingModel,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; EmbeddingModel:\n    \"\"\"Update an embedding in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the embedding.\n        embedding: Embedding to update.\n        settings: App settings.\n\n    Returns:\n        The embedding updated.\n    \"\"\"\n    return await create_row_handler(dataset_id, SchemaGroup.EMBEDDING, table, id, embedding, settings)\n</code></pre>"},{"location":"api_reference/app/routers/embeddings/#pixano.app.routers.embeddings.create_embeddings","title":"<code>create_embeddings(dataset_id, table, embeddings, settings)</code>  <code>async</code>","text":"<p>Add embeddings in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>embeddings</code> <code>list[EmbeddingModel]</code> <p>Embeddings to add.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[EmbeddingModel]</code> <p>List of embeddings added.</p> Source code in <code>pixano/app/routers/embeddings.py</code> <pre><code>@router.post(\"/{dataset_id}/{table}/\", response_model=list[EmbeddingModel])\nasync def create_embeddings(\n    dataset_id: str,\n    table: str,\n    embeddings: list[EmbeddingModel],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[EmbeddingModel]:\n    \"\"\"Add embeddings in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        embeddings: Embeddings to add.\n        settings: App settings.\n\n    Returns:\n        List of embeddings added.\n    \"\"\"\n    return await create_rows_handler(dataset_id, SchemaGroup.EMBEDDING, table, embeddings, settings)\n</code></pre>"},{"location":"api_reference/app/routers/embeddings/#pixano.app.routers.embeddings.delete_embedding","title":"<code>delete_embedding(dataset_id, table, id, settings)</code>  <code>async</code>","text":"<p>Delete an embedding from a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the embedding to delete.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/embeddings.py</code> <pre><code>@router.delete(\"/{dataset_id}/{table}/{id}\")\nasync def delete_embedding(\n    dataset_id: str, table: str, id: str, settings: Annotated[Settings, Depends(get_settings)]\n) -&gt; None:\n    \"\"\"Delete an embedding from a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the embedding to delete.\n        settings: App settings.\n    \"\"\"\n    return await delete_row_handler(dataset_id, SchemaGroup.EMBEDDING, table, id, settings)\n</code></pre>"},{"location":"api_reference/app/routers/embeddings/#pixano.app.routers.embeddings.delete_embeddings","title":"<code>delete_embeddings(dataset_id, table, ids, settings)</code>  <code>async</code>","text":"<p>Delete embeddings from a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>ids</code> <code>Annotated[list[str], Query()]</code> <p>IDs of the embeddings to delete.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/embeddings.py</code> <pre><code>@router.delete(\"/{dataset_id}/{table}/\")\nasync def delete_embeddings(\n    dataset_id: str,\n    table: str,\n    ids: Annotated[list[str], Query()],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; None:\n    \"\"\"Delete embeddings from a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        ids: IDs of the embeddings to delete.\n        settings: App settings.\n    \"\"\"\n    return await delete_rows_handler(dataset_id, SchemaGroup.EMBEDDING, table, ids, settings)\n</code></pre>"},{"location":"api_reference/app/routers/embeddings/#pixano.app.routers.embeddings.get_embedding","title":"<code>get_embedding(dataset_id, table, id, settings)</code>  <code>async</code>","text":"<p>Get an embedding from a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the embedding.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>EmbeddingModel</code> <p>The embedding.</p> Source code in <code>pixano/app/routers/embeddings.py</code> <pre><code>@router.get(\"/{dataset_id}/{table}/{id}\", response_model=EmbeddingModel)\nasync def get_embedding(\n    dataset_id: str, table: str, id: str, settings: Annotated[Settings, Depends(get_settings)]\n) -&gt; EmbeddingModel:\n    \"\"\"Get an embedding from a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the embedding.\n        settings: App settings.\n\n    Returns:\n        The embedding.\n    \"\"\"\n    return await get_row_handler(dataset_id, SchemaGroup.EMBEDDING, table, id, settings)\n</code></pre>"},{"location":"api_reference/app/routers/embeddings/#pixano.app.routers.embeddings.get_embeddings","title":"<code>get_embeddings(dataset_id, table, settings, ids=Query(None), limit=None, skip=0, where=None, item_ids=Query(None))</code>  <code>async</code>","text":"<p>Get embeddings from a table of a dataset.</p> <p>They can be filtered by IDs, item IDs, a where clause or paginated.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <code>ids</code> <code>list[str] | None</code> <p>IDs of the embeddings.</p> <code>Query(None)</code> <code>limit</code> <code>int | None</code> <p>Limit number of embeddings.</p> <code>None</code> <code>skip</code> <code>int</code> <p>Skip number of embeddings.</p> <code>0</code> <code>where</code> <code>str | None</code> <p>Where clause.</p> <code>None</code> <code>item_ids</code> <code>list[str] | None</code> <p>Item IDs.</p> <code>Query(None)</code> <p>Returns:</p> Type Description <code>list[EmbeddingModel]</code> <p>List of embeddings.</p> Source code in <code>pixano/app/routers/embeddings.py</code> <pre><code>@router.get(\"/{dataset_id}/{table}/\", response_model=list[EmbeddingModel])\nasync def get_embeddings(\n    dataset_id: str,\n    table: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n    ids: list[str] | None = Query(None),\n    limit: int | None = None,\n    skip: int = 0,\n    where: str | None = None,\n    item_ids: list[str] | None = Query(None),\n) -&gt; list[EmbeddingModel]:\n    \"\"\"Get embeddings from a table of a dataset.\n\n    They can be filtered by IDs, item IDs, a where clause or paginated.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        settings: App settings.\n        ids: IDs of the embeddings.\n        limit: Limit number of embeddings.\n        skip: Skip number of embeddings.\n        where: Where clause.\n        item_ids: Item IDs.\n\n    Returns:\n        List of embeddings.\n    \"\"\"\n    return await get_rows_handler(\n        dataset_id=dataset_id,\n        group=SchemaGroup.EMBEDDING,\n        table=table,\n        settings=settings,\n        where=where,\n        ids=ids,\n        item_ids=item_ids,\n        limit=limit,\n        skip=skip,\n    )\n</code></pre>"},{"location":"api_reference/app/routers/embeddings/#pixano.app.routers.embeddings.update_embedding","title":"<code>update_embedding(dataset_id, table, id, embedding, settings)</code>  <code>async</code>","text":"<p>Update an embedding in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the embedding.</p> required <code>embedding</code> <code>EmbeddingModel</code> <p>Embedding to update.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>EmbeddingModel</code> <p>The embedding updated.</p> Source code in <code>pixano/app/routers/embeddings.py</code> <pre><code>@router.put(\"/{dataset_id}/{table}/{id}\", response_model=EmbeddingModel)\nasync def update_embedding(\n    dataset_id: str,\n    table: str,\n    id: str,\n    embedding: EmbeddingModel,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; EmbeddingModel:\n    \"\"\"Update an embedding in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the embedding.\n        embedding: Embedding to update.\n        settings: App settings.\n\n    Returns:\n        The embedding updated.\n    \"\"\"\n    return await update_row_handler(dataset_id, SchemaGroup.EMBEDDING, table, id, embedding, settings)\n</code></pre>"},{"location":"api_reference/app/routers/embeddings/#pixano.app.routers.embeddings.update_embeddings","title":"<code>update_embeddings(dataset_id, table, embeddings, settings)</code>  <code>async</code>","text":"<p>Update embeddings in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>embeddings</code> <code>list[EmbeddingModel]</code> <p>Embeddings to update.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[EmbeddingModel]</code> <p>List of embeddings updated.</p> Source code in <code>pixano/app/routers/embeddings.py</code> <pre><code>@router.put(\"/{dataset_id}/{table}/\", response_model=list[EmbeddingModel])\nasync def update_embeddings(\n    dataset_id: str,\n    table: str,\n    embeddings: list[EmbeddingModel],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[EmbeddingModel]:\n    \"\"\"Update embeddings in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        embeddings: Embeddings to update.\n        settings: App settings.\n\n    Returns:\n        List of embeddings updated.\n    \"\"\"\n    return await update_rows_handler(dataset_id, SchemaGroup.EMBEDDING, table, embeddings, settings)\n</code></pre>"},{"location":"api_reference/app/routers/entities/","title":"entities","text":""},{"location":"api_reference/app/routers/entities/#pixano.app.routers.entities","title":"<code>pixano.app.routers.entities</code>","text":""},{"location":"api_reference/app/routers/entities/#pixano.app.routers.entities.create_entities","title":"<code>create_entities(dataset_id, table, entities, settings)</code>  <code>async</code>","text":"<p>Add entities in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>entities</code> <code>list[EntityModel]</code> <p>Entities to add.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[EntityModel]</code> <p>List of entities added.</p> Source code in <code>pixano/app/routers/entities.py</code> <pre><code>@router.post(\"/{dataset_id}/{table}/\", response_model=list[EntityModel])\nasync def create_entities(\n    dataset_id: str,\n    table: str,\n    entities: list[EntityModel],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[EntityModel]:\n    \"\"\"Add entities in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        entities: Entities to add.\n        settings: App settings.\n\n    Returns:\n        List of entities added.\n    \"\"\"\n    return await create_rows_handler(dataset_id, SchemaGroup.ENTITY, table, entities, settings)\n</code></pre>"},{"location":"api_reference/app/routers/entities/#pixano.app.routers.entities.create_entity","title":"<code>create_entity(dataset_id, table, id, entity, settings)</code>  <code>async</code>","text":"<p>Add an entity in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the entity.</p> required <code>entity</code> <code>EntityModel</code> <p>Entity to add.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>EntityModel</code> <p>The entity added.</p> Source code in <code>pixano/app/routers/entities.py</code> <pre><code>@router.post(\"/{dataset_id}/{table}/{id}\", response_model=EntityModel)\nasync def create_entity(\n    dataset_id: str,\n    table: str,\n    id: str,\n    entity: EntityModel,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; EntityModel:\n    \"\"\"Add an entity in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the entity.\n        entity: Entity to add.\n        settings: App settings.\n\n    Returns:\n        The entity added.\n    \"\"\"\n    return await create_row_handler(dataset_id, SchemaGroup.ENTITY, table, id, entity, settings)\n</code></pre>"},{"location":"api_reference/app/routers/entities/#pixano.app.routers.entities.delete_entities","title":"<code>delete_entities(dataset_id, table, ids, settings)</code>  <code>async</code>","text":"<p>Delete entities from a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>ids</code> <code>Annotated[list[str], Query()]</code> <p>IDs of the entities to delete.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/entities.py</code> <pre><code>@router.delete(\"/{dataset_id}/{table}/\")\nasync def delete_entities(\n    dataset_id: str,\n    table: str,\n    ids: Annotated[list[str], Query()],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; None:\n    \"\"\"Delete entities from a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        ids: IDs of the entities to delete.\n        settings: App settings.\n    \"\"\"\n    return await delete_rows_handler(dataset_id, SchemaGroup.ENTITY, table, ids, settings)\n</code></pre>"},{"location":"api_reference/app/routers/entities/#pixano.app.routers.entities.delete_entity","title":"<code>delete_entity(dataset_id, table, id, settings)</code>  <code>async</code>","text":"<p>Delete an entity from a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the entity to delete.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/entities.py</code> <pre><code>@router.delete(\"/{dataset_id}/{table}/{id}\")\nasync def delete_entity(\n    dataset_id: str, table: str, id: str, settings: Annotated[Settings, Depends(get_settings)]\n) -&gt; None:\n    \"\"\"Delete an entity from a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the entity to delete.\n        settings: App settings.\n    \"\"\"\n    return await delete_row_handler(dataset_id, SchemaGroup.ENTITY, table, id, settings)\n</code></pre>"},{"location":"api_reference/app/routers/entities/#pixano.app.routers.entities.get_entities","title":"<code>get_entities(dataset_id, table, settings, ids=Query(None), limit=None, skip=0, where=None, item_ids=Query(None))</code>  <code>async</code>","text":"<p>Get entities from a table of a dataset.</p> <p>They can be filtered by IDs, item IDs, a where clause or paginated.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <code>ids</code> <code>list[str] | None</code> <p>IDs of the views.</p> <code>Query(None)</code> <code>limit</code> <code>int | None</code> <p>Limit number of views.</p> <code>None</code> <code>skip</code> <code>int</code> <p>Skip number of views.</p> <code>0</code> <code>where</code> <code>str | None</code> <p>Where clause.</p> <code>None</code> <code>item_ids</code> <code>list[str] | None</code> <p>Item IDs.</p> <code>Query(None)</code> <p>Returns:</p> Type Description <code>list[EntityModel]</code> <p>List of views.</p> Source code in <code>pixano/app/routers/entities.py</code> <pre><code>@router.get(\"/{dataset_id}/{table}/\", response_model=list[EntityModel])\nasync def get_entities(\n    dataset_id: str,\n    table: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n    ids: list[str] | None = Query(None),\n    limit: int | None = None,\n    skip: int = 0,\n    where: str | None = None,\n    item_ids: list[str] | None = Query(None),\n) -&gt; list[EntityModel]:\n    \"\"\"Get entities from a table of a dataset.\n\n    They can be filtered by IDs, item IDs, a where clause or paginated.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        settings: App settings.\n        ids: IDs of the views.\n        limit: Limit number of views.\n        skip: Skip number of views.\n        where: Where clause.\n        item_ids: Item IDs.\n\n    Returns:\n        List of views.\n    \"\"\"\n    return await get_rows_handler(\n        dataset_id=dataset_id,\n        group=SchemaGroup.ENTITY,\n        table=table,\n        settings=settings,\n        where=where,\n        ids=ids,\n        item_ids=item_ids,\n        limit=limit,\n        skip=skip,\n    )\n</code></pre>"},{"location":"api_reference/app/routers/entities/#pixano.app.routers.entities.get_entity","title":"<code>get_entity(dataset_id, table, id, settings)</code>  <code>async</code>","text":"<p>Get an entity from a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the entity.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>EntityModel</code> <p>The entity.</p> Source code in <code>pixano/app/routers/entities.py</code> <pre><code>@router.get(\"/{dataset_id}/{table}/{id}\", response_model=EntityModel)\nasync def get_entity(\n    dataset_id: str, table: str, id: str, settings: Annotated[Settings, Depends(get_settings)]\n) -&gt; EntityModel:\n    \"\"\"Get an entity from a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the entity.\n        settings: App settings.\n\n    Returns:\n        The entity.\n    \"\"\"\n    return await get_row_handler(dataset_id, SchemaGroup.ENTITY, table, id, settings)\n</code></pre>"},{"location":"api_reference/app/routers/entities/#pixano.app.routers.entities.update_entities","title":"<code>update_entities(dataset_id, table, entities, settings)</code>  <code>async</code>","text":"<p>Update entities in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>entities</code> <code>list[EntityModel]</code> <p>Entities to update.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[EntityModel]</code> <p>List of entities updated.</p> Source code in <code>pixano/app/routers/entities.py</code> <pre><code>@router.put(\"/{dataset_id}/{table}/\", response_model=list[EntityModel])\nasync def update_entities(\n    dataset_id: str,\n    table: str,\n    entities: list[EntityModel],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[EntityModel]:\n    \"\"\"Update entities in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        entities: Entities to update.\n        settings: App settings.\n\n    Returns:\n        List of entities updated.\n    \"\"\"\n    return await update_rows_handler(dataset_id, SchemaGroup.ENTITY, table, entities, settings)\n</code></pre>"},{"location":"api_reference/app/routers/entities/#pixano.app.routers.entities.update_entity","title":"<code>update_entity(dataset_id, table, id, entity, settings)</code>  <code>async</code>","text":"<p>Update an entity in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the entity.</p> required <code>entity</code> <code>EntityModel</code> <p>Entity to update.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>EntityModel</code> <p>The entity updated.</p> Source code in <code>pixano/app/routers/entities.py</code> <pre><code>@router.put(\"/{dataset_id}/{table}/{id}\", response_model=EntityModel)\nasync def update_entity(\n    dataset_id: str,\n    table: str,\n    id: str,\n    entity: EntityModel,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; EntityModel:\n    \"\"\"Update an entity in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the entity.\n        entity: Entity to update.\n        settings: App settings.\n\n    Returns:\n        The entity updated.\n    \"\"\"\n    return await update_row_handler(dataset_id, SchemaGroup.ENTITY, table, id, entity, settings)\n</code></pre>"},{"location":"api_reference/app/routers/items/","title":"items","text":""},{"location":"api_reference/app/routers/items/#pixano.app.routers.items","title":"<code>pixano.app.routers.items</code>","text":""},{"location":"api_reference/app/routers/items/#pixano.app.routers.items.create_item","title":"<code>create_item(dataset_id, id, item, settings)</code>  <code>async</code>","text":"<p>Add an item in the <code>'item'</code> table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>id</code> <code>str</code> <p>ID of the item.</p> required <code>item</code> <code>ItemModel</code> <p>Item to add.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>ItemModel</code> <p>The item added.</p> Source code in <code>pixano/app/routers/items.py</code> <pre><code>@router.post(\"/{dataset_id}/{id}\", response_model=ItemModel)\nasync def create_item(\n    dataset_id: str,\n    id: str,\n    item: ItemModel,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; ItemModel:\n    \"\"\"Add an item in the `'item'` table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        id: ID of the item.\n        item: Item to add.\n        settings: App settings.\n\n    Returns:\n        The item added.\n    \"\"\"\n    return await create_row_handler(dataset_id, SchemaGroup.ITEM, SchemaGroup.ITEM.value, id, item, settings)\n</code></pre>"},{"location":"api_reference/app/routers/items/#pixano.app.routers.items.create_items","title":"<code>create_items(dataset_id, items, settings)</code>  <code>async</code>","text":"<p>Add items in the <code>'item'</code> table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>items</code> <code>list[ItemModel]</code> <p>Items to add.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[ItemModel]</code> <p>List of items added.</p> Source code in <code>pixano/app/routers/items.py</code> <pre><code>@router.post(\"/{dataset_id}/\", response_model=list[ItemModel])\nasync def create_items(\n    dataset_id: str,\n    items: list[ItemModel],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[ItemModel]:\n    \"\"\"Add items in the `'item'` table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        items: Items to add.\n        settings: App settings.\n\n    Returns:\n        List of items added.\n    \"\"\"\n    return await create_rows_handler(dataset_id, SchemaGroup.ITEM, SchemaGroup.ITEM.value, items, settings)\n</code></pre>"},{"location":"api_reference/app/routers/items/#pixano.app.routers.items.delete_item","title":"<code>delete_item(dataset_id, id, settings)</code>  <code>async</code>","text":"<p>Delete an item from the <code>'item'</code> table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>id</code> <code>str</code> <p>ID of the item to delete.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/items.py</code> <pre><code>@router.delete(\"/{dataset_id}/{id}\")\nasync def delete_item(dataset_id: str, id: str, settings: Annotated[Settings, Depends(get_settings)]) -&gt; None:\n    \"\"\"Delete an item from the `'item'` table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        id: ID of the item to delete.\n        settings: App settings.\n    \"\"\"\n    return await delete_row_handler(dataset_id, SchemaGroup.ITEM, SchemaGroup.ITEM.value, id, settings)\n</code></pre>"},{"location":"api_reference/app/routers/items/#pixano.app.routers.items.delete_items","title":"<code>delete_items(dataset_id, ids, settings)</code>  <code>async</code>","text":"<p>Delete items from the <code>'item'</code> table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>ids</code> <code>Annotated[list[str], Query()]</code> <p>IDs of the items to delete.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/items.py</code> <pre><code>@router.delete(\"/{dataset_id}/\")\nasync def delete_items(\n    dataset_id: str,\n    ids: Annotated[list[str], Query()],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; None:\n    \"\"\"Delete items from the `'item'` table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        ids: IDs of the items to delete.\n        settings: App settings.\n    \"\"\"\n    return await delete_rows_handler(dataset_id, SchemaGroup.ITEM, SchemaGroup.ITEM.value, ids, settings)\n</code></pre>"},{"location":"api_reference/app/routers/items/#pixano.app.routers.items.get_item","title":"<code>get_item(dataset_id, id, settings)</code>  <code>async</code>","text":"<p>Get an item from the <code>'item'</code> table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>id</code> <code>str</code> <p>ID of the item.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>ItemModel</code> <p>The item.</p> Source code in <code>pixano/app/routers/items.py</code> <pre><code>@router.get(\"/{dataset_id}/{id}\", response_model=ItemModel)\nasync def get_item(dataset_id: str, id: str, settings: Annotated[Settings, Depends(get_settings)]) -&gt; ItemModel:\n    \"\"\"Get an item from the `'item'` table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        id: ID of the item.\n        settings: App settings.\n\n    Returns:\n        The item.\n    \"\"\"\n    return await get_row_handler(dataset_id, SchemaGroup.ITEM, SchemaGroup.ITEM.value, id, settings)\n</code></pre>"},{"location":"api_reference/app/routers/items/#pixano.app.routers.items.get_items","title":"<code>get_items(dataset_id, settings, ids=Query(None), limit=None, skip=0, where=None)</code>  <code>async</code>","text":"<p>Get sources from the <code>'item'</code> table of a dataset.</p> <p>They can be filtered by IDs, a where clause or paginated.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <code>ids</code> <code>list[str] | None</code> <p>IDs of the sources.</p> <code>Query(None)</code> <code>limit</code> <code>int | None</code> <p>Limit number of sources.</p> <code>None</code> <code>skip</code> <code>int</code> <p>Skip number of sources.</p> <code>0</code> <code>where</code> <code>str | None</code> <p>Where clause.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[ItemModel]</code> <p>List of sources.</p> Source code in <code>pixano/app/routers/items.py</code> <pre><code>@router.get(\"/{dataset_id}/\", response_model=list[ItemModel])\nasync def get_items(\n    dataset_id: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n    ids: list[str] | None = Query(None),\n    limit: int | None = None,\n    skip: int = 0,\n    where: str | None = None,\n) -&gt; list[ItemModel]:\n    \"\"\"Get sources from the `'item'` table of a dataset.\n\n    They can be filtered by IDs, a where clause or paginated.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        settings: App settings.\n        ids: IDs of the sources.\n        limit: Limit number of sources.\n        skip: Skip number of sources.\n        where: Where clause.\n\n    Returns:\n        List of sources.\n    \"\"\"\n    return await get_rows_handler(\n        dataset_id=dataset_id,\n        group=SchemaGroup.ITEM,\n        table=SchemaGroup.ITEM.value,\n        settings=settings,\n        where=where,\n        ids=ids,\n        item_ids=None,\n        limit=limit,\n        skip=skip,\n    )\n</code></pre>"},{"location":"api_reference/app/routers/items/#pixano.app.routers.items.update_item","title":"<code>update_item(dataset_id, id, item, settings)</code>  <code>async</code>","text":"<p>Update an item in the <code>'item'</code> table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>id</code> <code>str</code> <p>ID of the item.</p> required <code>item</code> <code>ItemModel</code> <p>Item to update.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>ItemModel</code> <p>The item updated.</p> Source code in <code>pixano/app/routers/items.py</code> <pre><code>@router.put(\"/{dataset_id}/{id}\", response_model=ItemModel)\nasync def update_item(\n    dataset_id: str,\n    id: str,\n    item: ItemModel,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; ItemModel:\n    \"\"\"Update an item in the `'item'` table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        id: ID of the item.\n        item: Item to update.\n        settings: App settings.\n\n    Returns:\n        The item updated.\n    \"\"\"\n    return await update_row_handler(dataset_id, SchemaGroup.ITEM, SchemaGroup.ITEM.value, id, item, settings)\n</code></pre>"},{"location":"api_reference/app/routers/items/#pixano.app.routers.items.update_items","title":"<code>update_items(dataset_id, items, settings)</code>  <code>async</code>","text":"<p>Update items in the <code>'item'</code> table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>items</code> <code>list[ItemModel]</code> <p>Items to update.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[ItemModel]</code> <p>List of items updated.</p> Source code in <code>pixano/app/routers/items.py</code> <pre><code>@router.put(\"/{dataset_id}/\", response_model=list[ItemModel])\nasync def update_items(\n    dataset_id: str,\n    items: list[ItemModel],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[ItemModel]:\n    \"\"\"Update items in the `'item'` table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        items: Items to update.\n        settings: App settings.\n\n    Returns:\n        List of items updated.\n    \"\"\"\n    return await update_rows_handler(dataset_id, SchemaGroup.ITEM, SchemaGroup.ITEM.value, items, settings)\n</code></pre>"},{"location":"api_reference/app/routers/items_info/","title":"items_info","text":""},{"location":"api_reference/app/routers/items_info/#pixano.app.routers.items_info","title":"<code>pixano.app.routers.items_info</code>","text":""},{"location":"api_reference/app/routers/items_info/#pixano.app.routers.items_info.get_item_info","title":"<code>get_item_info(dataset_id, id, settings)</code>  <code>async</code>","text":"<p>Get an item info.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID.</p> required <code>id</code> <code>str</code> <p>ID.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>ItemInfoModel</code> <p>The item info.</p> Source code in <code>pixano/app/routers/items_info.py</code> <pre><code>@router.get(\"/{dataset_id}/{id}\", response_model=ItemInfoModel)\nasync def get_item_info(\n    dataset_id: str, id: str, settings: Annotated[Settings, Depends(get_settings)]\n) -&gt; ItemInfoModel:\n    \"\"\"Get an item info.\n\n    Args:\n        dataset_id: Dataset ID.\n        id: ID.\n        settings: App settings.\n\n    Returns:\n        The item info.\n    \"\"\"\n    items_info = await get_items_info(dataset_id=dataset_id, settings=settings, ids=[id], limit=None, skip=0)\n\n    return items_info[0]\n</code></pre>"},{"location":"api_reference/app/routers/items_info/#pixano.app.routers.items_info.get_items_info","title":"<code>get_items_info(dataset_id, settings, where=None, ids=Query(None), limit=None, skip=0)</code>  <code>async</code>","text":"<p>Get items info.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <code>where</code> <code>str | None</code> <p>Where clause for the item table.</p> <code>None</code> <code>ids</code> <code>list[str] | None</code> <p>IDs.</p> <code>Query(None)</code> <code>limit</code> <code>int | None</code> <p>Limit number of items.</p> <code>None</code> <code>skip</code> <code>int</code> <p>Skip number of items.</p> <code>0</code> <p>Returns:</p> Type Description <code>list[ItemInfoModel]</code> <p>List of items info.</p> Source code in <code>pixano/app/routers/items_info.py</code> <pre><code>@router.get(\"/{dataset_id}/\", response_model=list[ItemInfoModel])\nasync def get_items_info(\n    dataset_id: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n    where: str | None = None,\n    ids: list[str] | None = Query(None),\n    limit: int | None = None,\n    skip: int = 0,\n) -&gt; list[ItemInfoModel]:\n    \"\"\"Get items info.\n\n    Args:\n        dataset_id: Dataset ID.\n        settings: App settings.\n        where: Where clause for the item table.\n        ids: IDs.\n        limit: Limit number of items.\n        skip: Skip number of items.\n\n    Returns:\n        List of items info.\n    \"\"\"\n    dataset = get_dataset(dataset_id, settings.library_dir, None)\n    assert_table_in_group(dataset, SchemaGroup.ITEM.value, SchemaGroup.ITEM)\n\n    try:\n        item_rows = get_rows(dataset, SchemaGroup.ITEM.value, where, ids, None, limit, skip)\n    except DatasetPaginationError as err:\n        raise HTTPException(status_code=400, detail=str(err))\n    except DatasetAccessError as err:\n        raise HTTPException(status_code=500, detail=str(err))\n\n    items_models = get_models_from_rows(SchemaGroup.ITEM.value, ItemModel, item_rows)\n    item_models_identified = {item.id: item for item in items_models}\n\n    set_ids = {item.id for item in items_models}\n    infos = {\n        id: {\n            group.value: {table: {\"count\": 0} for table in tables}\n            for group, tables in dataset.schema.groups.items()\n            if group.value not in [SchemaGroup.EMBEDDING.value, SchemaGroup.ITEM.value]\n        }\n        for id in set_ids\n    }\n\n    for table_name, table in dataset.open_tables().items():\n        group_name = dataset.schema.get_table_group(table_name).value\n        if group_name in [SchemaGroup.EMBEDDING.value, SchemaGroup.ITEM.value]:\n            continue\n        sql_ids = to_sql_list(set_ids)\n        df: pd.DataFrame = (\n            TableQueryBuilder(table).select([\"item_ref.id\"]).where(f\"item_ref.id in {sql_ids}\").to_pandas()\n        )\n        for id, count in df[\"item_ref.id\"].value_counts().to_dict().items():\n            infos[id][group_name][table_name] = {\"count\": count}\n\n    items_info = [ItemInfoModel(info=info, **item_models_identified[id].model_dump()) for id, info in infos.items()]\n\n    return items_info\n</code></pre>"},{"location":"api_reference/app/routers/models/","title":"models","text":""},{"location":"api_reference/app/routers/models/#pixano.app.routers.models","title":"<code>pixano.app.routers.models</code>","text":""},{"location":"api_reference/app/routers/models/#pixano.app.routers.models.get_model","title":"<code>get_model(model_name, settings)</code>  <code>async</code>","text":"<p>Get model file by name.</p> <p>The model file is expected to be in the models directory with the extension <code>.onnx</code>.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>Model name.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>FileResponse</code> <p>Model file.</p> Source code in <code>pixano/app/routers/models.py</code> <pre><code>@router.get(\"/{model_name}\", response_class=FileResponse)\nasync def get_model(\n    model_name: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; FileResponse:\n    \"\"\"Get model file by name.\n\n    The model file is expected to be in the models directory with the extension `.onnx`.\n\n    Args:\n        model_name: Model name.\n        settings: App settings.\n\n    Returns:\n        Model file.\n    \"\"\"\n    if settings.models_dir is None:\n        raise HTTPException(status_code=500, detail=\"Models directory not set\")\n    model_path = settings.models_dir / f\"{model_name}.onnx\"\n    if not model_path.exists():\n        raise HTTPException(status_code=404, detail=f\"Model {model_name} not found in {settings.models_dir}\")\n    return FileResponse(model_path)\n</code></pre>"},{"location":"api_reference/app/routers/models/#pixano.app.routers.models.get_models","title":"<code>get_models(settings)</code>  <code>async</code>","text":"<p>Get all models in the models directory with the extension <code>.onnx</code>.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List of models.</p> Source code in <code>pixano/app/routers/models.py</code> <pre><code>@router.get(\"/\", response_model=list[str])\nasync def get_models(\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[str]:\n    \"\"\"Get all models in the models directory with the extension `.onnx`.\n\n    Args:\n        settings: App settings.\n\n    Returns:\n        List of models.\n    \"\"\"\n    if settings.models_dir is None:\n        raise HTTPException(status_code=500, detail=\"Models directory not set\")\n    models = [file.stem for file in settings.models_dir.glob(\"*.onnx\")]\n    return models\n</code></pre>"},{"location":"api_reference/app/routers/sources/","title":"sources","text":""},{"location":"api_reference/app/routers/sources/#pixano.app.routers.sources","title":"<code>pixano.app.routers.sources</code>","text":""},{"location":"api_reference/app/routers/sources/#pixano.app.routers.sources.create_source","title":"<code>create_source(dataset_id, id, source, settings)</code>  <code>async</code>","text":"<p>Add a source in the <code>'source'</code> table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>id</code> <code>str</code> <p>ID of the source.</p> required <code>source</code> <code>SourceModel</code> <p>Source to add.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>SourceModel</code> <p>The source added.</p> Source code in <code>pixano/app/routers/sources.py</code> <pre><code>@router.post(\"/{dataset_id}/{id}\", response_model=SourceModel)\nasync def create_source(\n    dataset_id: str,\n    id: str,\n    source: SourceModel,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; SourceModel:\n    \"\"\"Add a source in the `'source'` table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        id: ID of the source.\n        source: Source to add.\n        settings: App settings.\n\n    Returns:\n        The source added.\n    \"\"\"\n    return await create_row_handler(dataset_id, SchemaGroup.SOURCE, SchemaGroup.SOURCE.value, id, source, settings)\n</code></pre>"},{"location":"api_reference/app/routers/sources/#pixano.app.routers.sources.create_sources","title":"<code>create_sources(dataset_id, sources, settings)</code>  <code>async</code>","text":"<p>Add sources in the <code>'source'</code> table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>sources</code> <code>list[SourceModel]</code> <p>Sources to add.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[SourceModel]</code> <p>List of sources added.</p> Source code in <code>pixano/app/routers/sources.py</code> <pre><code>@router.post(\"/{dataset_id}/\", response_model=list[SourceModel])\nasync def create_sources(\n    dataset_id: str,\n    sources: list[SourceModel],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[SourceModel]:\n    \"\"\"Add sources in the `'source'` table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        sources: Sources to add.\n        settings: App settings.\n\n    Returns:\n        List of sources added.\n    \"\"\"\n    return await create_rows_handler(dataset_id, SchemaGroup.SOURCE, SchemaGroup.SOURCE.value, sources, settings)\n</code></pre>"},{"location":"api_reference/app/routers/sources/#pixano.app.routers.sources.delete_source","title":"<code>delete_source(dataset_id, id, settings)</code>  <code>async</code>","text":"<p>Delete a source from the <code>'source'</code> table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>id</code> <code>str</code> <p>ID of the source to delete.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/sources.py</code> <pre><code>@router.delete(\"/{dataset_id}/{id}\")\nasync def delete_source(dataset_id: str, id: str, settings: Annotated[Settings, Depends(get_settings)]) -&gt; None:\n    \"\"\"Delete a source from the `'source'` table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        id: ID of the source to delete.\n        settings: App settings.\n    \"\"\"\n    return await delete_row_handler(dataset_id, SchemaGroup.SOURCE, SchemaGroup.SOURCE.value, id, settings)\n</code></pre>"},{"location":"api_reference/app/routers/sources/#pixano.app.routers.sources.delete_sources","title":"<code>delete_sources(dataset_id, ids, settings)</code>  <code>async</code>","text":"<p>Delete sources from the <code>'source'</code> table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>ids</code> <code>Annotated[list[str], Query()]</code> <p>IDs of the sources to delete.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/sources.py</code> <pre><code>@router.delete(\"/{dataset_id}/\")\nasync def delete_sources(\n    dataset_id: str,\n    ids: Annotated[list[str], Query()],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; None:\n    \"\"\"Delete sources from the `'source'` table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        ids: IDs of the sources to delete.\n        settings: App settings.\n    \"\"\"\n    return await delete_rows_handler(dataset_id, SchemaGroup.SOURCE, SchemaGroup.SOURCE.value, ids, settings)\n</code></pre>"},{"location":"api_reference/app/routers/sources/#pixano.app.routers.sources.get_source","title":"<code>get_source(dataset_id, id, settings)</code>  <code>async</code>","text":"<p>Get a source from the <code>'source'</code> table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>id</code> <code>str</code> <p>ID of the source.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>SourceModel</code> <p>The source.</p> Source code in <code>pixano/app/routers/sources.py</code> <pre><code>@router.get(\"/{dataset_id}/{id}\", response_model=SourceModel)\nasync def get_source(dataset_id: str, id: str, settings: Annotated[Settings, Depends(get_settings)]) -&gt; SourceModel:\n    \"\"\"Get a source from the `'source'` table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        id: ID of the source.\n        settings: App settings.\n\n    Returns:\n        The source.\n    \"\"\"\n    return await get_row_handler(dataset_id, SchemaGroup.SOURCE, SchemaGroup.SOURCE.value, id, settings)\n</code></pre>"},{"location":"api_reference/app/routers/sources/#pixano.app.routers.sources.get_sources","title":"<code>get_sources(dataset_id, settings, ids=Query(None), limit=None, skip=0, where=None)</code>  <code>async</code>","text":"<p>Get sources from the <code>'source'</code> table of a dataset.</p> <p>They can be filtered by IDs, a where clause or paginated.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <code>ids</code> <code>list[str] | None</code> <p>IDs of the sources.</p> <code>Query(None)</code> <code>limit</code> <code>int | None</code> <p>Limit number of sources.</p> <code>None</code> <code>skip</code> <code>int</code> <p>Skip number of sources.</p> <code>0</code> <code>where</code> <code>str | None</code> <p>Where clause.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[SourceModel]</code> <p>List of sources.</p> Source code in <code>pixano/app/routers/sources.py</code> <pre><code>@router.get(\"/{dataset_id}/\", response_model=list[SourceModel])\nasync def get_sources(\n    dataset_id: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n    ids: list[str] | None = Query(None),\n    limit: int | None = None,\n    skip: int = 0,\n    where: str | None = None,\n) -&gt; list[SourceModel]:\n    \"\"\"Get sources from the `'source'` table of a dataset.\n\n    They can be filtered by IDs, a where clause or paginated.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        settings: App settings.\n        ids: IDs of the sources.\n        limit: Limit number of sources.\n        skip: Skip number of sources.\n        where: Where clause.\n\n    Returns:\n        List of sources.\n    \"\"\"\n    return await get_rows_handler(\n        dataset_id=dataset_id,\n        group=SchemaGroup.SOURCE,\n        table=SchemaGroup.SOURCE.value,\n        settings=settings,\n        where=where,\n        ids=ids,\n        item_ids=None,\n        limit=limit,\n        skip=skip,\n    )\n</code></pre>"},{"location":"api_reference/app/routers/sources/#pixano.app.routers.sources.update_source","title":"<code>update_source(dataset_id, id, source, settings)</code>  <code>async</code>","text":"<p>Update a source in the <code>'source'</code> table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>id</code> <code>str</code> <p>ID of the source.</p> required <code>source</code> <code>SourceModel</code> <p>Source to update.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>SourceModel</code> <p>The source updated.</p> Source code in <code>pixano/app/routers/sources.py</code> <pre><code>@router.put(\"/{dataset_id}/{id}\", response_model=SourceModel)\nasync def update_source(\n    dataset_id: str,\n    id: str,\n    source: SourceModel,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; SourceModel:\n    \"\"\"Update a source in the `'source'` table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        id: ID of the source.\n        source: Source to update.\n        settings: App settings.\n\n    Returns:\n        The source updated.\n    \"\"\"\n    return await update_row_handler(dataset_id, SchemaGroup.SOURCE, SchemaGroup.SOURCE.value, id, source, settings)\n</code></pre>"},{"location":"api_reference/app/routers/sources/#pixano.app.routers.sources.update_sources","title":"<code>update_sources(dataset_id, sources, settings)</code>  <code>async</code>","text":"<p>Update sources in the <code>'source'</code> table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>sources</code> <code>list[SourceModel]</code> <p>Sources to update.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[SourceModel]</code> <p>List of sources updated.</p> Source code in <code>pixano/app/routers/sources.py</code> <pre><code>@router.put(\"/{dataset_id}/\", response_model=list[SourceModel])\nasync def update_sources(\n    dataset_id: str,\n    sources: list[SourceModel],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[SourceModel]:\n    \"\"\"Update sources in the `'source'` table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        sources: Sources to update.\n        settings: App settings.\n\n    Returns:\n        List of sources updated.\n    \"\"\"\n    return await update_rows_handler(dataset_id, SchemaGroup.SOURCE, SchemaGroup.SOURCE.value, sources, settings)\n</code></pre>"},{"location":"api_reference/app/routers/utils/","title":"utils","text":""},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils","title":"<code>pixano.app.routers.utils</code>","text":""},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.assert_table_in_group","title":"<code>assert_table_in_group(dataset, table, group)</code>","text":"<p>Assert that a table belongs to a group.</p> <p>If the table does not belong to the group, raise a 404 error.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>group</code> <code>SchemaGroup</code> <p>Group.</p> required Source code in <code>pixano/app/routers/utils.py</code> <pre><code>def assert_table_in_group(dataset: Dataset, table: str, group: SchemaGroup) -&gt; None:\n    \"\"\"Assert that a table belongs to a group.\n\n    If the table does not belong to the group, raise a 404 error.\n\n    Args:\n        dataset: Dataset.\n        table: Table name.\n        group: Group.\n    \"\"\"\n    if table in [SchemaGroup.ITEM.value, SchemaGroup.SOURCE.value]:\n        return\n    elif table not in dataset.schema.groups[group]:\n        raise HTTPException(\n            status_code=404,\n            detail=f\"Table {table} is not in the {group.value} group table.\",\n        )\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.create_row_handler","title":"<code>create_row_handler(dataset_id, group, table, id, row, settings)</code>  <code>async</code>","text":"<p>Add a row to a table.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>group</code> <code>SchemaGroup</code> <p>Schema group of the schema of the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the row.</p> required <code>row</code> <code>BaseSchemaModel</code> <p>Row to add.</p> required <code>settings</code> <code>Settings</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>BaseSchemaModel</code> <p>The added row.</p> Source code in <code>pixano/app/routers/utils.py</code> <pre><code>async def create_row_handler(\n    dataset_id: str,\n    group: SchemaGroup,\n    table: str,\n    id: str,\n    row: BaseSchemaModel,\n    settings: Settings,\n) -&gt; BaseSchemaModel:\n    \"\"\"Add a row to a table.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        group: Schema group of the schema of the table.\n        table: Table name.\n        id: ID of the row.\n        row: Row to add.\n        settings: App settings.\n\n    Returns:\n        The added row.\n    \"\"\"\n    if id != row.id:\n        raise HTTPException(status_code=400, detail=\"ID in path and body do not match.\")\n    return (await create_rows_handler(dataset_id=dataset_id, group=group, table=table, rows=[row], settings=settings))[\n        0\n    ]\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.create_rows","title":"<code>create_rows(dataset, table, models)</code>","text":"<p>Add rows to a table.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>models</code> <code>list[BaseSchemaModel]</code> <p>Models of the rows to add.</p> required <p>Returns:</p> Type Description <code>list[BaseSchema]</code> <p>The added rows.</p> Source code in <code>pixano/app/routers/utils.py</code> <pre><code>def create_rows(\n    dataset: Dataset,\n    table: str,\n    models: list[BaseSchemaModel],\n) -&gt; list[BaseSchema]:\n    \"\"\"Add rows to a table.\n\n    Args:\n        dataset: Dataset containing the table.\n        table: Table name.\n        models: Models of the rows to add.\n\n    Returns:\n        The added rows.\n    \"\"\"\n    try:\n        schema: type[BaseSchema] = dataset.schema.schemas[table] if table != SchemaGroup.SOURCE.value else Source\n        rows: list[BaseSchema] = BaseSchemaModel.to_rows(models, schema)\n    except Exception as err:\n        raise HTTPException(\n            status_code=400,\n            detail=\"Invalid data.\\n\" + str(err),\n        )\n\n    try:\n        created_rows = dataset.add_data(table, rows)\n    except DatasetIntegrityError as err:\n        raise HTTPException(status_code=400, detail=\"Dataset integrity compromised.\\n\" + str(err))\n    except ValueError as err:\n        raise HTTPException(\n            status_code=400,\n            detail=\"Invalid data.\\n\" + str(err),\n        )\n\n    return created_rows\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.create_rows_handler","title":"<code>create_rows_handler(dataset_id, group, table, rows, settings)</code>  <code>async</code>","text":"<p>Add rows to a table.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>group</code> <code>SchemaGroup</code> <p>Schema group of the schema of the table.</p> required <code>table</code> <code>str</code> <p>Table name containing the rows.</p> required <code>rows</code> <code>list[BaseSchemaModel]</code> <p>Rows to add.</p> required <code>settings</code> <code>Settings</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[BaseSchemaModel]</code> <p>List of updated rows.</p> Source code in <code>pixano/app/routers/utils.py</code> <pre><code>async def create_rows_handler(\n    dataset_id: str,\n    group: SchemaGroup,\n    table: str,\n    rows: list[BaseSchemaModel],\n    settings: Settings,\n) -&gt; list[BaseSchemaModel]:\n    \"\"\"Add rows to a table.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        group: Schema group of the schema of the table.\n        table: Table name containing the rows.\n        rows: Rows to add.\n        settings: App settings.\n\n    Returns:\n        List of updated rows.\n    \"\"\"\n    group = validate_group(group)\n    dataset = get_dataset(dataset_id, settings.library_dir, settings.media_dir)\n    assert_table_in_group(dataset, table, group)\n    rows_rows = create_rows(dataset, table, rows)\n    rows_models = get_models_from_rows(table, _SCHEMA_GROUP_TO_SCHEMA_MODEL_DICT[group], rows_rows)\n    return rows_models\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.delete_row_handler","title":"<code>delete_row_handler(dataset_id, group, table, id, settings)</code>  <code>async</code>","text":"<p>Delete a row from a table.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>group</code> <code>SchemaGroup</code> <p>Schema group of the schema of the table.</p> required <code>table</code> <code>str</code> <p>Table name containing the row.</p> required <code>id</code> <code>str</code> <p>ID of the row to delete.</p> required <code>settings</code> <code>Settings</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/utils.py</code> <pre><code>async def delete_row_handler(dataset_id: str, group: SchemaGroup, table: str, id: str, settings: Settings) -&gt; None:\n    \"\"\"Delete a row from a table.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        group: Schema group of the schema of the table.\n        table: Table name containing the row.\n        id: ID of the row to delete.\n        settings: App settings.\n    \"\"\"\n    return await delete_rows_handler(dataset_id, group, table, ids=[id], settings=settings)\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.delete_rows","title":"<code>delete_rows(dataset, table, ids)</code>","text":"<p>Delete rows from a table.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>ids</code> <code>list[str]</code> <p>IDs of the rows to delete.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>IDs not found.</p> Source code in <code>pixano/app/routers/utils.py</code> <pre><code>def delete_rows(\n    dataset: Dataset,\n    table: str,\n    ids: list[str],\n) -&gt; list[str]:\n    \"\"\"Delete rows from a table.\n\n    Args:\n        dataset: Dataset containing the table.\n        table: Table name.\n        ids: IDs of the rows to delete.\n\n    Returns:\n        IDs not found.\n    \"\"\"\n    try:\n        ids_not_found = dataset.delete_data(table, ids)\n    except ValueError:\n        raise HTTPException(\n            status_code=400,\n            detail=\"Invalid query parameters. ids and item_ids cannot be set at the same time\",\n        )\n    return ids_not_found\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.delete_rows_handler","title":"<code>delete_rows_handler(dataset_id, group, table, ids, settings)</code>  <code>async</code>","text":"<p>Delete rows from a table.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>group</code> <code>SchemaGroup</code> <p>Schema group of the schema of the table.</p> required <code>table</code> <code>str</code> <p>Table name containing the rows.</p> required <code>ids</code> <code>list[str]</code> <p>IDs of the rows to delete.</p> required <code>settings</code> <code>Settings</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/utils.py</code> <pre><code>async def delete_rows_handler(\n    dataset_id: str,\n    group: SchemaGroup,\n    table: str,\n    ids: list[str],\n    settings: Settings,\n) -&gt; None:\n    \"\"\"Delete rows from a table.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        group: Schema group of the schema of the table.\n        table: Table name containing the rows.\n        ids: IDs of the rows to delete.\n        settings: App settings.\n    \"\"\"\n    group = validate_group(group)\n    dataset = get_dataset(dataset_id, settings.library_dir, settings.media_dir)\n    assert_table_in_group(dataset, table, group)\n    delete_rows(dataset, table, ids)\n    return None\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.get_dataset","title":"<code>get_dataset(dataset_id, dir, media_dir=None)</code>","text":"<p>Get a dataset.</p> <p>If the dataset is not found, raise a 404 error.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID.</p> required <code>dir</code> <code>Path</code> <p>Directory containing the dataset.</p> required <code>media_dir</code> <code>Path | None</code> <p>Directory containing the media files.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>The dataset.</p> Source code in <code>pixano/app/routers/utils.py</code> <pre><code>def get_dataset(dataset_id: str, dir: Path, media_dir: Path | None = None) -&gt; Dataset:\n    \"\"\"Get a dataset.\n\n    If the dataset is not found, raise a 404 error.\n\n    Args:\n        dataset_id: Dataset ID.\n        dir: Directory containing the dataset.\n        media_dir: Directory containing the media files.\n\n    Returns:\n        The dataset.\n    \"\"\"\n    try:\n        dataset = Dataset.find(dataset_id, dir, media_dir)\n    except FileNotFoundError:\n        raise HTTPException(\n            status_code=404,\n            detail=f\"Dataset {dataset_id} not found in {dir.absolute()}.\",\n        )\n    return dataset\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.get_model_from_row","title":"<code>get_model_from_row(table, model_type, row)</code>","text":"<p>Get a model from a row.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table name containing the row.</p> required <code>model_type</code> <code>type[T]</code> <p>Model type to create.</p> required <code>row</code> <code>BaseSchema</code> <p>Row.</p> required <p>Returns:</p> Type Description <code>T</code> <p>The model.</p> Source code in <code>pixano/app/routers/utils.py</code> <pre><code>def get_model_from_row(table: str, model_type: type[T], row: BaseSchema) -&gt; T:\n    \"\"\"Get a model from a row.\n\n    Args:\n        table: Table name containing the row.\n        model_type: Model type to create.\n        row: Row.\n\n    Returns:\n        The model.\n    \"\"\"\n    try:\n        is_group = issubclass(model_type, BaseSchemaModel)\n        if not is_group:\n            raise HTTPException(status_code=500, detail=\"Model type is not a subclass of BaseModelSchema.\")\n    except TypeError:\n        raise HTTPException(status_code=500, detail=\"Model type is not a subclass of BaseModelSchema.\")\n    if issubclass(model_type, AnnotationModel):\n        group = SchemaGroup.ANNOTATION\n    elif issubclass(model_type, EmbeddingModel):\n        group = SchemaGroup.EMBEDDING\n    elif issubclass(model_type, EntityModel):\n        group = SchemaGroup.ENTITY\n    elif issubclass(model_type, ItemModel):\n        group = SchemaGroup.ITEM\n    elif issubclass(model_type, SourceModel):\n        group = SchemaGroup.SOURCE\n    elif issubclass(model_type, ViewModel):\n        group = SchemaGroup.VIEW\n    else:\n        raise HTTPException(\n            status_code=500,\n            detail=\"Model type not correct.\",\n        )\n\n    pixano_schema_type = get_super_type_from_dict(type(row), _PIXANO_SCHEMA_REGISTRY)\n\n    if pixano_schema_type is None:\n        raise HTTPException(\n            status_code=500,\n            detail=\"Schema type not found in registry.\",\n        )\n    table_info = TableInfo(name=table, group=group.value, base_schema=pixano_schema_type.__name__)\n    model = model_type.from_row(row, table_info)\n    return model\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.get_models_from_rows","title":"<code>get_models_from_rows(table, model_type, rows)</code>","text":"<p>Get models from rows.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table name containing the rows.</p> required <code>model_type</code> <code>type[T]</code> <p>Model type to create.</p> required <code>rows</code> <code>list[BaseSchema]</code> <p>Rows.</p> required <p>Returns:</p> Type Description <code>list[T]</code> <p>List of models.</p> Source code in <code>pixano/app/routers/utils.py</code> <pre><code>def get_models_from_rows(\n    table: str,\n    model_type: type[T],\n    rows: list[BaseSchema],\n) -&gt; list[T]:\n    \"\"\"Get models from rows.\n\n    Args:\n        table: Table name containing the rows.\n        model_type: Model type to create.\n        rows: Rows.\n\n    Returns:\n        List of models.\n    \"\"\"\n    return [get_model_from_row(table, model_type, row) for row in rows]\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.get_row_handler","title":"<code>get_row_handler(dataset_id, group, table, id, settings)</code>  <code>async</code>","text":"<p>Get a row model.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>group</code> <code>SchemaGroup</code> <p>Schema group of the schema of the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the row.</p> required <code>settings</code> <code>Settings</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>BaseSchemaModel</code> <p>The model.</p> Source code in <code>pixano/app/routers/utils.py</code> <pre><code>async def get_row_handler(\n    dataset_id: str, group: SchemaGroup, table: str, id: str, settings: Settings\n) -&gt; BaseSchemaModel:\n    \"\"\"Get a row model.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        group: Schema group of the schema of the table.\n        table: Table name.\n        id: ID of the row.\n        settings: App settings.\n\n    Returns:\n        The model.\n    \"\"\"\n    return (await get_rows_handler(dataset_id, group, table, settings, ids=[id], item_ids=None, limit=None, skip=0))[0]\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.get_rows","title":"<code>get_rows(dataset, table, where=None, ids=None, item_ids=None, limit=None, skip=0)</code>","text":"<p>Get rows from a table.</p> <p>The rows can be filtered by a where clause, IDs, item IDs or a limit and a skip.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>where</code> <code>str | None</code> <p>Where clause.</p> <code>None</code> <code>ids</code> <code>list[str] | None</code> <p>IDs of the rows.</p> <code>None</code> <code>item_ids</code> <code>list[str] | None</code> <p>Item IDs of the rows.</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Limit number of rows.</p> <code>None</code> <code>skip</code> <code>int</code> <p>Skip number of rows.</p> <code>0</code> <p>Returns:</p> Type Description <code>list[BaseSchema]</code> <p>List of rows.</p> Source code in <code>pixano/app/routers/utils.py</code> <pre><code>def get_rows(\n    dataset: Dataset,\n    table: str,\n    where: str | None = None,\n    ids: list[str] | None = None,\n    item_ids: list[str] | None = None,\n    limit: int | None = None,\n    skip: int = 0,\n) -&gt; list[BaseSchema]:\n    \"\"\"Get rows from a table.\n\n    The rows can be filtered by a where clause, IDs, item IDs or a limit and a skip.\n\n    Args:\n        dataset: Dataset containing the table.\n        table: Table name.\n        where: Where clause.\n        ids: IDs of the rows.\n        item_ids: Item IDs of the rows.\n        limit: Limit number of rows.\n        skip: Skip number of rows.\n\n    Returns:\n        List of rows.\n    \"\"\"\n    try:\n        rows = dataset.get_data(table_name=table, where=where, ids=ids, limit=limit, skip=skip, item_ids=item_ids)\n    except DatasetPaginationError as err:\n        raise HTTPException(status_code=400, detail=\"Invalid query parameters. \" + str(err))\n    except DatasetAccessError as err:\n        raise HTTPException(status_code=500, detail=\"Internal server error. \" + str(err))\n\n    if rows == [] or rows is None:\n        raise HTTPException(\n            status_code=404,\n            detail=f\"No rows found for {dataset.info.id}/{table}.\",\n        )\n    return rows\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.get_rows_handler","title":"<code>get_rows_handler(dataset_id, group, table, settings, where=None, ids=None, item_ids=None, limit=None, skip=0)</code>  <code>async</code>","text":"<p>Get row models.</p> <p>Rows can be filtered by a where clause, IDs, item IDs or a limit and a skip.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>group</code> <code>SchemaGroup</code> <p>Schema group of the schema of the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>settings</code> <code>Settings</code> <p>App settings.</p> required <code>where</code> <code>str | None</code> <p>Where clause.</p> <code>None</code> <code>ids</code> <code>list[str] | None</code> <p>IDs of the rows.</p> <code>None</code> <code>item_ids</code> <code>list[str] | None</code> <p>Item IDs of the rows.</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Limit number of rows.</p> <code>None</code> <code>skip</code> <code>int</code> <p>Skip number of rows.</p> <code>0</code> <p>Returns:</p> Type Description <code>list[BaseSchemaModel]</code> <p>List of models.</p> Source code in <code>pixano/app/routers/utils.py</code> <pre><code>async def get_rows_handler(\n    dataset_id: str,\n    group: SchemaGroup,\n    table: str,\n    settings: Settings,\n    where: str | None = None,\n    ids: list[str] | None = None,\n    item_ids: list[str] | None = None,\n    limit: int | None = None,\n    skip: int = 0,\n) -&gt; list[BaseSchemaModel]:\n    \"\"\"Get row models.\n\n    Rows can be filtered by a where clause, IDs, item IDs or a limit and a skip.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        group: Schema group of the schema of the table.\n        table: Table name.\n        settings: App settings.\n        where: Where clause.\n        ids: IDs of the rows.\n        item_ids: Item IDs of the rows.\n        limit: Limit number of rows.\n        skip: Skip number of rows.\n\n    Returns:\n        List of models.\n    \"\"\"\n    group = validate_group(group)\n    dataset = get_dataset(dataset_id, settings.library_dir, settings.media_dir)\n    assert_table_in_group(dataset, table, group)\n    rows = get_rows(dataset=dataset, table=table, where=where, ids=ids, item_ids=item_ids, limit=limit, skip=skip)\n    models = get_models_from_rows(table, _SCHEMA_GROUP_TO_SCHEMA_MODEL_DICT[group], rows)\n    return models\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.update_row_handler","title":"<code>update_row_handler(dataset_id, group, table, id, row, settings)</code>  <code>async</code>","text":"<p>Update a row in a table.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>group</code> <code>SchemaGroup</code> <p>Schema group of the schema of the table.</p> required <code>table</code> <code>str</code> <p>Table name containing the row.</p> required <code>id</code> <code>str</code> <p>ID of the row.</p> required <code>row</code> <code>BaseSchemaModel</code> <p>Row to update.</p> required <code>settings</code> <code>Settings</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>BaseSchemaModel</code> <p>The updated row.</p> Source code in <code>pixano/app/routers/utils.py</code> <pre><code>async def update_row_handler(\n    dataset_id: str,\n    group: SchemaGroup,\n    table: str,\n    id: str,\n    row: BaseSchemaModel,\n    settings: Settings,\n) -&gt; BaseSchemaModel:\n    \"\"\"Update a row in a table.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        group: Schema group of the schema of the table.\n        table: Table name containing the row.\n        id: ID of the row.\n        row: Row to update.\n        settings: App settings.\n\n    Returns:\n        The updated row.\n    \"\"\"\n    if id != row.id:\n        raise HTTPException(status_code=400, detail=\"ID in path and body do not match.\")\n    return (await update_rows_handler(dataset_id=dataset_id, group=group, table=table, rows=[row], settings=settings))[\n        0\n    ]\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.update_rows","title":"<code>update_rows(dataset, table, models)</code>","text":"<p>Update rows in a table.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>models</code> <code>list[BaseSchemaModel]</code> <p>Models of the rows to update.</p> required <p>Returns:</p> Type Description <code>list[BaseSchema]</code> <p>The updated rows.</p> Source code in <code>pixano/app/routers/utils.py</code> <pre><code>def update_rows(\n    dataset: Dataset,\n    table: str,\n    models: list[BaseSchemaModel],\n) -&gt; list[BaseSchema]:\n    \"\"\"Update rows in a table.\n\n    Args:\n        dataset: Dataset containing the table.\n        table: Table name.\n        models: Models of the rows to update.\n\n    Returns:\n        The updated rows.\n    \"\"\"\n    try:\n        schema: type[BaseSchema] = dataset.schema.schemas[table] if table != SchemaGroup.SOURCE.value else Source\n        rows: list[BaseSchema] = BaseSchemaModel.to_rows(models, schema)\n    except Exception as err:\n        raise HTTPException(\n            status_code=400,\n            detail=\"Invalid data.\\n\" + str(err),\n        )\n\n    try:\n        updated_rows = dataset.update_data(table, rows)\n    except DatasetIntegrityError as err:\n        raise HTTPException(status_code=400, detail=\"Dataset integrity compromised.\\n\" + str(err))\n    except ValueError as err:\n        raise HTTPException(\n            status_code=400,\n            detail=\"Invalid data.\\n\" + str(err),\n        )\n\n    # TODO: return updated rows instead of input rows\n    # TODO: check if rows are updated or created which change HTTP status code\n    return updated_rows\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.update_rows_handler","title":"<code>update_rows_handler(dataset_id, group, table, rows, settings)</code>  <code>async</code>","text":"<p>Update rows in a table.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>group</code> <code>SchemaGroup</code> <p>Schema group of the schema of the table.</p> required <code>table</code> <code>str</code> <p>Table name containing the rows.</p> required <code>rows</code> <code>list[BaseSchemaModel]</code> <p>Rows to update.</p> required <code>settings</code> <code>Settings</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[BaseSchemaModel]</code> <p>List of updated rows.</p> Source code in <code>pixano/app/routers/utils.py</code> <pre><code>async def update_rows_handler(\n    dataset_id: str,\n    group: SchemaGroup,\n    table: str,\n    rows: list[BaseSchemaModel],\n    settings: Settings,\n) -&gt; list[BaseSchemaModel]:\n    \"\"\"Update rows in a table.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        group: Schema group of the schema of the table.\n        table: Table name containing the rows.\n        rows: Rows to update.\n        settings: App settings.\n\n    Returns:\n        List of updated rows.\n    \"\"\"\n    group = validate_group(group)\n    dataset = get_dataset(dataset_id, settings.library_dir, settings.media_dir)\n    assert_table_in_group(dataset, table, group)\n    row_rows = update_rows(dataset, table, rows)\n    row_models = get_models_from_rows(table, _SCHEMA_GROUP_TO_SCHEMA_MODEL_DICT[group], row_rows)\n    return row_models\n</code></pre>"},{"location":"api_reference/app/routers/utils/#pixano.app.routers.utils.validate_group","title":"<code>validate_group(group, valid_groups=set(SchemaGroup))</code>","text":"<p>Assert that a group is valid.</p> <p>Parameters:</p> Name Type Description Default <code>group</code> <code>str | SchemaGroup</code> <p>Group.</p> required <code>valid_groups</code> <code>set[SchemaGroup]</code> <p>The valid groups.</p> <code>set(SchemaGroup)</code> Source code in <code>pixano/app/routers/utils.py</code> <pre><code>def validate_group(\n    group: str | SchemaGroup,\n    valid_groups: set[SchemaGroup] = set(SchemaGroup),\n) -&gt; SchemaGroup:\n    \"\"\"Assert that a group is valid.\n\n    Args:\n        group: Group.\n        valid_groups: The valid groups.\n    \"\"\"\n    try:\n        group = SchemaGroup(group)\n    except ValueError:\n        raise HTTPException(\n            status_code=400,\n            detail=f\"Group {group} is not a SchemaGroup.\",\n        )\n    if group not in valid_groups:\n        raise HTTPException(\n            status_code=400,\n            detail=f\"Group {group.value} is not valid.\",\n        )\n    return group\n</code></pre>"},{"location":"api_reference/app/routers/views/","title":"views","text":""},{"location":"api_reference/app/routers/views/#pixano.app.routers.views","title":"<code>pixano.app.routers.views</code>","text":""},{"location":"api_reference/app/routers/views/#pixano.app.routers.views.create_view","title":"<code>create_view(dataset_id, table, id, view, settings)</code>  <code>async</code>","text":"<p>Add an view in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the view.</p> required <code>view</code> <code>ViewModel</code> <p>View to add.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>ViewModel</code> <p>The view added.</p> Source code in <code>pixano/app/routers/views.py</code> <pre><code>@router.post(\"/{dataset_id}/{table}/{id}\", response_model=ViewModel)\nasync def create_view(\n    dataset_id: str,\n    table: str,\n    id: str,\n    view: ViewModel,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; ViewModel:\n    \"\"\"Add an view in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the view.\n        view: View to add.\n        settings: App settings.\n\n    Returns:\n        The view added.\n    \"\"\"\n    return await create_row_handler(dataset_id, SchemaGroup.VIEW, table, id, view, settings)\n</code></pre>"},{"location":"api_reference/app/routers/views/#pixano.app.routers.views.create_views","title":"<code>create_views(dataset_id, table, views, settings)</code>  <code>async</code>","text":"<p>Add views in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>views</code> <code>list[ViewModel]</code> <p>Views to add.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[ViewModel]</code> <p>List of views added.</p> Source code in <code>pixano/app/routers/views.py</code> <pre><code>@router.post(\"/{dataset_id}/{table}/\", response_model=list[ViewModel])\nasync def create_views(\n    dataset_id: str,\n    table: str,\n    views: list[ViewModel],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[ViewModel]:\n    \"\"\"Add views in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        views: Views to add.\n        settings: App settings.\n\n    Returns:\n        List of views added.\n    \"\"\"\n    return await create_rows_handler(dataset_id, SchemaGroup.VIEW, table, views, settings)\n</code></pre>"},{"location":"api_reference/app/routers/views/#pixano.app.routers.views.delete_view","title":"<code>delete_view(dataset_id, table, id, settings)</code>  <code>async</code>","text":"<p>Delete an view from a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the view to delete.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/views.py</code> <pre><code>@router.delete(\"/{dataset_id}/{table}/{id}\")\nasync def delete_view(\n    dataset_id: str, table: str, id: str, settings: Annotated[Settings, Depends(get_settings)]\n) -&gt; None:\n    \"\"\"Delete an view from a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the view to delete.\n        settings: App settings.\n    \"\"\"\n    return await delete_row_handler(dataset_id, SchemaGroup.VIEW, table, id, settings)\n</code></pre>"},{"location":"api_reference/app/routers/views/#pixano.app.routers.views.delete_views","title":"<code>delete_views(dataset_id, table, ids, settings)</code>  <code>async</code>","text":"<p>Delete views from a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>ids</code> <code>Annotated[list[str], Query()]</code> <p>IDs of the views to delete.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required Source code in <code>pixano/app/routers/views.py</code> <pre><code>@router.delete(\"/{dataset_id}/{table}/\")\nasync def delete_views(\n    dataset_id: str,\n    table: str,\n    ids: Annotated[list[str], Query()],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; None:\n    \"\"\"Delete views from a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        ids: IDs of the views to delete.\n        settings: App settings.\n    \"\"\"\n    return await delete_rows_handler(dataset_id, SchemaGroup.VIEW, table, ids, settings)\n</code></pre>"},{"location":"api_reference/app/routers/views/#pixano.app.routers.views.get_view","title":"<code>get_view(dataset_id, table, id, settings)</code>  <code>async</code>","text":"<p>Get an view from a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the view.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>ViewModel</code> <p>The view.</p> Source code in <code>pixano/app/routers/views.py</code> <pre><code>@router.get(\"/{dataset_id}/{table}/{id}\", response_model=ViewModel)\nasync def get_view(\n    dataset_id: str, table: str, id: str, settings: Annotated[Settings, Depends(get_settings)]\n) -&gt; ViewModel:\n    \"\"\"Get an view from a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the view.\n        settings: App settings.\n\n    Returns:\n        The view.\n    \"\"\"\n    return await get_row_handler(dataset_id, SchemaGroup.VIEW, table, id, settings)\n</code></pre>"},{"location":"api_reference/app/routers/views/#pixano.app.routers.views.get_views","title":"<code>get_views(dataset_id, table, settings, ids=Query(None), limit=None, skip=0, where=None, item_ids=Query(None))</code>  <code>async</code>","text":"<p>Get views from a table of a dataset.</p> <p>They can be filtered by IDs, item IDs, a where clause or paginated.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <code>ids</code> <code>list[str] | None</code> <p>IDs of the views.</p> <code>Query(None)</code> <code>limit</code> <code>int | None</code> <p>Limit number of views.</p> <code>None</code> <code>skip</code> <code>int</code> <p>Skip number of views.</p> <code>0</code> <code>where</code> <code>str | None</code> <p>Where clause.</p> <code>None</code> <code>item_ids</code> <code>list[str] | None</code> <p>Item IDs.</p> <code>Query(None)</code> <p>Returns:</p> Type Description <code>list[ViewModel]</code> <p>List of views.</p> Source code in <code>pixano/app/routers/views.py</code> <pre><code>@router.get(\"/{dataset_id}/{table}/\", response_model=list[ViewModel])\nasync def get_views(\n    dataset_id: str,\n    table: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n    ids: list[str] | None = Query(None),\n    limit: int | None = None,\n    skip: int = 0,\n    where: str | None = None,\n    item_ids: list[str] | None = Query(None),\n) -&gt; list[ViewModel]:\n    \"\"\"Get views from a table of a dataset.\n\n    They can be filtered by IDs, item IDs, a where clause or paginated.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        settings: App settings.\n        ids: IDs of the views.\n        limit: Limit number of views.\n        skip: Skip number of views.\n        where: Where clause.\n        item_ids: Item IDs.\n\n    Returns:\n        List of views.\n    \"\"\"\n    return await get_rows_handler(\n        dataset_id=dataset_id,\n        group=SchemaGroup.VIEW,\n        table=table,\n        settings=settings,\n        where=where,\n        ids=ids,\n        item_ids=item_ids,\n        limit=limit,\n        skip=skip,\n    )\n</code></pre>"},{"location":"api_reference/app/routers/views/#pixano.app.routers.views.update_view","title":"<code>update_view(dataset_id, table, id, view, settings)</code>  <code>async</code>","text":"<p>Update an view in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>id</code> <code>str</code> <p>ID of the view.</p> required <code>view</code> <code>ViewModel</code> <p>View to update.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>ViewModel</code> <p>The view updated.</p> Source code in <code>pixano/app/routers/views.py</code> <pre><code>@router.put(\"/{dataset_id}/{table}/{id}\", response_model=ViewModel)\nasync def update_view(\n    dataset_id: str,\n    table: str,\n    id: str,\n    view: ViewModel,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; ViewModel:\n    \"\"\"Update an view in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        id: ID of the view.\n        view: View to update.\n        settings: App settings.\n\n    Returns:\n        The view updated.\n    \"\"\"\n    return await update_row_handler(dataset_id, SchemaGroup.VIEW, table, id, view, settings)\n</code></pre>"},{"location":"api_reference/app/routers/views/#pixano.app.routers.views.update_views","title":"<code>update_views(dataset_id, table, views, settings)</code>  <code>async</code>","text":"<p>Update views in a table of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID containing the table.</p> required <code>table</code> <code>str</code> <p>Table name.</p> required <code>views</code> <code>list[ViewModel]</code> <p>Views to update.</p> required <code>settings</code> <code>Annotated[Settings, Depends(get_settings)]</code> <p>App settings.</p> required <p>Returns:</p> Type Description <code>list[ViewModel]</code> <p>List of views updated.</p> Source code in <code>pixano/app/routers/views.py</code> <pre><code>@router.put(\"/{dataset_id}/{table}/\", response_model=list[ViewModel])\nasync def update_views(\n    dataset_id: str,\n    table: str,\n    views: list[ViewModel],\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[ViewModel]:\n    \"\"\"Update views in a table of a dataset.\n\n    Args:\n        dataset_id: Dataset ID containing the table.\n        table: Table name.\n        views: Views to update.\n        settings: App settings.\n\n    Returns:\n        List of views updated.\n    \"\"\"\n    return await update_rows_handler(dataset_id, SchemaGroup.VIEW, table, views, settings)\n</code></pre>"},{"location":"api_reference/datasets/dataset/","title":"dataset","text":""},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset","title":"<code>pixano.datasets.dataset</code>","text":""},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset","title":"<code>Dataset(path, media_dir=None)</code>","text":"<p>The Pixano Dataset.</p> <p>It is a collection of tables that can be queried and manipulated with LanceDB.</p> <p>The tables are defined by the DatasetSchema which allows the dataset to return the data in the form of LanceModel instances.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>Path</code> <p>Path to the dataset.</p> <code>info</code> <code>DatasetInfo</code> <p>Dataset info.</p> <code>schema</code> <code>DatasetSchema</code> <p>Dataset schema.</p> <code>features_values</code> <code>DatasetFeaturesValues</code> <p>Dataset features values.</p> <code>stats</code> <code>list[DatasetStatistic]</code> <p>Dataset statistics.</p> <code>thumbnail</code> <code>Path</code> <p>Dataset thumbnail base 64 URL.</p> <code>media_dir</code> <code>Path</code> <p>Path to the media directory.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the dataset.</p> required <code>media_dir</code> <code>Path | None</code> <p>Path to the media directory.</p> <code>None</code> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def __init__(self, path: Path, media_dir: Path | None = None):\n    \"\"\"Initialize the dataset.\n\n    Args:\n        path: Path to the dataset.\n        media_dir: Path to the media directory.\n    \"\"\"\n    self.path = path\n\n    self._info_file = self.path / self._INFO_FILE\n    self._schema_file = self.path / self._SCHEMA_FILE\n    self._features_values_file = self.path / self._FEATURES_VALUES_FILE\n    self._stat_file = self.path / self._STAT_FILE\n    self._thumb_file = self.path / self._THUMB_FILE\n    self._db_path = self.path / self._DB_PATH\n\n    self.info = DatasetInfo.from_json(self._info_file)\n    self.features_values = DatasetFeaturesValues.from_json(self._features_values_file)\n    self.stats = DatasetStatistic.from_json(self._stat_file) if self._stat_file.is_file() else []\n    self.media_dir = media_dir or self.path / \"media\"\n    self.thumbnail = self._thumb_file\n    self.previews_path = self.path / self._PREVIEWS_PATH\n\n    self._db_connection = self._connect()\n\n    self._reload_schema()\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.id","title":"<code>id: str</code>  <code>property</code>","text":"<p>Return the dataset ID.</p>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.num_rows","title":"<code>num_rows: int</code>  <code>property</code>","text":"<p>Return the number of rows in the dataset.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of rows.</p>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.add_data","title":"<code>add_data(table_name, data, ignore_integrity_checks=None, raise_or_warn='raise')</code>","text":"<p>Add data to a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name.</p> required <code>data</code> <code>list[BaseSchema]</code> <p>Data to add.</p> required <code>ignore_integrity_checks</code> <code>list[IntegrityCheck] | None</code> <p>List of integrity checks to ignore.</p> <code>None</code> <code>raise_or_warn</code> <code>Literal['raise', 'warn', 'none']</code> <p>Whether to raise or warn on integrity errors. Can be 'raise', 'warn' or 'none'.</p> <code>'raise'</code> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def add_data(\n    self,\n    table_name: str,\n    data: list[BaseSchema],\n    ignore_integrity_checks: list[IntegrityCheck] | None = None,\n    raise_or_warn: Literal[\"raise\", \"warn\", \"none\"] = \"raise\",\n) -&gt; list[BaseSchema]:\n    \"\"\"Add data to a table.\n\n    Args:\n        table_name: Table name.\n        data: Data to add.\n        ignore_integrity_checks: List of integrity checks to ignore.\n        raise_or_warn: Whether to raise or warn on integrity errors. Can be 'raise', 'warn' or 'none'.\n    \"\"\"\n    if not all((isinstance(item, type(data[0])) for item in data)) or not set(\n        type(data[0]).model_fields.keys()\n    ) == set(\n        self.schema.schemas[table_name].model_fields.keys()\n        if table_name != SchemaGroup.SOURCE.value\n        else Source.model_fields.keys()\n    ):\n        raise DatasetAccessError(\n            \"All data must be instances of the table type \"\n            f\"{self.schema.schemas[table_name] if table_name != SchemaGroup.SOURCE.value else Source}.\"\n        )\n    _validate_raise_or_warn(raise_or_warn)\n\n    table = self.open_table(table_name)\n    if raise_or_warn != \"none\":\n        handle_integrity_errors(\n            check_table_integrity(table_name, self, data, False, ignore_integrity_checks), raise_or_warn\n        )\n    for d in data:\n        d.created_at = datetime.now()\n        d.updated_at = d.created_at\n    table.add(data)\n\n    return data\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.add_dataset_items","title":"<code>add_dataset_items(dataset_items)</code>","text":"<pre><code>add_dataset_items(dataset_items: DatasetItem) -&gt; DatasetItem\n</code></pre><pre><code>add_dataset_items(dataset_items: list[DatasetItem]) -&gt; list[DatasetItem]\n</code></pre> <p>Add dataset items to the dataset.</p> Warn <p>Does not test for integrity of the data.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_items</code> <code>list[DatasetItem] | DatasetItem</code> <p>Dataset items to add.</p> required Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def add_dataset_items(self, dataset_items: list[DatasetItem] | DatasetItem) -&gt; list[DatasetItem] | DatasetItem:\n    \"\"\"Add dataset items to the dataset.\n\n    Warn:\n        Does not test for integrity of the data.\n\n    Args:\n        dataset_items: Dataset items to add.\n    \"\"\"\n    batch = True\n    if isinstance(dataset_items, DatasetItem):\n        dataset_items = [dataset_items]\n        batch = False\n    fields = self.dataset_item_model.model_fields.keys()\n    if not all(\n        isinstance(item, DatasetItem) and set(fields) == set(item.model_fields.keys()) for item in dataset_items\n    ):\n        raise DatasetAccessError(\"All data must be instances of the same DatasetItem.\")\n\n    schemas_data = [item.to_schemas_data(self.schema) for item in dataset_items]\n    tables_data: dict[str, Any] = {}\n    for table_name in self.schema.schemas.keys():\n        for item in schemas_data:\n            if table_name not in tables_data:\n                tables_data[table_name] = []\n            if table_name not in item:\n                continue\n            if isinstance(item[table_name], list):\n                tables_data[table_name].extend(item[table_name])\n            elif item[table_name] is not None:\n                tables_data[table_name].append(item[table_name])\n    for table_name, table_data in tables_data.items():\n        if table_data != []:\n            self.add_data(\n                table_name=table_name,\n                data=table_data,\n                ignore_integrity_checks=[],\n                raise_or_warn=\"none\",\n            )\n    return dataset_items if batch else dataset_items[0]\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.compute_view_embeddings","title":"<code>compute_view_embeddings(table_name, data)</code>","text":"<p>Compute the view embeddings via the     Embedding Function stored in the table metadata.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name containing the view embeddings.</p> required <code>data</code> <code>list[dict]</code> <p>Data to compute. Dictionary representing a view embedding without the vector field.</p> required Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def compute_view_embeddings(self, table_name: str, data: list[dict]) -&gt; None:\n    \"\"\"Compute the [view embeddings][pixano.features.ViewEmbedding] via the\n        [Embedding Function][lancedb.embeddings.base.EmbeddingFunction] stored in the table metadata.\n\n    Args:\n        table_name: Table name containing the view embeddings.\n        data: Data to compute. Dictionary representing a view embedding without the vector field.\n    \"\"\"\n    table_schema = self.schema.schemas[table_name]\n    if not issubclass(table_schema, ViewEmbedding):\n        raise DatasetAccessError(f\"Table {table_name} is not a view embedding table\")\n    if not isinstance(data, list) or not all(isinstance(item, dict) for item in data):\n        raise DatasetAccessError(\"Data must be a list of dictionaries\")\n    # TODO: improve how to handle shape, this works but feels hacky\n    for item in data:\n        if \"shape\" not in item:\n            item[\"shape\"] = []\n    table = self.open_table(table_name)\n    data = pa.Table.from_pylist(\n        data, schema=table_schema.to_arrow_schema(remove_vector=True, remove_metadata=True)\n    )\n    table.add(data)\n    return None\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.create_table","title":"<code>create_table(name, schema, relation_item, data=None, mode='create', exist_ok=False, on_bad_vectors='error', fill_value=0.0)</code>","text":"<p>Add a table to the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Table name.</p> required <code>schema</code> <code>type[BaseSchema]</code> <p>Table schema.</p> required <code>relation_item</code> <code>SchemaRelation</code> <p>Relation with the <code>'item'</code> table (table to item).</p> required <code>data</code> <code>DATA | None</code> <p>Table data.</p> <code>None</code> <code>mode</code> <code>str</code> <p>Table mode ('create', 'overwrite'd).</p> <code>'create'</code> <code>exist_ok</code> <code>bool</code> <p>If True, do not raise an error if the table already exists.</p> <code>False</code> <code>on_bad_vectors</code> <code>str</code> <p>Raise an error, drop or fill bad vectors (\"error\", \"drop\", \"fill\").</p> <code>'error'</code> <code>fill_value</code> <code>float</code> <p>Value to fill bad vectors.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>LanceTable</code> <p>The table created.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def create_table(\n    self,\n    name: str,\n    schema: type[BaseSchema],\n    relation_item: SchemaRelation,\n    data: DATA | None = None,\n    mode: str = \"create\",\n    exist_ok: bool = False,\n    on_bad_vectors: str = \"error\",\n    fill_value: float = 0.0,\n) -&gt; LanceTable:\n    \"\"\"Add a table to the dataset.\n\n    Args:\n        name: Table name.\n        schema: Table schema.\n        relation_item: Relation with the `'item'` table (table to item).\n        data: Table data.\n        mode: Table mode ('create', 'overwrite'd).\n        exist_ok: If True, do not raise an error if the table already exists.\n        on_bad_vectors: Raise an error, drop or fill bad vectors (\"error\", \"drop\", \"fill\").\n        fill_value: Value to fill bad vectors.\n\n    Returns:\n        The table created.\n    \"\"\"\n    table = self._db_connection.create_table(\n        name=name,\n        schema=schema,\n        data=data,\n        mode=mode,\n        exist_ok=exist_ok,\n        on_bad_vectors=on_bad_vectors,\n        fill_value=fill_value,\n        embedding_functions=None,\n    )\n    self.schema.add_schema(name, schema, relation_item)\n    self.schema.to_json(self._schema_file)\n    self._reload_schema()\n    return table\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.delete_data","title":"<code>delete_data(table_name, ids)</code>","text":"<p>Delete data from a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name.</p> required <code>ids</code> <code>list[str]</code> <p>Ids to delete.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>The list of ids not found.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def delete_data(self, table_name: str, ids: list[str]) -&gt; list[str]:\n    \"\"\"Delete data from a table.\n\n    Args:\n        table_name: Table name.\n        ids: Ids to delete.\n\n    Returns:\n        The list of ids not found.\n    \"\"\"\n    if not isinstance(ids, list) or not all(isinstance(i, str) for i in ids):\n        raise DatasetAccessError(\"ids must be a list of strings\")\n\n    set_ids = set(ids)\n\n    table = self.open_table(table_name)\n    sql_ids = to_sql_list(set_ids)\n\n    ids_found = {\n        row[\"id\"] for row in TableQueryBuilder(table).select([\"id\"]).where(f\"id in {to_sql_list(ids)}\").to_list()\n    }\n    ids_not_found = [id for id in set_ids if id not in ids_found]\n\n    table.delete(where=f\"id in {sql_ids}\")\n\n    return ids_not_found\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.delete_dataset_items","title":"<code>delete_dataset_items(ids)</code>","text":"<p>Delete dataset items.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>list[str]</code> <p>Ids to delete.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>The list of ids not found.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def delete_dataset_items(self, ids: list[str]) -&gt; list[str]:\n    \"\"\"Delete dataset items.\n\n    Args:\n        ids: Ids to delete.\n\n    Returns:\n        The list of ids not found.\n    \"\"\"\n    sql_ids = to_sql_list(ids)\n\n    ids_not_found = []\n    for table_name in self.schema.schemas.keys():\n        if table_name == SchemaGroup.ITEM.value:\n            ids_not_found = self.delete_data(table_name, ids)\n        else:\n            table = self.open_table(table_name)\n            table_ids = (\n                table.search()\n                .select([\"id\"])\n                .where(f\"item_ref.id in {sql_ids}\")\n                .limit(None)\n                .to_arrow()[\"id\"]\n                .to_pylist()\n            )\n            if table_ids == []:\n                continue\n            table_sql_ids = to_sql_list(table_ids)\n            table.delete(where=f\"id in {table_sql_ids}\")\n    return ids_not_found\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.find","title":"<code>find(id, directory, media_dir=None)</code>  <code>staticmethod</code>","text":"<p>Find a Dataset in a directory.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Dataset ID to find.</p> required <code>directory</code> <code>Path</code> <p>Directory to search in.</p> required <code>media_dir</code> <code>Path | None</code> <p>Media directory.</p> <code>None</code> <p>Returns:</p> Type Description <code>'Dataset'</code> <p>The found dataset.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>@staticmethod\ndef find(\n    id: str,\n    directory: Path,\n    media_dir: Path | None = None,\n) -&gt; \"Dataset\":\n    \"\"\"Find a Dataset in a directory.\n\n    Args:\n        id: Dataset ID to find.\n        directory: Directory to search in.\n        media_dir: Media directory.\n\n    Returns:\n        The found dataset.\n    \"\"\"\n    # Browse directory\n    for json_fp in directory.glob(\"*/info.json\"):\n        info = DatasetInfo.from_json(json_fp)\n        if info.id == id:\n            # Return dataset\n            return Dataset(json_fp.parent, media_dir)\n    raise FileNotFoundError(f\"Dataset {id} not found in {directory}\")\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.find_ids_in_table","title":"<code>find_ids_in_table(table_name, ids)</code>","text":"<p>Search ids in a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name.</p> required <code>ids</code> <code>set[str]</code> <p>Ids to find.</p> required <p>Returns:</p> Type Description <code>dict[str, bool]</code> <p>Dictionary of ids found. Keys are the ids and values are <code>True</code> if the id is found, <code>False</code> otherwise.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def find_ids_in_table(self, table_name: str, ids: set[str]) -&gt; dict[str, bool]:\n    \"\"\"Search ids in a table.\n\n    Args:\n        table_name: Table name.\n        ids: Ids to find.\n\n    Returns:\n        Dictionary of ids found. Keys are the ids and values are `True` if the id is found, `False` otherwise.\n    \"\"\"\n    if len(ids) == 0:\n        return {}\n    table = self.open_table(table_name)\n    ids_found = list(TableQueryBuilder(table).select([\"id\"]).where(f\"id in {to_sql_list(ids)}\").to_polars()[\"id\"])\n    return {id: id in ids_found for id in ids}\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.get_all_ids","title":"<code>get_all_ids(table_name=SchemaGroup.ITEM.value)</code>","text":"<p>Get all the ids from a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>table to look for ids.</p> <code>ITEM.value</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>list of the ids.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def get_all_ids(self, table_name: str = SchemaGroup.ITEM.value) -&gt; list[str]:\n    \"\"\"Get all the ids from a table.\n\n    Args:\n        table_name: table to look for ids.\n\n    Returns:\n        list of the ids.\n    \"\"\"\n    return [row[\"id\"] for row in TableQueryBuilder(self.open_table(table_name)).select([\"id\"]).to_list()]\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.get_data","title":"<code>get_data(table_name, ids=None, limit=None, skip=0, where=None, item_ids=None)</code>","text":"<pre><code>get_data(table_name: str, ids: list[str] | None = None, limit: int | None = None, skip: int = 0, where: str | None = None, item_ids: list[str] | None = None) -&gt; list[BaseSchema]\n</code></pre><pre><code>get_data(table_name: str, ids: str, limit: int | None = None, skip: int = 0, where: str | None = None, item_ids: None = None) -&gt; BaseSchema | None\n</code></pre> <p>Read data from a table.</p> <p>Data can be filtered by ids, item ids, where clause, or limit and skip.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name.</p> required <code>where</code> <code>str | None</code> <p>Where clause.</p> <code>None</code> <code>ids</code> <code>list[str] | str | None</code> <p>ids to read.</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Amount of items to read.</p> <code>None</code> <code>skip</code> <code>int</code> <p>The number of data to skip.</p> <code>0</code> <code>item_ids</code> <code>list[str] | None</code> <p>Item ids to read.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[BaseSchema] | BaseSchema | None</code> <p>List of values.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def get_data(\n    self,\n    table_name: str,\n    ids: list[str] | str | None = None,\n    limit: int | None = None,\n    skip: int = 0,\n    where: str | None = None,\n    item_ids: list[str] | None = None,\n) -&gt; list[BaseSchema] | BaseSchema | None:\n    \"\"\"Read data from a table.\n\n    Data can be filtered by ids, item ids, where clause, or limit and skip.\n\n    Args:\n        table_name: Table name.\n        where: Where clause.\n        ids: ids to read.\n        limit: Amount of items to read.\n        skip: The number of data to skip.\n        item_ids: Item ids to read.\n\n    Returns:\n        List of values.\n    \"\"\"\n    if table_name == SchemaGroup.ITEM.value:\n        if item_ids is not None:\n            if ids is None:\n                ids = item_ids\n            else:\n                raise DatasetAccessError(\"ids and item_ids cannot be set at the same time\")\n            item_ids = None\n\n    return_list = not isinstance(ids, str)\n    ids = [ids] if isinstance(ids, str) else ids\n\n    _validate_ids_item_ids_and_limit_and_skip(ids, limit, skip, item_ids)\n\n    if item_ids is not None:\n        sql_item_ids = to_sql_list(item_ids)\n    table = self.open_table(table_name)\n    if ids is None:\n        if item_ids is None:\n            if where is not None:\n                query = TableQueryBuilder(table).where(where).limit(limit).offset(skip)\n            else:\n                query = TableQueryBuilder(table).limit(limit).offset(skip)\n        else:\n            sql_item_ids = to_sql_list(item_ids)\n            if where is not None:\n                where += f\" AND item_ref.id IN {sql_item_ids}\"\n            else:\n                where = f\"item_ref.id IN {sql_item_ids}\"\n            query = TableQueryBuilder(table).where(where).limit(limit).offset(skip)\n    else:\n        sql_ids = to_sql_list(ids)\n        if where is not None:\n            where += f\" AND id IN {sql_ids}\"\n        else:\n            where = f\"id IN {sql_ids}\"\n        query = TableQueryBuilder(table).where(where)\n\n    schema = self.schema.schemas[table_name] if table_name != SchemaGroup.SOURCE.value else Source\n\n    query_models: list[BaseSchema] = query.to_pydantic(schema)\n    for model in query_models:\n        model.dataset = self  # type: ignore[attr-defined]\n        model.table_name = table_name\n\n    return query_models if return_list else (query_models[0] if query_models != [] else None)\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.get_dataset_items","title":"<code>get_dataset_items(ids=None, limit=None, skip=0)</code>","text":"<pre><code>get_dataset_items(ids: list[str] | None = None, limit: int | None = None, skip: int = 0) -&gt; list[DatasetItem]\n</code></pre><pre><code>get_dataset_items(ids: str, limit: int | None = None, skip: int = 0) -&gt; DatasetItem | None\n</code></pre> <p>Read dataset items.</p> <p>Filter dataset items by ids, or limit and skip.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>list[str] | str | None</code> <p>Item ids to read.</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Amount of items to read.</p> <code>None</code> <code>skip</code> <code>int</code> <p>The number of data to skip..</p> <code>0</code> <p>Returns:</p> Type Description <code>list[DatasetItem] | DatasetItem | None</code> <p>List of dataset items.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def get_dataset_items(\n    self,\n    ids: list[str] | str | None = None,\n    limit: int | None = None,\n    skip: int = 0,\n) -&gt; list[DatasetItem] | DatasetItem | None:\n    \"\"\"Read dataset items.\n\n    Filter dataset items by ids, or limit and skip.\n\n    Args:\n        ids: Item ids to read.\n        limit: Amount of items to read.\n        skip: The number of data to skip..\n\n    Returns:\n        List of dataset items.\n    \"\"\"\n    return_list = not isinstance(ids, str)\n    ids = [ids] if isinstance(ids, str) else ids\n\n    _validate_ids_and_limit_and_skip(ids, limit, skip)\n\n    items = self.get_data(table_name=SchemaGroup.ITEM.value, where=None, ids=ids, limit=limit, skip=skip)\n    if items == []:\n        return [] if return_list else None\n    item_ids: list[str] = [item.id for item in items]\n    sql_ids = to_sql_list(item_ids)\n\n    # Load tables\n    ds_tables = self.open_tables(exclude_embeddings=True)\n\n    # Load items data from the tables\n    data_dict: dict[str, dict[str, BaseSchema | list[BaseSchema]]] = {item.id: item.model_dump() for item in items}\n    for table_name, table in ds_tables.items():\n        if table_name == SchemaGroup.ITEM.value:\n            continue\n        is_collection = self.schema.relations[SchemaGroup.ITEM.value][table_name] == SchemaRelation.ONE_TO_MANY\n        table_schema = self.schema.schemas[table_name]\n\n        rows = TableQueryBuilder(table).where(f\"item_ref.id in {sql_ids}\").to_pydantic(table_schema)\n\n        for row in rows:\n            row.dataset = self\n            item_id = row.item_ref.id\n            if is_collection:\n                if table_name not in data_dict[item_id]:\n                    data_dict[item_id][table_name] = []\n                data_dict[item_id][table_name].append(row)\n            else:\n                data_dict[item_id][table_name] = row\n\n    dataset_items = [self.dataset_item_model(**data_dict[item_id]) for item_id in item_ids]  # type: ignore[arg-type]\n\n    return dataset_items if return_list else (dataset_items[0] if dataset_items != [] else None)\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.list","title":"<code>list(directory)</code>  <code>staticmethod</code>","text":"<p>List the datasets information in directory.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>Path</code> <p>Directory to search in.</p> required <p>Returns:</p> Type Description <code>list[DatasetInfo]</code> <p>List of dataset infos.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>@staticmethod\ndef list(directory: Path) -&gt; list[DatasetInfo]:\n    \"\"\"List the datasets information in directory.\n\n    Args:\n        directory: Directory to search in.\n\n    Returns:\n        List of dataset infos.\n    \"\"\"\n    dataset_infos = []\n    for json_fp in directory.glob(\"*/info.json\"):\n        dataset_infos.append(DatasetInfo.from_json(json_fp))\n    return dataset_infos\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.open_table","title":"<code>open_table(name)</code>","text":"<p>Open a dataset table with LanceDB.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the table to open.</p> required <p>Returns:</p> Type Description <code>LanceTable</code> <p>Dataset table.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def open_table(self, name: str) -&gt; LanceTable:\n    \"\"\"Open a dataset table with LanceDB.\n\n    Args:\n        name: Name of the table to open.\n\n    Returns:\n        Dataset table.\n    \"\"\"\n    if name not in self.schema.schemas.keys() and name != SchemaGroup.SOURCE.value:\n        raise DatasetAccessError(f\"Table {name} not found in dataset\")\n\n    table = self._db_connection.open_table(name)\n    if name == SchemaGroup.SOURCE.value:\n        return table\n\n    schema_table = self.schema.schemas[name]\n    if is_view_embedding(schema_table):\n        schema_table = cast(type[ViewEmbedding], schema_table)\n        try:\n            schema_table.get_embedding_fn_from_table(self, name, table.schema.metadata)\n        except TypeError:  # no embedding function\n            pass\n    return table\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.open_tables","title":"<code>open_tables(names=None, exclude_embeddings=True)</code>","text":"<p>Open the dataset tables with LanceDB.</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>list[str] | None</code> <p>Table names to open. If None, open all tables.</p> <code>None</code> <code>exclude_embeddings</code> <code>bool</code> <p>Whether to exclude embedding tables from the list.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict[str, LanceTable]</code> <p>Dataset tables.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def open_tables(self, names: list[str] | None = None, exclude_embeddings: bool = True) -&gt; dict[str, LanceTable]:\n    \"\"\"Open the dataset tables with LanceDB.\n\n    Args:\n        names: Table names to open. If None, open all tables.\n        exclude_embeddings: Whether to exclude embedding tables from the list.\n\n    Returns:\n        Dataset tables.\n    \"\"\"\n    tables: dict[str, LanceTable] = defaultdict(dict)\n\n    for name in names if names is not None else self.schema.schemas.keys():\n        if exclude_embeddings and name in self.schema.groups[SchemaGroup.EMBEDDING]:\n            continue\n        tables[name] = self.open_table(name)\n\n    return tables\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.resolve_ref","title":"<code>resolve_ref(ref)</code>","text":"<pre><code>resolve_ref(ref: ItemRef) -&gt; Item\n</code></pre><pre><code>resolve_ref(ref: ViewRef) -&gt; View\n</code></pre><pre><code>resolve_ref(ref: EmbeddingRef) -&gt; Embedding\n</code></pre><pre><code>resolve_ref(ref: EntityRef) -&gt; Entity\n</code></pre><pre><code>resolve_ref(ref: AnnotationRef) -&gt; Annotation\n</code></pre><pre><code>resolve_ref(ref: SourceRef) -&gt; Source\n</code></pre><pre><code>resolve_ref(ref: SchemaRef) -&gt; BaseSchema\n</code></pre> <p>Resolve a SchemaRef.</p> <p>It fetches the data from the table referenced.</p> <p>Parameters:</p> Name Type Description Default <code>ref</code> <code>SchemaRef | ItemRef | ViewRef | EmbeddingRef | EntityRef | AnnotationRef | SourceRef</code> <p>Reference to resolve.</p> required <p>Returns:</p> Type Description <code>BaseSchema | Item | View | Embedding | Entity | Annotation | Source</code> <p>The resolved reference.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def resolve_ref(\n    self, ref: SchemaRef | ItemRef | ViewRef | EmbeddingRef | EntityRef | AnnotationRef | SourceRef\n) -&gt; BaseSchema | Item | View | Embedding | Entity | Annotation | Source:\n    \"\"\"Resolve a [SchemaRef][pixano.features.SchemaRef].\n\n    It fetches the data from the table referenced.\n\n    Args:\n        ref: Reference to resolve.\n\n    Returns:\n        The resolved reference.\n    \"\"\"\n    if ref.id == \"\" or ref.name == \"\":\n        raise DatasetAccessError(\"Reference should have a name and an id.\")\n    return self.get_data(ref.name, ids=[ref.id])[0]\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.semantic_search","title":"<code>semantic_search(query, table_name, limit, skip=0)</code>","text":"<p>Perform a semantic search.</p> <p>It searches for the closest items to the query in the table embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Text query for semantic search.</p> required <code>table_name</code> <code>str</code> <p>Table name for embeddings.</p> required <code>limit</code> <code>int</code> <p>Limit number of items.</p> required <code>skip</code> <code>int</code> <p>Skip number of items</p> <code>0</code> <p>Returns:</p> Type Description <code>tuple[list[BaseSchema], list[float]]</code> <p>Tuple of items and distances.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def semantic_search(\n    self, query: str, table_name: str, limit: int, skip: int = 0\n) -&gt; tuple[list[BaseSchema], list[float]]:\n    \"\"\"Perform a semantic search.\n\n    It searches for the closest items to the query in the table embeddings.\n\n    Args:\n        query: Text query for semantic search.\n        table_name: Table name for embeddings.\n        limit: Limit number of items.\n        skip: Skip number of items\n\n    Returns:\n        Tuple of items and distances.\n    \"\"\"\n    if not isinstance(query, str):\n        raise DatasetAccessError(\"query must be a string.\")\n    elif not isinstance(table_name, str):\n        raise DatasetAccessError(\"table_name must be a string.\")\n    elif not isinstance(limit, int) or limit &lt; 1:\n        raise DatasetAccessError(\"limit must be a strictly positive integer.\")\n    elif not isinstance(skip, int) or skip &lt; 0:\n        raise DatasetAccessError(\"skip must be a positive integer.\")\n    elif table_name not in self.schema.schemas:\n        raise DatasetAccessError(f\"Table {table_name} not found in dataset {self.id}.\")\n    elif table_name not in self.schema.groups[SchemaGroup.EMBEDDING] or not is_view_embedding(\n        self.schema.schemas[table_name]\n    ):\n        raise DatasetAccessError(f\"Table {table_name} is not a view embedding table.\")\n\n    table = self.open_table(table_name)\n    semantic_results: pl.DataFrame = (\n        table.search(query).select([\"item_ref.id\"]).limit(1e9).to_polars()\n    )  # TODO: change high limit if lancedb supports it\n    item_results = semantic_results.group_by(\"item_ref.id\").agg(pl.min(\"_distance\")).sort(\"_distance\")\n    item_ids = item_results[\"item_ref.id\"].to_list()[skip : skip + limit]\n\n    item_rows = self.get_data(\"item\", ids=item_ids)\n    item_rows = sorted(item_rows, key=lambda x: item_ids.index(x.id))\n    distances = [\n        item_results.row(by_predicate=(pl.col(\"item_ref.id\") == item.id), named=True)[\"_distance\"]\n        for item in item_rows\n    ]\n    return item_rows, distances\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.update_data","title":"<code>update_data(table_name, data, return_separately=False, ignore_integrity_checks=None, raise_or_warn='raise')</code>","text":"<pre><code>update_data(table_name: str, data: list[BaseSchema], return_separately: Literal[False] = False, ignore_integrity_checks: list[IntegrityCheck] | None = None, raise_or_warn: Literal['raise', 'warn', 'none'] = 'raise') -&gt; list[BaseSchema]\n</code></pre><pre><code>update_data(table_name: str, data: list[BaseSchema], return_separately: Literal[True], ignore_integrity_checks: list[IntegrityCheck] | None = None, raise_or_warn: Literal['raise', 'warn', 'none'] = 'raise') -&gt; tuple[list[BaseSchema], list[BaseSchema]]\n</code></pre> <p>Update data in a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name.</p> required <code>data</code> <code>list[BaseSchema]</code> <p>Data to update.</p> required <code>return_separately</code> <code>bool</code> <p>Whether to return separately added and updated data.</p> <code>False</code> <code>ignore_integrity_checks</code> <code>list[IntegrityCheck] | None</code> <p>List of integrity checks to ignore.</p> <code>None</code> <code>raise_or_warn</code> <code>Literal['raise', 'warn', 'none']</code> <p>Whether to raise or warn on integrity errors. Can be 'raise', 'warn' or 'none'.</p> <code>'raise'</code> <p>Returns:</p> Type Description <code>list[BaseSchema] | tuple[list[BaseSchema], list[BaseSchema]]</code> <p>If <code>return_separately</code> is <code>True</code>, returns a tuple of updated and added data. Otherwise, returns the updated</p> <code>list[BaseSchema] | tuple[list[BaseSchema], list[BaseSchema]]</code> <p>data.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def update_data(\n    self,\n    table_name: str,\n    data: list[BaseSchema],\n    return_separately: bool = False,\n    ignore_integrity_checks: list[IntegrityCheck] | None = None,\n    raise_or_warn: Literal[\"raise\", \"warn\", \"none\"] = \"raise\",\n) -&gt; list[BaseSchema] | tuple[list[BaseSchema], list[BaseSchema]]:\n    \"\"\"Update data in a table.\n\n    Args:\n        table_name: Table name.\n        data: Data to update.\n        return_separately: Whether to return separately added and updated data.\n        ignore_integrity_checks: List of integrity checks to ignore.\n        raise_or_warn: Whether to raise or warn on integrity errors. Can be 'raise', 'warn' or 'none'.\n\n    Returns:\n        If `return_separately` is `True`, returns a tuple of updated and added data. Otherwise, returns the updated\n        data.\n    \"\"\"\n    if not all((isinstance(item, type(data[0])) for item in data)) or not set(\n        type(data[0]).model_fields.keys()\n    ) == set(\n        self.schema.schemas[table_name].model_fields.keys()\n        if table_name != SchemaGroup.SOURCE.value\n        else Source.model_fields.keys()\n    ):\n        raise DatasetAccessError(\n            \"All data must be instances of the table type \"\n            f\"{self.schema.schemas[table_name] if table_name != SchemaGroup.SOURCE.value else Source}.\"\n        )\n    _validate_raise_or_warn(raise_or_warn)\n\n    table = self.open_table(table_name)\n    if raise_or_warn != \"none\":\n        handle_integrity_errors(\n            check_table_integrity(table_name, self, data, True, ignore_integrity_checks), raise_or_warn\n        )\n    set_ids = {item.id for item in data}\n    ids_found: dict[str, datetime] = {}\n\n    ids_found = {\n        row[\"id\"]: row[\"created_at\"]\n        for row in TableQueryBuilder(table)\n        .select([\"id\", \"created_at\"])\n        .where(f\"id in {to_sql_list(set_ids)}\")\n        .to_list()\n    }\n\n    for d in data:\n        d.updated_at = datetime.now()\n        if d.id not in ids_found:\n            d.created_at = d.updated_at\n    table.merge_insert(\"id\").when_matched_update_all().when_not_matched_insert_all().execute(data)\n\n    if not return_separately:\n        return data\n\n    updated_data, added_data = [], []\n    for d in data:\n        if d.id not in ids_found:\n            added_data.append(d)\n        else:\n            updated_data.append(d)\n\n    return updated_data, added_data\n</code></pre>"},{"location":"api_reference/datasets/dataset/#pixano.datasets.dataset.Dataset.update_dataset_items","title":"<code>update_dataset_items(dataset_items, return_separately=False)</code>","text":"<pre><code>update_dataset_items(dataset_items: list[DatasetItem], return_separately: Literal[False] = False) -&gt; list[DatasetItem]\n</code></pre><pre><code>update_dataset_items(dataset_items: list[DatasetItem], return_separately: Literal[True]) -&gt; tuple[list[DatasetItem], list[DatasetItem]]\n</code></pre> <p>Update dataset items.</p> Warn <p>Does not test for integrity of the data.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_items</code> <code>list[DatasetItem]</code> <p>Dataset items to update.</p> required <code>return_separately</code> <code>bool</code> <p>Whether to return separately added and updated dataset items.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[DatasetItem] | tuple[list[DatasetItem], list[DatasetItem]]</code> <p>If <code>return_separately</code> is <code>True</code>, returns a tuple of updated and added dataset items. Otherwise, returns</p> <code>list[DatasetItem] | tuple[list[DatasetItem], list[DatasetItem]]</code> <p>the updated dataset items.</p> Source code in <code>pixano/datasets/dataset.py</code> <pre><code>def update_dataset_items(\n    self,\n    dataset_items: list[DatasetItem],\n    return_separately: bool = False,\n) -&gt; list[DatasetItem] | tuple[list[DatasetItem], list[DatasetItem]]:\n    \"\"\"Update dataset items.\n\n    Warn:\n        Does not test for integrity of the data.\n\n    Args:\n        dataset_items: Dataset items to update.\n        return_separately: Whether to return separately added and updated dataset items.\n\n    Returns:\n        If `return_separately` is `True`, returns a tuple of updated and added dataset items. Otherwise, returns\n        the updated dataset items.\n    \"\"\"\n    fields = self.dataset_item_model.model_fields.keys()\n    if not all(\n        isinstance(item, DatasetItem) and set(fields) == set(item.model_fields.keys()) for item in dataset_items\n    ):\n        raise DatasetAccessError(\"All data must be instances of the same DatasetItem.\")\n\n    schemas_data = [item.to_schemas_data(self.schema) for item in dataset_items]\n    updated_ids = set()\n    tables_data: dict[str, Any] = {}\n    for table_name in self.schema.schemas.keys():\n        for item in schemas_data:\n            if table_name not in tables_data:\n                tables_data[table_name] = []\n            if table_name not in item:\n                continue\n            if isinstance(item[table_name], list):\n                tables_data[table_name].extend(item[table_name])\n            elif item[table_name] is not None:\n                tables_data[table_name].append(item[table_name])\n    for table_name, table_data in tables_data.items():\n        if table_data != []:\n            updated, _ = self.update_data(\n                table_name,\n                table_data,\n                return_separately=True,\n                ignore_integrity_checks=[],\n                raise_or_warn=\"none\",\n            )\n            for row in updated:\n                updated_ids.add(row.item_ref.id if table_name != SchemaGroup.ITEM.value else row.id)\n\n    dataset_items = self.get_dataset_items([item.id for item in dataset_items])\n\n    if not return_separately:\n        return dataset_items\n\n    updated_items, added_items = [], []\n    for item in dataset_items:\n        if item.id not in updated_ids:\n            added_items.append(item)\n        else:\n            updated_items.append(item)\n    return updated_items, added_items\n</code></pre>"},{"location":"api_reference/datasets/dataset_features_values/","title":"dataset_features_values","text":""},{"location":"api_reference/datasets/dataset_features_values/#pixano.datasets.dataset_features_values","title":"<code>pixano.datasets.dataset_features_values</code>","text":""},{"location":"api_reference/datasets/dataset_features_values/#pixano.datasets.dataset_features_values.DatasetFeaturesValues","title":"<code>DatasetFeaturesValues(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Constraints for the dataset features values.</p> <p>Attributes:</p> Name Type Description <code>items</code> <code>dict[str, list]</code> <p>Constraints for the dataset item table.</p> <code>views</code> <code>dict[str, list]</code> <p>Constraints for the dataset view tables.</p> <code>entities</code> <code>dict[str, list]</code> <p>Constraints for the dataset entity tables.</p> <code>annotations</code> <code>dict[str, list]</code> <p>Constraints for the dataset annotation tables.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            stacklevel=2,\n        )\n</code></pre>"},{"location":"api_reference/datasets/dataset_features_values/#pixano.datasets.dataset_features_values.DatasetFeaturesValues.from_json","title":"<code>from_json(json_fp)</code>  <code>staticmethod</code>","text":"<p>Load DatasetFeaturesValues from json file.</p> Source code in <code>pixano/datasets/dataset_features_values.py</code> <pre><code>@staticmethod\ndef from_json(json_fp: Path) -&gt; \"DatasetFeaturesValues\":\n    \"\"\"Load DatasetFeaturesValues from json file.\"\"\"\n    fv_json = json.loads(json_fp.read_text(encoding=\"utf-8\"))\n    fv = DatasetFeaturesValues.model_validate(fv_json)\n\n    return fv\n</code></pre>"},{"location":"api_reference/datasets/dataset_features_values/#pixano.datasets.dataset_features_values.DatasetFeaturesValues.to_json","title":"<code>to_json(json_fp)</code>","text":"<p>Save DatasetFeaturesValues to json file.</p> Source code in <code>pixano/datasets/dataset_features_values.py</code> <pre><code>def to_json(self, json_fp: Path) -&gt; None:\n    \"\"\"Save DatasetFeaturesValues to json file.\"\"\"\n    json_fp.write_text(json.dumps(self.model_dump(), indent=4), encoding=\"utf-8\")\n</code></pre>"},{"location":"api_reference/datasets/dataset_info/","title":"dataset_info","text":""},{"location":"api_reference/datasets/dataset_info/#pixano.datasets.dataset_info","title":"<code>pixano.datasets.dataset_info</code>","text":""},{"location":"api_reference/datasets/dataset_info/#pixano.datasets.dataset_info.DatasetInfo","title":"<code>DatasetInfo(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information of a dataset.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Dataset ID. Must be unique.</p> <code>name</code> <code>str</code> <p>Dataset name.</p> <code>description</code> <code>str</code> <p>Dataset description.</p> <code>estimated_size</code> <code>str</code> <p>Dataset estimated size.</p> <code>preview</code> <code>str</code> <p>Path to a preview thumbnail.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            stacklevel=2,\n        )\n</code></pre>"},{"location":"api_reference/datasets/dataset_info/#pixano.datasets.dataset_info.DatasetInfo.from_json","title":"<code>from_json(json_fp)</code>  <code>staticmethod</code>","text":"<p>Read DatasetInfo from JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>json_fp</code> <code>Path</code> <p>JSON file path.</p> required <p>Returns:</p> Type Description <code>'DatasetInfo'</code> <p>the dataset info object.</p> Source code in <code>pixano/datasets/dataset_info.py</code> <pre><code>@staticmethod\ndef from_json(\n    json_fp: Path,\n) -&gt; \"DatasetInfo\":\n    \"\"\"Read DatasetInfo from JSON file.\n\n    Args:\n        json_fp: JSON file path.\n\n    Returns:\n        the dataset info object.\n    \"\"\"\n    info_json = json.loads(json_fp.read_text(encoding=\"utf-8\"))\n    info = DatasetInfo.model_validate(info_json)\n\n    return info\n</code></pre>"},{"location":"api_reference/datasets/dataset_info/#pixano.datasets.dataset_info.DatasetInfo.load_directory","title":"<code>load_directory(directory, return_path=False)</code>  <code>staticmethod</code>","text":"<pre><code>load_directory(directory: Path, return_path: Literal[False] = False) -&gt; list['DatasetInfo']\n</code></pre><pre><code>load_directory(directory: Path, return_path: Literal[True]) -&gt; list[tuple['DatasetInfo', Path]]\n</code></pre> <p>Load list of DatasetInfo from directory.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>Path</code> <p>Directory to load.</p> required <code>return_path</code> <code>bool</code> <p>Return the paths of the datasets.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[tuple['DatasetInfo', Path]] | list['DatasetInfo']</code> <p>The list of DatasetInfo and the paths of the datasets.</p> Source code in <code>pixano/datasets/dataset_info.py</code> <pre><code>@staticmethod\ndef load_directory(\n    directory: Path,\n    return_path: bool = False,\n) -&gt; list[tuple[\"DatasetInfo\", Path]] | list[\"DatasetInfo\"]:\n    \"\"\"Load list of DatasetInfo from directory.\n\n    Args:\n        directory: Directory to load.\n        return_path: Return the paths of the datasets.\n\n    Returns:\n        The list of DatasetInfo and the paths of the datasets.\n    \"\"\"\n    library: list[DatasetInfo] | list[tuple[DatasetInfo, Path]] = []\n\n    # Browse directory\n    for json_fp in sorted(directory.glob(\"*/info.json\")):\n        info: DatasetInfo = DatasetInfo.from_json(json_fp)\n        try:\n            info.preview = Image.open_url(\n                str(json_fp.parent / \"previews/dataset_preview.jpg\"),\n                Path(\"/\"),\n            )  # TODO choose correct preview name / path / extension\n        except Exception:  # TODO: specify exception URL and Value\n            info.preview = \"\"\n        if return_path:\n            library.append((info, json_fp.parent))  #  type: ignore[arg-type]\n        else:\n            library.append(info)\n\n    if library == []:\n        raise FileNotFoundError(f\"No dataset found in {directory}.\")\n\n    return library\n</code></pre>"},{"location":"api_reference/datasets/dataset_info/#pixano.datasets.dataset_info.DatasetInfo.load_id","title":"<code>load_id(id, directory, return_path=False)</code>  <code>staticmethod</code>","text":"<pre><code>load_id(id: str, directory: Path, return_path: Literal[False] = False) -&gt; 'DatasetInfo'\n</code></pre><pre><code>load_id(id: str, directory: Path, return_path: Literal[True] = True) -&gt; tuple['DatasetInfo', Path]\n</code></pre> <p>Load a specific DatasetInfo from directory.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The ID of the dataset to load.</p> required <code>directory</code> <code>Path</code> <p>Directory to load.</p> required <code>return_path</code> <code>bool</code> <p>Return the path of the dataset.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple['DatasetInfo', Path] | 'DatasetInfo'</code> <p>The DatasetInfo.</p> Source code in <code>pixano/datasets/dataset_info.py</code> <pre><code>@staticmethod\ndef load_id(id: str, directory: Path, return_path: bool = False) -&gt; tuple[\"DatasetInfo\", Path] | \"DatasetInfo\":\n    \"\"\"Load a specific DatasetInfo from directory.\n\n    Args:\n        id: The ID of the dataset to load.\n        directory: Directory to load.\n        return_path: Return the path of the dataset.\n\n    Returns:\n        The DatasetInfo.\n    \"\"\"\n    for json_fp in directory.glob(\"*/info.json\"):\n        info = DatasetInfo.from_json(json_fp)\n        if info.id == id:\n            try:\n                info.preview = Image.open_url(\n                    str(json_fp.parent / \"previews/dataset_preview.jpg\"),\n                    json_fp.parent / \"media\",\n                )  # TODO choose correct preview name / path / extension\n            except ValueError:\n                info.preview = \"\"\n            return (info, json_fp.parent) if return_path else info\n    raise FileNotFoundError(f\"No dataset found with ID {id}\")\n</code></pre>"},{"location":"api_reference/datasets/dataset_info/#pixano.datasets.dataset_info.DatasetInfo.to_json","title":"<code>to_json(json_fp)</code>","text":"<p>Writes the DatasetInfo object to a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>json_fp</code> <code>Path</code> <p>The path to the file where the DatasetInfo object will be written.</p> required Source code in <code>pixano/datasets/dataset_info.py</code> <pre><code>def to_json(self, json_fp: Path) -&gt; None:\n    \"\"\"Writes the DatasetInfo object to a JSON file.\n\n    Args:\n        json_fp: The path to the file where the DatasetInfo object\n            will be written.\n    \"\"\"\n    json_fp.write_text(json.dumps(self.model_dump(), indent=4), encoding=\"utf-8\")\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/","title":"dataset_schema","text":""},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema","title":"<code>pixano.datasets.dataset_schema</code>","text":""},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetItem","title":"<code>DatasetItem(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Dataset Item.</p> <p>It is a Pydantic model that represents an item in a dataset.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>The unique identifier of the item.</p> <code>split</code> <code>str</code> <p>The split of the item.</p> <code>created_at</code> <code>datetime</code> <p>The creation date of the item.</p> <code>updated_at</code> <code>datetime</code> <p>The last modification date of the item.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/datasets/dataset_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetItem.from_dataset_schema","title":"<code>from_dataset_schema(dataset_schema, exclude_embeddings=True)</code>  <code>staticmethod</code>","text":"<p>Create a dataset item model based on the schema.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_schema</code> <code>DatasetSchema</code> <p>The dataset schema.</p> required <code>exclude_embeddings</code> <code>bool</code> <p>Exclude embeddings from the dataset item model to reduce the size.</p> <code>True</code> <p>Returns:</p> Type Description <code>type[DatasetItem]</code> <p>The dataset item model</p> Source code in <code>pixano/datasets/dataset_schema.py</code> <pre><code>@staticmethod\ndef from_dataset_schema(dataset_schema: DatasetSchema, exclude_embeddings: bool = True) -&gt; type[\"DatasetItem\"]:\n    \"\"\"Create a dataset item model based on the schema.\n\n    Args:\n        dataset_schema: The dataset schema.\n        exclude_embeddings: Exclude embeddings from the dataset item model to reduce the size.\n\n    Returns:\n        The dataset item model\n    \"\"\"\n    item_type = dataset_schema.schemas[SchemaGroup.ITEM.value]\n    fields: dict[str, Any] = {}\n\n    if dataset_schema.relations != {} and SchemaGroup.ITEM.value in dataset_schema.relations:\n        for schema, relation in dataset_schema.relations[SchemaGroup.ITEM.value].items():\n            if exclude_embeddings and schema in dataset_schema.groups[SchemaGroup.EMBEDDING]:\n                continue\n            # Add default value in case an item does not have a specific view or entity.\n            schema_type = dataset_schema.schemas[schema]\n            if relation == SchemaRelation.ONE_TO_MANY:\n                fields[schema] = (list[schema_type], [])  # type: ignore[valid-type]\n            else:\n                fields[schema] = (schema_type | None, None)\n\n    for field_name, field in item_type.model_fields.items():\n        # No default value as all items metadata should be retrieved.\n        fields[field_name] = (field.annotation, ...)\n\n    CustomDatasetItem = create_model(\n        \"DatasetItem\",\n        **fields,\n        __base__=DatasetItem,\n    )\n    return CustomDatasetItem\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetItem.get_sub_dataset_item","title":"<code>get_sub_dataset_item(selected_fields)</code>  <code>classmethod</code>","text":"<p>Create a new dataset item based on the selected fields of the original dataset item.</p> Note <p>The id and split fields are always included in the sub dataset item.</p> Note <p>The sub dataset item does not have the methods and config of the original dataset item.</p> <p>Parameters:</p> Name Type Description Default <code>selected_fields</code> <code>list[str]</code> <p>The selected fields.</p> required <p>Returns:</p> Type Description <code>type[Self]</code> <p>The sub dataset item.</p> Source code in <code>pixano/datasets/dataset_schema.py</code> <pre><code>@classmethod\ndef get_sub_dataset_item(cls, selected_fields: list[str]) -&gt; type[Self]:\n    \"\"\"Create a new dataset item based on the selected fields of the original dataset\n    item.\n\n    Note:\n        The id and split fields are always included in the sub dataset item.\n\n    Note:\n        The sub dataset item does not have the methods and config of the original\n        dataset item.\n\n    Args:\n        selected_fields: The selected fields.\n\n    Returns:\n        The sub dataset item.\n    \"\"\"\n    fields = {}\n    for field_name, field in cls.model_fields.items():\n        if field_name in selected_fields or field_name in [\"id\", \"split\"]:\n            if isinstance(field.annotation, GenericAlias):\n                origin = field.annotation.__origin__\n                args = field.annotation.__args__\n\n                # Check if field is list or tuple\n                if origin is tuple:\n                    fields[field_name] = (origin[args[0], ...], field.default)  # type: ignore[index]\n                else:\n                    fields[field_name] = (field.annotation, field.default)\n            else:\n                fields[field_name] = (field.annotation, field.default)\n\n    SubDatasetItem: type[DatasetItem] = create_model(\n        cls.__name__,\n        **fields,\n        __base__=DatasetItem,\n    )\n\n    return SubDatasetItem\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetItem.model_dump","title":"<code>model_dump(exclude_timestamps=False, **kwargs)</code>","text":"<p>Dump the model to a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_timestamps</code> <code>bool</code> <p>Exclude timestamps \"created_at\" and \"updated_at\" from the model dump. Useful for comparing models without timestamps.</p> <code>False</code> <code>kwargs</code> <code>Any</code> <p>Arguments for pydantic <code>BaseModel.model_dump()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The model dump.</p> Source code in <code>pixano/datasets/dataset_schema.py</code> <pre><code>def model_dump(self, exclude_timestamps: bool = False, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Dump the model to a dictionary.\n\n    Args:\n        exclude_timestamps: Exclude timestamps \"created_at\" and \"updated_at\" from the model dump. Useful for\n            comparing models without timestamps.\n        kwargs: Arguments for pydantic `BaseModel.model_dump()`.\n\n    Returns:\n        The model dump.\n    \"\"\"\n    model_dump = super().model_dump(**kwargs)\n    if exclude_timestamps:\n        model_dump.pop(\"created_at\", None)\n        model_dump.pop(\"updated_at\", None)\n        for k, value in model_dump.items():\n            if isinstance(value, dict):\n                value.pop(\"created_at\", None)\n                value.pop(\"updated_at\", None)\n            elif isinstance(value, list):  # Only one level deep.\n                for item in value:\n                    if isinstance(item, dict):\n                        item.pop(\"created_at\", None)\n                        item.pop(\"updated_at\", None)\n    return model_dump\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetItem.to_dataset_schema","title":"<code>to_dataset_schema()</code>  <code>classmethod</code>","text":"<p>Convert a DatasetItem to a DatasetSchema.</p> Source code in <code>pixano/datasets/dataset_schema.py</code> <pre><code>@classmethod\ndef to_dataset_schema(cls) -&gt; DatasetSchema:\n    \"\"\"Convert a DatasetItem to a DatasetSchema.\"\"\"\n    return DatasetSchema.from_dataset_item(cls)\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetItem.to_schemas_data","title":"<code>to_schemas_data(dataset_schema)</code>","text":"<p>Convert DatasetItem to schemas data.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_schema</code> <code>DatasetSchema</code> <p>DatasetSchema to convert to.</p> required <p>Returns:</p> Type Description <code>dict[str, BaseSchema | list[BaseSchema] | None]</code> <p>Schemas data.</p> Source code in <code>pixano/datasets/dataset_schema.py</code> <pre><code>def to_schemas_data(self, dataset_schema: DatasetSchema) -&gt; dict[str, BaseSchema | list[BaseSchema] | None]:\n    \"\"\"Convert DatasetItem to schemas data.\n\n    Args:\n        dataset_schema: DatasetSchema to convert to.\n\n    Returns:\n        Schemas data.\n    \"\"\"\n    schemas_data = {}\n    item_data = {}\n    for field_name in self.model_fields.keys():\n        if field_name in dataset_schema.schemas:\n            schemas_data[field_name] = getattr(self, field_name)\n        else:\n            item_data[field_name] = getattr(self, field_name)\n    schemas_data[SchemaGroup.ITEM.value] = dataset_schema.schemas[SchemaGroup.ITEM.value](**item_data)\n    return schemas_data\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetSchema","title":"<code>DatasetSchema(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A dataset schema that defines the tables and the relations between them.</p> <p>Attributes:</p> Name Type Description <code>schemas</code> <code>dict[str, type[BaseSchema]]</code> <p>The mapping between the table names and their schema.</p> <code>relations</code> <code>dict[str, dict[str, SchemaRelation]]</code> <p>The relations between the item table and the other tables.</p> <code>groups</code> <code>dict[SchemaGroup, set[str]]</code> <p>The groups of tables. It is filled automatically based on the schemas.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            stacklevel=2,\n        )\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetSchema.add_schema","title":"<code>add_schema(table_name, schema, relation_item)</code>","text":"<p>Add a schema to the dataset schema.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Name of the table to add to the dataset schema.</p> required <code>schema</code> <code>type[BaseSchema]</code> <p>Schema of the table.</p> required <code>relation_item</code> <code>SchemaRelation</code> <p>Relationship with the item schema.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The dataset schema.</p> Source code in <code>pixano/datasets/dataset_schema.py</code> <pre><code>def add_schema(self, table_name: str, schema: type[BaseSchema], relation_item: SchemaRelation) -&gt; Self:\n    \"\"\"Add a schema to the dataset schema.\n\n    Args:\n        table_name: Name of the table to add to the dataset schema.\n        schema: Schema of the table.\n        relation_item: Relationship with the item schema.\n\n    Returns:\n        The dataset schema.\n    \"\"\"\n    table_name = self.format_table_name(table_name)\n    if table_name in self.schemas:\n        raise ValueError(f\"Table {table_name} already exists in the schemas.\")\n    elif not issubclass(schema, BaseSchema):\n        raise ValueError(f\"Schema {schema} should be a subclass of BaseSchema.\")\n    elif not isinstance(relation_item, SchemaRelation):\n        raise ValueError(f\"Invalid relation {relation_item}.\")\n    found_group = False\n    for group, group_type in _SCHEMA_GROUP_TO_SCHEMA_DICT.items():\n        if issubclass(schema, group_type):\n            self.groups[group].add(table_name)\n            found_group = True\n            break\n    if not found_group:\n        raise ValueError(f\"Invalid table type {schema}\")\n    self.schemas[table_name] = schema\n    if relation_item == SchemaRelation.ONE_TO_ONE:\n        self.relations[SchemaGroup.ITEM.value][table_name] = SchemaRelation.ONE_TO_ONE\n        self.relations[table_name] = {SchemaGroup.ITEM.value: SchemaRelation.ONE_TO_ONE}\n    elif relation_item == SchemaRelation.ONE_TO_MANY:\n        self.relations[SchemaGroup.ITEM.value][table_name] = SchemaRelation.MANY_TO_ONE\n        self.relations[table_name] = {SchemaGroup.ITEM.value: SchemaRelation.ONE_TO_MANY}\n    elif relation_item == SchemaRelation.MANY_TO_ONE:\n        self.relations[SchemaGroup.ITEM.value][table_name] = SchemaRelation.ONE_TO_MANY\n        self.relations[table_name] = {SchemaGroup.ITEM.value: SchemaRelation.MANY_TO_ONE}\n    elif relation_item == SchemaRelation.MANY_TO_MANY:\n        self.relations[SchemaGroup.ITEM.value][table_name] = SchemaRelation.MANY_TO_MANY\n        self.relations[table_name] = {SchemaGroup.ITEM.value: SchemaRelation.MANY_TO_MANY}\n    return self\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetSchema.deserialize","title":"<code>deserialize(dataset_schema_json)</code>  <code>staticmethod</code>","text":"<p>Deserialize the dataset schema.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_schema_json</code> <code>dict[str, dict[str, Any]]</code> <p>Serialized dataset schema.</p> required <p>Returns:</p> Type Description <code>DatasetSchema</code> <p>The dataset schema.</p> Source code in <code>pixano/datasets/dataset_schema.py</code> <pre><code>@staticmethod\ndef deserialize(dataset_schema_json: dict[str, dict[str, Any]]) -&gt; \"DatasetSchema\":\n    \"\"\"Deserialize the dataset schema.\n\n    Args:\n        dataset_schema_json: Serialized dataset schema.\n\n    Returns:\n        The dataset schema.\n    \"\"\"\n    dataset_schema_dict: dict[str, Any] = {\n        \"relations\": {\n            schema1: {schema2: SchemaRelation(relation) for schema2, relation in relations.items()}\n            for schema1, relations in dataset_schema_json[\"relations\"].items()\n        },\n        \"schemas\": {},\n        \"groups\": {SchemaGroup(group): set(schemas) for group, schemas in dataset_schema_json[\"groups\"].items()},\n    }\n    for table_name, schema in dataset_schema_json[\"schemas\"].items():\n        dataset_schema_dict[\"schemas\"][table_name] = BaseSchema.deserialize(schema)\n    return DatasetSchema(**dataset_schema_dict)\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetSchema.format_table_name","title":"<code>format_table_name(table_name)</code>  <code>staticmethod</code>","text":"<p>Format table name.</p> <p>It converts the table name to lowercase and replaces spaces with underscores.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name.</p> required <p>Returns:</p> Type Description <code>str</code> <p>the formatted table name.</p> Source code in <code>pixano/datasets/dataset_schema.py</code> <pre><code>@staticmethod\ndef format_table_name(table_name: str) -&gt; str:\n    \"\"\"Format table name.\n\n    It converts the table name to lowercase and replaces spaces with underscores.\n\n    Args:\n        table_name: Table name.\n\n    Returns:\n        the formatted table name.\n    \"\"\"\n    return table_name.lower().replace(\" \", \"_\")\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetSchema.from_dataset_item","title":"<code>from_dataset_item(dataset_item)</code>  <code>staticmethod</code>","text":"<p>Create a dataset schema from a DatasetItem.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_item</code> <code>type[DatasetItem]</code> <p>The dataset item.</p> required <p>Returns:</p> Type Description <code>DatasetSchema</code> <p>The dataset schema.</p> Source code in <code>pixano/datasets/dataset_schema.py</code> <pre><code>@staticmethod\ndef from_dataset_item(dataset_item: type[\"DatasetItem\"]) -&gt; \"DatasetSchema\":\n    \"\"\"Create a dataset schema from a [DatasetItem][pixano.datasets.DatasetItem].\n\n    Args:\n        dataset_item: The dataset item.\n\n    Returns:\n        The dataset schema.\n    \"\"\"\n    item_fields = {}\n\n    # table schemas\n    dataset_schema_dict: dict[str, Any] = {}\n    dataset_schema_dict[\"relations\"] = {SchemaGroup.ITEM.value: {}}\n    schemas = {}\n\n    for field_name, field in dataset_item.model_fields.items():\n        # Check if field is a generic alias (list or tuple)\n        if isinstance(field.annotation, GenericAlias):\n            origin = field.annotation.__origin__\n            args = field.annotation.__args__\n\n            # Check if field is list or tuple\n            if origin in [list, tuple]:\n                # Categorizing list of schemas as schemas and keeping track of the relation\n                if issubclass(args[0], tuple(_SCHEMA_REGISTRY.values())):\n                    schemas[field_name] = args[0]\n                    dataset_schema_dict[\"relations\"][SchemaGroup.ITEM.value][field_name] = (\n                        SchemaRelation.ONE_TO_MANY\n                    )\n                    dataset_schema_dict[\"relations\"][field_name] = {\n                        SchemaGroup.ITEM.value: SchemaRelation.MANY_TO_ONE\n                    }\n                else:\n                    item_fields[field_name] = (list[args[0]], ...)  # type: ignore[valid-type]\n            else:\n                # Default case: categorize as item attribute\n                item_fields[field_name] = (args[0], ...)  # type: ignore[valid-type]\n        # Check if field is a schema\n        elif issubclass(field.annotation, tuple(_SCHEMA_REGISTRY.values())):\n            schemas[field_name] = field.annotation\n            dataset_schema_dict[\"relations\"][SchemaGroup.ITEM.value][field_name] = SchemaRelation.ONE_TO_ONE\n            dataset_schema_dict[\"relations\"][field_name] = {SchemaGroup.ITEM.value: SchemaRelation.ONE_TO_ONE}\n        else:\n            # Default case: item attribute\n            item_fields[field_name] = (field.annotation, ...)\n\n    CustomItem = create_model(\"Item\", **item_fields, __base__=Item)\n\n    schemas[SchemaGroup.ITEM.value] = CustomItem\n    dataset_schema_dict[\"schemas\"] = schemas\n\n    return DatasetSchema(**dataset_schema_dict)\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetSchema.from_json","title":"<code>from_json(json_fp)</code>  <code>staticmethod</code>","text":"<p>Read a dataset schema from JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>json_fp</code> <code>Path</code> <p>JSON file path</p> required <p>Returns:</p> Type Description <code>DatasetSchema</code> <p>The dataset schema.</p> Source code in <code>pixano/datasets/dataset_schema.py</code> <pre><code>@staticmethod\ndef from_json(\n    json_fp: Path,\n) -&gt; \"DatasetSchema\":\n    \"\"\"Read a dataset schema from JSON file.\n\n    Args:\n        json_fp: JSON file path\n\n    Returns:\n        The dataset schema.\n    \"\"\"\n    schema_json = json.loads(json_fp.read_text(encoding=\"utf-8\"))\n\n    return DatasetSchema.deserialize(schema_json)\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetSchema.get_table_group","title":"<code>get_table_group(table_name)</code>","text":"<p>Get the group of a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name.</p> required <p>Returns:</p> Type Description <code>SchemaGroup</code> <p>The group of the table.</p> Source code in <code>pixano/datasets/dataset_schema.py</code> <pre><code>def get_table_group(self, table_name: str) -&gt; SchemaGroup:\n    \"\"\"Get the group of a table.\n\n    Args:\n        table_name: Table name.\n\n    Returns:\n        The group of the table.\n    \"\"\"\n    for group, tables in self.groups.items():\n        if table_name in tables:\n            return group\n    raise ValueError(f\"Table {table_name} not found in groups.\")\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetSchema.serialize","title":"<code>serialize()</code>","text":"<p>Serialize the dataset schema.</p> <p>The serialized schema is a dictionary with the following format: {     \"relations\": {         \"item\": {             \"image\": \"one_to_one\",         }     },     \"schemas\": {         \"table1\": {             \"schema\": \"CustomItem\",             \"base_schema\": \"Item\",             \"fields\": {                 \"id\": {                     \"type\": \"str\",                     \"collection\": False                 },                 \"split\": {                     \"type\": \"str\",                     \"collection\": False                 },                 ...             }</p> <pre><code>    }\n}\n</code></pre> <p>}</p> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>The serialized dataset schema.</p> Source code in <code>pixano/datasets/dataset_schema.py</code> <pre><code>@model_serializer\ndef serialize(self) -&gt; dict[str, dict[str, Any]]:\n    \"\"\"Serialize the dataset schema.\n\n    The serialized schema is a dictionary with the following format:\n    {\n        \"relations\": {\n            \"item\": {\n                \"image\": \"one_to_one\",\n            }\n        },\n        \"schemas\": {\n            \"table1\": {\n                \"schema\": \"CustomItem\",\n                \"base_schema\": \"Item\",\n                \"fields\": {\n                    \"id\": {\n                        \"type\": \"str\",\n                        \"collection\": False\n                    },\n                    \"split\": {\n                        \"type\": \"str\",\n                        \"collection\": False\n                    },\n                    ...\n                }\n\n            }\n        }\n    }\n\n    Returns:\n        The serialized dataset schema.\n    \"\"\"\n    dataset_schema_json: dict[str, dict[str, Any]] = {\n        \"relations\": {\n            schema1: {schema2: relation.value for schema2, relation in relations.items()}\n            for schema1, relations in self.relations.items()\n        },\n        \"schemas\": {},\n        \"groups\": {group.value: list(schemas) for group, schemas in self.groups.items()},\n    }\n    for table_name, schema in self.schemas.items():\n        dataset_schema_json[\"schemas\"][table_name] = schema.serialize()\n    return dataset_schema_json\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.DatasetSchema.to_json","title":"<code>to_json(json_fp)</code>","text":"<p>Save DatasetSchema to json file.</p> Source code in <code>pixano/datasets/dataset_schema.py</code> <pre><code>def to_json(self, json_fp: Path) -&gt; None:\n    \"\"\"Save DatasetSchema to json file.\"\"\"\n    if json_fp.exists():\n        old_json_content = json.loads(json_fp.read_text(encoding=\"utf-8\"))\n    else:\n        old_json_content = None\n\n    json_content = self.serialize()\n\n    # Keep the schema field from the old json content for custom schemas.\n    if old_json_content is not None:\n        for table, schema in json_content[\"schemas\"].items():\n            if table not in old_json_content[\"schemas\"]:\n                continue\n            schema[\"schema\"] = old_json_content[\"schemas\"][table][\"schema\"]\n    json_fp.write_text(json.dumps(json_content, indent=4), encoding=\"utf-8\")\n</code></pre>"},{"location":"api_reference/datasets/dataset_schema/#pixano.datasets.dataset_schema.SchemaRelation","title":"<code>SchemaRelation</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Relation between tables.</p> <p>Attributes:</p> Name Type Description <code>ONE_TO_MANY</code> <p>One to many relation.</p> <code>MANY_TO_ONE</code> <p>Many to one relation.</p> <code>ONE_TO_ONE</code> <p>One to one relation.</p> <code>MANY_TO_MANY</code> <p>Many to many relation</p>"},{"location":"api_reference/datasets/dataset_stat/","title":"dataset_stat","text":""},{"location":"api_reference/datasets/dataset_stat/#pixano.datasets.dataset_stat","title":"<code>pixano.datasets.dataset_stat</code>","text":""},{"location":"api_reference/datasets/dataset_stat/#pixano.datasets.dataset_stat.DatasetStatistic","title":"<code>DatasetStatistic(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A statistic of a dataset.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the statistic.</p> <code>type</code> <code>str</code> <p>The type ('numerical' or 'categorical') of the statistic.</p> <code>histogram</code> <code>list[dict[str, float | int | str]]</code> <p>The histogram of the statistic.</p> <code>range</code> <code>list[int | float] | None</code> <p>The range of the statistic.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            stacklevel=2,\n        )\n</code></pre>"},{"location":"api_reference/datasets/dataset_stat/#pixano.datasets.dataset_stat.DatasetStatistic.from_json","title":"<code>from_json(json_fp)</code>  <code>staticmethod</code>","text":"<p>Read list of <code>DatasetStatistic</code> from a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>json_fp</code> <code>Path</code> <p>JSON file path.</p> required <p>Returns:</p> Type Description <code>list[DatasetStatistic]</code> <p>A list of <code>DatasetStat</code>.</p> Source code in <code>pixano/datasets/dataset_stat.py</code> <pre><code>@staticmethod\ndef from_json(json_fp: Path) -&gt; list[\"DatasetStatistic\"]:\n    \"\"\"Read list of `DatasetStatistic` from a JSON file.\n\n    Args:\n        json_fp: JSON file path.\n\n    Returns:\n        A list of `DatasetStat`.\n    \"\"\"\n    stats_json = json.loads(json_fp.read_text(encoding=\"utf-8\"))\n\n    return [DatasetStatistic.model_validate(stat) for stat in stats_json]\n</code></pre>"},{"location":"api_reference/datasets/dataset_stat/#pixano.datasets.dataset_stat.DatasetStatistic.to_json","title":"<code>to_json(json_fp)</code>","text":"<p>Save <code>DatasetStatistic</code> to a json file.</p> <p>Replace the existing histogram in <code>json_fp</code>.</p> <p>Parameters:</p> Name Type Description Default <code>json_fp</code> <code>Path</code> <p>Save directory.</p> required Source code in <code>pixano/datasets/dataset_stat.py</code> <pre><code>def to_json(self, json_fp: Path) -&gt; None:\n    \"\"\"Save `DatasetStatistic` to a json file.\n\n    Replace the existing histogram in `json_fp`.\n\n    Args:\n        json_fp: Save directory.\n    \"\"\"\n    try:\n        stats_json = json.loads(json_fp.read_text(encoding=\"utf-8\"))\n    except FileNotFoundError:\n        stats_json = []\n    # keep all stats except the one with same name, we replace it if exist\n    stats_json = [stat for stat in stats_json if stat[\"name\"] != self.name]\n    stats_json.append({\"name\": self.name, \"type\": self.type, \"histogram\": self.histogram, \"range\": self.range})\n\n    json_fp.write_text(json.dumps(stats_json, indent=4), encoding=\"utf-8\")\n</code></pre>"},{"location":"api_reference/datasets/builders/dataset_builder/","title":"dataset_builder","text":""},{"location":"api_reference/datasets/builders/dataset_builder/#pixano.datasets.builders.dataset_builder","title":"<code>pixano.datasets.builders.dataset_builder</code>","text":""},{"location":"api_reference/datasets/builders/dataset_builder/#pixano.datasets.builders.dataset_builder.DatasetBuilder","title":"<code>DatasetBuilder(target_dir, dataset_item, info)</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for dataset builders.</p> <p>To build a dataset, inherit from this class, implement the <code>generate_data</code> method and launch the <code>build</code> method.</p> <p>Attributes:</p> Name Type Description <code>target_dir</code> <code>Path</code> <p>The target directory for the dataset.</p> <code>previews_path</code> <code>Path</code> <p>The path to the previews directory.</p> <code>info</code> <code>DatasetInfo</code> <p>Dataset information (name, description, ...).</p> <code>dataset_schema</code> <code>DatasetSchema</code> <p>The schema of the dataset.</p> <code>schemas</code> <code>dict[str, type[BaseSchema]]</code> <p>The schemas of the dataset tables.</p> <code>db</code> <code>DBConnection</code> <p>The connection to the <code>LanceDB</code> database of the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>target_dir</code> <code>Path | str</code> <p>The target directory for the dataset.</p> required <code>dataset_item</code> <code>type[DatasetItem]</code> <p>The dataset item schema.</p> required <code>info</code> <code>DatasetInfo</code> <p>Dataset information (name, description, ...).</p> required Source code in <code>pixano/datasets/builders/dataset_builder.py</code> <pre><code>def __init__(\n    self,\n    target_dir: Path | str,\n    dataset_item: type[DatasetItem],\n    info: DatasetInfo,\n):\n    \"\"\"Initialize a DatasetBuilder instance.\n\n    Args:\n        target_dir: The target directory for the dataset.\n        dataset_item: The dataset item schema.\n        info: Dataset information (name, description, ...).\n    \"\"\"\n    self.target_dir: Path = Path(target_dir)\n    self.previews_path: Path = self.target_dir / Dataset._PREVIEWS_PATH\n\n    self.info: DatasetInfo = info\n    self.dataset_schema: DatasetSchema = dataset_item.to_dataset_schema()\n    self.schemas: dict[str, type[BaseSchema]] = self.dataset_schema.schemas\n\n    self.db: lancedb.DBConnection = lancedb.connect(self.target_dir / Dataset._DB_PATH)\n</code></pre>"},{"location":"api_reference/datasets/builders/dataset_builder/#pixano.datasets.builders.dataset_builder.DatasetBuilder.item_schema","title":"<code>item_schema: type[Item]</code>  <code>property</code>","text":"<p>The item schema for the dataset.</p>"},{"location":"api_reference/datasets/builders/dataset_builder/#pixano.datasets.builders.dataset_builder.DatasetBuilder.item_schema_name","title":"<code>item_schema_name: str</code>  <code>property</code>","text":"<p>The item schema name for the dataset.</p>"},{"location":"api_reference/datasets/builders/dataset_builder/#pixano.datasets.builders.dataset_builder.DatasetBuilder.add_ground_truth_source","title":"<code>add_ground_truth_source(metadata={})</code>","text":"<p>Add a ground truth source to the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>str | dict[str, Any]</code> <p>Metadata of the ground truth source.</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>The id of the ground truth source.</p> Source code in <code>pixano/datasets/builders/dataset_builder.py</code> <pre><code>def add_ground_truth_source(self, metadata: str | dict[str, Any] = {}) -&gt; str:\n    \"\"\"Add a ground truth source to the dataset.\n\n    Args:\n        metadata: Metadata of the ground truth source.\n\n    Returns:\n        The id of the ground truth source.\n    \"\"\"\n    return self.add_source(\n        id=SourceKind.GROUND_TRUTH.value, name=\"Ground Truth\", kind=SourceKind.GROUND_TRUTH, metadata=metadata\n    )\n</code></pre>"},{"location":"api_reference/datasets/builders/dataset_builder/#pixano.datasets.builders.dataset_builder.DatasetBuilder.add_source","title":"<code>add_source(name, kind, metadata={}, id='')</code>","text":"<p>Add a source to the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the source.</p> required <code>kind</code> <code>str | SourceKind</code> <p>Kind of source.</p> required <code>metadata</code> <code>str | dict[str, Any]</code> <p>Metadata of the source. If a dict is provided, it is converted to a JSON string.</p> <code>{}</code> <code>id</code> <code>str</code> <p>The id of the source. If not provided, a random id is generated.</p> <code>''</code> <p>Returns:</p> Type Description <code>str</code> <p>The id of the source.</p> Source code in <code>pixano/datasets/builders/dataset_builder.py</code> <pre><code>def add_source(\n    self,\n    name: str,\n    kind: str | SourceKind,\n    metadata: str | dict[str, Any] = {},\n    id: str = \"\",\n) -&gt; str:\n    \"\"\"Add a source to the dataset.\n\n    Args:\n        name: Name of the source.\n        kind: Kind of source.\n        metadata: Metadata of the source. If a dict is provided, it is converted to a JSON string.\n        id: The id of the source. If not provided, a random id is generated.\n\n    Returns:\n        The id of the source.\n    \"\"\"\n    if id == \"\":\n        id = shortuuid.uuid()\n    if isinstance(kind, str):\n        kind = SourceKind(kind)\n    self.db.open_table(\"source\").add([Source(id=id, name=name, kind=kind.value, metadata=metadata)])\n    return id\n</code></pre>"},{"location":"api_reference/datasets/builders/dataset_builder/#pixano.datasets.builders.dataset_builder.DatasetBuilder.build","title":"<code>build(mode='create', flush_every_n_samples=None, compact_every_n_transactions=None, check_integrity='raise')</code>","text":"<p>Build the dataset.</p> <p>It generates data from the source directory and insert them in the tables of the database.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>Literal['add', 'create', 'overwrite']</code> <p>The mode for creating the tables in the database. The mode can be \"create\", \"overwrite\" or \"add\":     - \"create\": Create the tables in the database. If the tables already exist, an error is raised.     - \"overwrite\": Overwrite the tables in the database.     - \"add\": Append to the tables in the database.</p> <code>'create'</code> <code>flush_every_n_samples</code> <code>int | None</code> <p>The number of samples accumulated from <code>generate_data</code> before they are flushed in tables. The counter is per table. If None, data are inserted at each iteration.</p> <code>None</code> <code>compact_every_n_transactions</code> <code>int | None</code> <p>The number of transactions before compacting each table. If None, the dataset is compacted only at the end.</p> <code>None</code> <code>check_integrity</code> <code>Literal['raise', 'warn', 'none']</code> <p>The integrity check to perform after building the dataset. It can be \"raise\", \"warn\" or \"none\":     - \"raise\": Raise an error if integrity errors are found.     - \"warn\": Print a warning if integrity errors are found.     - \"none\": Do not check integrity.</p> <code>'raise'</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>The built dataset.</p> Source code in <code>pixano/datasets/builders/dataset_builder.py</code> <pre><code>def build(\n    self,\n    mode: Literal[\"add\", \"create\", \"overwrite\"] = \"create\",\n    flush_every_n_samples: int | None = None,\n    compact_every_n_transactions: int | None = None,\n    check_integrity: Literal[\"raise\", \"warn\", \"none\"] = \"raise\",\n) -&gt; Dataset:\n    \"\"\"Build the dataset.\n\n    It generates data from the source directory and insert them in the tables of the database.\n\n    Args:\n        mode: The mode for creating the tables in the database.\n            The mode can be \"create\", \"overwrite\" or \"add\":\n                - \"create\": Create the tables in the database. If the tables already exist, an error is raised.\n                - \"overwrite\": Overwrite the tables in the database.\n                - \"add\": Append to the tables in the database.\n        flush_every_n_samples: The number of samples accumulated from `generate_data` before they are\n            flushed in tables. The counter is per table. If None, data are inserted at each iteration.\n        compact_every_n_transactions: The number of transactions before compacting each table.\n            If None, the dataset is compacted only at the end.\n        check_integrity: The integrity check to perform after building the dataset. It can be \"raise\",\n            \"warn\" or \"none\":\n                - \"raise\": Raise an error if integrity errors are found.\n                - \"warn\": Print a warning if integrity errors are found.\n                - \"none\": Do not check integrity.\n\n    Returns:\n        The built dataset.\n    \"\"\"\n    if mode not in [\"add\", \"create\", \"overwrite\"]:\n        raise ValueError(f\"mode should be 'add', 'create' or 'overwrite' but got {mode}\")\n    if check_integrity not in [\"raise\", \"warn\", \"none\"]:\n        raise ValueError(f\"check_integrity should be 'raise', 'warn' or 'none' but got {check_integrity}\")\n    if flush_every_n_samples is not None and flush_every_n_samples &lt;= 0:\n        raise ValueError(f\"flush_every_n_samples should be greater than 0 but got {flush_every_n_samples}\")\n    if compact_every_n_transactions is not None and compact_every_n_transactions &lt;= 0:\n        raise ValueError(\n            f\"compact_every_n_transactions should be greater than 0 but got {compact_every_n_transactions}\"\n        )\n\n    if mode == \"add\":\n        tables = self.open_tables()\n    else:\n        tables = self.create_tables(mode)\n\n    # accumulate items to insert in tables\n    accumulate_data_tables: dict[str, list] = {table_name: [] for table_name in tables.keys()}\n    # count transactions per table\n    transactions_per_table: dict[str, int] = {table_name: 0 for table_name in tables.keys()}\n\n    print(\"Building dataset...\")\n    for items in tqdm.tqdm(self.generate_data(), desc=\"Generate data\"):\n        # assert that items have keys that are in tables\n        for table_name, item_value in items.items():\n            if item_value is None or item_value == []:\n                continue\n            if table_name not in tables:\n                raise KeyError(f\"Table {table_name} not found in tables\")\n\n            accumulate_data_tables[table_name].extend(item_value if isinstance(item_value, list) else [item_value])\n\n            # make transaction every n iterations per table\n            if len(accumulate_data_tables[table_name]) &gt; 0 and (\n                flush_every_n_samples is None\n                or len(accumulate_data_tables[table_name]) % flush_every_n_samples == 0\n            ):\n                table = tables[table_name]\n                table.add(accumulate_data_tables[table_name])\n                transactions_per_table[table_name] += 1\n                accumulate_data_tables[table_name] = []\n\n            # compact dataset every n transactions per table\n            if (\n                compact_every_n_transactions is not None\n                and transactions_per_table[table_name] % compact_every_n_transactions == 0\n                and transactions_per_table[table_name] &gt; 0\n            ):\n                self.compact_table(table_name)\n\n    # make transaction for final batch\n    for table_name, table in tables.items():\n        if len(accumulate_data_tables[table_name]) &gt; 0:\n            table.add(accumulate_data_tables[table_name])\n    self.compact_dataset()\n\n    # save info.json\n    self.info.id = shortuuid.uuid() if self.info.id == \"\" else self.info.id\n    self.info.to_json(self.target_dir / Dataset._INFO_FILE)\n\n    print(f\"Dataset built in {self.target_dir} with id {self.info.id}\")\n\n    # save features_values.json\n    # TMP: empty now\n    DatasetFeaturesValues().to_json(self.target_dir / Dataset._FEATURES_VALUES_FILE)\n\n    # remove previous schema.json if any\n    if (self.target_dir / Dataset._SCHEMA_FILE).exists():\n        (self.target_dir / Dataset._SCHEMA_FILE).unlink()\n    # save schema.json\n    self.dataset_schema.to_json(self.target_dir / Dataset._SCHEMA_FILE)\n\n    dataset = Dataset(self.target_dir)\n\n    if check_integrity != \"none\":\n        print(\"Checking dataset integrity...\")\n        handle_integrity_errors(check_dataset_integrity(dataset), raise_or_warn=check_integrity)\n\n    print(\"Dataset built successfully.\")\n    return dataset\n</code></pre>"},{"location":"api_reference/datasets/builders/dataset_builder/#pixano.datasets.builders.dataset_builder.DatasetBuilder.compact_dataset","title":"<code>compact_dataset()</code>","text":"<p>Compact the dataset by calling <code>compact_table</code> for each table in the database.</p> Source code in <code>pixano/datasets/builders/dataset_builder.py</code> <pre><code>def compact_dataset(self) -&gt; None:\n    \"\"\"Compact the dataset by calling `compact_table` for each table in the database.\"\"\"\n    for table_name in self.schemas.keys():\n        self.compact_table(table_name)\n</code></pre>"},{"location":"api_reference/datasets/builders/dataset_builder/#pixano.datasets.builders.dataset_builder.DatasetBuilder.compact_table","title":"<code>compact_table(table_name)</code>","text":"<p>Compact a table by cleaning up old versions and compacting files.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>The name of the table to compact.</p> required Source code in <code>pixano/datasets/builders/dataset_builder.py</code> <pre><code>def compact_table(self, table_name: str) -&gt; None:\n    \"\"\"Compact a table by cleaning up old versions and compacting files.\n\n    Args:\n        table_name: The name of the table to compact.\n    \"\"\"\n    table = self.db.open_table(table_name)\n    table.compact_files(\n        target_rows_per_fragment=1048576, max_rows_per_group=1024, materialize_deletions=False, num_threads=None\n    )\n    table.cleanup_old_versions(older_than=timedelta(days=0), delete_unverified=True)\n</code></pre>"},{"location":"api_reference/datasets/builders/dataset_builder/#pixano.datasets.builders.dataset_builder.DatasetBuilder.create_tables","title":"<code>create_tables(mode='create')</code>","text":"<p>Create tables in the database.</p> <p>Returns:</p> Type Description <code>dict[str, Table]</code> <p>The tables in the database.</p> Source code in <code>pixano/datasets/builders/dataset_builder.py</code> <pre><code>def create_tables(\n    self,\n    mode: Literal[\"create\", \"overwrite\"] = \"create\",\n) -&gt; dict[str, Table]:\n    \"\"\"Create tables in the database.\n\n    Returns:\n        The tables in the database.\n    \"\"\"\n    tables = {}\n    for key, schema in self.schemas.items():\n        self.db.create_table(key, schema=schema, mode=mode)\n\n        tables[key] = self.db.open_table(key)\n    self.db.create_table(\"source\", schema=Source, mode=mode)\n    tables[\"source\"] = self.db.open_table(\"source\")\n\n    return tables\n</code></pre>"},{"location":"api_reference/datasets/builders/dataset_builder/#pixano.datasets.builders.dataset_builder.DatasetBuilder.generate_data","title":"<code>generate_data()</code>  <code>abstractmethod</code>","text":"<p>Generate data from the source directory.</p> <p>It should yield a dictionary with keys corresponding to the table names and values corresponding to the data.</p> <p>It must be implemented in the subclass.</p> <p>Returns:</p> Type Description <code>Iterator[dict[str, BaseSchema | list[BaseSchema]]]</code> <p>An iterator over the data following the dataset schemas.</p> Source code in <code>pixano/datasets/builders/dataset_builder.py</code> <pre><code>@abstractmethod\ndef generate_data(self) -&gt; Iterator[dict[str, BaseSchema | list[BaseSchema]]]:\n    \"\"\"Generate data from the source directory.\n\n    It should yield a dictionary with keys corresponding to the table names and values corresponding to the data.\n\n    It must be implemented in the subclass.\n\n    Returns:\n        An iterator over the data following the dataset schemas.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api_reference/datasets/builders/dataset_builder/#pixano.datasets.builders.dataset_builder.DatasetBuilder.open_tables","title":"<code>open_tables()</code>","text":"<p>Open the tables in the database.</p> <p>Returns:</p> Type Description <code>dict[str, Table]</code> <p>The tables in the database.</p> Source code in <code>pixano/datasets/builders/dataset_builder.py</code> <pre><code>def open_tables(self) -&gt; dict[str, Table]:\n    \"\"\"Open the tables in the database.\n\n    Returns:\n        The tables in the database.\n    \"\"\"\n    tables = {}\n    for key in self.schemas.keys():\n        tables[key] = self.db.open_table(key)\n    tables[\"source\"] = self.db.open_table(\"source\")\n\n    return tables\n</code></pre>"},{"location":"api_reference/datasets/builders/folders/base/","title":"base","text":""},{"location":"api_reference/datasets/builders/folders/base/#pixano.datasets.builders.folders.base","title":"<code>pixano.datasets.builders.folders.base</code>","text":""},{"location":"api_reference/datasets/builders/folders/base/#pixano.datasets.builders.folders.base.FolderBaseBuilder","title":"<code>FolderBaseBuilder(source_dir, target_dir, dataset_item, info, url_prefix=None)</code>","text":"<p>               Bases: <code>DatasetBuilder</code></p> <p>This is a class for building datasets based on a folder structure.</p> The folder structure should be as follows <ul> <li>source_dir/{split}/{item}.{ext}</li> <li>source_dir/{split}/metadata.jsonl</li> </ul> <p>The metadata file should be a jsonl file with the following format: <pre><code>    [\n        {\n            \"item\": \"item1\",\n            \"metadata1\": \"value1\",\n            \"metadata2\": \"value2\",\n            ...\n            \"entities\": {\n                \"attr1\": [val1, val2, ...],\n                \"attr2\": [val1, val2, ...],\n                ...\n            }\n        },\n        {\n            \"item\": \"item2\",\n            \"metadata1\": \"value1\",\n            \"metadata2\": \"value2\",\n            ...\n            \"entities\": {\n                \"attr1\": [val1, val2, ...],\n                \"attr2\": [val1, val2, ...],\n                ...\n            }\n        },\n        ...\n    ]\n</code></pre></p> Note <p>Only one view and one entity are supported in folder builders.</p> <p>Attributes:</p> Name Type Description <code>source_dir</code> <p>The source directory for the dataset.</p> <code>view_name</code> <p>The name of the view schema.</p> <code>view_schema</code> <code>type[View]</code> <p>The schema of the view.</p> <code>entity_name</code> <p>The name of the entities schema.</p> <code>entity_schema</code> <code>type[Entity]</code> <p>The schema of the entities.</p> <code>METADATA_FILENAME</code> <code>str</code> <p>The metadata filename.</p> <code>EXTENSIONS</code> <code>list[str]</code> <p>The list of supported extensions.</p> <p>Parameters:</p> Name Type Description Default <code>source_dir</code> <code>Path | str</code> <p>The source directory for the dataset.</p> required <code>target_dir</code> <code>Path | str</code> <p>The target directory for the dataset.</p> required <code>dataset_item</code> <code>type[DatasetItem]</code> <p>The dataset item schema.</p> required <code>info</code> <code>DatasetInfo</code> <p>User informations (name, description, ...) for the dataset.</p> required <code>url_prefix</code> <code>Path | str | None</code> <p>The path to build relative URLs for the views. Useful to build dataset libraries to pass the relative path from the media directory.</p> <code>None</code> Source code in <code>pixano/datasets/builders/folders/base.py</code> <pre><code>def __init__(\n    self,\n    source_dir: Path | str,\n    target_dir: Path | str,\n    dataset_item: type[DatasetItem],\n    info: DatasetInfo,\n    url_prefix: Path | str | None = None,\n) -&gt; None:\n    \"\"\"Initialize the `FolderBaseBuilder`.\n\n    Args:\n        source_dir: The source directory for the dataset.\n        target_dir: The target directory for the dataset.\n        dataset_item: The dataset item schema.\n        info: User informations (name, description, ...) for the dataset.\n        url_prefix: The path to build relative URLs for the views. Useful to build dataset libraries to pass the\n            relative path from the media directory.\n    \"\"\"\n    super().__init__(target_dir=target_dir, dataset_item=dataset_item, info=info)\n    self.source_dir = Path(source_dir)\n    if url_prefix is None:\n        url_prefix = Path(\".\")\n    else:\n        url_prefix = Path(url_prefix)\n    self.url_prefix = url_prefix\n\n    view_name = None\n    entity_name = None\n    for k, s in self.schemas.items():\n        if issubclass(s, View):\n            if view_name is not None:\n                raise ValueError(\"Only one view schema is supported in folder based builders.\")\n            view_name = k\n            view_schema = s\n        if issubclass(s, Entity):\n            if entity_name is not None:\n                raise ValueError(\"Only one entity schema is supported in folder based builders.\")\n            entity_name = k\n            entity_schema = s\n    if view_name is None or entity_name is None:\n        raise ValueError(\"View and entity schemas must be defined in the schemas argument.\")\n    self.view_name = view_name\n    self.view_schema: type[View] = view_schema\n    self.entity_name = entity_name\n    self.entity_schema: type[Entity] = entity_schema\n</code></pre>"},{"location":"api_reference/datasets/builders/folders/base/#pixano.datasets.builders.folders.base.FolderBaseBuilder.generate_data","title":"<code>generate_data()</code>","text":"<p>Generate data from the source directory.</p> <p>Returns:</p> Type Description <code>Iterator[dict[str, BaseSchema | list[BaseSchema]]]</code> <p>An iterator over the data following the dataset schemas.</p> Source code in <code>pixano/datasets/builders/folders/base.py</code> <pre><code>def generate_data(\n    self,\n) -&gt; Iterator[dict[str, BaseSchema | list[BaseSchema]]]:\n    \"\"\"Generate data from the source directory.\n\n    Returns:\n        An iterator over the data following the dataset schemas.\n    \"\"\"\n    source_id = None\n    for split in self.source_dir.glob(\"*\"):\n        if split.is_dir() and not split.name.startswith(\".\"):\n            metadata = self._read_metadata(split / self.METADATA_FILENAME)\n\n            for view_file in split.glob(\"*\"):\n                # only consider {split}/{item}.{ext} files\n                if view_file.is_file() and view_file.suffix in self.EXTENSIONS:\n                    # retrieve item metadata in metadata file\n                    item_metadata = {}\n                    for m in metadata:\n                        if m[self.view_name] == view_file.name:\n                            item_metadata = m\n                            break\n                    if not item_metadata:\n                        raise ValueError(f\"Metadata not found for {view_file}\")\n\n                    # extract entity metadata from item metadata\n                    entities_data = item_metadata.pop(self.entity_name, None)\n\n                    # create item\n                    item = self._create_item(split.name, **item_metadata)\n\n                    # create view\n                    view = self._create_view(item, view_file, self.view_schema)\n\n                    if entities_data is None:\n                        yield {\n                            self.item_schema_name: item,\n                            self.view_name: view,\n                        }\n                        continue\n                    elif source_id is None:\n                        source_id = self.add_source(\"Builder\", SourceKind.OTHER)\n\n                    # create entities and their annotations\n                    entities, annotations = self._create_entities(item, view, entities_data, source_id)\n\n                    yield {\n                        self.item_schema_name: item,\n                        self.view_name: view,\n                        self.entity_name: entities,\n                        **annotations,\n                    }\n</code></pre>"},{"location":"api_reference/datasets/builders/folders/image/","title":"image","text":""},{"location":"api_reference/datasets/builders/folders/image/#pixano.datasets.builders.folders.image","title":"<code>pixano.datasets.builders.folders.image</code>","text":""},{"location":"api_reference/datasets/builders/folders/image/#pixano.datasets.builders.folders.image.ImageFolderBuilder","title":"<code>ImageFolderBuilder(source_dir, target_dir, dataset_item, info, url_prefix=None)</code>","text":"<p>               Bases: <code>FolderBaseBuilder</code></p> <p>Builder for image datasets stored in a folder.</p> <p>Parameters:</p> Name Type Description Default <code>source_dir</code> <code>Path | str</code> <p>The source directory for the dataset.</p> required <code>target_dir</code> <code>Path | str</code> <p>The target directory for the dataset.</p> required <code>dataset_item</code> <code>type[DatasetItem]</code> <p>The dataset item schema.</p> required <code>info</code> <code>DatasetInfo</code> <p>User informations (name, description, ...) for the dataset.</p> required <code>url_prefix</code> <code>Path | str | None</code> <p>The path to build relative URLs for the views. Useful to build dataset libraries to pass the relative path from the media directory.</p> <code>None</code> Source code in <code>pixano/datasets/builders/folders/base.py</code> <pre><code>def __init__(\n    self,\n    source_dir: Path | str,\n    target_dir: Path | str,\n    dataset_item: type[DatasetItem],\n    info: DatasetInfo,\n    url_prefix: Path | str | None = None,\n) -&gt; None:\n    \"\"\"Initialize the `FolderBaseBuilder`.\n\n    Args:\n        source_dir: The source directory for the dataset.\n        target_dir: The target directory for the dataset.\n        dataset_item: The dataset item schema.\n        info: User informations (name, description, ...) for the dataset.\n        url_prefix: The path to build relative URLs for the views. Useful to build dataset libraries to pass the\n            relative path from the media directory.\n    \"\"\"\n    super().__init__(target_dir=target_dir, dataset_item=dataset_item, info=info)\n    self.source_dir = Path(source_dir)\n    if url_prefix is None:\n        url_prefix = Path(\".\")\n    else:\n        url_prefix = Path(url_prefix)\n    self.url_prefix = url_prefix\n\n    view_name = None\n    entity_name = None\n    for k, s in self.schemas.items():\n        if issubclass(s, View):\n            if view_name is not None:\n                raise ValueError(\"Only one view schema is supported in folder based builders.\")\n            view_name = k\n            view_schema = s\n        if issubclass(s, Entity):\n            if entity_name is not None:\n                raise ValueError(\"Only one entity schema is supported in folder based builders.\")\n            entity_name = k\n            entity_schema = s\n    if view_name is None or entity_name is None:\n        raise ValueError(\"View and entity schemas must be defined in the schemas argument.\")\n    self.view_name = view_name\n    self.view_schema: type[View] = view_schema\n    self.entity_name = entity_name\n    self.entity_schema: type[Entity] = entity_schema\n</code></pre>"},{"location":"api_reference/datasets/builders/folders/video/","title":"video","text":""},{"location":"api_reference/datasets/builders/folders/video/#pixano.datasets.builders.folders.video","title":"<code>pixano.datasets.builders.folders.video</code>","text":""},{"location":"api_reference/datasets/builders/folders/video/#pixano.datasets.builders.folders.video.VideoFolderBuilder","title":"<code>VideoFolderBuilder(source_dir, target_dir, dataset_item, info, url_prefix=None)</code>","text":"<p>               Bases: <code>FolderBaseBuilder</code></p> <p>Builder for video datasets stored in a folder.</p> <p>Parameters:</p> Name Type Description Default <code>source_dir</code> <code>Path | str</code> <p>The source directory for the dataset.</p> required <code>target_dir</code> <code>Path | str</code> <p>The target directory for the dataset.</p> required <code>dataset_item</code> <code>type[DatasetItem]</code> <p>The dataset item schema.</p> required <code>info</code> <code>DatasetInfo</code> <p>User informations (name, description, ...) for the dataset.</p> required <code>url_prefix</code> <code>Path | str | None</code> <p>The path to build relative URLs for the views. Useful to build dataset libraries to pass the relative path from the media directory.</p> <code>None</code> Source code in <code>pixano/datasets/builders/folders/base.py</code> <pre><code>def __init__(\n    self,\n    source_dir: Path | str,\n    target_dir: Path | str,\n    dataset_item: type[DatasetItem],\n    info: DatasetInfo,\n    url_prefix: Path | str | None = None,\n) -&gt; None:\n    \"\"\"Initialize the `FolderBaseBuilder`.\n\n    Args:\n        source_dir: The source directory for the dataset.\n        target_dir: The target directory for the dataset.\n        dataset_item: The dataset item schema.\n        info: User informations (name, description, ...) for the dataset.\n        url_prefix: The path to build relative URLs for the views. Useful to build dataset libraries to pass the\n            relative path from the media directory.\n    \"\"\"\n    super().__init__(target_dir=target_dir, dataset_item=dataset_item, info=info)\n    self.source_dir = Path(source_dir)\n    if url_prefix is None:\n        url_prefix = Path(\".\")\n    else:\n        url_prefix = Path(url_prefix)\n    self.url_prefix = url_prefix\n\n    view_name = None\n    entity_name = None\n    for k, s in self.schemas.items():\n        if issubclass(s, View):\n            if view_name is not None:\n                raise ValueError(\"Only one view schema is supported in folder based builders.\")\n            view_name = k\n            view_schema = s\n        if issubclass(s, Entity):\n            if entity_name is not None:\n                raise ValueError(\"Only one entity schema is supported in folder based builders.\")\n            entity_name = k\n            entity_schema = s\n    if view_name is None or entity_name is None:\n        raise ValueError(\"View and entity schemas must be defined in the schemas argument.\")\n    self.view_name = view_name\n    self.view_schema: type[View] = view_schema\n    self.entity_name = entity_name\n    self.entity_schema: type[Entity] = entity_schema\n</code></pre>"},{"location":"api_reference/datasets/queries/table/","title":"table","text":""},{"location":"api_reference/datasets/queries/table/#pixano.datasets.queries.table","title":"<code>pixano.datasets.queries.table</code>","text":""},{"location":"api_reference/datasets/queries/table/#pixano.datasets.queries.table.TableQueryBuilder","title":"<code>TableQueryBuilder(table)</code>","text":"<p>Builder class for querying LanceTables.</p> <p>It supports the select, where, limit, offset, and order_by clauses: - The select clause can be used to select specific columns from the table. If not provided, all columns     are selected. - The where clause can be used to filter the rows of the table. - The limit clause can be used to limit the number of rows returned. - The offset clause can be used to skip the first n rows. - The order_by clause can be used to sort the rows of the table.</p> <p>The query is built and executed when calling to_pandas(), to_list(), to_pydantic(), or to_polars().</p> <p>Attributes:</p> Name Type Description <code>table</code> <code>LanceTable</code> <p>The LanceTable to query.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>LanceTable</code> <p>The LanceTable to query.</p> required Source code in <code>pixano/datasets/queries/table.py</code> <pre><code>def __init__(self, table: LanceTable):\n    \"\"\"Initializes the TableQueryBuilder.\n\n    Args:\n        table: The LanceTable to query.\n    \"\"\"\n    if not isinstance(table, LanceTable):\n        raise ValueError(\"table must be a LanceTable.\")\n\n    self.table: LanceTable = table\n    self._columns: list[str] | dict[str, str] | None = None\n    self._where: str | None = None\n    self._limit: int | None = None\n    self._offset: int | None = None\n    self._order_by: list[str] = []\n    self._descending: list[bool] = []\n    self._function_called: dict[str, bool] = {\n        \"select\": False,\n        \"where\": False,\n        \"limit\": False,\n        \"offset\": False,\n        \"order_by\": False,\n        \"build\": False,\n    }\n</code></pre>"},{"location":"api_reference/datasets/queries/table/#pixano.datasets.queries.table.TableQueryBuilder.limit","title":"<code>limit(limit)</code>","text":"<p>Sets the limit for the query.</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int | None</code> <p>The number of rows to return.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The TableQueryBuilder instance.</p> Source code in <code>pixano/datasets/queries/table.py</code> <pre><code>def limit(self, limit: int | None) -&gt; Self:\n    \"\"\"Sets the limit for the query.\n\n    Args:\n        limit: The number of rows to return.\n\n    Returns:\n        The TableQueryBuilder instance.\n    \"\"\"\n    self._check_called(\"limit\")\n    if limit is not None:\n        if not isinstance(limit, int) or limit &lt; 0:\n            raise ValueError(\"limit must be None or a positive integer.\")\n    self._limit = limit\n    return self\n</code></pre>"},{"location":"api_reference/datasets/queries/table/#pixano.datasets.queries.table.TableQueryBuilder.offset","title":"<code>offset(offset)</code>","text":"<p>Sets the offset for the query.</p> <p>Parameters:</p> Name Type Description Default <code>offset</code> <code>int | None</code> <p>The number of rows to skip.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The TableQueryBuilder instance.</p> Source code in <code>pixano/datasets/queries/table.py</code> <pre><code>def offset(self, offset: int | None) -&gt; Self:\n    \"\"\"Sets the offset for the query.\n\n    Args:\n        offset: The number of rows to skip.\n\n    Returns:\n        The TableQueryBuilder instance.\n    \"\"\"\n    self._check_called(\"offset\")\n    if offset is not None:\n        if not isinstance(offset, int) or offset &lt; 0:\n            raise ValueError(\"offset must be None or a positive integer.\")\n    self._offset = offset\n    return self\n</code></pre>"},{"location":"api_reference/datasets/queries/table/#pixano.datasets.queries.table.TableQueryBuilder.order_by","title":"<code>order_by(order_by, descending=False)</code>","text":"<p>Sets the order_by clause for the query.</p> <p>Parameters:</p> Name Type Description Default <code>order_by</code> <code>str | list[str]</code> <p>The column(s) to sort by.</p> required <code>descending</code> <code>bool | list[bool]</code> <p>Whether to sort in descending order.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The TableQueryBuilder instance.</p> Source code in <code>pixano/datasets/queries/table.py</code> <pre><code>def order_by(self, order_by: str | list[str], descending: bool | list[bool] = False) -&gt; Self:\n    \"\"\"Sets the order_by clause for the query.\n\n    Args:\n        order_by: The column(s) to sort by.\n        descending: Whether to sort in descending order.\n\n    Returns:\n        The TableQueryBuilder instance.\n    \"\"\"\n    self._check_called(\"order_by\")\n    if isinstance(order_by, str):\n        order_by = [order_by]\n    elif not isinstance(order_by, list) or not all(isinstance(x, str) for x in order_by):\n        raise ValueError(\"order_by must be a string or a list of strings.\")\n    if isinstance(descending, bool):\n        descending = [descending] * len(order_by)\n    elif (\n        not isinstance(descending, list)\n        or not all(isinstance(x, bool) for x in descending)\n        or len(descending) != len(order_by)\n    ):\n        raise ValueError(\"descending must be a boolean or a list of booleans with the same length as order_by.\")\n\n    self._order_by = order_by\n    self._descending = descending\n    return self\n</code></pre>"},{"location":"api_reference/datasets/queries/table/#pixano.datasets.queries.table.TableQueryBuilder.select","title":"<code>select(columns)</code>","text":"<p>Selects columns to include in the query.</p> Note <p>'id' is always included in the select clause.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>str | list[str] | dict[str, str]</code> <p>The columns to include in the query. If a list, the columns are selected in the order they are provided. If a dictionary, the keys are the column names and the values are the aliases.</p> required Source code in <code>pixano/datasets/queries/table.py</code> <pre><code>def select(self, columns: str | list[str] | dict[str, str]) -&gt; Self:\n    \"\"\"Selects columns to include in the query.\n\n    Note:\n        'id' is always included in the select clause.\n\n    Args:\n        columns: The columns to include in the query. If a list, the columns are selected in the order they are\n            provided. If a dictionary, the keys are the column names and the values are the aliases.\n    \"\"\"\n    self._check_called(\"select\")\n    if isinstance(columns, str):\n        columns = [columns]\n\n    if isinstance(columns, list) or isinstance(columns, dict):\n        if isinstance(columns, list) and not all(isinstance(x, str) for x in columns):\n            raise ValueError(\"columns must be a list of strings.\")\n        elif isinstance(columns, dict) and not all(\n            isinstance(k, str) and isinstance(v, str) for k, v in columns.items()\n        ):\n            raise ValueError(\"columns must be a dictionary with string keys and values.\")\n        if isinstance(columns, list) and \"id\" not in columns:\n            columns = [\"id\"] + columns\n        elif isinstance(columns, dict) and \"id\" not in columns.values():\n            columns[\"id\"] = \"id\"\n        self._columns = columns\n    else:\n        raise ValueError(\"columns must be a string, a list of string or a string mapping dictionary.\")\n    return self\n</code></pre>"},{"location":"api_reference/datasets/queries/table/#pixano.datasets.queries.table.TableQueryBuilder.to_list","title":"<code>to_list()</code>","text":"<p>Builds the query and returns the result as a list of dictionaries.</p> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>The result as a list of dictionaries.</p> Source code in <code>pixano/datasets/queries/table.py</code> <pre><code>def to_list(self) -&gt; list[dict[str, Any]]:\n    \"\"\"Builds the query and returns the result as a list of dictionaries.\n\n    Returns:\n        The result as a list of dictionaries.\n    \"\"\"\n    return _PixanoEmptyQueryBuilder(self._execute()).to_list()\n</code></pre>"},{"location":"api_reference/datasets/queries/table/#pixano.datasets.queries.table.TableQueryBuilder.to_pandas","title":"<code>to_pandas()</code>","text":"<p>Builds the query and returns the result as a pandas DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The result as a pandas DataFrame.</p> Source code in <code>pixano/datasets/queries/table.py</code> <pre><code>def to_pandas(self) -&gt; pd.DataFrame:\n    \"\"\"Builds the query and returns the result as a pandas DataFrame.\n\n    Returns:\n        The result as a pandas DataFrame.\n    \"\"\"\n    return _PixanoEmptyQueryBuilder(self._execute()).to_pandas()\n</code></pre>"},{"location":"api_reference/datasets/queries/table/#pixano.datasets.queries.table.TableQueryBuilder.to_polars","title":"<code>to_polars()</code>","text":"<p>Builds the query and returns the result as a polars DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The result as a polars DataFrame.</p> Source code in <code>pixano/datasets/queries/table.py</code> <pre><code>def to_polars(self) -&gt; pl.DataFrame:\n    \"\"\"Builds the query and returns the result as a polars DataFrame.\n\n    Returns:\n        The result as a polars DataFrame.\n    \"\"\"\n    return _PixanoEmptyQueryBuilder(self._execute()).to_polars()\n</code></pre>"},{"location":"api_reference/datasets/queries/table/#pixano.datasets.queries.table.TableQueryBuilder.to_pydantic","title":"<code>to_pydantic(model)</code>","text":"<p>Builds the query and returns the result as a list of Pydantic models.</p> <p>Returns:</p> Type Description <code>list[T]</code> <p>The result as a list of Pydantic models.</p> Source code in <code>pixano/datasets/queries/table.py</code> <pre><code>def to_pydantic(self, model: type[T]) -&gt; list[T]:\n    \"\"\"Builds the query and returns the result as a list of Pydantic models.\n\n    Returns:\n        The result as a list of Pydantic models.\n    \"\"\"\n    return _PixanoEmptyQueryBuilder(self._execute()).to_pydantic(model)\n</code></pre>"},{"location":"api_reference/datasets/queries/table/#pixano.datasets.queries.table.TableQueryBuilder.where","title":"<code>where(where)</code>","text":"<p>Sets the where clause for the query.</p> <p>Parameters:</p> Name Type Description Default <code>where</code> <code>str</code> <p>The condition to filter the rows.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The TableQueryBuilder instance.</p> Source code in <code>pixano/datasets/queries/table.py</code> <pre><code>def where(self, where: str) -&gt; Self:\n    \"\"\"Sets the where clause for the query.\n\n    Args:\n        where: The condition to filter the rows.\n\n    Returns:\n        The TableQueryBuilder instance.\n    \"\"\"\n    self._check_called(\"where\")\n    if not isinstance(where, str):\n        raise ValueError(\"where must be a string.\")\n    self._where = where\n    return self\n</code></pre>"},{"location":"api_reference/datasets/utils/errors/","title":"errors","text":""},{"location":"api_reference/datasets/utils/errors/#pixano.datasets.utils.errors","title":"<code>pixano.datasets.utils.errors</code>","text":""},{"location":"api_reference/datasets/utils/errors/#pixano.datasets.utils.errors.DatasetAccessError","title":"<code>DatasetAccessError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Error raised when accessing a dataset.</p>"},{"location":"api_reference/datasets/utils/errors/#pixano.datasets.utils.errors.DatasetIntegrityError","title":"<code>DatasetIntegrityError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Error raised when dataset integrity is compromised.</p>"},{"location":"api_reference/datasets/utils/errors/#pixano.datasets.utils.errors.DatasetPaginationError","title":"<code>DatasetPaginationError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Error raised when paginating a dataset.</p>"},{"location":"api_reference/datasets/utils/errors/#pixano.datasets.utils.errors.DatasetWriteError","title":"<code>DatasetWriteError</code>","text":"<p>               Bases: <code>ValueError</code></p> <p>Error raised when writing to a dataset.</p>"},{"location":"api_reference/datasets/utils/integrity/","title":"integrity","text":""},{"location":"api_reference/datasets/utils/integrity/#pixano.datasets.utils.integrity","title":"<code>pixano.datasets.utils.integrity</code>","text":""},{"location":"api_reference/datasets/utils/integrity/#pixano.datasets.utils.integrity.IntegrityCheck","title":"<code>IntegrityCheck</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Integrity check types.</p> <p>Attributes:</p> Name Type Description <code>DEFINED_ID</code> <p>Check if the id field is defined.</p> <code>UNIQUE_ID</code> <p>Check if the id field is unique.</p> <code>REF_NAME</code> <p>Check if the ref name is defined in the schema.</p> <code>REF_TYPE</code> <p>Check if the ref type is defined in the schema.</p> <code>REF_ID</code> <p>Check if the ref id is stored in the referenced table.</p>"},{"location":"api_reference/datasets/utils/integrity/#pixano.datasets.utils.integrity.check_dataset_integrity","title":"<code>check_dataset_integrity(dataset)</code>","text":"<p>Check the integrity of a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset to check.</p> required <p>Returns:</p> Type Description <code>List of errors as tuples with the following values</code> <code>-check_type</code> <p>Check type.</p> <code>-table</code> <p>Table name.</p> <code>-field_name</code> <p>Field name that caused the error.</p> <code>-schema_id</code> <p>Schema id that raised the error.</p> <code>-field</code> <p>Field value that caused the error.</p> Source code in <code>pixano/datasets/utils/integrity.py</code> <pre><code>def check_dataset_integrity(dataset: \"Dataset\") -&gt; list[tuple[IntegrityCheck, str, str, str, Any]]:\n    \"\"\"Check the integrity of a dataset.\n\n    Args:\n        dataset: Dataset to check.\n\n    Returns:\n        List of errors as tuples with the following values:\n        - check_type: Check type.\n        - table: Table name.\n        - field_name: Field name that caused the error.\n        - schema_id: Schema id that raised the error.\n        - field: Field value that caused the error.\n    \"\"\"\n    check_errors: list[tuple[IntegrityCheck, str, str, str, Any]] = []\n    for table_name in dataset.schema.schemas.keys():\n        check_errors.extend(check_table_integrity(table_name, dataset))\n    return check_errors\n</code></pre>"},{"location":"api_reference/datasets/utils/integrity/#pixano.datasets.utils.integrity.check_table_integrity","title":"<code>check_table_integrity(table_name, dataset, schemas=None, updating=False, ignore_checks=None)</code>","text":"<p>Check the integrity of schemas against a table.</p> <p>Parameters:</p> Name Type Description Default <code>table_name</code> <code>str</code> <p>Table name.</p> required <code>dataset</code> <code>Dataset</code> <p>Dataset that contains the table.</p> required <code>schemas</code> <code>list[BaseSchema] | None</code> <p>List of schemas to insert in table. If None, the table is checked, otherwise the schemas are checked against the table.</p> <code>None</code> <code>updating</code> <code>bool</code> <p>If True, the table is being updated. It is used to avoid checking the id uniqueness when updating schemas.</p> <code>False</code> <code>ignore_checks</code> <code>list[IntegrityCheck] | None</code> <p>List of integrity checks to ignore.</p> <code>None</code> <p>Returns:</p> Type Description <code>List of errors as tuples with the following values</code> <code>-check_type</code> <p>Check type.</p> <code>-table</code> <p>Table name.</p> <code>-field_name</code> <p>Field name that caused the error.</p> <code>-schema_id</code> <p>Schema id that raised the error.</p> <code>-field</code> <p>Field value that caused the error.</p> Source code in <code>pixano/datasets/utils/integrity.py</code> <pre><code>def check_table_integrity(\n    table_name: str,\n    dataset: \"Dataset\",\n    schemas: list[BaseSchema] | None = None,\n    updating: bool = False,\n    ignore_checks: list[IntegrityCheck] | None = None,\n) -&gt; list[tuple[IntegrityCheck, str, str, str, Any]]:\n    \"\"\"Check the integrity of schemas against a table.\n\n    Args:\n        table_name: Table name.\n        dataset: Dataset that contains the table.\n        schemas: List of schemas to insert in table. If None, the table is checked, otherwise the schemas are checked\n            against the table.\n        updating: If True, the table is being updated. It is used to avoid checking the id uniqueness when updating\n            schemas.\n        ignore_checks: List of integrity checks to ignore.\n\n    Returns:\n        List of errors as tuples with the following values:\n        - check_type: Check type.\n        - table: Table name.\n        - field_name: Field name that caused the error.\n        - schema_id: Schema id that raised the error.\n        - field: Field value that caused the error.\n    \"\"\"\n    table = dataset.open_table(table_name)\n\n    if ignore_checks is not None:\n        ignore_checks_set: set[IntegrityCheck] = {IntegrityCheck(check) for check in ignore_checks}\n    else:\n        ignore_checks_set = set()\n    table_schema = Source if table_name == \"source\" else dataset.schema.schemas[table_name]\n\n    checking_table = schemas is None\n    if schemas is None:\n        if updating:\n            raise ValueError(\"schemas must be provided when updating a table.\")\n        table_schema = cast(BaseSchema, table_schema)\n        fields_to_check = [\"id\"] + [\n            field_name\n            for field_name, field in table_schema.model_fields.items()\n            if field_name != \"id\"\n            and not isinstance(field.annotation, GenericAlias)\n            and is_schema_ref(field.annotation)\n        ]\n        model = create_model(\n            \"_Schema\",\n            __base__=LanceModel,\n            **{field_name: (table_schema.model_fields[field_name].annotation, ...) for field_name in fields_to_check},\n        )\n        schemas = TableQueryBuilder(table).select(fields_to_check).to_pydantic(model)\n\n    table_ids = [schema.id for schema in schemas]\n    count_ids: dict[str, int] = {}\n    for id in table_ids:\n        count_ids[id] = count_ids.get(id, 0) + 1\n    integrity_checks = get_integry_checks_from_schemas(schemas, table_name)\n    check_errors: dict[str, tuple[IntegrityCheck, str, str, str, Any]] = {}\n    ids_to_check: dict[str, str] = {}\n    schemas_refs_to_check: dict[str, list[tuple[str, str, SchemaRef, str]]] = {}\n\n    for check_type_id, checks in enumerate(integrity_checks):\n        check_type = IntegrityCheck(check_type_id)\n        if check_type in ignore_checks_set:\n            continue\n        for check_id, _, schema_id, field_name, field in checks:\n            if check_id in check_errors:\n                continue\n            if check_type == IntegrityCheck.DEFINED_ID and field == \"\":  # id is not defined\n                check_errors[check_id] = (check_type, table_name, field_name, schema_id, field)\n            elif check_type == IntegrityCheck.UNIQUE_ID:\n                if count_ids[schema_id] &gt; 1:  # id is not unique\n                    check_errors[check_id] = (check_type, table_name, field_name, schema_id, field)\n                elif not checking_table:\n                    ids_to_check[schema_id] = check_id\n            elif check_type == IntegrityCheck.REF_NAME:\n                field = cast(SchemaRef, field)\n                if field.name != \"\" and field.name not in (\n                    list(dataset.schema.schemas.keys()) + [\"source\"]\n                ):  # ref name is not defined\n                    check_errors[check_id] = (check_type, table_name, field_name, schema_id, field)\n            elif check_type == IntegrityCheck.REF_TYPE:\n                field = cast(SchemaRef, field)\n                if field.name == \"\":\n                    continue\n                field_type = type(field)\n                if is_view_ref(field_type):  # field is a view ref\n                    field = cast(ViewRef, field)\n                    if field.name not in dataset.schema.groups[SchemaGroup.VIEW]:  # field name is not a view\n                        check_errors[check_id] = (check_type, table_name, field_name, schema_id, field)\n                elif is_annotation_ref(field_type):  # field is an annotation ref\n                    field = cast(AnnotationRef, field)\n                    if (\n                        field.name not in dataset.schema.groups[SchemaGroup.ANNOTATION]\n                    ):  # field name is not an annotation\n                        check_errors[check_id] = (check_type, table_name, field_name, schema_id, field)\n                elif is_embedding_ref(field_type):  # field is an embedding ref\n                    field = cast(EmbeddingRef, field)\n                    if (\n                        field.name not in dataset.schema.groups[SchemaGroup.EMBEDDING]\n                    ):  # field name is not an embedding\n                        check_errors[check_id] = (check_type, table_name, field_name, schema_id, field)\n                elif is_entity_ref(field_type):  # field is an entity ref\n                    field = cast(EntityRef, field)\n                    if field.name not in dataset.schema.groups[SchemaGroup.ENTITY]:  # field name is not an entity\n                        check_errors[check_id] = (check_type, table_name, field_name, schema_id, field)\n                elif is_item_ref(field_type) or is_source_ref(field_type):\n                    pass  # item_ref and source_ref are validated before.\n            elif check_type == IntegrityCheck.REF_ID:  # ref id and ref item relation checked below\n                field = cast(SchemaRef, field)\n                if field_name == \"\":\n                    continue\n                # If the field is empty, the reference is to the table itself so no need to check\n                if field.id == \"\":\n                    continue\n                if field.name not in schemas_refs_to_check:\n                    schemas_refs_to_check[field.name] = []\n                schemas_refs_to_check[field.name].append((check_id, schema_id, field, field_name))\n\n    if not checking_table and not updating and len(ids_to_check) &gt; 0:\n        for id, found in dataset.find_ids_in_table(table_name, set(ids_to_check.keys())).items():\n            if found:\n                check_errors[ids_to_check[id]] = (IntegrityCheck.UNIQUE_ID, table_name, \"id\", id, id)\n\n    if len(check_errors) == len(\n        {check_id for check_id, *_ in integrity_checks[IntegrityCheck.REF_ID.value]}\n    ):  # all checks failed, no need to check later checks that are costly\n        return list(check_errors.values())\n\n    for ref_schema_name, refs in schemas_refs_to_check.items():\n        if ref_schema_name == \"\":\n            continue\n        ref_ids_to_check = {field_ref.id for check_id, _, field_ref, _ in refs if check_id not in check_errors}\n        found_ref_ids = dataset.find_ids_in_table(ref_schema_name, ref_ids_to_check)\n        for check_id, schema_id, field_ref, field_name in refs:\n            if check_id in check_errors:\n                continue\n            if not found_ref_ids[field_ref.id]:\n                check_errors[check_id] = (\n                    IntegrityCheck.REF_ID,\n                    table_name,\n                    field_name,\n                    schema_id,\n                    field_ref,\n                )\n\n    return list(check_errors.values())\n</code></pre>"},{"location":"api_reference/datasets/utils/integrity/#pixano.datasets.utils.integrity.get_integry_checks_from_schemas","title":"<code>get_integry_checks_from_schemas(schemas, table_name)</code>","text":"<p>Get the integrity checks to perform on a table.</p> <p>Parameters:</p> Name Type Description Default <code>schemas</code> <code>list[BaseSchema]</code> <p>List of schemas to check.</p> required <code>table_name</code> <code>str</code> <p>Table name.</p> required <p>Returns:</p> Type Description <code>list[list[tuple[str, str, str, str, Any]]]</code> <p>List of integrity checks to perform on the table. The checks are grouped by type.</p> <code>-check_id</code> <p>Check id (unique identifier for the checks). It is used to avoid checking subsequent checks with the same id when an error is found.</p> <code>-table</code> <p>Table name.</p> <code>-schema_id</code> <p>Schema id which is the id field value from the schema.</p> <code>-field_name</code> <p>Field name to check.</p> <code>-field</code> <p>Field value to check.</p> Source code in <code>pixano/datasets/utils/integrity.py</code> <pre><code>def get_integry_checks_from_schemas(\n    schemas: list[BaseSchema], table_name: str\n) -&gt; list[list[tuple[str, str, str, str, Any]]]:\n    \"\"\"Get the integrity checks to perform on a table.\n\n    Args:\n        schemas: List of schemas to check.\n        table_name: Table name.\n\n    Returns:\n        List of integrity checks to perform on the table. The checks are grouped by type.\n        - check_id: Check id (unique identifier for the checks). It is used to avoid checking subsequent checks with\n            the same id when an error is found.\n        - table: Table name.\n        - schema_id: Schema id which is the id field value from the schema.\n        - field_name: Field name to check.\n        - field: Field value to check.\n    \"\"\"\n    checks: list[list[tuple[str, str, str, str, Any]]] = [[] for _ in IntegrityCheck]\n    for schema in schemas:\n        schema_id = schema.id\n        check_id = shortuuid.uuid()\n        checks[IntegrityCheck.DEFINED_ID.value].append((check_id, table_name, schema_id, \"id\", schema_id))\n        checks[IntegrityCheck.UNIQUE_ID.value].append((check_id, table_name, schema_id, \"id\", schema_id))\n        for field_name, field in schema.model_fields.items():\n            if field_name == \"id\":\n                continue\n            if isinstance(field.annotation, GenericAlias):\n                continue\n            type_field = field.annotation\n            if is_schema_ref(type_field):\n                checks[IntegrityCheck.REF_NAME.value].append(\n                    (check_id, table_name, schema_id, field_name, getattr(schema, field_name))\n                )\n                checks[IntegrityCheck.REF_TYPE.value].append(\n                    (check_id, table_name, schema_id, field_name, getattr(schema, field_name))\n                )\n                checks[IntegrityCheck.REF_ID.value].append(\n                    (check_id, table_name, schema_id, field_name, getattr(schema, field_name))\n                )\n\n    return checks\n</code></pre>"},{"location":"api_reference/datasets/utils/integrity/#pixano.datasets.utils.integrity.handle_integrity_errors","title":"<code>handle_integrity_errors(check_errors, raise_or_warn='raise')</code>","text":"<p>Handle integrity check errors.</p> <p>Parameters:</p> Name Type Description Default <code>check_errors</code> <code>list[tuple[IntegrityCheck, str, str, str, Any]]</code> <p>List of errors.</p> required <code>raise_or_warn</code> <code>Literal['raise', 'warn']</code> <p>If \"raise\", raise a ValueError with the errors. If \"warn\", warns a UserWarning with the errors.</p> <code>'raise'</code> Source code in <code>pixano/datasets/utils/integrity.py</code> <pre><code>def handle_integrity_errors(\n    check_errors: list[tuple[IntegrityCheck, str, str, str, Any]],\n    raise_or_warn: Literal[\"raise\", \"warn\"] = \"raise\",\n) -&gt; None:\n    \"\"\"Handle integrity check errors.\n\n    Args:\n        check_errors: List of errors.\n        raise_or_warn: If \"raise\", raise a ValueError with the errors. If \"warn\", warns a UserWarning with the errors.\n    \"\"\"\n    if len(check_errors) == 0:\n        return\n    message = \"Integrity check errors:\\n\"\n    for check_type, table_name, field_name, schema_id, field in check_errors:\n        message += \"- \"\n        if check_type == IntegrityCheck.DEFINED_ID:\n            message += f\"An id is not defined in table {table_name}.\\n\"\n        elif check_type == IntegrityCheck.UNIQUE_ID:\n            message += f\"The id {schema_id} is not unique in table {table_name}.\\n\"\n        elif check_type == IntegrityCheck.REF_NAME:\n            message += f\"The reference {field_name} from {schema_id} to the table {field.name} does not exist.\\n\"\n        elif check_type == IntegrityCheck.REF_TYPE:\n            message += (\n                f\"The reference {field_name} from {schema_id} to the table {field.name} is to an invalid type. \"\n                f\"Got {type(field)}.\\n\"\n            )\n        elif check_type == IntegrityCheck.REF_ID:\n            message += (\n                f\"The reference {field_name} from {schema_id} to the table {field.name} has an invalid id. Got \"\n                f\"{field.id}.\\n\"\n            )\n    if raise_or_warn == \"raise\":\n        raise DatasetIntegrityError(message)\n    else:\n        warnings.warn(message, category=UserWarning)\n</code></pre>"},{"location":"api_reference/datasets/utils/labels/","title":"labels","text":""},{"location":"api_reference/datasets/utils/labels/#pixano.datasets.utils.labels","title":"<code>pixano.datasets.utils.labels</code>","text":""},{"location":"api_reference/datasets/utils/labels/#pixano.datasets.utils.labels.coco_ids_80to91","title":"<code>coco_ids_80to91(category_id)</code>","text":"<p>Return COCO category ID (80 to 91 classes).</p> <p>Parameters:</p> Name Type Description Default <code>category_id</code> <code>int</code> <p>Category ID (80 classes).</p> required <p>Returns:</p> Type Description <code>int</code> <p>Category ID (91 classes).</p> Source code in <code>pixano/datasets/utils/labels.py</code> <pre><code>def coco_ids_80to91(category_id: int) -&gt; int:\n    \"\"\"Return COCO category ID (80 to 91 classes).\n\n    Args:\n        category_id: Category ID (80 classes).\n\n    Returns:\n        Category ID (91 classes).\n    \"\"\"\n    coco_dict = {\n        1: 1,\n        2: 2,\n        3: 3,\n        4: 4,\n        5: 5,\n        6: 6,\n        7: 7,\n        8: 8,\n        9: 9,\n        10: 10,\n        11: 11,\n        12: 13,\n        13: 14,\n        14: 15,\n        15: 16,\n        16: 17,\n        17: 18,\n        18: 19,\n        19: 20,\n        20: 21,\n        21: 22,\n        22: 23,\n        23: 24,\n        24: 25,\n        25: 27,\n        26: 28,\n        27: 31,\n        28: 32,\n        29: 33,\n        30: 34,\n        31: 35,\n        32: 36,\n        33: 37,\n        34: 38,\n        35: 39,\n        36: 40,\n        37: 41,\n        38: 42,\n        39: 43,\n        40: 44,\n        41: 46,\n        42: 47,\n        43: 48,\n        44: 49,\n        45: 50,\n        46: 51,\n        47: 52,\n        48: 53,\n        49: 54,\n        50: 55,\n        51: 56,\n        52: 57,\n        53: 58,\n        54: 59,\n        55: 60,\n        56: 61,\n        57: 62,\n        58: 63,\n        59: 64,\n        60: 65,\n        61: 67,\n        62: 70,\n        63: 72,\n        64: 73,\n        65: 74,\n        66: 75,\n        67: 76,\n        68: 77,\n        69: 78,\n        70: 79,\n        71: 80,\n        72: 81,\n        73: 82,\n        74: 84,\n        75: 85,\n        76: 86,\n        77: 87,\n        78: 88,\n        79: 89,\n        80: 90,\n    }\n\n    return coco_dict[int(category_id)]\n</code></pre>"},{"location":"api_reference/datasets/utils/labels/#pixano.datasets.utils.labels.coco_names_80","title":"<code>coco_names_80(category_id)</code>","text":"<p>Return COCO category name (80 classes).</p> <p>Parameters:</p> Name Type Description Default <code>category_id</code> <code>int</code> <p>Category ID.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Category name.</p> Source code in <code>pixano/datasets/utils/labels.py</code> <pre><code>def coco_names_80(category_id: int) -&gt; str:\n    \"\"\"Return COCO category name (80 classes).\n\n    Args:\n        category_id: Category ID.\n\n    Returns:\n        Category name.\n    \"\"\"\n    coco_dict = {\n        1: \"person\",\n        2: \"bicycle\",\n        3: \"car\",\n        4: \"motorcycle\",\n        5: \"airplane\",\n        6: \"bus\",\n        7: \"train\",\n        8: \"truck\",\n        9: \"boat\",\n        10: \"traffic light\",\n        11: \"fire hydrant\",\n        12: \"stop sign\",\n        13: \"parking meter\",\n        14: \"bench\",\n        15: \"bird\",\n        16: \"cat\",\n        17: \"dog\",\n        18: \"horse\",\n        19: \"sheep\",\n        20: \"cow\",\n        21: \"elephant\",\n        22: \"bear\",\n        23: \"zebra\",\n        24: \"giraffe\",\n        25: \"backpack\",\n        26: \"umbrella\",\n        27: \"handbag\",\n        28: \"tie\",\n        29: \"suitcase\",\n        30: \"frisbee\",\n        31: \"skis\",\n        32: \"snowboard\",\n        33: \"sports ball\",\n        34: \"kite\",\n        35: \"baseball bat\",\n        36: \"baseball glove\",\n        37: \"skateboard\",\n        38: \"surfboard\",\n        39: \"tennis racket\",\n        40: \"bottle\",\n        41: \"wine glass\",\n        42: \"cup\",\n        43: \"fork\",\n        44: \"knife\",\n        45: \"spoon\",\n        46: \"bowl\",\n        47: \"banana\",\n        48: \"apple\",\n        49: \"sandwich\",\n        50: \"orange\",\n        51: \"broccoli\",\n        52: \"carrot\",\n        53: \"hot dog\",\n        54: \"pizza\",\n        55: \"donut\",\n        56: \"cake\",\n        57: \"chair\",\n        58: \"couch\",\n        59: \"potted plant\",\n        60: \"bed\",\n        61: \"dining table\",\n        62: \"toilet\",\n        63: \"tv\",\n        64: \"laptop\",\n        65: \"mouse\",\n        66: \"remote\",\n        67: \"keyboard\",\n        68: \"cell phone\",\n        69: \"microwave\",\n        70: \"oven\",\n        71: \"toaster\",\n        72: \"sink\",\n        73: \"refrigerator\",\n        74: \"book\",\n        75: \"clock\",\n        76: \"vase\",\n        77: \"scissors\",\n        78: \"teddy bear\",\n        79: \"hair drier\",\n        80: \"toothbrush\",\n    }\n\n    return coco_dict[int(category_id)]\n</code></pre>"},{"location":"api_reference/datasets/utils/labels/#pixano.datasets.utils.labels.coco_names_91","title":"<code>coco_names_91(cat_id)</code>","text":"<p>Return COCO category name (91 classes).</p> <p>Parameters:</p> Name Type Description Default <code>cat_id</code> <code>int</code> <p>Category ID.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Category name.</p> Source code in <code>pixano/datasets/utils/labels.py</code> <pre><code>def coco_names_91(cat_id: int) -&gt; str:\n    \"\"\"Return COCO category name (91 classes).\n\n    Args:\n        cat_id: Category ID.\n\n    Returns:\n        Category name.\n    \"\"\"\n    coco_dict = {\n        1: \"person\",\n        2: \"bicycle\",\n        3: \"car\",\n        4: \"motorcycle\",\n        5: \"airplane\",\n        6: \"bus\",\n        7: \"train\",\n        8: \"truck\",\n        9: \"boat\",\n        10: \"traffic light\",\n        11: \"fire hydrant\",\n        12: \"street sign\",\n        13: \"stop sign\",\n        14: \"parking meter\",\n        15: \"bench\",\n        16: \"bird\",\n        17: \"cat\",\n        18: \"dog\",\n        19: \"horse\",\n        20: \"sheep\",\n        21: \"cow\",\n        22: \"elephant\",\n        23: \"bear\",\n        24: \"zebra\",\n        25: \"giraffe\",\n        26: \"hat\",\n        27: \"backpack\",\n        28: \"umbrella\",\n        29: \"shoe\",\n        30: \"eye glasses\",\n        31: \"handbag\",\n        32: \"tie\",\n        33: \"suitcase\",\n        34: \"frisbee\",\n        35: \"skis\",\n        36: \"snowboard\",\n        37: \"sports ball\",\n        38: \"kite\",\n        39: \"baseball bat\",\n        40: \"baseball glove\",\n        41: \"skateboard\",\n        42: \"surfboard\",\n        43: \"tennis racket\",\n        44: \"bottle\",\n        45: \"plate\",\n        46: \"wine glass\",\n        47: \"cup\",\n        48: \"fork\",\n        49: \"knife\",\n        50: \"spoon\",\n        51: \"bowl\",\n        52: \"banana\",\n        53: \"apple\",\n        54: \"sandwich\",\n        55: \"orange\",\n        56: \"broccoli\",\n        57: \"carrot\",\n        58: \"hot dog\",\n        59: \"pizza\",\n        60: \"donut\",\n        61: \"cake\",\n        62: \"chair\",\n        63: \"couch\",\n        64: \"potted plant\",\n        65: \"bed\",\n        66: \"mirror\",\n        67: \"dining table\",\n        68: \"window\",\n        69: \"desk\",\n        70: \"toilet\",\n        71: \"door\",\n        72: \"tv\",\n        73: \"laptop\",\n        74: \"mouse\",\n        75: \"remote\",\n        76: \"keyboard\",\n        77: \"cell phone\",\n        78: \"microwave\",\n        79: \"oven\",\n        80: \"toaster\",\n        81: \"sink\",\n        82: \"refrigerator\",\n        83: \"blender\",\n        84: \"book\",\n        85: \"clock\",\n        86: \"vase\",\n        87: \"scissors\",\n        88: \"teddy bear\",\n        89: \"hair drier\",\n        90: \"toothbrush\",\n        91: \"hair brush\",\n    }\n\n    return coco_dict[int(cat_id)]\n</code></pre>"},{"location":"api_reference/datasets/utils/labels/#pixano.datasets.utils.labels.dota_ids","title":"<code>dota_ids(name)</code>","text":"<p>Return DOTAv2 category ID (18 classes).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Category name.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Category ID.</p> Source code in <code>pixano/datasets/utils/labels.py</code> <pre><code>def dota_ids(name: str) -&gt; int:\n    \"\"\"Return DOTAv2 category ID (18 classes).\n\n    Args:\n        name: Category name.\n\n    Returns:\n        Category ID.\n    \"\"\"\n    dota_dict = {\n        \"plane\": 1,\n        \"ship\": 2,\n        \"storage tank\": 3,\n        \"baseball diamond\": 4,\n        \"tennis court\": 5,\n        \"basketball court\": 6,\n        \"ground track field\": 7,\n        \"harbor\": 8,\n        \"bridge\": 9,\n        \"large vehicle\": 10,\n        \"small vehicle\": 11,\n        \"helicopter\": 12,\n        \"roundabout\": 13,\n        \"soccer ball field\": 14,\n        \"swimming pool\": 15,\n        \"container crane\": 16,\n        \"airport\": 17,\n        \"helipad\": 18,\n    }\n\n    return dota_dict[str(name).replace(\"-\", \" \")]\n</code></pre>"},{"location":"api_reference/datasets/utils/labels/#pixano.datasets.utils.labels.voc_names","title":"<code>voc_names(category_id)</code>","text":"<p>Return VOC category name (20 classes).</p> <p>Parameters:</p> Name Type Description Default <code>category_id</code> <code>int</code> <p>Category ID.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Category name.</p> Source code in <code>pixano/datasets/utils/labels.py</code> <pre><code>def voc_names(category_id: int) -&gt; str:\n    \"\"\"Return VOC category name (20 classes).\n\n    Args:\n        category_id: Category ID.\n\n    Returns:\n        Category name.\n    \"\"\"\n    voc_dict = {\n        1: \"aeroplane\",\n        2: \"bicycle\",\n        3: \"bird\",\n        4: \"boat\",\n        5: \"bottle\",\n        6: \"bus\",\n        7: \"car\",\n        8: \"cat\",\n        9: \"chair\",\n        10: \"cow\",\n        11: \"dining table\",\n        12: \"dog\",\n        13: \"horse\",\n        14: \"motorbike\",\n        15: \"person\",\n        16: \"potted plant\",\n        17: \"sheep\",\n        18: \"sofa\",\n        19: \"train\",\n        20: \"tv / monitor\",\n    }\n\n    return voc_dict[int(category_id)]\n</code></pre>"},{"location":"api_reference/datasets/utils/video/","title":"video","text":""},{"location":"api_reference/datasets/utils/video/#pixano.datasets.utils.video","title":"<code>pixano.datasets.utils.video</code>","text":""},{"location":"api_reference/datasets/utils/video/#pixano.datasets.utils.video.create_video_preview","title":"<code>create_video_preview(path, frame_urls, fps=25, scale=0.5)</code>","text":"<p>Create a video preview by writing a sequence of frames to a video file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path to the output video file.</p> required <code>frame_urls</code> <code>Iterable[str]</code> <p>URLs pointing to the frames of the video.</p> required <code>fps</code> <code>int</code> <p>The frames per second of the output video.</p> <code>25</code> <code>scale</code> <code>float</code> <p>The scale factor to resize the frames.</p> <code>0.5</code> Source code in <code>pixano/datasets/utils/video.py</code> <pre><code>def create_video_preview(path: Path, frame_urls: Iterable[str], fps: int = 25, scale: float = 0.5):\n    \"\"\"Create a video preview by writing a sequence of frames to a video file.\n\n    Args:\n        path: The path to the output video file.\n        frame_urls: URLs pointing to the frames of the video.\n        fps: The frames per second of the output video.\n        scale: The scale factor to resize the frames.\n    \"\"\"\n    # Import mediapy only when needed to avoid unnecessary dependencies.\n    import mediapy\n\n    frames = [mediapy.read_image(url) for url in frame_urls]\n\n    if scale &lt; 1:\n        size = frames[0].shape[:2]\n        target_size = (int(size[0] * scale), int(size[1] * scale))\n        frames = mediapy.resize_video(frames, target_size)\n\n    mediapy.write_video(path, frames, fps=fps)\n</code></pre>"},{"location":"api_reference/features/pyarrow_utils/","title":"pyarrow_utils","text":""},{"location":"api_reference/features/pyarrow_utils/#pixano.features.pyarrow_utils","title":"<code>pixano.features.pyarrow_utils</code>","text":""},{"location":"api_reference/features/schemas/base_schema/","title":"base_schema","text":""},{"location":"api_reference/features/schemas/base_schema/#pixano.features.schemas.base_schema","title":"<code>pixano.features.schemas.base_schema</code>","text":""},{"location":"api_reference/features/schemas/base_schema/#pixano.features.schemas.base_schema.BaseSchema","title":"<code>BaseSchema(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>LanceModel</code></p> <p>Base class for all schemas.</p> <p>All schemas should inherit from this class and therefore all elements in the dataset contains an id.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>the id of the manipulated object.</p> <code>created_at</code> <code>datetime</code> <p>the creation date of the object.</p> <code>updated_at</code> <code>datetime</code> <p>the last modification date of the object.</p> Note <p>If the <code>created_at</code> and <code>updated_at</code> fields are not provided, they are set to the current date and time.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/base_schema/#pixano.features.schemas.base_schema.BaseSchema.dataset","title":"<code>dataset: Dataset</code>  <code>property</code> <code>writable</code>","text":"<p>Get the dataset.</p>"},{"location":"api_reference/features/schemas/base_schema/#pixano.features.schemas.base_schema.BaseSchema.table_name","title":"<code>table_name: str</code>  <code>property</code> <code>writable</code>","text":"<p>Get the table name.</p>"},{"location":"api_reference/features/schemas/base_schema/#pixano.features.schemas.base_schema.BaseSchema.deserialize","title":"<code>deserialize(dataset_schema_json)</code>  <code>staticmethod</code>","text":"<p>Deserialize the dataset schema.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_schema_json</code> <code>dict[str, str | dict[str, Any]]</code> <p>Serialized dataset schema.</p> required <p>Returns:</p> Type Description <code>type['BaseSchema']</code> <p>The dataset schema.</p> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>@staticmethod\ndef deserialize(dataset_schema_json: dict[str, str | dict[str, Any]]) -&gt; type[\"BaseSchema\"]:\n    \"\"\"Deserialize the dataset schema.\n\n    Args:\n        dataset_schema_json: Serialized dataset schema.\n\n    Returns:\n        The dataset schema.\n    \"\"\"\n    from .registry import _PIXANO_SCHEMA_REGISTRY, _SCHEMA_REGISTRY\n\n    json_fields = dataset_schema_json[\"fields\"]\n    if not isinstance(json_fields, dict):\n        raise ValueError(\"Fields should be a dictionary.\")\n\n    fields: dict[str, Any] = {}\n    for key, value in json_fields.items():\n        if value[\"type\"] in _TYPES_REGISTRY:\n            type_ = _TYPES_REGISTRY[value[\"type\"]]\n        elif value[\"type\"] == \"FixedSizeList\":  # LanceDB Vector\n            type_ = value[\"type\"]\n            dim = value[\"dim\"]\n            value_type = DESERIALIZE_PYARROW_DATATYPE[value[\"value_type\"]]\n            type_ = Vector(dim, value_type)\n        else:\n            raise ValueError(f\"Type {value['type']} not registered\")\n        if value[\"collection\"]:\n            type_ = list[type_]  # type: ignore[valid-type]\n        fields[key] = (type_, ...)\n\n    schema, base_schema = dataset_schema_json[\"schema\"], dataset_schema_json[\"base_schema\"]\n\n    if not isinstance(schema, str) or not isinstance(base_schema, str):\n        raise ValueError(\"Schema and base schema should be strings.\")\n\n    if schema in _SCHEMA_REGISTRY:\n        table_type = _SCHEMA_REGISTRY[schema]\n    else:\n        table_type = _PIXANO_SCHEMA_REGISTRY[base_schema]\n\n    model = create_model(dataset_schema_json[\"schema\"], **fields, __base__=table_type)\n\n    return model\n</code></pre>"},{"location":"api_reference/features/schemas/base_schema/#pixano.features.schemas.base_schema.BaseSchema.model_dump","title":"<code>model_dump(exclude_timestamps=False, **kwargs)</code>","text":"<p>Dump the model to a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_timestamps</code> <code>bool</code> <p>Exclude timestamps \"created_at\" and \"updated_at\" from the model dump. Useful for comparing models without timestamps.</p> <code>False</code> <code>kwargs</code> <code>Any</code> <p>Arguments for pydantic <code>BaseModel.model_dump()</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The model dump.</p> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def model_dump(self, exclude_timestamps: bool = False, **kwargs: Any) -&gt; dict[str, Any]:\n    \"\"\"Dump the model to a dictionary.\n\n    Args:\n        exclude_timestamps: Exclude timestamps \"created_at\" and \"updated_at\" from the model dump. Useful for\n            comparing models without timestamps.\n        kwargs: Arguments for pydantic `BaseModel.model_dump()`.\n\n    Returns:\n        The model dump.\n    \"\"\"\n    model_dump = super().model_dump(**kwargs)\n    if exclude_timestamps:\n        model_dump.pop(\"created_at\", None)\n        model_dump.pop(\"updated_at\", None)\n    return model_dump\n</code></pre>"},{"location":"api_reference/features/schemas/base_schema/#pixano.features.schemas.base_schema.BaseSchema.resolve_ref","title":"<code>resolve_ref(ref)</code>","text":"<pre><code>resolve_ref(ref: 'ItemRef') -&gt; 'Item'\n</code></pre><pre><code>resolve_ref(ref: 'ViewRef') -&gt; 'View'\n</code></pre><pre><code>resolve_ref(ref: 'EmbeddingRef') -&gt; 'Embedding'\n</code></pre><pre><code>resolve_ref(ref: 'EntityRef') -&gt; 'Entity'\n</code></pre><pre><code>resolve_ref(ref: 'AnnotationRef') -&gt; 'Annotation'\n</code></pre><pre><code>resolve_ref(ref: 'SourceRef') -&gt; 'Source'\n</code></pre><pre><code>resolve_ref(ref: 'SchemaRef') -&gt; 'BaseSchema'\n</code></pre> <p>Resolve a reference to a schema object in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>ref</code> <code>'SchemaRef' | 'ItemRef' | 'ViewRef' | 'EmbeddingRef' | 'EntityRef' | 'AnnotationRef' | 'SourceRef'</code> <p>The reference to resolve.</p> required <p>Returns:</p> Type Description <code>'BaseSchema' | 'Item' | 'View' | 'Embedding' | 'Entity' | 'Annotation' | 'Source'</code> <p>The resolved schema object.</p> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def resolve_ref(\n    self, ref: \"SchemaRef\" | \"ItemRef\" | \"ViewRef\" | \"EmbeddingRef\" | \"EntityRef\" | \"AnnotationRef\" | \"SourceRef\"\n) -&gt; \"BaseSchema\" | \"Item\" | \"View\" | \"Embedding\" | \"Entity\" | \"Annotation\" | \"Source\":\n    \"\"\"Resolve a reference to a schema object in the dataset.\n\n    Args:\n        ref: The reference to resolve.\n\n    Returns:\n        The resolved schema object.\n    \"\"\"\n    return self.dataset.resolve_ref(ref)\n</code></pre>"},{"location":"api_reference/features/schemas/base_schema/#pixano.features.schemas.base_schema.BaseSchema.serialize","title":"<code>serialize()</code>  <code>classmethod</code>","text":"<p>Serialize the table.</p> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>@classmethod\ndef serialize(cls) -&gt; dict[str, str | dict[str, Any]]:\n    \"\"\"Serialize the table.\"\"\"\n    from .registry import _PIXANO_SCHEMA_REGISTRY\n\n    # schema can be customized by the user\n    # base_schema is the closest schema in the registry\n    super_type = get_super_type_from_dict(cls, _PIXANO_SCHEMA_REGISTRY)\n    if super_type is None:\n        raise ValueError(f\"Schema {cls.__name__} does not have a super type in the registry.\")\n    json: dict[str, str | dict[str, Any]] = {\n        \"schema\": cls.__name__,\n        \"base_schema\": super_type.__name__,\n    }\n    fields: dict[str, Any] = {}\n    for field_name, field in cls.model_fields.items():\n        if isinstance(field.annotation, GenericAlias):\n            origin = field.annotation.__origin__\n            args = field.annotation.__args__\n\n            if origin in [list, tuple]:\n                if issubclass(args[0], tuple(_TYPES_REGISTRY.values())):\n                    fields[field_name] = {\n                        \"type\": args[0].__name__,\n                        \"collection\": True,\n                    }\n                else:\n                    fields[field_name] = {\n                        \"type\": args[0].__name__,\n                        \"collection\": True,\n                    }\n            else:\n                raise NotImplementedError(\"Should be a list or tuple.\")\n        else:\n            if issubclass(field.annotation, tuple(_TYPES_REGISTRY.values())):\n                fields[field_name] = {\n                    \"type\": field.annotation.__name__,\n                    \"collection\": False,\n                }\n            elif issubclass(field.annotation, FixedSizeListMixin):  # LanceDB Vector\n                fields[field_name] = {\n                    \"type\": field.annotation.__name__,\n                    \"collection\": False,\n                    \"dim\": field.annotation.dim(),\n                    \"value_type\": SERIALIZE_PYARROW_DATATYPE[field.annotation.value_arrow_type()],\n                }\n            else:\n                fields[field_name] = {\n                    \"type\": field.annotation.__name__,\n                    \"collection\": False,\n                }\n    json[\"fields\"] = fields\n    return json\n</code></pre>"},{"location":"api_reference/features/schemas/base_schema/#pixano.features.schemas.base_schema.is_base_schema","title":"<code>is_base_schema(cls, strict=False)</code>","text":"<p>Check if a class is a <code>BaseSchema</code> or subclass of <code>BaseSchema</code>.</p> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def is_base_schema(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a `BaseSchema` or subclass of `BaseSchema`.\"\"\"\n    return issubclass_strict(cls, BaseSchema, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/registry/","title":"registry","text":""},{"location":"api_reference/features/schemas/registry/#pixano.features.schemas.registry","title":"<code>pixano.features.schemas.registry</code>","text":""},{"location":"api_reference/features/schemas/registry/#pixano.features.schemas.registry.register_schema","title":"<code>register_schema(cls)</code>","text":"<p>Class decorator to register a schema.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>type[BaseSchema]</code> <p>The schema to register.</p> required Source code in <code>pixano/features/schemas/registry.py</code> <pre><code>def register_schema(cls: type[BaseSchema]):\n    \"\"\"Class decorator to register a schema.\n\n    Args:\n        cls: The schema to register.\n    \"\"\"\n    _add_schema_to_registry(cls, _SCHEMA_REGISTRY)\n    return cls\n</code></pre>"},{"location":"api_reference/features/schemas/schema_group/","title":"schema_group","text":""},{"location":"api_reference/features/schemas/schema_group/#pixano.features.schemas.schema_group","title":"<code>pixano.features.schemas.schema_group</code>","text":""},{"location":"api_reference/features/schemas/schema_group/#pixano.features.schemas.schema_group.SchemaGroup","title":"<code>SchemaGroup</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Schema group.</p> <p>It defines the different schema groups to which a schema can belong.</p> <p>Attributes:</p> Name Type Description <code>ANNOTATION</code> <p>Annotation schema group.</p> <code>EMBEDDING</code> <p>Embedding schema group.</p> <code>ITEM</code> <p>Item schema group.</p> <code>ENTITY</code> <p>Entity schema group.</p> <code>VIEW</code> <p>View schema group.</p>"},{"location":"api_reference/features/schemas/source/","title":"source","text":""},{"location":"api_reference/features/schemas/source/#pixano.features.schemas.source","title":"<code>pixano.features.schemas.source</code>","text":""},{"location":"api_reference/features/schemas/source/#pixano.features.schemas.source.Source","title":"<code>Source(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>BaseSchema</code></p> <p>Source of the annotation.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the source.</p> <code>kind</code> <code>str</code> <p>Kind of source.</p> <code>metadata</code> <code>str</code> <p>Metadata of the source. dict[str, Any] encoded in a string.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/source/#pixano.features.schemas.source.Source.create_ground_truth","title":"<code>create_ground_truth(metadata={})</code>  <code>classmethod</code>","text":"<p>Create a ground truth source.</p> Source code in <code>pixano/features/schemas/source.py</code> <pre><code>@classmethod\ndef create_ground_truth(cls, metadata: str | dict[str, Any] = {}) -&gt; \"Source\":\n    \"\"\"Create a ground truth source.\"\"\"\n    return cls(\n        id=SourceKind.GROUND_TRUTH.value,\n        name=\"Ground Truth\",\n        kind=SourceKind.GROUND_TRUTH.value,\n        metadata=metadata,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/source/#pixano.features.schemas.source.SourceKind","title":"<code>SourceKind</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Kind of source that produced the annotation.</p> <p>Attributes:</p> Name Type Description <code>MODEL</code> <p>Source produced by a model.</p> <code>HUMAN</code> <p>Source produced by a human.</p> <code>GROUND_TRUTH</code> <p>The source is a ground truth.</p> <code>OTHER</code> <p>Source produced by other means.</p>"},{"location":"api_reference/features/schemas/source/#pixano.features.schemas.source.create_source","title":"<code>create_source(id, name, kind, metadata)</code>","text":"<p>Create a <code>Source</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>Identifier of the source.</p> required <code>name</code> <code>str</code> <p>Name of the source.</p> required <code>kind</code> <code>Literal['model', 'human', 'ground_truth', 'other'] | SourceKind</code> <p>Kind of source.</p> required <code>metadata</code> <code>str | dict[str, Any]</code> <p>Metadata of the source.</p> required <p>Returns:</p> Type Description <code>Source</code> <p>The created <code>Source</code> instance.</p> Source code in <code>pixano/features/schemas/source.py</code> <pre><code>def create_source(\n    id: str,\n    name: str,\n    kind: Literal[\"model\", \"human\", \"ground_truth\", \"other\"] | SourceKind,\n    metadata: str | dict[str, Any],\n) -&gt; Source:\n    \"\"\"Create a `Source` instance.\n\n    Args:\n        id: Identifier of the source.\n        name: Name of the source.\n        kind: Kind of source.\n        metadata: Metadata of the source.\n\n    Returns:\n        The created `Source` instance.\n    \"\"\"\n    return Source(id=id, name=name, kind=kind, metadata=metadata)\n</code></pre>"},{"location":"api_reference/features/schemas/source/#pixano.features.schemas.source.is_source","title":"<code>is_source(cls, strict=False)</code>","text":"<p>Check if a class is a Source or subclass of Source.</p> Source code in <code>pixano/features/schemas/source.py</code> <pre><code>def is_source(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a Source or subclass of Source.\"\"\"\n    return issubclass_strict(cls, Source, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/annotation/","title":"annotation","text":""},{"location":"api_reference/features/schemas/annotations/annotation/#pixano.features.schemas.annotations.annotation","title":"<code>pixano.features.schemas.annotations.annotation</code>","text":""},{"location":"api_reference/features/schemas/annotations/annotation/#pixano.features.schemas.annotations.annotation.Annotation","title":"<code>Annotation(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>BaseSchema</code></p> <p>Annotations are used to annotate an entity in a dataset.</p> <p>It can refer to an entity, an item, and a view.</p> <p>Attributes:</p> Name Type Description <code>item_ref</code> <code>ItemRef</code> <p>Reference to the annotation's item.</p> <code>view_ref</code> <code>ViewRef</code> <p>Reference to the annotation's view.</p> <code>entity_ref</code> <code>EntityRef</code> <p>Reference to the annotation's entity.</p> <code>source_ref</code> <code>SourceRef</code> <p>Reference to the annotation's source.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/annotation/#pixano.features.schemas.annotations.annotation.Annotation.entity","title":"<code>entity: Entity</code>  <code>property</code>","text":"<p>Get the annotation's entity.</p>"},{"location":"api_reference/features/schemas/annotations/annotation/#pixano.features.schemas.annotations.annotation.Annotation.item","title":"<code>item: Item</code>  <code>property</code>","text":"<p>Get the annotation's item.</p>"},{"location":"api_reference/features/schemas/annotations/annotation/#pixano.features.schemas.annotations.annotation.Annotation.view","title":"<code>view: View</code>  <code>property</code>","text":"<p>Get the annotation's view.</p>"},{"location":"api_reference/features/schemas/annotations/annotation/#pixano.features.schemas.annotations.annotation.is_annotation","title":"<code>is_annotation(cls, strict=False)</code>","text":"<p>Check if a class is an Annotation or subclass of Annotation.</p> Source code in <code>pixano/features/schemas/annotations/annotation.py</code> <pre><code>def is_annotation(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is an Annotation or subclass of Annotation.\"\"\"\n    return issubclass_strict(cls, Annotation, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/","title":"bbox","text":""},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox","title":"<code>pixano.features.schemas.annotations.bbox</code>","text":""},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.BBox","title":"<code>BBox(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>Annotation</code></p> <p>Bounding box using coordinates in xyxy or xywh format.</p> <p>Attributes:</p> Name Type Description <code>coords</code> <code>list[float]</code> <p>List of coordinates in given format.</p> <code>format</code> <code>str</code> <p>Coordinates format, 'xyxy' or 'xywh'.</p> <code>is_normalized</code> <code>bool</code> <p>True if coordinates are normalized to image size.</p> <code>confidence</code> <code>float</code> <p>Bounding box confidence if predicted. -1 if not predicted.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.BBox.xywh_coords","title":"<code>xywh_coords: list[float]</code>  <code>property</code>","text":"<p>Return the bounding box xywh coordinates.</p> <p>Returns:</p> Type Description <code>list[float]</code> <p>Coordinates in xywh format.</p>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.BBox.xyxy_coords","title":"<code>xyxy_coords: list[float]</code>  <code>property</code>","text":"<p>Return the bounding box xyxy coordinates.</p> <p>Returns:</p> Type Description <code>list[float]</code> <p>Coordinates in xyxy format.</p>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.BBox.denormalize","title":"<code>denormalize(height, width)</code>","text":"<p>Return the bounding box with coordinates denormalized relatively to the image size.</p> <p>Parameters:</p> Name Type Description Default <code>height</code> <code>int</code> <p>Image height.</p> required <code>width</code> <code>int</code> <p>Image width.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>Bounding box with coordinates denormalized relatively to the image size.</p> Source code in <code>pixano/features/schemas/annotations/bbox.py</code> <pre><code>def denormalize(self, height: int, width: int) -&gt; Self:\n    \"\"\"Return the bounding box with coordinates denormalized relatively to the image size.\n\n    Args:\n        height: Image height.\n        width: Image width.\n\n    Returns:\n        Bounding box with coordinates denormalized relatively to the image size.\n    \"\"\"\n    return BBox(\n        coords=bbox_utils.denormalize_coords(self.coords, height, width),\n        format=self.format,\n        is_normalized=False,\n        confidence=self.confidence,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.BBox.from_mask","title":"<code>from_mask(mask, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Create a bounding box using a NumPy array mask.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>NumPy array mask.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>BBox</code> <p>The bounding box.</p> Source code in <code>pixano/features/schemas/annotations/bbox.py</code> <pre><code>@staticmethod\ndef from_mask(mask: np.ndarray, **kwargs: Any) -&gt; \"BBox\":\n    \"\"\"Create a bounding box using a NumPy array mask.\n\n    Args:\n        mask: NumPy array mask.\n        kwargs: Additional arguments.\n\n    Returns:\n        The bounding box.\n    \"\"\"\n    return BBox.from_xywh(\n        xywh=bbox_utils.mask_to_bbox(mask),\n        is_normalized=True,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.BBox.from_rle","title":"<code>from_rle(rle, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Create a bounding box using a RLE mask.</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>CompressedRLE</code> <p>RLE mask.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>BBox</code> <p>The bounding box.</p> Source code in <code>pixano/features/schemas/annotations/bbox.py</code> <pre><code>@staticmethod\ndef from_rle(\n    rle: CompressedRLE,\n    **kwargs: Any,\n) -&gt; \"BBox\":\n    \"\"\"Create a bounding box using a RLE mask.\n\n    Args:\n        rle: RLE mask.\n        kwargs: Additional arguments.\n\n    Returns:\n        The bounding box.\n    \"\"\"\n    return BBox.from_mask(mask=rle.to_mask(), **kwargs)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.BBox.from_xywh","title":"<code>from_xywh(xywh, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Create a bounding box using normalized xywh coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>xywh</code> <code>list[float]</code> <p>List of coordinates in xywh format.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>BBox</code> <p>The bounding box.</p> Source code in <code>pixano/features/schemas/annotations/bbox.py</code> <pre><code>@staticmethod\ndef from_xywh(\n    xywh: list[float],\n    **kwargs: Any,\n) -&gt; \"BBox\":\n    \"\"\"Create a bounding box using normalized xywh coordinates.\n\n    Args:\n        xywh: List of coordinates in xywh format.\n        kwargs: Additional arguments.\n\n    Returns:\n        The bounding box.\n    \"\"\"\n    return BBox(\n        coords=xywh,\n        format=\"xywh\",\n        **kwargs,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.BBox.from_xyxy","title":"<code>from_xyxy(xyxy, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Create a bounding box using normalized xyxy coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>xyxy</code> <code>list[float]</code> <p>List of coordinates in xyxy format.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>BBox</code> <p>The bounding box.</p> Source code in <code>pixano/features/schemas/annotations/bbox.py</code> <pre><code>@staticmethod\ndef from_xyxy(\n    xyxy: list[float],\n    **kwargs: Any,\n) -&gt; \"BBox\":\n    \"\"\"Create a bounding box using normalized xyxy coordinates.\n\n    Args:\n        xyxy: List of coordinates in xyxy format.\n        kwargs: Additional arguments.\n\n    Returns:\n        The bounding box.\n    \"\"\"\n    return BBox(\n        coords=xyxy,\n        format=\"xyxy\",\n        **kwargs,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.BBox.none","title":"<code>none()</code>  <code>classmethod</code>","text":"<p>Utility function to get a <code>None</code> equivalent. Should be removed as soon as Lance manages <code>None</code> value.</p> <p>Returns:</p> Type Description <code>Self</code> <p>\"None\" <code>BBox</code>.</p> Source code in <code>pixano/features/schemas/annotations/bbox.py</code> <pre><code>@classmethod\ndef none(cls) -&gt; Self:\n    \"\"\"Utility function to get a `None` equivalent.\n    Should be removed as soon as Lance manages `None` value.\n\n    Returns:\n        \"None\" `BBox`.\n    \"\"\"\n    return cls(\n        id=\"\",\n        item=ItemRef.none(),\n        view=ViewRef.none(),\n        entity=EntityRef.none(),\n        coords=[0.0, 0.0, 0.0, 0.0],\n        format=\"xywh\",\n        is_normalized=True,\n        confidence=-1,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.BBox.normalize","title":"<code>normalize(height, width)</code>","text":"<p>Return the bounding box with coordinates normalized relatively to the image size.</p> <p>Parameters:</p> Name Type Description Default <code>height</code> <code>int</code> <p>Image height.</p> required <code>width</code> <code>int</code> <p>Image width.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>Bounding box with coordinates normalized relatively to the image size.</p> Source code in <code>pixano/features/schemas/annotations/bbox.py</code> <pre><code>def normalize(self, height: int, width: int) -&gt; Self:\n    \"\"\"Return the bounding box with coordinates normalized relatively to the image size.\n\n    Args:\n        height: Image height.\n        width: Image width.\n\n    Returns:\n        Bounding box with coordinates normalized relatively to the image size.\n    \"\"\"\n    return BBox(\n        coords=bbox_utils.normalize_coords(self.coords, height, width),\n        format=self.format,\n        is_normalized=True,\n        confidence=self.confidence,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.BBox.to_xywh","title":"<code>to_xywh()</code>","text":"<p>Return the bounding box in xywh format.</p> <p>Returns:</p> Type Description <code>Self</code> <p>Bounding box in xyxy format.</p> Source code in <code>pixano/features/schemas/annotations/bbox.py</code> <pre><code>def to_xywh(self) -&gt; Self:\n    \"\"\"Return the bounding box in xywh format.\n\n    Returns:\n        Bounding box in xyxy format.\n    \"\"\"\n    return BBox(\n        coords=self.xywh_coords,\n        format=\"xywh\",\n        is_normalized=self.is_normalized,\n        confidence=self.confidence,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.BBox.to_xyxy","title":"<code>to_xyxy()</code>","text":"<p>Return the bounding box in xyxy format.</p> <p>Returns:</p> Type Description <code>Self</code> <p>Bounding box in xyxy format.</p> Source code in <code>pixano/features/schemas/annotations/bbox.py</code> <pre><code>def to_xyxy(self) -&gt; Self:\n    \"\"\"Return the bounding box in xyxy format.\n\n    Returns:\n        Bounding box in xyxy format.\n    \"\"\"\n    return BBox(\n        coords=self.xyxy_coords,\n        format=\"xyxy\",\n        is_normalized=self.is_normalized,\n        confidence=self.confidence,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.BBox3D","title":"<code>BBox3D(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>Annotation</code></p> <p>A 3D bounding Box.</p> <p>Attributes:</p> Name Type Description <code>coords</code> <code>list[float]</code> <p>List of coordinates in given format.</p> <code>format</code> <code>str</code> <p>Coordinates format, 'xyzxyz' or 'xyzwhd'.</p> <code>heading</code> <code>list[float]</code> <p>Orientation of the bounding box.</p> <code>is_normalized</code> <code>bool</code> <p>True if coordinates are normalized to image size.</p> <code>confidence</code> <code>float</code> <p>Bounding box confidence if predicted. -1 if not predicted.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.BBox3D.none","title":"<code>none()</code>  <code>classmethod</code>","text":"<p>Utility function to get a <code>None</code> equivalent. Should be removed as soon as Lance manages <code>None</code> value.</p> <p>Returns:</p> Type Description <code>Self</code> <p>\"None\" BBox3D.</p> Source code in <code>pixano/features/schemas/annotations/bbox.py</code> <pre><code>@classmethod\ndef none(cls) -&gt; Self:\n    \"\"\"Utility function to get a `None` equivalent.\n    Should be removed as soon as Lance manages `None` value.\n\n    Returns:\n        \"None\" BBox3D.\n    \"\"\"\n    return cls(\n        id=\"\",\n        item=ItemRef.none(),\n        view=ViewRef.none(),\n        entity=EntityRef.none(),\n        coords=[0, 0, 0, 0, 0, 0],\n        format=\"xyzwhd\",\n        heading=[0, 0, 0],\n        is_normalized=True,\n        confidence=-1,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.create_bbox","title":"<code>create_bbox(coords, format, is_normalized, confidence=-1, id='', item_ref=ItemRef.none(), view_ref=ViewRef.none(), entity_ref=EntityRef.none(), source_ref=SourceRef.none())</code>","text":"<p>Create a <code>BBox</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>coords</code> <code>list[float]</code> <p>List of coordinates in given format.</p> required <code>format</code> <code>Literal['xyxy', 'xywh']</code> <p>Coordinates format, 'xyxy' or 'xywh'.</p> required <code>is_normalized</code> <code>bool</code> <p>True if coordinates are normalized to image size.</p> required <code>confidence</code> <code>float</code> <p>Bounding box confidence if predicted.</p> <code>-1</code> <code>id</code> <code>str</code> <p>BBox ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>view_ref</code> <code>ViewRef</code> <p>View reference.</p> <code>none()</code> <code>entity_ref</code> <code>EntityRef</code> <p>Entity reference.</p> <code>none()</code> <code>source_ref</code> <code>SourceRef</code> <p>Source reference.</p> <code>none()</code> <p>Returns:</p> Type Description <code>BBox</code> <p>The created <code>BBox</code> instance.</p> Source code in <code>pixano/features/schemas/annotations/bbox.py</code> <pre><code>def create_bbox(\n    coords: list[float],\n    format: Literal[\"xyxy\", \"xywh\"],\n    is_normalized: bool,\n    confidence: float = -1,\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    view_ref: ViewRef = ViewRef.none(),\n    entity_ref: EntityRef = EntityRef.none(),\n    source_ref: SourceRef = SourceRef.none(),\n) -&gt; BBox:\n    \"\"\"Create a `BBox` instance.\n\n    Args:\n        coords: List of coordinates in given format.\n        format: Coordinates format, 'xyxy' or 'xywh'.\n        is_normalized: True if coordinates are normalized to image size.\n        confidence: Bounding box confidence if predicted.\n        id: BBox ID.\n        item_ref: Item reference.\n        view_ref: View reference.\n        entity_ref: Entity reference.\n        source_ref: Source reference.\n\n    Returns:\n        The created `BBox` instance.\n    \"\"\"\n    return BBox(\n        id=id,\n        item_ref=item_ref,\n        view_ref=view_ref,\n        entity_ref=entity_ref,\n        source_ref=source_ref,\n        coords=coords,\n        format=str(format),\n        is_normalized=is_normalized,\n        confidence=confidence,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.create_bbox3d","title":"<code>create_bbox3d(coords, format, heading, is_normalized, confidence=-1.0, id='', item_ref=ItemRef.none(), view_ref=ViewRef.none(), entity_ref=EntityRef.none(), source_ref=SourceRef.none())</code>","text":"<p>Create a <code>BBox3D</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>coords</code> <code>list[float]</code> <p>The 3D position coordinates.</p> required <code>format</code> <code>Literal['xyzxyz', 'xyzwhd']</code> <p>Coordinates format, 'xyzxyz' or 'xyzwhd'.</p> required <code>heading</code> <code>list[float]</code> <p>The orientation.</p> required <code>is_normalized</code> <code>bool</code> <p>True if coordinates are normalized to image size.</p> required <code>confidence</code> <code>float</code> <p>Bounding box confidence if predicted.</p> <code>-1.0</code> <code>id</code> <code>str</code> <p>BBox3D ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>view_ref</code> <code>ViewRef</code> <p>View reference.</p> <code>none()</code> <code>entity_ref</code> <code>EntityRef</code> <p>Entity reference.</p> <code>none()</code> <code>source_ref</code> <code>SourceRef</code> <p>Source reference.</p> <code>none()</code> <p>Returns:</p> Type Description <code>BBox3D</code> <p>The created <code>BBox3D</code> instance.</p> Source code in <code>pixano/features/schemas/annotations/bbox.py</code> <pre><code>def create_bbox3d(\n    coords: list[float],\n    format: Literal[\"xyzxyz\", \"xyzwhd\"],\n    heading: list[float],\n    is_normalized: bool,\n    confidence: float = -1.0,\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    view_ref: ViewRef = ViewRef.none(),\n    entity_ref: EntityRef = EntityRef.none(),\n    source_ref: SourceRef = SourceRef.none(),\n) -&gt; BBox3D:\n    \"\"\"Create a `BBox3D` instance.\n\n    Args:\n        coords: The 3D position coordinates.\n        format: Coordinates format, 'xyzxyz' or 'xyzwhd'.\n        heading: The orientation.\n        is_normalized: True if coordinates are normalized to image size.\n        confidence: Bounding box confidence if predicted.\n        id: BBox3D ID.\n        item_ref: Item reference.\n        view_ref: View reference.\n        entity_ref: Entity reference.\n        source_ref: Source reference.\n\n    Returns:\n        The created `BBox3D` instance.\n    \"\"\"\n    return BBox3D(\n        id=id,\n        item_ref=item_ref,\n        view_ref=view_ref,\n        entity_ref=entity_ref,\n        source_ref=source_ref,\n        coords=coords,\n        format=str(format),\n        heading=heading,\n        is_normalized=is_normalized,\n        confidence=confidence,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.is_bbox","title":"<code>is_bbox(cls, strict=False)</code>","text":"<p>Check if a class is a <code>BBox</code> or a subclass of <code>BBox</code>.</p> Source code in <code>pixano/features/schemas/annotations/bbox.py</code> <pre><code>def is_bbox(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a `BBox` or a subclass of `BBox`.\"\"\"\n    return issubclass_strict(cls, BBox, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/bbox/#pixano.features.schemas.annotations.bbox.is_bbox3d","title":"<code>is_bbox3d(cls, strict=False)</code>","text":"<p>Check if a class is a <code>BBox3D</code> or subclass of <code>BBox3D</code>.</p> Source code in <code>pixano/features/schemas/annotations/bbox.py</code> <pre><code>def is_bbox3d(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a `BBox3D` or subclass of `BBox3D`.\"\"\"\n    return issubclass_strict(cls, BBox3D, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/camcalibration/","title":"camcalibration","text":""},{"location":"api_reference/features/schemas/annotations/camcalibration/#pixano.features.schemas.annotations.camcalibration","title":"<code>pixano.features.schemas.annotations.camcalibration</code>","text":""},{"location":"api_reference/features/schemas/annotations/camcalibration/#pixano.features.schemas.annotations.camcalibration.BaseIntrinsics","title":"<code>BaseIntrinsics</code>","text":"<p>               Bases: <code>BaseType</code></p> <p>BaseIntrinsics (TODO: description?).</p> <p>Attributes:</p> Name Type Description <code>cx_offset_px</code> <code>float</code> <p>cx_offset_px</p> <code>cy_offset_px</code> <code>float</code> <p>cy_offset_px</p> <code>img_height_px</code> <code>int</code> <p>img_height_px</p> <code>img_width_px</code> <code>int</code> <p>img_width_px</p>"},{"location":"api_reference/features/schemas/annotations/camcalibration/#pixano.features.schemas.annotations.camcalibration.CamCalibration","title":"<code>CamCalibration(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>Annotation</code></p> <p>Camera calibration.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>Type of camera.</p> <code>base_intrinsics</code> <code>BaseIntrinsics</code> <p>Base intrinsics values.</p> <code>extrinsics</code> <code>Extrinsics</code> <p>Extrinsics values.</p> <code>intrinsics</code> <code>Intrinsics</code> <p>Intrinsics values.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/camcalibration/#pixano.features.schemas.annotations.camcalibration.CamCalibration.none","title":"<code>none()</code>  <code>classmethod</code>","text":"<p>Utility function to get a <code>None</code> equivalent. Should be removed as soon as Lance manages <code>None</code> value.</p> <p>Returns:</p> Type Description <code>Self</code> <p>\"None\" <code>CamCalibration</code>.</p> Source code in <code>pixano/features/schemas/annotations/camcalibration.py</code> <pre><code>@classmethod\ndef none(cls) -&gt; Self:\n    \"\"\"Utility function to get a `None` equivalent.\n    Should be removed as soon as Lance manages `None` value.\n\n    Returns:\n        \"None\" `CamCalibration`.\n    \"\"\"\n    return cls(\n        id=\"\",\n        item_ref=ItemRef.none(),\n        view_ref=ViewRef.none(),\n        entity_ref=EntityRef.none(),\n        type=\"\",\n        base_intrinsics=BaseIntrinsics(\n            cx_offset_px=0.0,\n            cy_offset_px=0.0,\n            img_height_px=0,\n            img_width_px=0,\n        ),\n        extrinsics=Extrinsics(\n            pos_x_m=0.0,\n            pos_y_m=0.0,\n            pos_z_m=0.0,\n            rot_x_deg=0.0,\n            rot_z1_deg=0.0,\n            rot_z2_deg=0.0,\n        ),\n        intrinsics=Intrinsics(\n            c1=0.0,\n            c2=0.0,\n            c3=0.0,\n            c4=0.0,\n            pixel_aspect_ratio=0.0,\n        ),\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/camcalibration/#pixano.features.schemas.annotations.camcalibration.Extrinsics","title":"<code>Extrinsics</code>","text":"<p>               Bases: <code>BaseType</code></p> <p>Extrinsics (TODO: description?).</p> <p>Attributes:</p> Name Type Description <code>pos_x_m</code> <code>float</code> <p>pos_x_m.</p> <code>pos_y_m</code> <code>float</code> <p>pos_y_m.</p> <code>pos_z_m</code> <code>float</code> <p>pos_z_m.</p> <code>rot_x_deg</code> <code>float</code> <p>rot_x_deg.</p> <code>rot_z1_deg</code> <code>float</code> <p>rot_z1_deg.</p> <code>rot_z2_deg</code> <code>float</code> <p>rot_z2_deg.</p>"},{"location":"api_reference/features/schemas/annotations/camcalibration/#pixano.features.schemas.annotations.camcalibration.Intrinsics","title":"<code>Intrinsics</code>","text":"<p>               Bases: <code>BaseType</code></p> <p>Intrinsics (TODO: description?).</p> <p>Attributes:</p> Name Type Description <code>c1</code> <code>float</code> <p>c1.</p> <code>c2</code> <code>float</code> <p>c2.</p> <code>c3</code> <code>float</code> <p>c3.</p> <code>c4</code> <code>float</code> <p>c4.</p> <code>pixel_aspect_ratio</code> <code>float</code> <p>pixel_aspect_ratio.</p>"},{"location":"api_reference/features/schemas/annotations/camcalibration/#pixano.features.schemas.annotations.camcalibration.create_cam_calibration","title":"<code>create_cam_calibration(type, base_intrinsics=None, extrinsics=None, intrinsics=None, cx_offset_px=None, cy_offset_px=None, img_height_px=None, img_width_px=None, pos_x_m=None, pos_y_m=None, pos_z_m=None, rot_x_deg=None, rot_z1_deg=None, rot_z2_deg=None, c1=None, c2=None, c3=None, c4=None, pixel_aspect_ratio=None, id='', item_ref=ItemRef.none(), view_ref=ViewRef.none(), entity_ref=EntityRef.none(), source_ref=SourceRef.none(), validate=True)</code>","text":"<p>Create a <code>CamCalibration</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>str</code> <p>The type of camera.</p> required <code>base_intrinsics</code> <code>BaseIntrinsics | None</code> <p>The base intrinsics.</p> <code>None</code> <code>extrinsics</code> <code>Extrinsics | None</code> <p>The extrinsics.</p> <code>None</code> <code>intrinsics</code> <code>Intrinsics | None</code> <p>The intrinsics.</p> <code>None</code> <code>cx_offset_px</code> <code>float | None</code> <p>cx_offset_px.</p> <code>None</code> <code>cy_offset_px</code> <code>float | None</code> <p>cy_offset_px.</p> <code>None</code> <code>img_height_px</code> <code>int | None</code> <p>img_height_px.</p> <code>None</code> <code>img_width_px</code> <code>int | None</code> <p>img_width_px.</p> <code>None</code> <code>pos_x_m</code> <code>float | None</code> <p>pos_x_m.</p> <code>None</code> <code>pos_y_m</code> <code>float | None</code> <p>pos_y_m.</p> <code>None</code> <code>pos_z_m</code> <code>float | None</code> <p>pos_z_m.</p> <code>None</code> <code>rot_x_deg</code> <code>float | None</code> <p>rot_x_deg.</p> <code>None</code> <code>rot_z1_deg</code> <code>float | None</code> <p>rot_z1_deg.</p> <code>None</code> <code>rot_z2_deg</code> <code>float | None</code> <p>rot_z2_deg.</p> <code>None</code> <code>c1</code> <code>float | None</code> <p>c1.</p> <code>None</code> <code>c2</code> <code>float | None</code> <p>c2.</p> <code>None</code> <code>c3</code> <code>float | None</code> <p>c3.</p> <code>None</code> <code>c4</code> <code>float | None</code> <p>c4.</p> <code>None</code> <code>pixel_aspect_ratio</code> <code>float | None</code> <p>pixel_aspect_ratio.</p> <code>None</code> <code>id</code> <code>str</code> <p><code>CamCalibration</code> ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>view_ref</code> <code>ViewRef</code> <p>View reference.</p> <code>none()</code> <code>entity_ref</code> <code>EntityRef</code> <p>Entity reference.</p> <code>none()</code> <code>source_ref</code> <code>SourceRef</code> <p>Source reference.</p> <code>none()</code> <code>validate</code> <code>bool</code> <p>Set to False to skip pydantic validation.</p> <code>True</code> <p>Returns:</p> Type Description <code>CamCalibration</code> <p>The created <code>CamCalibration</code> instance.</p> Source code in <code>pixano/features/schemas/annotations/camcalibration.py</code> <pre><code>def create_cam_calibration(\n    type: str,\n    base_intrinsics: BaseIntrinsics | None = None,\n    extrinsics: Extrinsics | None = None,\n    intrinsics: Intrinsics | None = None,\n    cx_offset_px: float | None = None,\n    cy_offset_px: float | None = None,\n    img_height_px: int | None = None,\n    img_width_px: int | None = None,\n    pos_x_m: float | None = None,\n    pos_y_m: float | None = None,\n    pos_z_m: float | None = None,\n    rot_x_deg: float | None = None,\n    rot_z1_deg: float | None = None,\n    rot_z2_deg: float | None = None,\n    c1: float | None = None,\n    c2: float | None = None,\n    c3: float | None = None,\n    c4: float | None = None,\n    pixel_aspect_ratio: float | None = None,\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    view_ref: ViewRef = ViewRef.none(),\n    entity_ref: EntityRef = EntityRef.none(),\n    source_ref: SourceRef = SourceRef.none(),\n    validate: bool = True,\n) -&gt; CamCalibration:\n    \"\"\"Create a `CamCalibration` instance.\n\n    Args:\n        type: The type of camera.\n        base_intrinsics: The base intrinsics.\n        extrinsics: The extrinsics.\n        intrinsics: The intrinsics.\n        cx_offset_px: cx_offset_px.\n        cy_offset_px: cy_offset_px.\n        img_height_px: img_height_px.\n        img_width_px: img_width_px.\n        pos_x_m: pos_x_m.\n        pos_y_m: pos_y_m.\n        pos_z_m: pos_z_m.\n        rot_x_deg: rot_x_deg.\n        rot_z1_deg: rot_z1_deg.\n        rot_z2_deg: rot_z2_deg.\n        c1: c1.\n        c2: c2.\n        c3: c3.\n        c4: c4.\n        pixel_aspect_ratio: pixel_aspect_ratio.\n        id: `CamCalibration` ID.\n        item_ref: Item reference.\n        view_ref: View reference.\n        entity_ref: Entity reference.\n        source_ref: Source reference.\n        validate: Set to False to skip pydantic validation.\n\n    Returns:\n        The created `CamCalibration` instance.\n    \"\"\"\n    none_obj_conditions = [\n        base_intrinsics is None,\n        extrinsics is None,\n        intrinsics is None,\n    ]\n    not_none_obj_conditions = [\n        base_intrinsics is not None,\n        extrinsics is not None,\n        intrinsics is not None,\n    ]\n\n    none_field_conditions = [\n        cx_offset_px is None,\n        cy_offset_px is None,\n        img_height_px is None,\n        img_width_px is None,\n        pos_x_m is None,\n        pos_y_m is None,\n        pos_z_m is None,\n        rot_x_deg is None,\n        rot_z1_deg is None,\n        rot_z2_deg is None,\n        c1 is None,\n        c2 is None,\n        c3 is None,\n        c4 is None,\n        pixel_aspect_ratio is None,\n    ]\n\n    not_none_field_conditions = [\n        cx_offset_px is not None,\n        cy_offset_px is not None,\n        img_height_px is not None,\n        img_width_px is not None,\n        pos_x_m is not None,\n        pos_y_m is not None,\n        pos_z_m is not None,\n        rot_x_deg is not None,\n        rot_z1_deg is not None,\n        rot_z2_deg is not None,\n        c1 is not None,\n        c2 is not None,\n        c3 is not None,\n        c4 is not None,\n        pixel_aspect_ratio is not None,\n    ]\n\n    if not all(none_obj_conditions) and not all(not_none_obj_conditions):\n        raise ValueError(\"base_intrinsics, extrinsics and intrinsics must be all defined or all None\")\n    elif not all(none_field_conditions) and not all(not_none_field_conditions):\n        raise ValueError(\n            \"cx_offset_px, cy_offset_px, img_height_px, img_width_px, pos_x_m, pos_y_m, pos_z_m, \"\n            \"rot_x_deg, rot_z1_deg, rot_z2_deg, c1, c2, c3, c4 and pixel_aspect_ratio must be all \"\n            \"defined or all None\"\n        )\n    elif any(not_none_obj_conditions) and any(not_none_field_conditions):\n        raise ValueError(\n            \"base_intrinsics, extrinsics and intrinsics must defined or cx_offset_px, cy_offset_px, img_height_px, \"\n            \"img_width_px, pos_x_m, pos_y_m, pos_z_m, rot_x_deg, rot_z1_deg, rot_z2_deg, c1, c2, c3, c4 and \"\n            \"pixel_aspect_ratio must be defined but not both\"\n        )\n    if any(not_none_field_conditions):\n        if validate:\n            base_intrinsics = BaseIntrinsics(\n                cx_offset_px=cx_offset_px,\n                cy_offset_px=cy_offset_px,\n                img_height_px=img_height_px,\n                img_width_px=img_width_px,\n            )\n            extrinsics = Extrinsics(\n                pos_x_m=pos_x_m,\n                pos_y_m=pos_y_m,\n                pos_z_m=pos_z_m,\n                rot_x_deg=rot_x_deg,\n                rot_z1_deg=rot_z1_deg,\n                rot_z2_deg=rot_z2_deg,\n            )\n            intrinsics = Intrinsics(\n                c1=c1,\n                c2=c2,\n                c3=c3,\n                c4=c4,\n                pixel_aspect_ratio=pixel_aspect_ratio,\n            )\n        else:\n            base_intrinsics = BaseIntrinsics.construct(\n                cx_offset_px=cx_offset_px,\n                cy_offset_px=cy_offset_px,\n                img_height_px=img_height_px,\n                img_width_px=img_width_px,\n            )\n            extrinsics = Extrinsics.construct(\n                pos_x_m=pos_x_m,\n                pos_y_m=pos_y_m,\n                pos_z_m=pos_z_m,\n                rot_x_deg=rot_x_deg,\n                rot_z1_deg=rot_z1_deg,\n                rot_z2_deg=rot_z2_deg,\n            )\n            intrinsics = Intrinsics.construct(\n                c1=c1,\n                c2=c2,\n                c3=c3,\n                c4=c4,\n                pixel_aspect_ratio=pixel_aspect_ratio,\n            )\n\n    if validate:\n        return CamCalibration(\n            type=type,\n            base_intrinsics=base_intrinsics,\n            extrinsics=extrinsics,\n            intrinsics=intrinsics,\n            id=id,\n            item_ref=item_ref,\n            view_ref=view_ref,\n            entity_ref=entity_ref,\n            source_ref=source_ref,\n        )\n    else:\n        return CamCalibration.construct(\n            type=type,\n            base_intrinsics=base_intrinsics,\n            extrinsics=extrinsics,\n            intrinsics=intrinsics,\n            id=id,\n            item_ref=item_ref,\n            view_ref=view_ref,\n            entity_ref=entity_ref,\n            source_ref=source_ref,\n        )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/camcalibration/#pixano.features.schemas.annotations.camcalibration.is_cam_calibration","title":"<code>is_cam_calibration(cls, strict=False)</code>","text":"<p>Check if a class is a <code>CamCalibration</code> or subclass of <code>CamCalibration</code>.</p> Source code in <code>pixano/features/schemas/annotations/camcalibration.py</code> <pre><code>def is_cam_calibration(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a `CamCalibration` or subclass of `CamCalibration`.\"\"\"\n    return issubclass_strict(cls, CamCalibration, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/classification/","title":"classification","text":""},{"location":"api_reference/features/schemas/annotations/classification/#pixano.features.schemas.annotations.classification","title":"<code>pixano.features.schemas.annotations.classification</code>","text":""},{"location":"api_reference/features/schemas/annotations/classification/#pixano.features.schemas.annotations.classification.Classification","title":"<code>Classification(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>Annotation</code></p> <p>Classification at the media level (Image or Text).</p> <p>Attributes:</p> Name Type Description <code>labels</code> <code>list[str]</code> <p>List of class names.</p> <code>confidences</code> <code>list[float]</code> <p>List of prediction confidences.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/classification/#pixano.features.schemas.annotations.classification.Classification.predictions","title":"<code>predictions: list[tuple[str, float]]</code>  <code>property</code>","text":"<p>Get list of zipped predictions (labels and confidences).</p>"},{"location":"api_reference/features/schemas/annotations/classification/#pixano.features.schemas.annotations.classification.Classification.none","title":"<code>none()</code>  <code>classmethod</code>","text":"<p>Utility function to get a <code>None</code> equivalent. Should be removed as soon as Lance manages <code>None</code> value.</p> <p>Returns:</p> Type Description <code>Classification</code> <p>\"None\" Classification.</p> Source code in <code>pixano/features/schemas/annotations/classification.py</code> <pre><code>@classmethod\ndef none(cls) -&gt; \"Classification\":\n    \"\"\"Utility function to get a `None` equivalent.\n    Should be removed as soon as Lance manages `None` value.\n\n    Returns:\n        \"None\" Classification.\n    \"\"\"\n    return cls(\n        id=\"\",\n        item=ItemRef.none(),\n        view=ViewRef.none(),\n        entity=EntityRef.none(),\n        labels=[],\n        confidences=[],\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/classification/#pixano.features.schemas.annotations.classification.create_classification","title":"<code>create_classification(labels, confidences, id='', item_ref=ItemRef.none(), view_ref=ViewRef.none(), entity_ref=EntityRef.none(), source_ref=SourceRef.none())</code>","text":"<p>Create a <code>Classification</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>list[str]</code> <p>List of class names.</p> required <code>confidences</code> <code>list[float]</code> <p>List of prediction confidences.</p> required <code>id</code> <code>str</code> <p><code>Classification</code> ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>view_ref</code> <code>ViewRef</code> <p>View reference.</p> <code>none()</code> <code>entity_ref</code> <code>EntityRef</code> <p>Entity reference.</p> <code>none()</code> <code>source_ref</code> <code>SourceRef</code> <p>Source reference.</p> <code>none()</code> <p>Returns:</p> Type Description <code>Classification</code> <p>The created <code>Classification</code> instance.</p> Source code in <code>pixano/features/schemas/annotations/classification.py</code> <pre><code>def create_classification(\n    labels: list[str],\n    confidences: list[float],\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    view_ref: ViewRef = ViewRef.none(),\n    entity_ref: EntityRef = EntityRef.none(),\n    source_ref: SourceRef = SourceRef.none(),\n) -&gt; Classification:\n    \"\"\"Create a `Classification` instance.\n\n    Args:\n        labels: List of class names.\n        confidences: List of prediction confidences.\n        id: `Classification` ID.\n        item_ref: Item reference.\n        view_ref: View reference.\n        entity_ref: Entity reference.\n        source_ref: Source reference.\n\n    Returns:\n        The created `Classification` instance.\n    \"\"\"\n    return Classification(\n        labels=labels,\n        confidences=confidences,\n        id=id,\n        item_ref=item_ref,\n        view_ref=view_ref,\n        entity_ref=entity_ref,\n        source_ref=source_ref,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/classification/#pixano.features.schemas.annotations.classification.is_classification","title":"<code>is_classification(cls, strict=False)</code>","text":"<p>Check if a class is a <code>Classification</code> or subclass of <code>Classification</code>.</p> Source code in <code>pixano/features/schemas/annotations/classification.py</code> <pre><code>def is_classification(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a `Classification` or subclass of `Classification`.\"\"\"\n    return issubclass_strict(cls, Classification, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/compressed_rle/","title":"compressed_rle","text":""},{"location":"api_reference/features/schemas/annotations/compressed_rle/#pixano.features.schemas.annotations.compressed_rle","title":"<code>pixano.features.schemas.annotations.compressed_rle</code>","text":""},{"location":"api_reference/features/schemas/annotations/compressed_rle/#pixano.features.schemas.annotations.compressed_rle.CompressedRLE","title":"<code>CompressedRLE(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>Annotation</code></p> <p>Compressed RLE mask type.</p> <p>Attributes:</p> Name Type Description <code>size</code> <code>list[int]</code> <p>Mask size.</p> <code>counts</code> <code>bytes</code> <p>Mask RLE encoding.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/compressed_rle/#pixano.features.schemas.annotations.compressed_rle.CompressedRLE.encode","title":"<code>encode(mask, height, width, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Create a compressed RLE mask from polygons / uncompressed RLE / compressed RLE.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>list[list] | dict[str, list[int]]</code> <p>Mask as polygons / uncompressed RLE / compressed RLE.</p> required <code>height</code> <code>int</code> <p>Image height.</p> required <code>width</code> <code>int</code> <p>Image width.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>CompressedRLE</code> <p>The compressed RLE mask.</p> Source code in <code>pixano/features/schemas/annotations/compressed_rle.py</code> <pre><code>@staticmethod\ndef encode(mask: list[list] | dict[str, list[int]], height: int, width: int, **kwargs: Any) -&gt; \"CompressedRLE\":\n    \"\"\"Create a compressed RLE mask from polygons / uncompressed RLE / compressed RLE.\n\n    Args:\n        mask: Mask as polygons / uncompressed RLE / compressed RLE.\n        height: Image height.\n        width: Image width.\n        kwargs: Additional arguments.\n\n    Returns:\n        The compressed RLE mask.\n    \"\"\"\n    return CompressedRLE(**image_utils.encode_rle(mask, height, width), **kwargs)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/compressed_rle/#pixano.features.schemas.annotations.compressed_rle.CompressedRLE.from_mask","title":"<code>from_mask(mask, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Create a compressed RLE mask from a NumPy array.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>Image | ndarray</code> <p>The mask as a NumPy array.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>CompressedRLE</code> <p>The compressed RLE mask.</p> Source code in <code>pixano/features/schemas/annotations/compressed_rle.py</code> <pre><code>@staticmethod\ndef from_mask(mask: pil_image.Image | np.ndarray, **kwargs: Any) -&gt; \"CompressedRLE\":\n    \"\"\"Create a compressed RLE mask from a NumPy array.\n\n    Args:\n        mask: The mask as a NumPy array.\n        kwargs: Additional arguments.\n\n    Returns:\n        The compressed RLE mask.\n    \"\"\"\n    rle = image_utils.mask_to_rle(mask)\n    return CompressedRLE(size=rle[\"size\"], counts=rle[\"counts\"], **kwargs)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/compressed_rle/#pixano.features.schemas.annotations.compressed_rle.CompressedRLE.from_polygons","title":"<code>from_polygons(polygons, height, width, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Create a compressed RLE mask from polygons.</p> <p>Parameters:</p> Name Type Description Default <code>polygons</code> <code>list[list]</code> <p>The mask as polygons.</p> required <code>height</code> <code>int</code> <p>Image height.</p> required <code>width</code> <code>int</code> <p>Image width.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>CompressedRLE</code> <p>The compressed RLE mask.</p> Source code in <code>pixano/features/schemas/annotations/compressed_rle.py</code> <pre><code>@staticmethod\ndef from_polygons(\n    polygons: list[list],\n    height: int,\n    width: int,\n    **kwargs: Any,\n) -&gt; \"CompressedRLE\":\n    \"\"\"Create a compressed RLE mask from polygons.\n\n    Args:\n        polygons: The mask as polygons.\n        height: Image height.\n        width: Image width.\n        kwargs: Additional arguments.\n\n    Returns:\n        The compressed RLE mask.\n    \"\"\"\n    return CompressedRLE(**image_utils.polygons_to_rle(polygons, height, width), **kwargs)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/compressed_rle/#pixano.features.schemas.annotations.compressed_rle.CompressedRLE.from_urle","title":"<code>from_urle(urle, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Create a compressed RLE mask from an uncompressed RLE.</p> <p>Parameters:</p> Name Type Description Default <code>urle</code> <code>dict[str, list[int]]</code> <p>The mask as an uncompressed RLE.</p> required <code>kwargs</code> <code>Any</code> <p>Additional arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>CompressedRLE</code> <p>The compressed RLE mask.</p> Source code in <code>pixano/features/schemas/annotations/compressed_rle.py</code> <pre><code>@staticmethod\ndef from_urle(urle: dict[str, list[int]], **kwargs: Any) -&gt; \"CompressedRLE\":\n    \"\"\"Create a compressed RLE mask from an uncompressed RLE.\n\n    Args:\n        urle: The mask as an uncompressed RLE.\n        kwargs: Additional arguments.\n\n    Returns:\n        The compressed RLE mask.\n    \"\"\"\n    return CompressedRLE(**image_utils.urle_to_rle(urle), **kwargs)  #  type: ignore[arg-type]\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/compressed_rle/#pixano.features.schemas.annotations.compressed_rle.CompressedRLE.none","title":"<code>none()</code>  <code>classmethod</code>","text":"<p>Utility function to get a <code>None</code> equivalent. Should be removed as soon as Lance manages <code>None</code> value.</p> <p>Returns:</p> Type Description <code>Self</code> <p>\"None\" <code>CompressedRLE</code>.</p> Source code in <code>pixano/features/schemas/annotations/compressed_rle.py</code> <pre><code>@classmethod\ndef none(cls) -&gt; Self:\n    \"\"\"Utility function to get a `None` equivalent.\n    Should be removed as soon as Lance manages `None` value.\n\n    Returns:\n        \"None\" `CompressedRLE`.\n    \"\"\"\n    return cls(\n        id=\"\",\n        item=ItemRef.none(),\n        view=ViewRef.none(),\n        entity=EntityRef.none(),\n        size=[0, 0],\n        counts=b\"\",\n        created_at=datetime(1970, 1, 1),\n        updated_at=datetime(1970, 1, 1),\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/compressed_rle/#pixano.features.schemas.annotations.compressed_rle.CompressedRLE.to_mask","title":"<code>to_mask()</code>","text":"<p>Convert the compressed RLE mask to a NumPy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The mask as a NumPy array.</p> Source code in <code>pixano/features/schemas/annotations/compressed_rle.py</code> <pre><code>def to_mask(self) -&gt; np.ndarray:\n    \"\"\"Convert the compressed RLE mask to a NumPy array.\n\n    Returns:\n        The mask as a NumPy array.\n    \"\"\"\n    return image_utils.rle_to_mask({\"size\": self.size, \"counts\": self.counts})\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/compressed_rle/#pixano.features.schemas.annotations.compressed_rle.CompressedRLE.to_polygons","title":"<code>to_polygons()</code>","text":"<p>Convert the compressed RLE mask to poylgons.</p> <p>Returns:</p> Type Description <code>list[list]</code> <p>The mask as polygons.</p> Source code in <code>pixano/features/schemas/annotations/compressed_rle.py</code> <pre><code>def to_polygons(self) -&gt; list[list]:\n    \"\"\"Convert the compressed RLE mask to poylgons.\n\n    Returns:\n        The mask as polygons.\n    \"\"\"\n    return image_utils.rle_to_polygons(self.model_dump())\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/compressed_rle/#pixano.features.schemas.annotations.compressed_rle.CompressedRLE.to_urle","title":"<code>to_urle()</code>","text":"<p>Convert compressed RLE mask to uncompressed RLE.</p> <p>Returns:</p> Type Description <code>dict[str, list[int]]</code> <p>The mask as an uncompressed RLE.</p> Source code in <code>pixano/features/schemas/annotations/compressed_rle.py</code> <pre><code>def to_urle(self) -&gt; dict[str, list[int]]:\n    \"\"\"Convert compressed RLE mask to uncompressed RLE.\n\n    Returns:\n        The mask as an uncompressed RLE.\n    \"\"\"\n    return image_utils.rle_to_urle(self.model_dump())\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/compressed_rle/#pixano.features.schemas.annotations.compressed_rle.create_compressed_rle","title":"<code>create_compressed_rle(size, counts, id='', item_ref=ItemRef.none(), view_ref=ViewRef.none(), entity_ref=EntityRef.none(), source_ref=SourceRef.none())</code>","text":"<p>Create a <code>CompressedRLE</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int]</code> <p>Mask size.</p> required <code>counts</code> <code>bytes</code> <p>Mask RLE encoding.</p> required <code>id</code> <code>str</code> <p><code>CompressedRLE</code> ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>view_ref</code> <code>ViewRef</code> <p>View reference.</p> <code>none()</code> <code>entity_ref</code> <code>EntityRef</code> <p>Entity reference.</p> <code>none()</code> <code>source_ref</code> <code>SourceRef</code> <p>Source reference.</p> <code>none()</code> <p>Returns:</p> Type Description <code>CompressedRLE</code> <p>The compressed RLE instance.</p> Source code in <code>pixano/features/schemas/annotations/compressed_rle.py</code> <pre><code>def create_compressed_rle(\n    size: list[int],\n    counts: bytes,\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    view_ref: ViewRef = ViewRef.none(),\n    entity_ref: EntityRef = EntityRef.none(),\n    source_ref: SourceRef = SourceRef.none(),\n) -&gt; CompressedRLE:\n    \"\"\"Create a `CompressedRLE` instance.\n\n    Args:\n        size: Mask size.\n        counts: Mask RLE encoding.\n        id: `CompressedRLE` ID.\n        item_ref: Item reference.\n        view_ref: View reference.\n        entity_ref: Entity reference.\n        source_ref: Source reference.\n\n    Returns:\n        The compressed RLE instance.\n    \"\"\"\n    return CompressedRLE(\n        size=size,\n        counts=counts,\n        id=id,\n        item_ref=item_ref,\n        view_ref=view_ref,\n        entity_ref=entity_ref,\n        source_ref=source_ref,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/compressed_rle/#pixano.features.schemas.annotations.compressed_rle.is_compressed_rle","title":"<code>is_compressed_rle(cls, strict=False)</code>","text":"<p>Check if the given class is a subclass of <code>CompressedRLE</code>.</p> Source code in <code>pixano/features/schemas/annotations/compressed_rle.py</code> <pre><code>def is_compressed_rle(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if the given class is a subclass of `CompressedRLE`.\"\"\"\n    return issubclass_strict(cls, CompressedRLE, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/info_extraction/","title":"info_extraction","text":""},{"location":"api_reference/features/schemas/annotations/info_extraction/#pixano.features.schemas.annotations.info_extraction","title":"<code>pixano.features.schemas.annotations.info_extraction</code>","text":""},{"location":"api_reference/features/schemas/annotations/info_extraction/#pixano.features.schemas.annotations.info_extraction.Relation","title":"<code>Relation(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>Annotation</code></p> <p>Observation of a relation between two annotations,    for instance between text-spans in a text.</p> <p>Attributes:</p> Name Type Description <code>predicate</code> <code>str</code> <p>type of relation, as in semantic-web (OWL, RDF, etc)</p> <code>subject_ref</code> <code>AnnotationRef</code> <p>annotation_ref to the subject Annotation (eg TextSpan)</p> <code>object_ref</code> <code>AnnotationRef</code> <p>annotation_ref to the object Annotation (eg TextSpan)</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/info_extraction/#pixano.features.schemas.annotations.info_extraction.Relation.none","title":"<code>none()</code>  <code>classmethod</code>","text":"<p>Utility function to get a <code>None</code> equivalent. Should be removed as soon as Lance manages <code>None</code> value.</p> <p>Returns:</p> Type Description <code>Self</code> <p>\"None\" Relation.</p> Source code in <code>pixano/features/schemas/annotations/info_extraction.py</code> <pre><code>@classmethod\ndef none(cls) -&gt; Self:\n    \"\"\"Utility function to get a `None` equivalent.\n    Should be removed as soon as Lance manages `None` value.\n\n    Returns:\n        \"None\" Relation.\n    \"\"\"\n    return cls(\n        id=\"\",\n        predicate=\"\",\n        item_ref=ItemRef.none(),\n        view_ref=ViewRef.none(),\n        entity_ref=EntityRef.none(),\n        subject_ref=AnnotationRef.none(),\n        object_ref=AnnotationRef.none(),\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/info_extraction/#pixano.features.schemas.annotations.info_extraction.TextSpan","title":"<code>TextSpan(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>Annotation</code></p> <p>Designation of a Text-Span in a text, especially in the    use-case of Named-Entity Recognition on a textual annotation    having a str 'content' attribute .</p> <p>Attributes:</p> Name Type Description <code>mention</code> <code>str</code> <p>text-span assembled mention.</p> <code>spans_start</code> <code>list[int]</code> <p>List of start offsets of the spans in the text.</p> <code>spans_end</code> <code>list[int]</code> <p>List of end offsets of the spans in the text.</p> <code>annotation_ref</code> <code>AnnotationRef</code> <p>Annotation reference toward an textual Annotation having a str 'content' attribute</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/info_extraction/#pixano.features.schemas.annotations.info_extraction.TextSpan.spans","title":"<code>spans: list[tuple[int, int]]</code>  <code>property</code>","text":"<p>Get the list of zipped spans offsets (starts and ends).</p>"},{"location":"api_reference/features/schemas/annotations/info_extraction/#pixano.features.schemas.annotations.info_extraction.TextSpan.spans_length","title":"<code>spans_length: list[int]</code>  <code>property</code>","text":"<p>Get the computed list of spans lengths.</p>"},{"location":"api_reference/features/schemas/annotations/info_extraction/#pixano.features.schemas.annotations.info_extraction.TextSpan.none","title":"<code>none()</code>  <code>classmethod</code>","text":"<p>Utility function to get a <code>None</code> equivalent. Should be removed as soon as Lance manages <code>None</code> value.</p> <p>Returns:</p> Type Description <code>Self</code> <p>\"None\" TextSpan.</p> Source code in <code>pixano/features/schemas/annotations/info_extraction.py</code> <pre><code>@classmethod\ndef none(cls) -&gt; Self:\n    \"\"\"Utility function to get a `None` equivalent.\n    Should be removed as soon as Lance manages `None` value.\n\n    Returns:\n        \"None\" TextSpan.\n    \"\"\"\n    return cls(\n        id=\"\",\n        item_ref=ItemRef.none(),\n        view_ref=ViewRef.none(),\n        entity_ref=EntityRef.none(),\n        mention=\"\",\n        spans_start=[],\n        spans_end=[],\n        annotation_ref=AnnotationRef.none(),\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/info_extraction/#pixano.features.schemas.annotations.info_extraction.create_relation","title":"<code>create_relation(predicate, subject_ref=AnnotationRef.none(), object_ref=AnnotationRef.none(), id='', item_ref=ItemRef.none(), view_ref=ViewRef.none(), entity_ref=EntityRef.none(), source_ref=SourceRef.none())</code>","text":"<p>Create a <code>Relation</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>predicate</code> <code>str</code> <p>type of relation</p> required <code>subject_ref</code> <code>AnnotationRef</code> <p>annotation_ref to the subject TextSpan</p> <code>none()</code> <code>object_ref</code> <code>AnnotationRef</code> <p>annotation_ref to the object TextSpan</p> <code>none()</code> <code>id</code> <code>str</code> <p>Relation ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>view_ref</code> <code>ViewRef</code> <p>View reference.</p> <code>none()</code> <code>entity_ref</code> <code>EntityRef</code> <p>Entity reference.</p> <code>none()</code> <code>source_ref</code> <code>SourceRef</code> <p>Source reference.</p> <code>none()</code> <p>Returns:</p> Type Description <code>Relation</code> <p>The created <code>Relation</code> instance.</p> Source code in <code>pixano/features/schemas/annotations/info_extraction.py</code> <pre><code>def create_relation(\n    predicate: str,\n    subject_ref: AnnotationRef = AnnotationRef.none(),\n    object_ref: AnnotationRef = AnnotationRef.none(),\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    view_ref: ViewRef = ViewRef.none(),\n    entity_ref: EntityRef = EntityRef.none(),\n    source_ref: SourceRef = SourceRef.none(),\n) -&gt; Relation:\n    \"\"\"Create a `Relation` instance.\n\n    Args:\n        predicate: type of relation\n        subject_ref: annotation_ref to the subject TextSpan\n        object_ref: annotation_ref to the object TextSpan\n        id: Relation ID.\n        item_ref: Item reference.\n        view_ref: View reference.\n        entity_ref: Entity reference.\n        source_ref: Source reference.\n\n    Returns:\n        The created `Relation` instance.\n    \"\"\"\n    return Relation(\n        predicate=predicate,\n        subject_ref=subject_ref,\n        object_ref=object_ref,\n        id=id,\n        item_ref=item_ref,\n        view_ref=view_ref,\n        entity_ref=entity_ref,\n        source_ref=source_ref,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/info_extraction/#pixano.features.schemas.annotations.info_extraction.create_text_span","title":"<code>create_text_span(mention, spans_start, spans_end, id='', item_ref=ItemRef.none(), view_ref=ViewRef.none(), entity_ref=EntityRef.none(), source_ref=SourceRef.none(), annotation_ref=AnnotationRef.none())</code>","text":"<p>Create a TextSpan instance.</p> <p>Parameters:</p> Name Type Description Default <code>mention</code> <code>str</code> <p>text-span observed mention.</p> required <code>spans_start</code> <code>list[int]</code> <p>List of start offsets of the spans in the text.</p> required <code>spans_end</code> <code>list[int]</code> <p>List of end offsets of the spans in the text.</p> required <code>id</code> <code>str</code> <p>TextSpan ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>view_ref</code> <code>ViewRef</code> <p>View reference.</p> <code>none()</code> <code>entity_ref</code> <code>EntityRef</code> <p>Entity reference.</p> <code>none()</code> <code>source_ref</code> <code>SourceRef</code> <p>Source reference.</p> <code>none()</code> <code>annotation_ref</code> <code>AnnotationRef</code> <p>Annotation reference toward an textual Annotation having a str 'content' attribute</p> <code>none()</code> <p>Returns:</p> Type Description <code>TextSpan</code> <p>The created <code>TextSpan</code> instance.</p> Source code in <code>pixano/features/schemas/annotations/info_extraction.py</code> <pre><code>def create_text_span(\n    mention: str,\n    spans_start: list[int],\n    spans_end: list[int],\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    view_ref: ViewRef = ViewRef.none(),\n    entity_ref: EntityRef = EntityRef.none(),\n    source_ref: SourceRef = SourceRef.none(),\n    annotation_ref: AnnotationRef = AnnotationRef.none(),\n) -&gt; TextSpan:\n    \"\"\"Create a TextSpan instance.\n\n    Args:\n        mention: text-span observed mention.\n        spans_start: List of start offsets of the spans in the text.\n        spans_end: List of end offsets of the spans in the text.\n        id: TextSpan ID.\n        item_ref: Item reference.\n        view_ref: View reference.\n        entity_ref: Entity reference.\n        source_ref: Source reference.\n        annotation_ref: Annotation reference toward an textual Annotation having a\n          str 'content' attribute\n\n    Returns:\n        The created `TextSpan` instance.\n    \"\"\"\n    return TextSpan(\n        mention=mention,\n        spans_start=spans_start,\n        spans_end=spans_end,\n        annotation_ref=annotation_ref,\n        id=id,\n        item_ref=item_ref,\n        view_ref=view_ref,\n        entity_ref=entity_ref,\n        source_ref=source_ref,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/info_extraction/#pixano.features.schemas.annotations.info_extraction.is_relation","title":"<code>is_relation(cls, strict=False)</code>","text":"<p>Check if a class is a <code>Relation</code> or subclass of <code>Relation</code>.</p> Source code in <code>pixano/features/schemas/annotations/info_extraction.py</code> <pre><code>def is_relation(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a `Relation` or subclass of `Relation`.\"\"\"\n    return issubclass_strict(cls, Relation, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/info_extraction/#pixano.features.schemas.annotations.info_extraction.is_text_span","title":"<code>is_text_span(cls, strict=False)</code>","text":"<p>Check if a class is a TextSpan or subclass of TextSpan.</p> Source code in <code>pixano/features/schemas/annotations/info_extraction.py</code> <pre><code>def is_text_span(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a TextSpan or subclass of TextSpan.\"\"\"\n    return issubclass_strict(cls, TextSpan, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/keypoints/","title":"keypoints","text":""},{"location":"api_reference/features/schemas/annotations/keypoints/#pixano.features.schemas.annotations.keypoints","title":"<code>pixano.features.schemas.annotations.keypoints</code>","text":""},{"location":"api_reference/features/schemas/annotations/keypoints/#pixano.features.schemas.annotations.keypoints.KeyPoints","title":"<code>KeyPoints(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>Annotation</code></p> <p>A set of keypoints.</p> <p>Attributes:</p> Name Type Description <code>template_id</code> <code>str</code> <p>Id of the keypoint template.</p> <code>coords</code> <code>list[float]</code> <p>List of 2D coordinates of the keypoints.</p> <code>states</code> <code>list[str]</code> <p>Status for each keypoint. (\"visible\", \"invisible\", \"hidden\").</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/keypoints/#pixano.features.schemas.annotations.keypoints.KeyPoints.map_back2front_vertices","title":"<code>map_back2front_vertices()</code>","text":"<p>Utility function to map back format for KeyPoint to front vertices format.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If keypoints is ill-formed.</p> <p>Returns:</p> Type Description <code>list</code> <p>keypoint list for vertices front format.</p> Source code in <code>pixano/features/schemas/annotations/keypoints.py</code> <pre><code>def map_back2front_vertices(self) -&gt; list:\n    \"\"\"Utility function to map back format for KeyPoint to front vertices format.\n\n    Raises:\n        ValueError: If keypoints is ill-formed.\n\n    Returns:\n        keypoint list for vertices front format.\n    \"\"\"\n    # Check coords are even\n    if len(self.coords) % 2 != 0:\n        raise ValueError(\"There must be an even number of coords\")\n\n    result = []\n    if self.states is not None:\n        num_points = len(self.coords) // 2\n        if len(self.states) != num_points:\n            raise ValueError(\"There must be the same number of states than points\")\n\n        result = [\n            {\"x\": x, \"y\": y, \"features\": {\"state\": state}}\n            for (x, y), state in zip(zip(self.coords[0::2], self.coords[1::2]), self.states)\n        ]\n    else:\n        result = [{\"x\": x, \"y\": y} for x, y in zip(self.coords[0::2], self.coords[1::2])]\n    return result\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/keypoints/#pixano.features.schemas.annotations.keypoints.KeyPoints.none","title":"<code>none()</code>  <code>classmethod</code>","text":"<p>Utility function to get a <code>None</code> equivalent. Should be removed as soon as Lance manages <code>None</code> value.</p> <p>Returns:</p> Type Description <code>KeyPoints</code> <p>\"None\" KeyPoints.</p> Source code in <code>pixano/features/schemas/annotations/keypoints.py</code> <pre><code>@classmethod\ndef none(cls) -&gt; \"KeyPoints\":\n    \"\"\"Utility function to get a `None` equivalent.\n    Should be removed as soon as Lance manages `None` value.\n\n    Returns:\n        \"None\" KeyPoints.\n    \"\"\"\n    return cls(\n        id=\"\",\n        item=ItemRef.none(),\n        view=ViewRef.none(),\n        entity=EntityRef.none(),\n        template_id=\"\",\n        coords=[0, 0],\n        states=[\"invisible\"],\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/keypoints/#pixano.features.schemas.annotations.keypoints.KeyPoints3D","title":"<code>KeyPoints3D(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>Annotation</code></p> <p>A set of 3D keypoints.</p> <p>Attributes:</p> Name Type Description <code>template_id</code> <code>str</code> <p>id of keypoint template.</p> <code>coords</code> <code>list[float]</code> <p>List of 3D coordinates of the keypoints.</p> <code>states</code> <code>list[str]</code> <p>Status for each keypoint.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/keypoints/#pixano.features.schemas.annotations.keypoints.KeyPoints3D.map_back2front_vertices","title":"<code>map_back2front_vertices()</code>","text":"<p>Utility function to map back format for KeyPoint3D to front vertices format.</p> Warn <p>Not implemented for 3D keypoints.</p> Source code in <code>pixano/features/schemas/annotations/keypoints.py</code> <pre><code>def map_back2front_vertices(self) -&gt; list:\n    \"\"\"Utility function to map back format for KeyPoint3D to front vertices format.\n\n    Warn:\n        Not implemented for 3D keypoints.\n    \"\"\"\n    raise NotImplementedError(\"Not implemented for 3D keypoints.\")\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/keypoints/#pixano.features.schemas.annotations.keypoints.KeyPoints3D.none","title":"<code>none()</code>  <code>classmethod</code>","text":"<p>Utility function to get a <code>None</code> equivalent. Should be removed as soon as Lance manages <code>None</code> value.</p> <p>Returns:</p> Type Description <code>KeyPoints3D</code> <p>\"None\" KeyPoints3D.</p> Source code in <code>pixano/features/schemas/annotations/keypoints.py</code> <pre><code>@classmethod\ndef none(cls) -&gt; \"KeyPoints3D\":\n    \"\"\"Utility function to get a `None` equivalent.\n    Should be removed as soon as Lance manages `None` value.\n\n    Returns:\n        \"None\" KeyPoints3D.\n    \"\"\"\n    return cls(\n        id=\"\",\n        item=ItemRef.none(),\n        view=ViewRef.none(),\n        entity=EntityRef.none(),\n        template_id=\"\",\n        coords=[0, 0, 0],\n        states=[\"visible\"],\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/keypoints/#pixano.features.schemas.annotations.keypoints.create_keypoints","title":"<code>create_keypoints(template_id, coords, states, id='', item_ref=ItemRef.none(), view_ref=ViewRef.none(), entity_ref=EntityRef.none(), source_ref=SourceRef.none())</code>","text":"<p>Create a <code>KeyPoints</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>template_id</code> <code>str</code> <p>id of keypoint template.</p> required <code>coords</code> <code>list[float]</code> <p>List of 2D coordinates of the keypoints.</p> required <code>states</code> <code>list[str]</code> <p>Status for each keypoint. (\"visible\", \"invisible\", \"hidden\").</p> required <code>id</code> <code>str</code> <p>Keypoints ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>view_ref</code> <code>ViewRef</code> <p>View reference.</p> <code>none()</code> <code>entity_ref</code> <code>EntityRef</code> <p>Entity reference.</p> <code>none()</code> <code>source_ref</code> <code>SourceRef</code> <p>Source reference.</p> <code>none()</code> <p>Returns:</p> Type Description <code>KeyPoints</code> <p>The created <code>KeyPoints</code> instance.</p> Source code in <code>pixano/features/schemas/annotations/keypoints.py</code> <pre><code>def create_keypoints(\n    template_id: str,\n    coords: list[float],\n    states: list[str],\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    view_ref: ViewRef = ViewRef.none(),\n    entity_ref: EntityRef = EntityRef.none(),\n    source_ref: SourceRef = SourceRef.none(),\n) -&gt; KeyPoints:\n    \"\"\"Create a `KeyPoints` instance.\n\n    Args:\n        template_id: id of keypoint template.\n        coords: List of 2D coordinates of the keypoints.\n        states: Status for each keypoint. (\"visible\", \"invisible\", \"hidden\").\n        id: Keypoints ID.\n        item_ref: Item reference.\n        view_ref: View reference.\n        entity_ref: Entity reference.\n        source_ref: Source reference.\n\n    Returns:\n        The created `KeyPoints` instance.\n    \"\"\"\n    return KeyPoints(\n        template_id=template_id,\n        coords=coords,\n        states=states,\n        id=id,\n        item_ref=item_ref,\n        view_ref=view_ref,\n        entity_ref=entity_ref,\n        source_ref=source_ref,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/keypoints/#pixano.features.schemas.annotations.keypoints.create_keypoints3d","title":"<code>create_keypoints3d(template_id, coords, states, id='', item_ref=ItemRef.none(), view_ref=ViewRef.none(), entity_ref=EntityRef.none(), source_ref=SourceRef.none())</code>","text":"<p>Create a <code>KeyPoints3D</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>template_id</code> <code>str</code> <p>The id of the keypoint template.</p> required <code>coords</code> <code>list[float]</code> <p>The 3D coordinates of the keypoints.</p> required <code>states</code> <code>list[Literal['visible', 'invisble', 'hidden']]</code> <p>The visibility status for each keypoint.</p> required <code>id</code> <code>str</code> <p>Keypoints3D ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>view_ref</code> <code>ViewRef</code> <p>View reference.</p> <code>none()</code> <code>entity_ref</code> <code>EntityRef</code> <p>Entity reference.</p> <code>none()</code> <code>source_ref</code> <code>SourceRef</code> <p>Source reference.</p> <code>none()</code> <p>Returns:</p> Type Description <code>KeyPoints3D</code> <p>The created <code>KeyPoints3D</code> instance.</p> Source code in <code>pixano/features/schemas/annotations/keypoints.py</code> <pre><code>def create_keypoints3d(\n    template_id: str,\n    coords: list[float],\n    states: list[Literal[\"visible\", \"invisble\", \"hidden\"]],\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    view_ref: ViewRef = ViewRef.none(),\n    entity_ref: EntityRef = EntityRef.none(),\n    source_ref: SourceRef = SourceRef.none(),\n) -&gt; KeyPoints3D:\n    \"\"\"Create a `KeyPoints3D` instance.\n\n    Args:\n        template_id: The id of the keypoint template.\n        coords: The 3D coordinates of the keypoints.\n        states: The visibility status for each keypoint.\n        id: Keypoints3D ID.\n        item_ref: Item reference.\n        view_ref: View reference.\n        entity_ref: Entity reference.\n        source_ref: Source reference.\n\n    Returns:\n        The created `KeyPoints3D` instance.\n    \"\"\"\n    return KeyPoints3D(\n        template_id=template_id,\n        coords=coords,\n        states=states,\n        id=id,\n        item_ref=item_ref,\n        view_ref=view_ref,\n        entity_ref=entity_ref,\n        source_ref=source_ref,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/keypoints/#pixano.features.schemas.annotations.keypoints.is_keypoints","title":"<code>is_keypoints(cls, strict=False)</code>","text":"<p>Check if a class is a <code>KeyPoints</code> or subclass of <code>KeyPoints</code>.</p> Source code in <code>pixano/features/schemas/annotations/keypoints.py</code> <pre><code>def is_keypoints(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a `KeyPoints` or subclass of `KeyPoints`.\"\"\"\n    return issubclass_strict(cls, KeyPoints, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/keypoints/#pixano.features.schemas.annotations.keypoints.is_keypoints3d","title":"<code>is_keypoints3d(cls, strict=False)</code>","text":"<p>Check if a class is <code>Keypoints3D</code> or a subclass of <code>Keypoints3D</code>.</p> Source code in <code>pixano/features/schemas/annotations/keypoints.py</code> <pre><code>def is_keypoints3d(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is `Keypoints3D` or a subclass of `Keypoints3D`.\"\"\"\n    return issubclass_strict(cls, KeyPoints3D, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/text_generation/","title":"text_generation","text":""},{"location":"api_reference/features/schemas/annotations/text_generation/#pixano.features.schemas.annotations.text_generation","title":"<code>pixano.features.schemas.annotations.text_generation</code>","text":""},{"location":"api_reference/features/schemas/annotations/text_generation/#pixano.features.schemas.annotations.text_generation.Message","title":"<code>Message(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>Annotation</code></p> <p>Textual exchange in a question/answer conversation for image or text description and information extraction.</p> <p>Attributes:</p> Name Type Description <code>number</code> <code>int</code> <p>message number to associate different ANSWER messages to a QUESTION.</p> <code>user</code> <code>str</code> <p>identify who is the author of the message (eg a human, a model, the ground truth, etc).</p> <code>content</code> <code>str</code> <p>actual text of the message.</p> <code>timestamp</code> <code>datetime</code> <p>creation date of the message.</p> <code>type</code> <code>str</code> <p>type of the message within \"SYSTEM\", \"QUESTION\" or\"ANSWER\". - SYSTEM: used for prefix messages stating the context. No associated answer expected - QUESTION: used to ask a question about a View. Expecting at least one answer (same message number) - ANSWER: used to reply to a question message by refering its message number</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/text_generation/#pixano.features.schemas.annotations.text_generation.Message.none","title":"<code>none()</code>  <code>classmethod</code>","text":"<p>Utility function to get a None equivalent. Should be removed when Lance could manage None value.</p> <p>Returns:</p> Type Description <code>Message</code> <p>\"None\" Message.</p> Source code in <code>pixano/features/schemas/annotations/text_generation.py</code> <pre><code>@classmethod\ndef none(cls) -&gt; \"Message\":\n    \"\"\"Utility function to get a None equivalent.\n    Should be removed when Lance could manage None value.\n\n    Returns:\n        \"None\" Message.\n    \"\"\"\n    return cls(\n        id=\"\",\n        item=ItemRef.none(),\n        view=ViewRef.none(),\n        entity=EntityRef.none(),\n        source_ref=SourceRef.none(),\n        number=0,\n        user=\"\",\n        type=\"QUESTION\",\n        content=\"\",\n        timestamp=datetime(1, 1, 1, 0, 0, 0, 0),\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/text_generation/#pixano.features.schemas.annotations.text_generation.create_message","title":"<code>create_message(number, user, type, content, timestamp=datetime(1, 1, 1, 0, 0, 0, 0), id='', item_ref=ItemRef.none(), view_ref=ViewRef.none(), entity_ref=EntityRef.none(), source_ref=SourceRef.none())</code>","text":"<p>Create a Message instance.</p> <p>Parameters:</p> Name Type Description Default <code>number</code> <code>int</code> <p>message number to associate diffrent ANSWER messages to a QUESTION</p> required <code>user</code> <code>str</code> <p>identify who is the author of the message (eg a human, a model, the ground truth, etc)</p> required <code>type</code> <code>Literal['SYSTEM', 'QUESTION', 'ANSWER']</code> <p>type of the message within \"SYSTEM\", \"QUESTION\" or\"ANSWER\"</p> required <code>content</code> <code>str</code> <p>actual text of the message</p> required <code>timestamp</code> <code>datetime</code> <p>creation date of the message</p> <code>datetime(1, 1, 1, 0, 0, 0, 0)</code> <code>id</code> <code>str</code> <p>object id</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>view_ref</code> <code>ViewRef</code> <p>View reference.</p> <code>none()</code> <code>entity_ref</code> <code>EntityRef</code> <p>Entity reference.</p> <code>none()</code> <code>source_ref</code> <code>SourceRef</code> <p>Source reference.</p> <code>none()</code> <p>Returns:</p> Type Description <code>Message</code> <p>The created <code>Message</code> instance.</p> Source code in <code>pixano/features/schemas/annotations/text_generation.py</code> <pre><code>def create_message(\n    number: int,\n    user: str,\n    type: Literal[\"SYSTEM\", \"QUESTION\", \"ANSWER\"],\n    content: str,\n    timestamp: datetime = datetime(1, 1, 1, 0, 0, 0, 0),\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    view_ref: ViewRef = ViewRef.none(),\n    entity_ref: EntityRef = EntityRef.none(),\n    source_ref: SourceRef = SourceRef.none(),\n) -&gt; Message:\n    \"\"\"Create a Message instance.\n\n    Args:\n        number: message number to associate diffrent ANSWER messages to a QUESTION\n        user: identify who is the author of the message (eg a human, a model, the ground truth, etc)\n        type: type of the message within \"SYSTEM\", \"QUESTION\" or\"ANSWER\"\n        content: actual text of the message\n        timestamp: creation date of the message\n        id: object id\n        item_ref: Item reference.\n        view_ref: View reference.\n        entity_ref: Entity reference.\n        source_ref: Source reference.\n\n    Returns:\n        The created `Message` instance.\n    \"\"\"\n    return Message(\n        number=number,\n        user=user,\n        type=type,\n        content=content,\n        timestamp=timestamp,\n        id=id,\n        item_ref=item_ref,\n        view_ref=view_ref,\n        entity_ref=entity_ref,\n        source_ref=source_ref,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/text_generation/#pixano.features.schemas.annotations.text_generation.is_message","title":"<code>is_message(cls, strict=False)</code>","text":"<p>Check if a class is a Message or subclass of Message.</p> Source code in <code>pixano/features/schemas/annotations/text_generation.py</code> <pre><code>def is_message(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a Message or subclass of Message.\"\"\"\n    return issubclass_strict(cls, Message, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/tracklet/","title":"tracklet","text":""},{"location":"api_reference/features/schemas/annotations/tracklet/#pixano.features.schemas.annotations.tracklet","title":"<code>pixano.features.schemas.annotations.tracklet</code>","text":""},{"location":"api_reference/features/schemas/annotations/tracklet/#pixano.features.schemas.annotations.tracklet.Tracklet","title":"<code>Tracklet(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>Annotation</code></p> <p>A <code>Tracklet</code> is a temporal segment of a video sequence.</p> <p>Attributes:</p> Name Type Description <code>start_timestep</code> <code>int</code> <p>The start timestep of the tracklet.</p> <code>end_timestep</code> <code>int</code> <p>The end timestep of the tracklet.</p> <code>start_timestamp</code> <code>float</code> <p>The start timestamp of the tracklet.</p> <code>end_timestamp</code> <code>float</code> <p>The end timestamp of the tracklet.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/tracklet/#pixano.features.schemas.annotations.tracklet.create_tracklet","title":"<code>create_tracklet(id='', item_ref=ItemRef.none(), view_ref=ViewRef.none(), entity_ref=EntityRef.none(), source_ref=SourceRef.none(), start_timestep=-1, end_timestep=-1, start_timestamp=-1.0, end_timestamp=-1.0)</code>","text":"<p>Create a <code>Tracklet</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str</code> <p>The tracklet id.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>The item reference.</p> <code>none()</code> <code>view_ref</code> <code>ViewRef</code> <p>The view reference.</p> <code>none()</code> <code>entity_ref</code> <code>EntityRef</code> <p>The parent track reference.</p> <code>none()</code> <code>source_ref</code> <code>SourceRef</code> <p>The source reference.</p> <code>none()</code> <code>start_timestep</code> <code>int</code> <p>The start timestep of the tracklet.</p> <code>-1</code> <code>end_timestep</code> <code>int</code> <p>The end timestep of the tracklet.</p> <code>-1</code> <code>start_timestamp</code> <code>float</code> <p>The start timestamp of the tracklet.</p> <code>-1.0</code> <code>end_timestamp</code> <code>float</code> <p>The end timestamp of the tracklet.</p> <code>-1.0</code> <p>Returns:</p> Type Description <code>Tracklet</code> <p>The created <code>Tracklet</code> instance.</p> Source code in <code>pixano/features/schemas/annotations/tracklet.py</code> <pre><code>def create_tracklet(\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    view_ref: ViewRef = ViewRef.none(),\n    entity_ref: EntityRef = EntityRef.none(),\n    source_ref: SourceRef = SourceRef.none(),\n    start_timestep: int = -1,\n    end_timestep: int = -1,\n    start_timestamp: float = -1.0,\n    end_timestamp: float = -1.0,\n) -&gt; Tracklet:\n    \"\"\"Create a `Tracklet` instance.\n\n    Args:\n        id: The tracklet id.\n        item_ref: The item reference.\n        view_ref: The view reference.\n        entity_ref: The parent track reference.\n        source_ref: The source reference.\n        start_timestep: The start timestep of the tracklet.\n        end_timestep: The end timestep of the tracklet.\n        start_timestamp: The start timestamp of the tracklet.\n        end_timestamp: The end timestamp of the tracklet.\n\n    Returns:\n        The created `Tracklet` instance.\n    \"\"\"\n    return Tracklet(\n        id=id,\n        item_ref=item_ref,\n        view_ref=view_ref,\n        entity_ref=entity_ref,\n        source_ref=source_ref,\n        start_timestep=start_timestep,\n        end_timestep=end_timestep,\n        start_timestamp=start_timestamp,\n        end_timestamp=end_timestamp,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/annotations/tracklet/#pixano.features.schemas.annotations.tracklet.is_tracklet","title":"<code>is_tracklet(cls, strict=False)</code>","text":"<p>Check if the given class is a subclass of <code>Tracklet</code>.</p> Source code in <code>pixano/features/schemas/annotations/tracklet.py</code> <pre><code>def is_tracklet(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if the given class is a subclass of `Tracklet`.\"\"\"\n    return issubclass_strict(cls, Tracklet, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/embeddings/embedding/","title":"embedding","text":""},{"location":"api_reference/features/schemas/embeddings/embedding/#pixano.features.schemas.embeddings.embedding","title":"<code>pixano.features.schemas.embeddings.embedding</code>","text":""},{"location":"api_reference/features/schemas/embeddings/embedding/#pixano.features.schemas.embeddings.embedding.Embedding","title":"<code>Embedding(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>BaseSchema</code>, <code>ABC</code></p> <p>Embeddings are used to define an embedding vector for an item in a dataset.</p> <p>Attributes:</p> Name Type Description <code>item_ref</code> <code>ItemRef</code> <p>Reference to the embedding's item.</p> <code>vector</code> <code>Any</code> <p>The embedding vector that should be defined by subclasses.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/embeddings/embedding/#pixano.features.schemas.embeddings.embedding.Embedding.item","title":"<code>item: Item</code>  <code>property</code>","text":"<p>Get the embedding's item.</p>"},{"location":"api_reference/features/schemas/embeddings/embedding/#pixano.features.schemas.embeddings.embedding.Embedding.to_arrow_schema","title":"<code>to_arrow_schema(remove_vector=False, remove_metadata=False)</code>  <code>classmethod</code>","text":"<p>Get the pyarrow schema of an <code>Embedding</code>.</p> <p>This function allows to remove the vector field and the metadata from the schema which can be useful for adding data with auto-vectorization.</p> <p>Parameters:</p> Name Type Description Default <code>remove_vector</code> <code>bool</code> <p>Remove the vector field.</p> <code>False</code> <code>remove_metadata</code> <code>bool</code> <p>Remove the metadata.</p> <code>False</code> <p>Returns:</p> Type Description <code>Schema</code> <p>The pyarrow schema.</p> Source code in <code>pixano/features/schemas/embeddings/embedding.py</code> <pre><code>@classmethod\ndef to_arrow_schema(\n    cls,\n    remove_vector: bool = False,\n    remove_metadata: bool = False,\n) -&gt; pa.Schema:\n    \"\"\"Get the pyarrow schema of an `Embedding`.\n\n    This function allows to remove the vector field and the metadata from the schema which can be useful for adding\n    data with auto-vectorization.\n\n    Args:\n        remove_vector: Remove the vector field.\n        remove_metadata: Remove the metadata.\n\n    Returns:\n        The pyarrow schema.\n    \"\"\"\n    pa_schema = super().to_arrow_schema()\n    if remove_vector:\n        pa_schema = pa_schema.remove(pa_schema.get_field_index(\"vector\"))\n    if remove_metadata:\n        pa_schema = pa_schema.remove_metadata()\n    return pa_schema\n</code></pre>"},{"location":"api_reference/features/schemas/embeddings/embedding/#pixano.features.schemas.embeddings.embedding.ViewEmbedding","title":"<code>ViewEmbedding(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>Embedding</code>, <code>ABC</code></p> <p>ViewEmbeddings are used to define an embedding vector for a view in a dataset.</p> <p>Attributes:</p> Name Type Description <code>view_ref</code> <code>ViewRef</code> <p>Reference to the embedding's view.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/embeddings/embedding/#pixano.features.schemas.embeddings.embedding.ViewEmbedding.view","title":"<code>view: View</code>  <code>property</code>","text":"<p>Get the embedding's view.</p>"},{"location":"api_reference/features/schemas/embeddings/embedding/#pixano.features.schemas.embeddings.embedding.ViewEmbedding.create_schema","title":"<code>create_schema(embedding_fn, table_name, dataset, **embedding_function_kwargs)</code>  <code>classmethod</code>","text":"<p>Create a ViewEmbedding schema.</p> <p>Parameters:</p> Name Type Description Default <code>embedding_fn</code> <code>str</code> <p>The embedding function.</p> required <code>table_name</code> <code>str</code> <p>The name of the table containing the schema.</p> required <code>dataset</code> <code>Dataset</code> <p>The dataset to which the schema belongs.</p> required <code>embedding_function_kwargs</code> <code>Any</code> <p>The keyword arguments for creating the embedding function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>type[ViewEmbedding]</code> <p>The <code>ViewEmbedding</code> schema.</p> Source code in <code>pixano/features/schemas/embeddings/embedding.py</code> <pre><code>@classmethod\ndef create_schema(\n    cls,\n    embedding_fn: str,\n    table_name: str,\n    dataset: \"Dataset\",\n    **embedding_function_kwargs: Any,\n) -&gt; type[\"ViewEmbedding\"]:\n    \"\"\"Create a ViewEmbedding schema.\n\n    Args:\n        embedding_fn: The embedding function.\n        table_name: The name of the table containing the schema.\n        dataset: The dataset to which the schema belongs.\n        embedding_function_kwargs: The keyword arguments for creating the embedding function.\n\n    Returns:\n        The `ViewEmbedding` schema.\n    \"\"\"\n    lance_registry = get_registry()\n    if not isinstance(embedding_fn, str):\n        raise TypeError(f\"{embedding_fn} should be a string\")\n\n    pixano_name = _to_pixano_name(dataset, table_name, embedding_fn)\n    if pixano_name not in lance_registry._functions:\n        type_embedding_function = lance_registry.get(embedding_fn)\n        view_embedding_function: type[EmbeddingFunction] = create_view_embedding_function(\n            type_embedding_function, pixano_name, dataset\n        )\n    else:\n        view_embedding_function = lance_registry.get(pixano_name)\n\n    view_embedding_function = view_embedding_function.create(**embedding_function_kwargs)\n\n    embedding_fields = {\n        \"vector\": (Vector(view_embedding_function.ndims()), view_embedding_function.VectorField()),\n        \"view_ref\": (ViewRef, view_embedding_function.SourceField()),\n    }\n    return create_model(\n        \"ViewEmbedding\",\n        __base__=ViewEmbedding,\n        **embedding_fields,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/embeddings/embedding/#pixano.features.schemas.embeddings.embedding.ViewEmbedding.get_embedding_fn_from_table","title":"<code>get_embedding_fn_from_table(dataset, table_name, metadata)</code>  <code>staticmethod</code>","text":"<p>Get the embedding function from a table.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>The dataset containing the table.</p> required <code>table_name</code> <code>str</code> <p>The name of the table containing the embedding function.</p> required <code>metadata</code> <code>dict</code> <p>The pyarrow metadata of the table.</p> required <p>Returns:</p> Type Description <code>EmbeddingFunction</code> <p>The embedding function.</p> Source code in <code>pixano/features/schemas/embeddings/embedding.py</code> <pre><code>@staticmethod\ndef get_embedding_fn_from_table(dataset: \"Dataset\", table_name: str, metadata: dict) -&gt; EmbeddingFunction:\n    \"\"\"Get the embedding function from a table.\n\n    Args:\n        dataset: The dataset containing the table.\n        table_name: The name of the table containing the embedding function.\n        metadata: The pyarrow metadata of the table.\n\n    Returns:\n        The embedding function.\n    \"\"\"\n    registry = get_registry()\n\n    serialized = metadata[b\"embedding_functions\"]\n    raw_list = json.loads(serialized.decode(\"utf-8\"))\n\n    if len(raw_list) &gt; 1:\n        raise ValueError(\"Only one embedding function per table is supported\")\n\n    pixano_name = raw_list[0][\"name\"]\n    if pixano_name not in registry._functions:\n        name = _from_pixano_name(dataset, table_name, pixano_name)\n        create_view_embedding_function(registry._functions[name], pixano_name, dataset)\n    return registry.get(pixano_name)\n</code></pre>"},{"location":"api_reference/features/schemas/embeddings/embedding/#pixano.features.schemas.embeddings.embedding.create_view_embedding_function","title":"<code>create_view_embedding_function(type_embedding_function, name, dataset)</code>","text":"<p>Create a <code>ViewEmbeddingFunction</code> based on an EmbeddingFunction.</p> Source code in <code>pixano/features/schemas/embeddings/embedding.py</code> <pre><code>def create_view_embedding_function(\n    type_embedding_function: type[EmbeddingFunction], name: str, dataset: \"Dataset\"\n) -&gt; type[EmbeddingFunction]:\n    \"\"\"Create a `ViewEmbeddingFunction` based on an\n    [EmbeddingFunction][lancedb.embeddings.base.EmbeddingFunction].\n    \"\"\"\n\n    @register(name)\n    class ViewEmbeddingFunction(type_embedding_function):\n        \"\"\"A `ViewEmbeddingFunction` based on an [EmbeddingFunction][lancedb.embeddings.base.EmbeddingFunction].\"\"\"\n\n        def _open_views(self, views: list[Any]) -&gt; list[Any]:\n            \"\"\"Open the views in the dataset.\"\"\"\n            return [view.open(dataset.media_dir, \"image\") for view in views]\n\n        def compute_source_embeddings(self, view_refs: pa.Table, *args, **kwargs) -&gt; list:\n            \"\"\"Compute the embeddings for the source column in the database.\"\"\"\n            views = [dataset.resolve_ref(ViewRef(**view_ref)) for view_ref in view_refs.to_pylist()]\n            view_type = type(views[0])\n            if is_image(view_type) or is_sequence_frame(view_type):\n                views = cast(list[Image], views)\n                return super().compute_source_embeddings(self._open_views(views=views), *args, **kwargs)\n            else:\n                raise ValueError(f\"View type {view_type} not supported for embedding.\")\n\n    return ViewEmbeddingFunction\n</code></pre>"},{"location":"api_reference/features/schemas/embeddings/embedding/#pixano.features.schemas.embeddings.embedding.is_embedding","title":"<code>is_embedding(cls, strict=False)</code>","text":"<p>Check if a class is an <code>Embedding</code> or subclass of <code>Embedding</code>.</p> Source code in <code>pixano/features/schemas/embeddings/embedding.py</code> <pre><code>def is_embedding(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is an `Embedding` or subclass of `Embedding`.\"\"\"\n    return issubclass_strict(cls, Embedding, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/embeddings/embedding/#pixano.features.schemas.embeddings.embedding.is_view_embedding","title":"<code>is_view_embedding(cls, strict=False)</code>","text":"<p>Check if a class is an <code>ViewEmbedding</code> or subclass of <code>ViewEmbedding</code>.</p> Source code in <code>pixano/features/schemas/embeddings/embedding.py</code> <pre><code>def is_view_embedding(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is an `ViewEmbedding` or subclass of `ViewEmbedding`.\"\"\"\n    return issubclass_strict(cls, ViewEmbedding, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/entities/entity/","title":"entity","text":""},{"location":"api_reference/features/schemas/entities/entity/#pixano.features.schemas.entities.entity","title":"<code>pixano.features.schemas.entities.entity</code>","text":""},{"location":"api_reference/features/schemas/entities/entity/#pixano.features.schemas.entities.entity.Entity","title":"<code>Entity(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>BaseSchema</code></p> <p><code>Entity</code> base class.</p> <p>Entities are used to define an entity in a dataset such as an object, a track. It can refer to an item, a view, and a parent entity.</p> <p>Attributes:</p> Name Type Description <code>item_ref</code> <code>ItemRef</code> <p>Reference to the entity's item.</p> <code>view_ref</code> <code>ViewRef</code> <p>Reference to the entity's view.</p> <code>parent_ref</code> <code>EntityRef</code> <p>Reference to the entity's parent entity.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/entities/entity/#pixano.features.schemas.entities.entity.Entity.item","title":"<code>item: Item</code>  <code>property</code>","text":"<p>Get the entity's item.</p>"},{"location":"api_reference/features/schemas/entities/entity/#pixano.features.schemas.entities.entity.Entity.parent","title":"<code>parent: Entity</code>  <code>property</code>","text":"<p>Get the entity's parent entity.</p>"},{"location":"api_reference/features/schemas/entities/entity/#pixano.features.schemas.entities.entity.Entity.view","title":"<code>view: View</code>  <code>property</code>","text":"<p>Get the entity's view.</p>"},{"location":"api_reference/features/schemas/entities/entity/#pixano.features.schemas.entities.entity.is_entity","title":"<code>is_entity(cls, strict=False)</code>","text":"<p>Check if a class is an Entity or subclass of Entity.</p> Source code in <code>pixano/features/schemas/entities/entity.py</code> <pre><code>def is_entity(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is an Entity or subclass of Entity.\"\"\"\n    return issubclass_strict(cls, Entity, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/entities/track/","title":"track","text":""},{"location":"api_reference/features/schemas/entities/track/#pixano.features.schemas.entities.track","title":"<code>pixano.features.schemas.entities.track</code>","text":""},{"location":"api_reference/features/schemas/entities/track/#pixano.features.schemas.entities.track.Track","title":"<code>Track(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>Entity</code></p> <p>A <code>Track</code> entity.</p> <p>A track represents an entity that is shared among multiple view across time.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the track.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/entities/track/#pixano.features.schemas.entities.track.create_track","title":"<code>create_track(name, id='', item_ref=ItemRef.none(), view_ref=ViewRef.none(), parent_ref=EntityRef.none())</code>","text":"<p>Create a <code>Track</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the track.</p> required <code>id</code> <code>str</code> <p>Track ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>view_ref</code> <code>ViewRef</code> <p>View reference.</p> <code>none()</code> <code>parent_ref</code> <code>EntityRef</code> <p>Entity reference.</p> <code>none()</code> <p>Returns:</p> Type Description <code>Track</code> <p>The created <code>Track</code> instance.</p> Source code in <code>pixano/features/schemas/entities/track.py</code> <pre><code>def create_track(\n    name: str,\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    view_ref: ViewRef = ViewRef.none(),\n    parent_ref: EntityRef = EntityRef.none(),\n) -&gt; Track:\n    \"\"\"Create a `Track` instance.\n\n    Args:\n        name: The name of the track.\n        id: Track ID.\n        item_ref: Item reference.\n        view_ref: View reference.\n        parent_ref: Entity reference.\n\n    Returns:\n        The created `Track` instance.\n    \"\"\"\n    return Track(\n        id=id,\n        item_ref=item_ref,\n        view_ref=view_ref,\n        parent_ref=parent_ref,\n        name=name,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/entities/track/#pixano.features.schemas.entities.track.is_track","title":"<code>is_track(cls, strict=False)</code>","text":"<p>Check if the given class is a <code>Track</code> or a subclass of <code>Track</code>.</p> Source code in <code>pixano/features/schemas/entities/track.py</code> <pre><code>def is_track(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if the given class is a `Track` or a subclass of `Track`.\"\"\"\n    return issubclass_strict(cls, Track, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/items/item/","title":"item","text":""},{"location":"api_reference/features/schemas/items/item/#pixano.features.schemas.items.item","title":"<code>pixano.features.schemas.items.item</code>","text":""},{"location":"api_reference/features/schemas/items/item/#pixano.features.schemas.items.item.Item","title":"<code>Item(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>BaseSchema</code></p> <p>Item base class.</p> <p>Items are used to store information about an item in a dataset. It contains at least a split attribute. It also federates the information about the item's views, entities, annotations, embeddings, etc via its id.</p> <p>Attributes:</p> Name Type Description <code>split</code> <code>str</code> <p>Split of the item.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/items/item/#pixano.features.schemas.items.item.is_item","title":"<code>is_item(cls, strict=False)</code>","text":"<p>Check if a class is an <code>Item</code> or subclass of <code>Item</code>.</p> Source code in <code>pixano/features/schemas/items/item.py</code> <pre><code>def is_item(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is an `Item` or subclass of `Item`.\"\"\"\n    return issubclass_strict(cls, Item, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/views/image/","title":"image","text":""},{"location":"api_reference/features/schemas/views/image/#pixano.features.schemas.views.image","title":"<code>pixano.features.schemas.views.image</code>","text":""},{"location":"api_reference/features/schemas/views/image/#pixano.features.schemas.views.image.Image","title":"<code>Image(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>View</code></p> <p>Image view.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The image URL. Can be relative or absolute or a data URL.</p> <code>width</code> <code>int</code> <p>The image width.</p> <code>height</code> <code>int</code> <p>The image height.</p> <code>format</code> <code>str</code> <p>The image format.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/views/image/#pixano.features.schemas.views.image.Image.open","title":"<code>open(media_dir=None, output_type='base64')</code>","text":"<pre><code>open(media_dir: Path | None, output_type: Literal['base64'] = 'base64') -&gt; str\n</code></pre><pre><code>open(media_dir: Path | None, output_type: Literal['image']) -&gt; PILImage\n</code></pre> <p>Open the image.</p> Note <p>If the output type is \"base64\", the image is returned as a base64 string formatted as \"data:image/{image_format};base64,{base64}\".</p> <p>Parameters:</p> Name Type Description Default <code>media_dir</code> <code>Path | None</code> <p>Path to the media directory. If the URL is relative, it is relative to this directory.</p> <code>None</code> <code>output_type</code> <code>Literal['base64', 'image']</code> <p>The output type. Can be \"base64\" or \"image\" (PIL.Image).</p> <code>'base64'</code> <p>Returns:</p> Type Description <code>str | Image</code> <p>opened image.</p> Source code in <code>pixano/features/schemas/views/image.py</code> <pre><code>def open(\n    self,\n    media_dir: Path | None = None,\n    output_type: Literal[\"base64\", \"image\"] = \"base64\",\n) -&gt; str | PILImage:\n    \"\"\"Open the image.\n\n    Note:\n        If the output type is \"base64\", the image is returned as a base64 string formatted as\n        \"data:image/{image_format};base64,{base64}\".\n\n    Args:\n        media_dir: Path to the media directory. If the URL is relative, it is relative to this directory.\n        output_type: The output type. Can be \"base64\" or \"image\" (PIL.Image).\n\n    Returns:\n        opened image.\n    \"\"\"\n    return Image.open_url(url=self.url, media_dir=media_dir, output_type=output_type)\n</code></pre>"},{"location":"api_reference/features/schemas/views/image/#pixano.features.schemas.views.image.Image.open_url","title":"<code>open_url(url, media_dir=None, output_type='base64')</code>  <code>staticmethod</code>","text":"<pre><code>open_url(url: str, media_dir: Path | None, output_type: Literal['base64'] = 'base64') -&gt; str\n</code></pre><pre><code>open_url(url: str, media_dir: Path | None, output_type: Literal['image']) -&gt; PILImage\n</code></pre> <p>Open an image from a URL.</p> Note <p>If the output type is \"base64\", the image is returned as a base64 string formatted as \"data:image/{image_format};base64,{base64}\".</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>image url relative to media_dir or absolute.</p> required <code>media_dir</code> <code>Path | None</code> <p>path to the media directory if the URL is relative.</p> <code>None</code> <code>output_type</code> <code>Literal['base64', 'image']</code> <p>output type. Can be \"base64\" or \"image\" (PIL.Image).</p> <code>'base64'</code> <p>Returns:</p> Type Description <code>str | Image</code> <p>The opened image.</p> Source code in <code>pixano/features/schemas/views/image.py</code> <pre><code>@staticmethod\ndef open_url(\n    url: str,\n    media_dir: Path | None = None,\n    output_type: Literal[\"base64\", \"image\"] = \"base64\",\n) -&gt; str | PILImage:\n    \"\"\"Open an image from a URL.\n\n    Note:\n        If the output type is \"base64\", the image is returned as a base64 string formatted as\n        \"data:image/{image_format};base64,{base64}\".\n\n    Args:\n        url: image url relative to media_dir or absolute.\n        media_dir: path to the media directory if the URL is relative.\n        output_type: output type. Can be \"base64\" or \"image\" (PIL.Image).\n\n    Returns:\n        The opened image.\n    \"\"\"\n    if output_type not in [\"base64\", \"image\"]:\n        raise ValueError(f\"Invalid output type: {output_type}\")\n\n    # URI is incomplete\n    if urlparse(url).scheme == \"\":\n        if media_dir is None:\n            raise ValueError(\"URI is incomplete, need media directory\")\n        uri_prefix = media_dir.absolute().as_uri()\n        # URI prefix exists\n        if uri_prefix is not None:\n            parsed_uri = urlparse(uri_prefix)\n            # URI prefix is incomplete\n            if parsed_uri.scheme == \"\":\n                raise ValueError(\"URI prefix is incomplete, no scheme provided (http://, file://, ...)\")\n            if url.startswith(\"/\"):\n                url = url[1:]\n            combined_path = Path(parsed_uri.path) / url\n            parsed_uri = parsed_uri._replace(path=str(combined_path))\n            api_url = parsed_uri.geturl()\n        else:\n            # No URI prefix\n            raise ValueError(\"URI is incomplete, need URI prefix\")\n    # URI is already complete\n    else:\n        api_url = url\n\n    try:\n        with urlopen(api_url) as f:\n            im_bytes = f.read()\n    except URLError:\n        raise ValueError(f\"Error: image not found ({api_url})\")\n\n    pil_image = PIL.Image.open(io.BytesIO(im_bytes))\n\n    # Handle output types\n    if output_type == \"base64\":\n        return image_to_base64(pil_image)\n\n    return pil_image\n</code></pre>"},{"location":"api_reference/features/schemas/views/image/#pixano.features.schemas.views.image.create_image","title":"<code>create_image(url, id='', item_ref=ItemRef.none(), parent_ref=ViewRef.none(), width=None, height=None, format=None, url_relative_path=None)</code>","text":"<p>Create an <code>Image</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>Path</code> <p>The image URL. If not relative, the URL is converted to a relative path using <code>other_path</code>.</p> required <code>id</code> <code>str</code> <p>Image ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>parent_ref</code> <code>ViewRef</code> <p>Parent view reference.</p> <code>none()</code> <code>width</code> <code>int | None</code> <p>The image width. If None, the width is extracted from the image file.</p> <code>None</code> <code>height</code> <code>int | None</code> <p>The image height. If None, the height is extracted from the image file.</p> <code>None</code> <code>format</code> <code>str | None</code> <p>The image format. If None, the format is extracted from the image file.</p> <code>None</code> <code>url_relative_path</code> <code>Path | None</code> <p>The path to convert the URL to a relative path.</p> <code>None</code> <p>Returns:</p> Type Description <code>Image</code> <p>The created <code>Image</code> instance.</p> Source code in <code>pixano/features/schemas/views/image.py</code> <pre><code>def create_image(\n    url: Path,\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    parent_ref: ViewRef = ViewRef.none(),\n    width: int | None = None,\n    height: int | None = None,\n    format: str | None = None,\n    url_relative_path: Path | None = None,\n) -&gt; Image:\n    \"\"\"Create an `Image` instance.\n\n    Args:\n        url: The image URL. If not relative, the URL is converted to a relative path using `other_path`.\n        id: Image ID.\n        item_ref: Item reference.\n        parent_ref: Parent view reference.\n        width: The image width. If None, the width is extracted from the image file.\n        height: The image height. If None, the height is extracted from the image file.\n        format: The image format. If None, the format is extracted from the image file.\n        url_relative_path: The path to convert the URL to a relative path.\n\n    Returns:\n        The created `Image` instance.\n    \"\"\"\n    none_conditions = [width is None, height is None, format is None]\n    not_none_conditions = [width is not None, height is not None, format is not None]\n    if not all(none_conditions) and not all(not_none_conditions):\n        raise ValueError(\"width, height and format must be all defined or all None\")\n\n    url = Path(url)\n\n    if width is None:\n        img = PIL.Image.open(url)\n        width = img.width\n        height = img.height\n        format = img.format\n\n    if url_relative_path is not None:\n        url_relative_path = Path(url_relative_path)\n        url = url.relative_to(url_relative_path)\n\n    return Image(\n        id=id, item_ref=item_ref, parent_ref=parent_ref, url=url.as_posix(), width=width, height=height, format=format\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/views/image/#pixano.features.schemas.views.image.is_image","title":"<code>is_image(cls, strict=False)</code>","text":"<p>Check if the given class is <code>Image</code> or a subclass of <code>Image</code>.</p> Source code in <code>pixano/features/schemas/views/image.py</code> <pre><code>def is_image(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if the given class is `Image` or a subclass of `Image`.\"\"\"\n    return issubclass_strict(cls, Image, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/views/point_cloud/","title":"point_cloud","text":""},{"location":"api_reference/features/schemas/views/point_cloud/#pixano.features.schemas.views.point_cloud","title":"<code>pixano.features.schemas.views.point_cloud</code>","text":""},{"location":"api_reference/features/schemas/views/point_cloud/#pixano.features.schemas.views.point_cloud.PointCloud","title":"<code>PointCloud(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>View</code></p> <p>Point Cloud view.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The point cloud URL.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/views/point_cloud/#pixano.features.schemas.views.point_cloud.create_point_cloud","title":"<code>create_point_cloud(url, id='', item_ref=ItemRef.none(), parent_ref=ViewRef.none())</code>","text":"<p>Create a <code>PointCloud</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The point cloud URL.</p> required <code>id</code> <code>str</code> <p>Point cloud ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>parent_ref</code> <code>ViewRef</code> <p>Parent view reference.</p> <code>none()</code> <p>Returns:</p> Type Description <code>PointCloud</code> <p>The created <code>PointCloud</code> instance.</p> Source code in <code>pixano/features/schemas/views/point_cloud.py</code> <pre><code>def create_point_cloud(\n    url: str, id: str = \"\", item_ref: ItemRef = ItemRef.none(), parent_ref: ViewRef = ViewRef.none()\n) -&gt; PointCloud:\n    \"\"\"Create a `PointCloud` instance.\n\n    Args:\n        url: The point cloud URL.\n        id: Point cloud ID.\n        item_ref: Item reference.\n        parent_ref: Parent view reference.\n\n    Returns:\n        The created `PointCloud` instance.\n    \"\"\"\n    return PointCloud(url=url, id=id, item_ref=item_ref, parent_ref=parent_ref)\n</code></pre>"},{"location":"api_reference/features/schemas/views/point_cloud/#pixano.features.schemas.views.point_cloud.is_point_cloud","title":"<code>is_point_cloud(cls, strict=False)</code>","text":"<p>Check if the given class is a subclass of <code>PointCloud</code>.</p> Source code in <code>pixano/features/schemas/views/point_cloud.py</code> <pre><code>def is_point_cloud(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if the given class is a subclass of `PointCloud`.\"\"\"\n    return issubclass_strict(cls, PointCloud, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/views/sequence_frame/","title":"sequence_frame","text":""},{"location":"api_reference/features/schemas/views/sequence_frame/#pixano.features.schemas.views.sequence_frame","title":"<code>pixano.features.schemas.views.sequence_frame</code>","text":""},{"location":"api_reference/features/schemas/views/sequence_frame/#pixano.features.schemas.views.sequence_frame.SequenceFrame","title":"<code>SequenceFrame(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>Image</code></p> <p>Sequence Frame view.</p> <p>Attributes:</p> Name Type Description <code>timestamp</code> <code>float</code> <p>The timestamp of the frame.</p> <code>frame_index</code> <code>int</code> <p>The index of the frame in the sequence.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/views/sequence_frame/#pixano.features.schemas.views.sequence_frame.create_sequence_frame","title":"<code>create_sequence_frame(url, timestamp, frame_index, id='', item_ref=ItemRef.none(), parent_ref=ViewRef.none(), width=None, height=None, format=None, url_relative_path=None)</code>","text":"<p>Create a <code>SequenceFrame</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>Path</code> <p>The frame URL. If not relative, the URL is converted to a relative path using <code>other_path</code>.</p> required <code>timestamp</code> <code>float</code> <p>The timestamp of the frame.</p> required <code>frame_index</code> <code>int</code> <p>The index of the frame in the sequence.</p> required <code>id</code> <code>str</code> <p>Point cloud ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>parent_ref</code> <code>ViewRef</code> <p>Parent view reference.</p> <code>none()</code> <code>width</code> <code>int | None</code> <p>The frame width. If None, the width is extracted from the frame file.</p> <code>None</code> <code>height</code> <code>int | None</code> <p>The frame height. If None, the height is extracted from the frame file.</p> <code>None</code> <code>format</code> <code>str | None</code> <p>The frame format. If None, the format is extracted from the frame file.</p> <code>None</code> <code>url_relative_path</code> <code>Path | None</code> <p>The path to convert the URL to a relative path.</p> <code>None</code> <p>Returns:</p> Type Description <code>SequenceFrame</code> <p>The created <code>SequenceFrame</code> instance.</p> Source code in <code>pixano/features/schemas/views/sequence_frame.py</code> <pre><code>def create_sequence_frame(\n    url: Path,\n    timestamp: float,\n    frame_index: int,\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    parent_ref: ViewRef = ViewRef.none(),\n    width: int | None = None,\n    height: int | None = None,\n    format: str | None = None,\n    url_relative_path: Path | None = None,\n) -&gt; SequenceFrame:\n    \"\"\"Create a `SequenceFrame` instance.\n\n    Args:\n        url: The frame URL. If not relative, the URL is converted to a relative path using `other_path`.\n        timestamp: The timestamp of the frame.\n        frame_index: The index of the frame in the sequence.\n        id: Point cloud ID.\n        item_ref: Item reference.\n        parent_ref: Parent view reference.\n        width: The frame width. If None, the width is extracted from the frame file.\n        height: The frame height. If None, the height is extracted from the frame file.\n        format: The frame format. If None, the format is extracted from the frame file.\n        url_relative_path: The path to convert the URL to a relative path.\n\n    Returns:\n        The created `SequenceFrame` instance.\n    \"\"\"\n    image = create_image(url, id, item_ref, parent_ref, width, height, format, url_relative_path)\n    return SequenceFrame(\n        id=id,\n        item_ref=item_ref,\n        parent_ref=parent_ref,\n        url=image.url,\n        width=image.width,\n        height=image.height,\n        format=image.format,\n        timestamp=timestamp,\n        frame_index=frame_index,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/views/sequence_frame/#pixano.features.schemas.views.sequence_frame.is_sequence_frame","title":"<code>is_sequence_frame(cls, strict=False)</code>","text":"<p>Check if the given class is a subclass of <code>SequenceFrame</code>.</p> Source code in <code>pixano/features/schemas/views/sequence_frame.py</code> <pre><code>def is_sequence_frame(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if the given class is a subclass of `SequenceFrame`.\"\"\"\n    return issubclass_strict(cls, SequenceFrame, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/views/text/","title":"text","text":""},{"location":"api_reference/features/schemas/views/text/#pixano.features.schemas.views.text","title":"<code>pixano.features.schemas.views.text</code>","text":""},{"location":"api_reference/features/schemas/views/text/#pixano.features.schemas.views.text.Text","title":"<code>Text(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>View</code></p> <p>Text view.</p> <p>Attributes:</p> Name Type Description <code>content</code> <code>str</code> <p>The text content.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/views/text/#pixano.features.schemas.views.text.create_text","title":"<code>create_text(content, id='', item_ref=ItemRef.none(), parent_ref=ViewRef.none())</code>","text":"<p>Create a <code>Text</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The text content.</p> required <code>id</code> <code>str</code> <p>Text ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>parent_ref</code> <code>ViewRef</code> <p>Parent view reference.</p> <code>none()</code> <p>Returns:</p> Type Description <code>Text</code> <p>The created <code>Text</code> instance.</p> Source code in <code>pixano/features/schemas/views/text.py</code> <pre><code>def create_text(\n    content: str,\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    parent_ref: ViewRef = ViewRef.none(),\n) -&gt; Text:\n    \"\"\"Create a `Text` instance.\n\n    Args:\n        content: The text content.\n        id: Text ID.\n        item_ref: Item reference.\n        parent_ref: Parent view reference.\n\n    Returns:\n        The created `Text` instance.\n    \"\"\"\n    return Text(id=id, item_ref=item_ref, parent_ref=parent_ref, content=content)\n</code></pre>"},{"location":"api_reference/features/schemas/views/text/#pixano.features.schemas.views.text.is_text","title":"<code>is_text(cls, strict=False)</code>","text":"<p>Check if the given class is <code>Text</code> or a subclass of <code>Text</code>.</p> Source code in <code>pixano/features/schemas/views/text.py</code> <pre><code>def is_text(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if the given class is `Text` or a subclass of `Text`.\"\"\"\n    return issubclass_strict(cls, Text, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/views/video/","title":"video","text":""},{"location":"api_reference/features/schemas/views/video/#pixano.features.schemas.views.video","title":"<code>pixano.features.schemas.views.video</code>","text":""},{"location":"api_reference/features/schemas/views/video/#pixano.features.schemas.views.video.Video","title":"<code>Video(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>View</code></p> <p>Video view.</p> <p>Attributes:</p> Name Type Description <code>url</code> <code>str</code> <p>The video URL.</p> <code>num_frames</code> <code>int</code> <p>The number of frames in the video.</p> <code>fps</code> <code>float</code> <p>The frames per second of the video.</p> <code>width</code> <code>int</code> <p>The video width.</p> <code>height</code> <code>int</code> <p>The video height.</p> <code>format</code> <code>str</code> <p>The video format.</p> <code>duration</code> <code>float</code> <p>The video duration.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/views/video/#pixano.features.schemas.views.video.create_video","title":"<code>create_video(url, id='', item_ref=ItemRef.none(), parent_ref=ViewRef.none(), num_frames=None, fps=None, width=None, height=None, format=None, duration=None, url_relative_path=None)</code>","text":"<p>Create a <code>Video</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>Path</code> <p>The image URL. If not relative, the URL is converted to a relative path using <code>other_path</code>.</p> required <code>id</code> <code>str</code> <p>Point cloud ID.</p> <code>''</code> <code>item_ref</code> <code>ItemRef</code> <p>Item reference.</p> <code>none()</code> <code>parent_ref</code> <code>ViewRef</code> <p>Parent view reference.</p> <code>none()</code> <code>num_frames</code> <code>int | None</code> <p>The number of frames in the video. If None, the number of frames is extracted from the video file.</p> <code>None</code> <code>fps</code> <code>float | None</code> <p>The frames per second of the video. If None, the fps is extracted from the video file.</p> <code>None</code> <code>width</code> <code>int | None</code> <p>The video width. If None, the width is extracted from the video file.</p> <code>None</code> <code>height</code> <code>int | None</code> <p>The video height. If None, the height is extracted from the video file.</p> <code>None</code> <code>format</code> <code>str | None</code> <p>The video format. If None, the format is extracted from the video file.</p> <code>None</code> <code>duration</code> <code>float | None</code> <p>The video duration. If None, the duration is extracted from the video file.</p> <code>None</code> <code>url_relative_path</code> <code>Path | None</code> <p>The path to convert the URL to a relative path.</p> <code>None</code> <p>Returns:</p> Type Description <code>Video</code> <p>The created <code>Video</code> instance.</p> Source code in <code>pixano/features/schemas/views/video.py</code> <pre><code>def create_video(\n    url: Path,\n    id: str = \"\",\n    item_ref: ItemRef = ItemRef.none(),\n    parent_ref: ViewRef = ViewRef.none(),\n    num_frames: int | None = None,\n    fps: float | None = None,\n    width: int | None = None,\n    height: int | None = None,\n    format: str | None = None,\n    duration: float | None = None,\n    url_relative_path: Path | None = None,\n) -&gt; Video:\n    \"\"\"Create a `Video` instance.\n\n    Args:\n        url: The image URL. If not relative, the URL is converted to a relative path using `other_path`.\n        id: Point cloud ID.\n        item_ref: Item reference.\n        parent_ref: Parent view reference.\n        num_frames: The number of frames in the video. If None, the number of frames is\n            extracted from the video file.\n        fps: The frames per second of the video. If None, the fps is extracted from the video\n            file.\n        width: The video width. If None, the width is extracted from the video file.\n        height: The video height. If None, the height is extracted from the video file.\n        format: The video format. If None, the format is extracted from the video file.\n        duration: The video duration. If None, the duration is extracted from the video file.\n        url_relative_path: The path to convert the URL to a relative path.\n\n    Returns:\n        The created `Video` instance.\n    \"\"\"\n    none_conditions = [\n        num_frames is None,\n        fps is None,\n        width is None,\n        height is None,\n        format is None,\n        duration is None,\n    ]\n    not_none_conditions = [\n        num_frames is not None,\n        fps is not None,\n        width is not None,\n        height is not None,\n        format is not None,\n        duration is not None,\n    ]\n    if not all(none_conditions) and not all(not_none_conditions):\n        raise ValueError(\n            \"All or none of the following arguments must be provided: width, height, format, num_frames, fps, duration\"\n        )\n\n    url = Path(url)\n    if id is None:\n        id = shortuuid.uuid()\n\n    if width is None:\n        try:\n            import ffmpeg\n        except ImportError:\n            raise ImportError(\"To load video files metadata, install ffmpeg\")\n        try:\n            metadata = ffmpeg.probe(str(url.resolve()), cmd=\"ffprobe\")[\"streams\"][0]\n        except FileNotFoundError:\n            raise FileNotFoundError(\"File not found or ffprobe is not installed.\")\n        r_frame_rate = metadata[\"r_frame_rate\"].split(\"/\")\n        fps = float(r_frame_rate[0]) / float(r_frame_rate[1])\n        num_frames = int(metadata[\"nb_frames\"])\n        width = int(metadata[\"width\"])\n        height = int(metadata[\"height\"])\n        format = url.suffix[1:]\n        duration = float(metadata[\"duration\"])\n\n    if url_relative_path is not None:\n        url_relative_path = Path(url_relative_path)\n        url = url.relative_to(url_relative_path)\n\n    return Video(\n        id=id,\n        item_ref=item_ref,\n        parent_ref=parent_ref,\n        url=url.as_posix(),\n        num_frames=num_frames,\n        fps=fps,\n        width=width,\n        height=height,\n        format=format,\n        duration=duration,\n    )\n</code></pre>"},{"location":"api_reference/features/schemas/views/video/#pixano.features.schemas.views.video.is_video","title":"<code>is_video(cls, strict=False)</code>","text":"<p>Check if the given class is a <code>Video</code> or a subclass of <code>Video</code>.</p> Source code in <code>pixano/features/schemas/views/video.py</code> <pre><code>def is_video(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if the given class is a `Video` or a subclass of `Video`.\"\"\"\n    return issubclass_strict(cls, Video, strict)\n</code></pre>"},{"location":"api_reference/features/schemas/views/view/","title":"view","text":""},{"location":"api_reference/features/schemas/views/view/#pixano.features.schemas.views.view","title":"<code>pixano.features.schemas.views.view</code>","text":""},{"location":"api_reference/features/schemas/views/view/#pixano.features.schemas.views.view.View","title":"<code>View(created_at=None, updated_at=None, **data)</code>","text":"<p>               Bases: <code>BaseSchema</code></p> <p>View base class.</p> <p>Views are used to define a view in a dataset such as an image, a point cloud, a text. It can refer to an item and a parent view.</p> <p>Attributes:</p> Name Type Description <code>item_ref</code> <code>ItemRef</code> <p>Reference to the view's item.</p> <code>parent_ref</code> <code>ViewRef</code> <p>Reference to the view's parent view.</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | None</code> <p>The creation date of the object.</p> <code>None</code> <code>updated_at</code> <code>datetime | None</code> <p>The last modification date of the object.</p> <code>None</code> <code>data</code> <code>Any</code> <p>The data of the object validated by Pydantic.</p> <code>{}</code> Source code in <code>pixano/features/schemas/base_schema.py</code> <pre><code>def __init__(self, /, created_at: datetime | None = None, updated_at: datetime | None = None, **data: Any):\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n        data: The data of the object validated by Pydantic.\n    \"\"\"\n    created_at, updated_at = validate_and_init_create_at_and_update_at(created_at, updated_at)\n    data.update({\"created_at\": created_at, \"updated_at\": updated_at})\n    super().__init__(**data)\n</code></pre>"},{"location":"api_reference/features/schemas/views/view/#pixano.features.schemas.views.view.View.item","title":"<code>item: Item</code>  <code>property</code>","text":"<p>Get the view's item.</p>"},{"location":"api_reference/features/schemas/views/view/#pixano.features.schemas.views.view.View.parent","title":"<code>parent: View</code>  <code>property</code>","text":"<p>Get the view's parent view.</p>"},{"location":"api_reference/features/schemas/views/view/#pixano.features.schemas.views.view.is_view","title":"<code>is_view(cls, strict=False)</code>","text":"<p>Check if a class is a <code>View</code> or subclass of <code>View</code>.</p> Source code in <code>pixano/features/schemas/views/view.py</code> <pre><code>def is_view(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a `View` or subclass of `View`.\"\"\"\n    return issubclass_strict(cls, View, strict)\n</code></pre>"},{"location":"api_reference/features/types/base_type/","title":"base_type","text":""},{"location":"api_reference/features/types/base_type/#pixano.features.types.base_type","title":"<code>pixano.features.types.base_type</code>","text":""},{"location":"api_reference/features/types/base_type/#pixano.features.types.base_type.BaseType","title":"<code>BaseType</code>","text":"<p>               Bases: <code>LanceModel</code></p> <p>Base class for all Pixano types.</p> <p>This class should be inherited by all Pixano types. BaseSchemas can only have a primitive type or a <code>BaseType</code> attribute.</p>"},{"location":"api_reference/features/types/base_type/#pixano.features.types.base_type.is_base_type","title":"<code>is_base_type(cls, strict=False)</code>","text":"<p>Check if a class is a <code>BaseType</code> or subclass of <code>BaseType</code>.</p> Source code in <code>pixano/features/types/base_type.py</code> <pre><code>def is_base_type(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a `BaseType` or subclass of `BaseType`.\"\"\"\n    return issubclass_strict(cls, BaseType, strict)\n</code></pre>"},{"location":"api_reference/features/types/nd_array_float/","title":"nd_array_float","text":""},{"location":"api_reference/features/types/nd_array_float/#pixano.features.types.nd_array_float","title":"<code>pixano.features.types.nd_array_float</code>","text":""},{"location":"api_reference/features/types/nd_array_float/#pixano.features.types.nd_array_float.NDArrayFloat","title":"<code>NDArrayFloat</code>","text":"<p>               Bases: <code>BaseType</code></p> <p>Represents an N-dimensional array of floating-point values.</p> <p>Attributes:</p> Name Type Description <code>values</code> <code>list[float]</code> <p>The list of floating-point values in the array.</p> <code>shape</code> <code>list[int]</code> <p>The shape of the array, represented as a list of integers.</p>"},{"location":"api_reference/features/types/nd_array_float/#pixano.features.types.nd_array_float.NDArrayFloat.from_numpy","title":"<code>from_numpy(arr)</code>  <code>staticmethod</code>","text":"<p>Create an instance of the class from a NumPy array.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>The NumPy array to convert.</p> required <p>Returns:</p> Type Description <code>NDArrayFloat</code> <p>An instance of the class with values and shape derived from the input array.</p> Source code in <code>pixano/features/types/nd_array_float.py</code> <pre><code>@staticmethod\ndef from_numpy(arr: np.ndarray) -&gt; \"NDArrayFloat\":\n    \"\"\"Create an instance of the class from a NumPy array.\n\n    Args:\n        arr: The NumPy array to convert.\n\n    Returns:\n        An instance of the class with values and shape derived from the input array.\n    \"\"\"\n    return NDArrayFloat(values=arr.reshape(-1).tolist(), shape=list(arr.shape))\n</code></pre>"},{"location":"api_reference/features/types/nd_array_float/#pixano.features.types.nd_array_float.NDArrayFloat.none","title":"<code>none()</code>  <code>classmethod</code>","text":"<p>Utility function to get a <code>None</code> equivalent. Should be removed as soon as Lance manages <code>None</code> value.</p> <p>Returns:</p> Type Description <code>NDArrayFloat</code> <p>\"None\" <code>NDArrayFloat</code>.</p> Source code in <code>pixano/features/types/nd_array_float.py</code> <pre><code>@classmethod\ndef none(cls) -&gt; \"NDArrayFloat\":\n    \"\"\"Utility function to get a `None` equivalent.\n    Should be removed as soon as Lance manages `None` value.\n\n    Returns:\n        \"None\" `NDArrayFloat`.\n    \"\"\"\n    return cls(values=[0], shape=[1])\n</code></pre>"},{"location":"api_reference/features/types/nd_array_float/#pixano.features.types.nd_array_float.create_ndarray_float","title":"<code>create_ndarray_float(values, shape)</code>","text":"<p>Create a <code>NDArrayFloat</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>list[float]</code> <p>The list of floating-point values in the array.</p> required <code>shape</code> <code>list[int]</code> <p>The shape of the array, represented as a list of integers.</p> required <p>Returns:</p> Type Description <code>NDArrayFloat</code> <p>The created <code>NDArrayFloat</code> instance.</p> Source code in <code>pixano/features/types/nd_array_float.py</code> <pre><code>def create_ndarray_float(values: list[float], shape: list[int]) -&gt; NDArrayFloat:\n    \"\"\"Create a `NDArrayFloat` instance.\n\n    Args:\n        values: The list of floating-point values in the array.\n        shape: The shape of the array, represented as a list of integers.\n\n    Returns:\n        The created `NDArrayFloat` instance.\n    \"\"\"\n    return NDArrayFloat(values=values, shape=shape)\n</code></pre>"},{"location":"api_reference/features/types/nd_array_float/#pixano.features.types.nd_array_float.is_ndarray_float","title":"<code>is_ndarray_float(cls, strict=False)</code>","text":"<p>Check if a class is a <code>NDArrayFloat</code> or a subclass of <code>NDArrayFloat</code>.</p> Source code in <code>pixano/features/types/nd_array_float.py</code> <pre><code>def is_ndarray_float(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a `NDArrayFloat` or a subclass of `NDArrayFloat`.\"\"\"\n    return issubclass_strict(cls, NDArrayFloat, strict)\n</code></pre>"},{"location":"api_reference/features/types/registry/","title":"registry","text":""},{"location":"api_reference/features/types/registry/#pixano.features.types.registry","title":"<code>pixano.features.types.registry</code>","text":""},{"location":"api_reference/features/types/schema_reference/","title":"schema_reference","text":""},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference","title":"<code>pixano.features.types.schema_reference</code>","text":""},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.AnnotationRef","title":"<code>AnnotationRef</code>","text":"<p>               Bases: <code>SchemaRef['Annotation']</code></p> <p>Annotation reference.</p>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.EmbeddingRef","title":"<code>EmbeddingRef</code>","text":"<p>               Bases: <code>SchemaRef['Embedding']</code></p> <p>Embedding reference.</p>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.EntityRef","title":"<code>EntityRef</code>","text":"<p>               Bases: <code>SchemaRef['Entity']</code></p> <p>Entity reference.</p>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.ItemRef","title":"<code>ItemRef</code>","text":"<p>               Bases: <code>SchemaRef['Item']</code></p> <p>Item reference.</p>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.SchemaRef","title":"<code>SchemaRef</code>","text":"<p>               Bases: <code>BaseType</code>, <code>Generic[T]</code></p> <p>A schema reference.</p> <p>A schema reference is used to reference a schema in a dataset. If an id is provided, the reference points to a specific element stored in the table associated to the schema.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the schema.</p> <code>id</code> <code>str</code> <p>The id of the schema.</p>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.SchemaRef.none","title":"<code>none()</code>  <code>classmethod</code>","text":"<p>Return a reference to no schema.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>@classmethod\ndef none(cls) -&gt; \"SchemaRef\":\n    \"\"\"Return a reference to no schema.\"\"\"\n    return cls(name=\"\", id=\"\")\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.SchemaRef.resolve","title":"<code>resolve(dataset)</code>","text":"<p>Resolve the reference to the schema.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def resolve(self, dataset: \"Dataset\") -&gt; T:\n    \"\"\"Resolve the reference to the schema.\"\"\"\n    return dataset.resolve_ref(self)\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.SourceRef","title":"<code>SourceRef</code>","text":"<p>               Bases: <code>SchemaRef['Source']</code></p> <p>Source reference.</p>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.ViewRef","title":"<code>ViewRef</code>","text":"<p>               Bases: <code>SchemaRef['View']</code></p> <p>View reference.</p>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.create_annotation_ref","title":"<code>create_annotation_ref(id, name)</code>","text":"<p>Create an annotation reference.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def create_annotation_ref(id: str, name: str) -&gt; AnnotationRef:\n    \"\"\"Create an annotation reference.\"\"\"\n    return AnnotationRef(name=name, id=id)\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.create_embedding_ref","title":"<code>create_embedding_ref(id, name)</code>","text":"<p>Create an embedding reference.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def create_embedding_ref(id: str, name: str) -&gt; EmbeddingRef:\n    \"\"\"Create an embedding reference.\"\"\"\n    return EmbeddingRef(name=name, id=id)\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.create_entity_ref","title":"<code>create_entity_ref(id, name)</code>","text":"<p>Create an entity reference.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def create_entity_ref(id: str, name: str) -&gt; EntityRef:\n    \"\"\"Create an entity reference.\"\"\"\n    return EntityRef(name=name, id=id)\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.create_item_ref","title":"<code>create_item_ref(id, name='item')</code>","text":"<p>Create an item reference.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def create_item_ref(id: str, name: str = \"item\") -&gt; ItemRef:\n    \"\"\"Create an item reference.\"\"\"\n    return ItemRef(name=name, id=id)\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.create_schema_ref","title":"<code>create_schema_ref(id, name)</code>","text":"<p>Create a schema reference.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def create_schema_ref(id: str, name: str) -&gt; SchemaRef:\n    \"\"\"Create a schema reference.\"\"\"\n    return SchemaRef(name=name, id=id)\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.create_source_ref","title":"<code>create_source_ref(id)</code>","text":"<p>Create a source reference.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def create_source_ref(id: str) -&gt; SourceRef:\n    \"\"\"Create a source reference.\"\"\"\n    return SourceRef(id=id)\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.create_view_ref","title":"<code>create_view_ref(id, name)</code>","text":"<p>Create a view reference.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def create_view_ref(id: str, name: str) -&gt; ViewRef:\n    \"\"\"Create a view reference.\"\"\"\n    return ViewRef(name=name, id=id)\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.is_annotation_ref","title":"<code>is_annotation_ref(cls, strict=False)</code>","text":"<p>Check if a class is an <code>AnnotationRef</code> or subclass of <code>AnnotationRef</code>.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def is_annotation_ref(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is an `AnnotationRef` or subclass of `AnnotationRef`.\"\"\"\n    return issubclass_strict(cls, AnnotationRef, strict)\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.is_embedding_ref","title":"<code>is_embedding_ref(cls, strict=False)</code>","text":"<p>Check if a class is an <code>EmbeddingRef</code> or subclass of <code>EmbeddingRef</code>.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def is_embedding_ref(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is an `EmbeddingRef` or subclass of `EmbeddingRef`.\"\"\"\n    return issubclass_strict(cls, EmbeddingRef, strict)\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.is_entity_ref","title":"<code>is_entity_ref(cls, strict=False)</code>","text":"<p>Check if a class is an <code>EntityRef</code> or subclass of <code>EntityRef</code>.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def is_entity_ref(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is an `EntityRef` or subclass of `EntityRef`.\"\"\"\n    return issubclass_strict(cls, EntityRef, strict)\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.is_item_ref","title":"<code>is_item_ref(cls, strict=False)</code>","text":"<p>Check if a class is an <code>ItemRef</code> or subclass of <code>ItemRef</code>.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def is_item_ref(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is an `ItemRef` or subclass of `ItemRef`.\"\"\"\n    return issubclass_strict(cls, ItemRef, strict)\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.is_schema_ref","title":"<code>is_schema_ref(cls, strict=False)</code>","text":"<p>Check if a class is a <code>SchemaRef</code> or subclass of <code>SchemaRef</code>.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def is_schema_ref(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a `SchemaRef` or subclass of `SchemaRef`.\"\"\"\n    return issubclass_strict(cls, SchemaRef, strict)\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.is_source_ref","title":"<code>is_source_ref(cls, strict=False)</code>","text":"<p>Check if a class is a <code>SourceRef</code> or subclass of <code>SourceRef</code>.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def is_source_ref(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a `SourceRef` or subclass of `SourceRef`.\"\"\"\n    return issubclass_strict(cls, SourceRef, strict)\n</code></pre>"},{"location":"api_reference/features/types/schema_reference/#pixano.features.types.schema_reference.is_view_ref","title":"<code>is_view_ref(cls, strict=False)</code>","text":"<p>Check if a class is a <code>ViewRef</code> or subclass of <code>ViewRef</code>.</p> Source code in <code>pixano/features/types/schema_reference.py</code> <pre><code>def is_view_ref(cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if a class is a `ViewRef` or subclass of `ViewRef`.\"\"\"\n    return issubclass_strict(cls, ViewRef, strict)\n</code></pre>"},{"location":"api_reference/features/utils/boxes/","title":"boxes","text":""},{"location":"api_reference/features/utils/boxes/#pixano.features.utils.boxes","title":"<code>pixano.features.utils.boxes</code>","text":""},{"location":"api_reference/features/utils/boxes/#pixano.features.utils.boxes.denormalize_coords","title":"<code>denormalize_coords(coord, height, width, rounded_int=True)</code>","text":"<p>Denormalize coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>coord</code> <code>list[float]</code> <p>Normalized coordinates.</p> required <code>height</code> <code>int</code> <p>Height.</p> required <code>width</code> <code>int</code> <p>Width.</p> required <code>rounded_int</code> <code>bool</code> <p>True to round denormalized float to nearest integer.</p> <code>True</code> <p>Returns:</p> Type Description <code>list[float]</code> <p>Unnormalized coordinates.</p> Source code in <code>pixano/features/utils/boxes.py</code> <pre><code>def denormalize_coords(coord: list[float], height: int, width: int, rounded_int: bool = True) -&gt; list[float]:\n    \"\"\"Denormalize coordinates.\n\n    Args:\n        coord: Normalized coordinates.\n        height: Height.\n        width: Width.\n        rounded_int: True to round denormalized float to nearest integer.\n\n    Returns:\n        Unnormalized coordinates.\n    \"\"\"\n    denorm = []\n\n    for i, c in enumerate(coord):\n        if i % 2 == 0:\n            denorm.append(round(c * width) if rounded_int else c * width)\n        else:\n            denorm.append(round(c * height) if rounded_int else c * height)\n\n    return denorm\n</code></pre>"},{"location":"api_reference/features/utils/boxes/#pixano.features.utils.boxes.mask_to_bbox","title":"<code>mask_to_bbox(mask)</code>","text":"<p>Return the smallest bounding box containing all the mask pixels.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>Mask as NumPy Array.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>Normalized xywh bounding box.</p> Source code in <code>pixano/features/utils/boxes.py</code> <pre><code>def mask_to_bbox(mask: np.ndarray) -&gt; list[float]:\n    \"\"\"Return the smallest bounding box containing all the mask pixels.\n\n    Args:\n        mask: Mask as NumPy Array.\n\n    Returns:\n        Normalized xywh bounding box.\n    \"\"\"\n    height, width = mask.shape\n    bool_mask = np.array(mask).astype(bool)\n\n    # Find all columns and rows that contain ones\n    rows = np.any(bool_mask, axis=1)\n    cols = np.any(bool_mask, axis=0)\n\n    # Find the min and max col/row index that contain ones\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n\n    # Calculate bbox height and width\n    w = (cmax - cmin + 1) / width\n    h = (rmax - rmin + 1) / height\n\n    return [cmin / width, rmin / height, w, h]\n</code></pre>"},{"location":"api_reference/features/utils/boxes/#pixano.features.utils.boxes.normalize_coords","title":"<code>normalize_coords(coord, height, width)</code>","text":"<p>Normalize coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>coord</code> <code>list[float]</code> <p>Unnormalized coordinates.</p> required <code>height</code> <code>int</code> <p>Height.</p> required <code>width</code> <code>int</code> <p>Width.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>Normalized coordinates.</p> Source code in <code>pixano/features/utils/boxes.py</code> <pre><code>def normalize_coords(coord: list[float], height: int, width: int) -&gt; list[float]:\n    \"\"\"Normalize coordinates.\n\n    Args:\n        coord: Unnormalized coordinates.\n        height: Height.\n        width: Width.\n\n    Returns:\n        Normalized coordinates.\n    \"\"\"\n    norm = []\n\n    for i, c in enumerate(coord):\n        if i % 2 == 0:\n            norm.append(c / width)\n        else:\n            norm.append(c / height)\n\n    return norm\n</code></pre>"},{"location":"api_reference/features/utils/boxes/#pixano.features.utils.boxes.urle_to_bbox","title":"<code>urle_to_bbox(urle)</code>","text":"<p>Return the smallest bounding box containing all the mask pixels.</p> <p>Parameters:</p> Name Type Description Default <code>urle</code> <code>dict</code> <p>Mask as uncompressed RLE.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>Normalized xywh bounding box.</p> Source code in <code>pixano/features/utils/boxes.py</code> <pre><code>def urle_to_bbox(urle: dict) -&gt; list[float]:\n    \"\"\"Return the smallest bounding box containing all the mask pixels.\n\n    Args:\n        urle: Mask as uncompressed RLE.\n\n    Returns:\n        Normalized xywh bounding box.\n    \"\"\"\n    return mask_to_bbox(rle_to_mask(urle_to_rle(urle)))\n</code></pre>"},{"location":"api_reference/features/utils/boxes/#pixano.features.utils.boxes.xywh_to_xyxy","title":"<code>xywh_to_xyxy(xywh)</code>","text":"<p>Convert bounding box coordinates from xywh (using top left point as reference) to xyxy.</p> <p>Parameters:</p> Name Type Description Default <code>xywh</code> <code>list[float]</code> <p>xywh coordinates.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>xyxy coordinates.</p> Source code in <code>pixano/features/utils/boxes.py</code> <pre><code>def xywh_to_xyxy(xywh: list[float]) -&gt; list[float]:\n    \"\"\"Convert bounding box coordinates from xywh\n    (using top left point as reference) to xyxy.\n\n    Args:\n        xywh: xywh coordinates.\n\n    Returns:\n        xyxy coordinates.\n    \"\"\"\n    return [\n        float(xywh[0]),\n        float(xywh[1]),\n        float(xywh[0] + xywh[2]),\n        float(xywh[1] + xywh[3]),\n    ]\n</code></pre>"},{"location":"api_reference/features/utils/boxes/#pixano.features.utils.boxes.xyxy_to_xywh","title":"<code>xyxy_to_xywh(xyxy)</code>","text":"<p>Convert bounding box coordinates from xyxy to xywh (using top left point as reference).</p> <p>Parameters:</p> Name Type Description Default <code>xyxy</code> <code>list[float]</code> <p>xyxy coordinates.</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>xywh coordinates.</p> Source code in <code>pixano/features/utils/boxes.py</code> <pre><code>def xyxy_to_xywh(xyxy: list[float]) -&gt; list[float]:\n    \"\"\"Convert bounding box coordinates from xyxy to xywh\n    (using top left point as reference).\n\n    Args:\n        xyxy: xyxy coordinates.\n\n    Returns:\n        xywh coordinates.\n    \"\"\"\n    return [\n        float(xyxy[0]),\n        float(xyxy[1]),\n        float(xyxy[2] - xyxy[0]),\n        float(xyxy[3] - xyxy[1]),\n    ]\n</code></pre>"},{"location":"api_reference/features/utils/creators/","title":"creators","text":""},{"location":"api_reference/features/utils/creators/#pixano.features.utils.creators","title":"<code>pixano.features.utils.creators</code>","text":""},{"location":"api_reference/features/utils/creators/#pixano.features.utils.creators.create_instance_of_pixano_type","title":"<code>create_instance_of_pixano_type(pix_type, **data)</code>","text":"<p>Create a pixano object.</p> Source code in <code>pixano/features/utils/creators.py</code> <pre><code>def create_instance_of_pixano_type(pix_type: type[\"BaseType\"], **data) -&gt; \"BaseType\":\n    \"\"\"Create a pixano object.\"\"\"\n    # Import here to avoid circular imports\n    from pixano.features.types import (\n        create_annotation_ref,\n        create_embedding_ref,\n        create_entity_ref,\n        create_item_ref,\n        create_ndarray_float,\n        create_schema_ref,\n        create_source_ref,\n        create_view_ref,\n        is_annotation_ref,\n        is_base_type,\n        is_embedding_ref,\n        is_entity_ref,\n        is_item_ref,\n        is_ndarray_float,\n        is_schema_ref,\n        is_source_ref,\n        is_view_ref,\n    )\n\n    if is_ndarray_float(pix_type, True):\n        return create_ndarray_float(**data)\n\n    elif is_schema_ref(pix_type, True):\n        return create_schema_ref(**data)\n\n    elif is_item_ref(pix_type, True):\n        return create_item_ref(**data)\n\n    elif is_view_ref(pix_type, True):\n        return create_view_ref(**data)\n\n    elif is_entity_ref(pix_type, True):\n        return create_entity_ref(**data)\n\n    elif is_annotation_ref(pix_type, True):\n        return create_annotation_ref(**data)\n\n    elif is_embedding_ref(pix_type, True):\n        return create_embedding_ref(**data)\n\n    elif is_source_ref(pix_type, True):\n        return create_source_ref(**data)\n\n    elif is_base_type(pix_type, False):\n        return pix_type(**data)\n\n    raise ValueError(f\"Type {pix_type} not supported.\")\n</code></pre>"},{"location":"api_reference/features/utils/creators/#pixano.features.utils.creators.create_instance_of_schema","title":"<code>create_instance_of_schema(schema, **data)</code>","text":"<p>Create a row in a Schema.</p> Source code in <code>pixano/features/utils/creators.py</code> <pre><code>def create_instance_of_schema(schema: type[\"BaseSchema\"], **data) -&gt; \"BaseSchema\":\n    \"\"\"Create a row in a Schema.\"\"\"\n    # Import here to avoid circular imports\n    from pixano.features.schemas import (\n        create_bbox,\n        create_bbox3d,\n        create_cam_calibration,\n        create_compressed_rle,\n        create_image,\n        create_keypoints,\n        create_keypoints3d,\n        create_sequence_frame,\n        create_track,\n        create_tracklet,\n        create_video,\n        is_base_schema,\n        is_bbox,\n        is_bbox3d,\n        is_cam_calibration,\n        is_compressed_rle,\n        is_image,\n        is_keypoints,\n        is_keypoints3d,\n        is_sequence_frame,\n        is_track,\n        is_tracklet,\n        is_video,\n    )\n\n    if is_image(schema, strict=True):\n        return create_image(**data)\n\n    elif is_video(schema, strict=True):\n        return create_video(**data)\n\n    elif is_sequence_frame(schema, strict=True):\n        return create_sequence_frame(**data)\n\n    elif is_tracklet(schema, strict=True):\n        return create_tracklet(**data)\n\n    elif is_track(schema, True):\n        return create_track(**data)\n\n    elif is_bbox(schema, True):\n        return create_bbox(**data)\n\n    elif is_bbox3d(schema, True):\n        return create_bbox3d(**data)\n\n    elif is_cam_calibration(schema, True):\n        return create_cam_calibration(**data)\n\n    elif is_compressed_rle(schema, True):\n        return create_compressed_rle(**data)\n\n    elif is_keypoints(schema, True):\n        return create_keypoints(**data)\n\n    elif is_keypoints3d(schema, True):\n        return create_keypoints3d(**data)\n\n    elif is_base_schema(schema, False):\n        return schema(**data)\n\n    raise ValueError(f\"Schema {schema} is not a base schema.\")\n</code></pre>"},{"location":"api_reference/features/utils/image/","title":"image","text":""},{"location":"api_reference/features/utils/image/#pixano.features.utils.image","title":"<code>pixano.features.utils.image</code>","text":""},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.base64_to_image","title":"<code>base64_to_image(base64_image)</code>","text":"<p>Decode image from base64 to Pillow.</p> <p>Expect the image to be formatted as \"data:image/{image_format};base64,{base64}\".</p> <p>Parameters:</p> Name Type Description Default <code>base64_image</code> <code>str</code> <p>Image as base64.</p> required <p>Returns:</p> Type Description <code>Image</code> <p>Pillow image.</p> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def base64_to_image(base64_image: str) -&gt; Image.Image:\n    \"\"\"Decode image from base64 to Pillow.\n\n    Expect the image to be formatted as \"data:image/{image_format};base64,{base64}\".\n\n    Args:\n        base64_image: Image as base64.\n\n    Returns:\n        Pillow image.\n    \"\"\"\n    image_data = base64.b64decode(base64_image.split(\",\", maxsplit=1)[1].encode(\"utf-8\"))\n    return Image.open(io.BytesIO(image_data))\n</code></pre>"},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.binary_to_url","title":"<code>binary_to_url(im_bytes)</code>","text":"<p>Encode image from binary to base 64 URL.</p> <p>Parameters:</p> Name Type Description Default <code>im_bytes</code> <code>bytes</code> <p>Image as binary.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Image base 64 URL.</p> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def binary_to_url(im_bytes: bytes) -&gt; str:\n    \"\"\"Encode image from binary to base 64 URL.\n\n    Args:\n        im_bytes: Image as binary.\n\n    Returns:\n        Image base 64 URL.\n    \"\"\"\n    encoded = base64.b64encode(im_bytes).decode(\"utf-8\")\n    return f\"data:image;base64,{encoded}\"\n</code></pre>"},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.depth_array_to_gray","title":"<code>depth_array_to_gray(depth, valid_start=0.2, valid_end=1, scale=1.0)</code>","text":"<p>Encode depth array to gray levels.</p> <p>Parameters:</p> Name Type Description Default <code>depth</code> <code>ndarray</code> <p>Depth array</p> required <code>valid_start</code> <code>float</code> <p>Valid start.</p> <code>0.2</code> <code>valid_end</code> <code>float</code> <p>Valid end.</p> <code>1</code> <code>scale</code> <code>float</code> <p>Scale.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Depth array in gray levels.</p> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def depth_array_to_gray(\n    depth: np.ndarray,\n    valid_start: float = 0.2,\n    valid_end: float = 1,\n    scale: float = 1.0,\n) -&gt; np.ndarray:\n    \"\"\"Encode depth array to gray levels.\n\n    Args:\n        depth: Depth array\n        valid_start: Valid start.\n        valid_end: Valid end.\n        scale: Scale.\n\n    Returns:\n        Depth array in gray levels.\n    \"\"\"\n    mask = depth &gt; 1\n\n    # Scale gives depth in mm\n    depth_n = depth * scale * 0.001\n\n    if mask.sum() &gt; 0:\n        depth_n[mask] -= depth_n[mask].min()\n        depth_n[mask] /= depth_n[mask].max() / (valid_end - valid_start)\n        depth_n[mask] += valid_start\n\n    depth_n *= 255\n    depth_n = cv2.applyColorMap(depth_n[:, :, np.newaxis].astype(np.uint8), cv2.COLORMAP_PLASMA)\n\n    return depth_n\n</code></pre>"},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.depth_file_to_binary","title":"<code>depth_file_to_binary(depth_path)</code>","text":"<p>Encode depth file to RGB image in binary.</p> <p>Parameters:</p> Name Type Description Default <code>depth_path</code> <code>str</code> <p>Depth file path.</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>Depth file as RGB image in binary.</p> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def depth_file_to_binary(depth_path: str) -&gt; bytes:\n    \"\"\"Encode depth file to RGB image in binary.\n\n    Args:\n        depth_path: Depth file path.\n\n    Returns:\n        Depth file as RGB image in binary.\n    \"\"\"\n    depth = cv2.imread(depth_path, cv2.IMREAD_ANYDEPTH).astype(np.float32)\n    depth = depth_array_to_gray(depth)\n    depth_rgb = Image.fromarray(depth)\n\n    return image_to_binary(depth_rgb)\n</code></pre>"},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.encode_rle","title":"<code>encode_rle(mask, height, width)</code>","text":"<p>Encode mask from polygons / uncompressed RLE / RLE to RLE.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>list[list] | dict</code> <p>Mask as polygons / uncompressed RLE / RLE.</p> required <code>height</code> <code>int</code> <p>Image height.</p> required <code>width</code> <code>int</code> <p>Image width.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Mask as RLE.</p> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def encode_rle(mask: list[list] | dict, height: int, width: int) -&gt; dict:\n    \"\"\"Encode mask from polygons / uncompressed RLE / RLE to RLE.\n\n    Args:\n        mask: Mask as polygons / uncompressed RLE / RLE.\n        height: Image height.\n        width: Image width.\n\n    Returns:\n        Mask as RLE.\n    \"\"\"\n    if isinstance(mask, list):\n        return polygons_to_rle(mask, height, width)\n    elif isinstance(mask, dict):\n        if isinstance(mask[\"counts\"], list):\n            return urle_to_rle(mask)\n        return mask\n    raise ValueError(\"Mask must be a list of polygons or an uncompressed RLE\")\n</code></pre>"},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.get_image_thumbnail","title":"<code>get_image_thumbnail(image, size)</code>","text":"<p>Get image thumbnail.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Pillow Image.</p> required <code>size</code> <code>tuple[int, int]</code> <p>Thumbnail size.</p> required <p>Returns:</p> Type Description <code>Image</code> <p>Image thumbnail as Pillow.</p> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def get_image_thumbnail(image: Image.Image, size: tuple[int, int]) -&gt; Image.Image:\n    \"\"\"Get image thumbnail.\n\n    Args:\n        image: Pillow Image.\n        size: Thumbnail size.\n\n    Returns:\n        Image thumbnail as Pillow.\n    \"\"\"\n    if (\n        not isinstance(size, tuple)\n        or len(size) != 2\n        or not isinstance(size[0], int)\n        or not isinstance(size[1], int)\n        or size[0] &lt;= 0\n        or size[1] &lt;= 0\n    ):\n        raise ValueError(f\"Invalid thumbnail size: {size}\")\n    thumbnail = image.copy()\n    thumbnail.thumbnail(size)\n    return thumbnail\n</code></pre>"},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.image_to_base64","title":"<code>image_to_base64(image, format=None)</code>","text":"<p>Encode image from Pillow to base64.</p> <p>The image is returned as a base64 string formatted as \"data:image/{image_format};base64,{base64}\".</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Pillow image.</p> required <code>format</code> <code>str | None</code> <p>Image format.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Image as base64.</p> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def image_to_base64(image: Image.Image, format: str | None = None) -&gt; str:\n    \"\"\"Encode image from Pillow to base64.\n\n    The image is returned as a base64 string formatted as\n    \"data:image/{image_format};base64,{base64}\".\n\n    Args:\n        image: Pillow image.\n        format: Image format.\n\n    Returns:\n        Image as base64.\n    \"\"\"\n    if image.format is None and format is None:\n        raise ValueError(\"Image format is not defined\")\n\n    buffered = io.BytesIO()\n    out_format = format or image.format\n    if out_format.upper() == \"UNKNOWN\":\n        out_format = \"JPEG\"\n    image.save(buffered, format=out_format)\n\n    encoded = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n\n    return f\"data:image/{out_format.lower()};base64,{encoded}\"\n</code></pre>"},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.image_to_binary","title":"<code>image_to_binary(image, im_format='PNG')</code>","text":"<p>Encode an image from Pillow to binary.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Pillow image.</p> required <code>im_format</code> <code>str</code> <p>Image file extension.</p> <code>'PNG'</code> <p>Returns:</p> Type Description <code>bytes</code> <p>Image as binary.</p> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def image_to_binary(image: Image.Image, im_format: str = \"PNG\") -&gt; bytes:\n    \"\"\"Encode an image from Pillow to binary.\n\n    Args:\n        image: Pillow image.\n        im_format: Image file extension.\n\n    Returns:\n        Image as binary.\n    \"\"\"\n    with BytesIO() as output_bytes:\n        image.save(output_bytes, im_format)\n        im_bytes = output_bytes.getvalue()\n\n    return im_bytes\n</code></pre>"},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.mask_to_polygons","title":"<code>mask_to_polygons(mask)</code>","text":"<p>Encode mask from NumPy array to polygons.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>Mask as NumPy array</p> required <p>Returns:</p> Type Description <code>Tuple</code> <ul> <li>Mask as polygons</li> <li>True if mask has holes</li> </ul> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def mask_to_polygons(mask: np.ndarray) -&gt; tuple[list[list], bool]:\n    \"\"\"Encode mask from NumPy array to polygons.\n\n    Args:\n        mask: Mask as NumPy array\n\n    Returns:\n        Tuple:\n            - Mask as polygons\n            - True if mask has holes\n    \"\"\"\n    # Some versions of cv2 does not support incontiguous arr\n    mask = np.ascontiguousarray(mask)\n\n    # cv2.RETR_CCOMP flag retrieves all the contours and arranges them\n    # to a 2-level hierarchy.\n    # External contours (boundary) of the object are placed in hierarchy-1.\n    # Internal contours (holes) are placed in hierarchy-2.\n    # cv2.CHAIN_APPROX_NONE flag gets vertices of polygons from contours.\n    res = cv2.findContours(mask.astype(\"uint8\"), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n    hierarchy = res[-1]\n\n    # If mask is empty\n    if hierarchy is None:\n        return [], False\n\n    # Check if mask has holes\n    has_holes = (hierarchy.reshape(-1, 4)[:, 3] &gt;= 0).sum() &gt; 0\n\n    res = res[-2]\n    res = [x.flatten() for x in res]\n\n    # The coordinates from OpenCV are integers in range [0, W-1 or H-1].\n    # We add 0.5 to turn them into real-value coordinate space. A better solution\n    # would be to first +0.5 and then dilate the returned polygon by 0.5.\n    res = [x + 0.5 for x in res if len(x) &gt;= 6]\n\n    # Convert np.array to lists\n    res = [x.tolist() for x in res]\n\n    return res, has_holes\n</code></pre>"},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.mask_to_rle","title":"<code>mask_to_rle(mask)</code>","text":"<p>Encode mask from Pillow or NumPy array to RLE.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>Image | ndarray</code> <p>Mask as Pillow or NumPy array.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Mask as RLE.</p> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def mask_to_rle(mask: Image.Image | np.ndarray) -&gt; dict:\n    \"\"\"Encode mask from Pillow or NumPy array to RLE.\n\n    Args:\n        mask: Mask as Pillow or NumPy array.\n\n    Returns:\n        Mask as RLE.\n    \"\"\"\n    mask_array = np.asfortranarray(mask)\n    return mask_api.encode(mask_array)\n</code></pre>"},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.polygons_to_rle","title":"<code>polygons_to_rle(polygons, height, width)</code>","text":"<p>Encode mask from polygons to RLE.</p> <p>Parameters:</p> Name Type Description Default <code>polygons</code> <code>list[list]</code> <p>Mask as polygons.</p> required <code>height</code> <code>int</code> <p>Image height.</p> required <code>width</code> <code>int</code> <p>Image width.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Mask as RLE.</p> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def polygons_to_rle(polygons: list[list], height: int, width: int) -&gt; dict:\n    \"\"\"Encode mask from polygons to RLE.\n\n    Args:\n        polygons: Mask as polygons.\n        height: Image height.\n        width: Image width.\n\n    Returns:\n        Mask as RLE.\n    \"\"\"\n    rles = mask_api.frPyObjects(polygons, height, width)\n    return mask_api.merge(rles)\n</code></pre>"},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.rle_to_mask","title":"<code>rle_to_mask(rle)</code>","text":"<p>Decode mask from RLE to NumPy array.</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>dict[str, list[int] | bytes]</code> <p>Mask as RLE.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Mask as NumPy array.</p> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def rle_to_mask(rle: dict[str, list[int] | bytes]) -&gt; np.ndarray:\n    \"\"\"Decode mask from RLE to NumPy array.\n\n    Args:\n        rle: Mask as RLE.\n\n    Returns:\n        Mask as NumPy array.\n    \"\"\"\n    return mask_api.decode(rle)\n</code></pre>"},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.rle_to_polygons","title":"<code>rle_to_polygons(rle)</code>","text":"<p>Encode mask from RLE to polygons.</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>dict[str, list[int] | bytes]</code> <p>Mask as RLE.</p> required <p>Returns:</p> Type Description <code>list[list]</code> <p>Mask as polygons.</p> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def rle_to_polygons(rle: dict[str, list[int] | bytes]) -&gt; list[list]:\n    \"\"\"Encode mask from RLE to polygons.\n\n    Args:\n        rle: Mask as RLE.\n\n    Returns:\n        Mask as polygons.\n    \"\"\"\n    if \"size\" not in rle:\n        raise ValueError(\"RLE must have a size\")\n    h, w = rle[\"size\"]\n    polygons, _ = mask_to_polygons(rle_to_mask(rle))\n\n    # Normalize point coordinates\n    for p in polygons:\n        p[::2] = [x / w for x in p[::2]]\n        p[1::2] = [y / h for y in p[1::2]]\n\n    return polygons\n</code></pre>"},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.rle_to_urle","title":"<code>rle_to_urle(rle)</code>","text":"<p>Encode mask from RLE to uncompressed RLE.</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>dict[str, list[int] | bytes]</code> <p>Mask as RLE.</p> required <p>Returns:</p> Type Description <code>dict[str, list[int]]</code> <p>Mask as uncompressed RLE.</p> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def rle_to_urle(rle: dict[str, list[int] | bytes]) -&gt; dict[str, list[int]]:\n    \"\"\"Encode mask from RLE to uncompressed RLE.\n\n    Args:\n        rle: Mask as RLE.\n\n    Returns:\n        Mask as uncompressed RLE.\n    \"\"\"\n    if \"counts\" not in rle or rle[\"counts\"] is None:\n        raise ValueError(\"RLE must have counts\")\n    mask = rle_to_mask(rle)\n    urle = {\"counts\": [], \"size\": list(mask.shape)}\n\n    for i, (value, elements) in enumerate(groupby(mask.ravel(order=\"F\"))):\n        urle[\"counts\"].append(0 if i == 0 and value == 1 else len(list(elements)))\n\n    return urle\n</code></pre>"},{"location":"api_reference/features/utils/image/#pixano.features.utils.image.urle_to_rle","title":"<code>urle_to_rle(urle)</code>","text":"<p>Encode mask from uncompressed RLE to RLE.</p> <p>Parameters:</p> Name Type Description Default <code>urle</code> <code>dict[str, list[int]]</code> <p>Mask as uncompressed RLE.</p> required <p>Returns:</p> Type Description <code>dict[str, list[int] | bytes]</code> <p>Mask as RLE.</p> Source code in <code>pixano/features/utils/image.py</code> <pre><code>def urle_to_rle(urle: dict[str, list[int]]) -&gt; dict[str, list[int] | bytes]:\n    \"\"\"Encode mask from uncompressed RLE to RLE.\n\n    Args:\n        urle: Mask as uncompressed RLE.\n\n    Returns:\n        Mask as RLE.\n    \"\"\"\n    height, width = urle[\"size\"]\n    return mask_api.frPyObjects(urle, height, width)\n</code></pre>"},{"location":"api_reference/utils/python/","title":"python","text":""},{"location":"api_reference/utils/python/#pixano.utils.python","title":"<code>pixano.utils.python</code>","text":""},{"location":"api_reference/utils/python/#pixano.utils.python.estimate_folder_size","title":"<code>estimate_folder_size(folder_path)</code>","text":"<p>Estimate a folder size and return it as a human-readable string.</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>Path</code> <p>Folder path.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Folder size as a human-readable string.</p> Source code in <code>pixano/utils/python.py</code> <pre><code>def estimate_folder_size(folder_path: Path) -&gt; str:\n    \"\"\"Estimate a folder size and return it as a human-readable string.\n\n    Args:\n        folder_path: Folder path.\n\n    Returns:\n        Folder size as a human-readable string.\n    \"\"\"\n    # Estimate size\n    total_size = 0.0\n    for dirpath, _, filenames in os.walk(folder_path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            # skip if it is symbolic link\n            if not os.path.islink(fp):\n                total_size += os.path.getsize(fp)\n\n    # Format size\n    i = 0\n    suffixes = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n    while total_size &gt;= 1024 and i &lt; len(suffixes) - 1:\n        total_size /= 1024.0\n        i += 1\n    f = (f\"{total_size:.2f}\").rstrip(\"0\").rstrip(\".\")\n    readable_size = f\"{f} {suffixes[i]}\"\n\n    return readable_size\n</code></pre>"},{"location":"api_reference/utils/python/#pixano.utils.python.fn_sort_dict","title":"<code>fn_sort_dict(dict_, order_by, descending)</code>","text":"<p>Function to sort a dictionary by multiple keys in different orders.</p> <p>Parameters:</p> Name Type Description Default <code>dict_</code> <code>dict[str, Any]</code> <p>Dictionary to sort.</p> required <code>order_by</code> <code>list[str]</code> <p>List of keys to sort by.</p> required <code>descending</code> <code>list[bool]</code> <p>List of booleans indicating the order for each key.</p> required Source code in <code>pixano/utils/python.py</code> <pre><code>def fn_sort_dict(dict_: dict[str, Any], order_by: list[str], descending: list[bool]) -&gt; tuple[Any, ...]:\n    \"\"\"Function to sort a dictionary by multiple keys in different orders.\n\n    Args:\n        dict_: Dictionary to sort.\n        order_by: List of keys to sort by.\n        descending: List of booleans indicating the order for each key.\n    \"\"\"\n    key: list[Any] = []\n    for col, desc in zip(order_by, descending, strict=True):\n        value = dict_.get(col)\n        if desc:\n            if isinstance(value, (int, float)):\n                key.append(-value)\n            elif isinstance(value, str):\n                key.append(\"\".join(chr(255 - ord(c)) for c in value))\n            elif value is bool:\n                key.append(not value)\n            elif value is None:\n                key.append(None)\n            else:\n                raise ValueError(\n                    f\"Cannot sort by {type(value)} in descending order. \"\n                    \"Please use open an issue if you need this feature.\"\n                )\n        else:\n            key.append(value)\n    return tuple(key)\n</code></pre>"},{"location":"api_reference/utils/python/#pixano.utils.python.get_super_type_from_dict","title":"<code>get_super_type_from_dict(sub_type, dict_types)</code>","text":"<p>Get the first super type in a dictionary of types for the given type.</p> <p>Parameters:</p> Name Type Description Default <code>sub_type</code> <code>type</code> <p>Sub type to find the super type for.</p> required <code>dict_types</code> <code>dict[str, type]</code> <p>Dictionary of types.</p> required <p>Returns:</p> Type Description <code>type | None</code> <p>Super type if found, None otherwise.</p> Source code in <code>pixano/utils/python.py</code> <pre><code>def get_super_type_from_dict(sub_type: type, dict_types: dict[str, type]) -&gt; type | None:\n    \"\"\"Get the first super type in a dictionary of types for the given type.\n\n    Args:\n        sub_type: Sub type to find the super type for.\n        dict_types: Dictionary of types.\n\n    Returns:\n        Super type if found, None otherwise.\n    \"\"\"\n    if sub_type in dict_types.values():\n        return sub_type\n\n    sup_type = None\n    for dict_type in dict_types.values():\n        if issubclass(sub_type, dict_type):\n            sup_type = dict_type\n            break\n\n    if sup_type is None:\n        return None\n\n    found_type = True\n    while found_type:\n        found_type = False\n        for dict_type in dict_types.values():\n            if issubclass(sub_type, dict_type) and issubclass(dict_type, sup_type) and dict_type is not sup_type:\n                sup_type = dict_type\n                found_type = True\n                break\n\n    return sup_type\n</code></pre>"},{"location":"api_reference/utils/python/#pixano.utils.python.natural_key","title":"<code>natural_key(string)</code>","text":"<p>Return key for string natural sort.</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <code>str</code> <p>Input string.</p> required <p>Returns:</p> Type Description <code>list</code> <p>Sort key.</p> Source code in <code>pixano/utils/python.py</code> <pre><code>def natural_key(string: str) -&gt; list:\n    \"\"\"Return key for string natural sort.\n\n    Args:\n        string: Input string.\n\n    Returns:\n        Sort key.\n    \"\"\"\n    return [int(s) if s.isdecimal() else s for s in re.split(r\"(\\d+)\", string)]\n</code></pre>"},{"location":"api_reference/utils/python/#pixano.utils.python.to_sql_list","title":"<code>to_sql_list(ids)</code>","text":"<p>Convert a list of IDs to a SQL-friendly string.</p> <p>Parameters:</p> Name Type Description Default <code>ids</code> <code>str | Sequence[str] | set[str]</code> <p>List of IDs.</p> required <p>Returns:</p> Type Description <code>str</code> <p>SQL-friendly string of IDs.</p> Source code in <code>pixano/utils/python.py</code> <pre><code>def to_sql_list(ids: str | Sequence[str] | set[str]) -&gt; str:\n    \"\"\"Convert a list of IDs to a SQL-friendly string.\n\n    Args:\n        ids: List of IDs.\n\n    Returns:\n        SQL-friendly string of IDs.\n    \"\"\"\n    if isinstance(ids, str):\n        return f\"('{ids}')\"\n    elif len(ids) == 0:\n        raise ValueError(\"IDs must not be empty.\")\n    else:\n        for id in ids:\n            if not isinstance(id, str):\n                raise ValueError(\"IDs must be strings.\")\n    ids = list(dict.fromkeys(ids))  # Keep order and remove duplicates\n    if len(ids) == 1:\n        return f\"('{ids.pop()}')\"\n    return str(tuple(ids))\n</code></pre>"},{"location":"api_reference/utils/python/#pixano.utils.python.unique_list","title":"<code>unique_list(sequence)</code>","text":"<p>Select unique elements in a list while keeping order.</p> <p>Parameters:</p> Name Type Description Default <code>sequence</code> <code>Sequence[Any]</code> <p>Input sequence.</p> required <p>Returns:</p> Type Description <code>list[Any]</code> <p>List of unique elements.</p> Source code in <code>pixano/utils/python.py</code> <pre><code>def unique_list(sequence: Sequence[Any]) -&gt; list[Any]:\n    \"\"\"Select unique elements in a list while keeping order.\n\n    Args:\n        sequence: Input sequence.\n\n    Returns:\n        List of unique elements.\n    \"\"\"\n    return list(OrderedDict.fromkeys(sequence))\n</code></pre>"},{"location":"api_reference/utils/validation/","title":"validation","text":""},{"location":"api_reference/utils/validation/#pixano.utils.validation","title":"<code>pixano.utils.validation</code>","text":""},{"location":"api_reference/utils/validation/#pixano.utils.validation.issubclass_strict","title":"<code>issubclass_strict(obj, cls, strict=False)</code>","text":"<p>Check if the given object is of the given class type or a subclass of the given class type.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>type</code> <p>The object to check.</p> required <code>cls</code> <code>type</code> <p>The class to compare against.</p> required <code>strict</code> <code>bool</code> <p>If True, the object must be of the given class type.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the object is of the given class type or a subclass of the given class type.</p> Source code in <code>pixano/utils/validation.py</code> <pre><code>def issubclass_strict(obj: type, cls: type, strict: bool = False) -&gt; bool:\n    \"\"\"Check if the given object is of the given class type or a subclass of the given class type.\n\n    Args:\n        obj: The object to check.\n        cls: The class to compare against.\n        strict: If True, the object must be of the given class type.\n\n    Returns:\n        True if the object is of the given class type or a subclass of the given class type.\n    \"\"\"\n    if strict:\n        return obj == cls\n    return issubclass(obj, cls)\n</code></pre>"},{"location":"api_reference/utils/validation/#pixano.utils.validation.validate_and_init_create_at_and_update_at","title":"<code>validate_and_init_create_at_and_update_at(created_at, updated_at)</code>","text":"<p>Validate and initialize created_at and updated_at.</p> <p>The validation and initialization of created_at and updated_at is done as follows: - If created_at is None, it is set to the current date and time. - If updated_at is None, it is set to created_at. - If updated_at is not None and created_at is None, a ValueError is raised. - If updated_at is not None and created_at is not None, updated_at should be greater than created_at. - If created_at and updated_at are provided as strings, they are converted to datetime objects from ISO format.</p> <p>Parameters:</p> Name Type Description Default <code>created_at</code> <code>datetime | str | None</code> <p>The creation date of the object.</p> required <code>updated_at</code> <code>datetime | str | None</code> <p>The last modification date of the object.</p> required <p>Returns:</p> Type Description <code>tuple[datetime, datetime]</code> <p>A tuple containing the created_at and updated_at.</p> Source code in <code>pixano/utils/validation.py</code> <pre><code>def validate_and_init_create_at_and_update_at(\n    created_at: datetime | str | None, updated_at: datetime | str | None\n) -&gt; tuple[datetime, datetime]:\n    \"\"\"Validate and initialize created_at and updated_at.\n\n    The validation and initialization of created_at and updated_at is done as follows:\n    - If created_at is None, it is set to the current date and time.\n    - If updated_at is None, it is set to created_at.\n    - If updated_at is not None and created_at is None, a ValueError is raised.\n    - If updated_at is not None and created_at is not None, updated_at should be greater than created_at.\n    - If created_at and updated_at are provided as strings, they are converted to datetime objects from ISO format.\n\n    Args:\n        created_at: The creation date of the object.\n        updated_at: The last modification date of the object.\n\n    Returns:\n        A tuple containing the created_at and updated_at.\n    \"\"\"\n    if created_at is not None and not isinstance(created_at, datetime):\n        if isinstance(created_at, str):\n            created_at = datetime.fromisoformat(created_at)\n        else:\n            raise ValueError(\"created_at should be a datetime object or None.\")\n    if updated_at is not None and not isinstance(updated_at, datetime):\n        if isinstance(updated_at, str):\n            updated_at = datetime.fromisoformat(updated_at)\n        else:\n            raise ValueError(\"updated_at should be a datetime object or None.\")\n    if updated_at is not None and created_at is None:\n        raise ValueError(\"created_at should be set if updated_at is set.\")\n    elif created_at is not None:\n        if updated_at is not None:\n            if not isinstance(updated_at, datetime):\n                raise ValueError(\"updated_at should be a datetime object.\")\n            elif updated_at &lt; created_at:\n                raise ValueError(\"updated_at should be greater than created_at.\")\n        else:\n            updated_at = created_at\n    elif created_at is None:\n        created_at = datetime.now()\n        updated_at = created_at\n    return created_at, updated_at\n</code></pre>"},{"location":"getting_started/","title":"Getting started with Pixano","text":"<ul> <li>Installing Pixano</li> <li>Key Concepts</li> <li>Launching the app</li> <li>Using the app</li> </ul>"},{"location":"getting_started/installing_pixano/","title":"Install","text":""},{"location":"getting_started/installing_pixano/#python-environment","title":"Python Environment","text":"<p>As Pixano requires specific versions for its dependencies, we recommend creating a new Python virtual environment to install it.</p> <p>For example, with miniforge:</p> <pre><code>conda create -n pixano_env -y python~=3.12\nconda activate pixano_env\n</code></pre> <p>Then, you can install the Pixano package inside that environment with pip:</p> <pre><code>pip install pixano\n</code></pre>"},{"location":"getting_started/installing_pixano/#docker","title":"Docker","text":"<p>Pixano is available on Docker Hub. We suggest you to pull the stable version which is the last release:</p> <pre><code>docker pull pixano/pixano:stable\n</code></pre>"},{"location":"getting_started/key_concepts/","title":"Key Concepts","text":""},{"location":"getting_started/key_concepts/#context","title":"Context","text":"<p>Pixano is a data-centric tool that provides multiple functionalities:</p> <ol> <li>Dataset management in a fast, columnar data format based on the Lance format and the LanceDB vector database. The dataset is split into various Lance tables to separate features of each dataset item:</li> <li>metadata</li> <li>views</li> <li>entities</li> <li>annotations</li> <li>embeddings</li> <li>sources</li> <li>An annotation web platform powered by AI.</li> </ol>"},{"location":"getting_started/key_concepts/#pixano-layers","title":"Pixano Layers","text":"<p>Pixano has three layers:</p> <ul> <li>The backend manages datasets from creation to operations like insertions, deletions, updates, and statistical computations.</li> <li>The REST API, which requires an app to be started, handles REST requests (as its name suggests). These requests are translated for the backend to perform one or multiple operations based on the request, and it returns the results.</li> <li>The UI, which also requires an app to be started, allows users to visualize data and interact with it to add, update, or delete annotations and entities.</li> </ul>"},{"location":"getting_started/key_concepts/#datasets","title":"Datasets","text":"<p>Datasets are specific LanceDB databases. They are split into tables storing different types of information. Each dataset contains features that have two levels of description:</p> <ul> <li>Top-level features, or schemas, which are tables containing comprehensive information on a part of a dataset item, such as a view, an annotation, or an entity.</li> <li>Bottom-level features, or types, which contain atomic information. They can be standard Python types or complex types allowed by LanceDB, which are BaseModels with constraints.</li> </ul>"},{"location":"getting_started/key_concepts/#features","title":"Features","text":""},{"location":"getting_started/key_concepts/#schemas","title":"Schemas","text":"<p>Schemas contain information related to a specific part of an item in dedicated tables. They are defined using the Python API from a <code>BaseSchema</code>, which inherits from LanceModel.</p> <p>We strongly suggest reviewing LanceModel before proceeding further.</p> <p>Since Lance stores data in a columnar format, the <code>BaseSchema</code> is structured as follows:</p> <pre><code>from lancedb.pydantic import LanceModel\n\n\nclass BaseSchema(LanceModel):\n    id: str\n    created_at: datetime\n    updated_at: datetime\n</code></pre> <p>The id must be a unique identifier to retrieve the correct data.</p> <p>Pixano supports various schema groups (<code>SchemaGroup</code>), including:</p> <ul> <li><code>SchemaGroup.ITEM</code>: the unique schema named <code>'item'</code> containing metadata related to each dataset item.</li> <li><code>SchemaGroup.VIEW</code>: schemas related to the views of each dataset item, such as images, videos, or text.</li> <li><code>SchemaGroup.EMBEDDING</code>: schemas related to the embeddings of one or multiple views of a dataset item or its entities.</li> <li><code>SchemaGroup.ENTITY</code>: schemas related to entities (or objects) within a dataset item.</li> <li><code>SchemaGroup.ANNOTATION</code>: schemas related to annotations of the entities in a dataset item.</li> <li><code>SchemaGroup.SOURCE</code>: the unique schema named <code>'source'</code>, containing sources for the dataset.</li> </ul> <p>Each group has a base class that organizes all subclasses, defined by Pixano or users, into their respective groups. These are:</p> <ul> <li><code>Item</code></li> <li><code>View</code></li> <li><code>Embedding</code></li> <li><code>Entity</code></li> <li><code>Annotation</code></li> <li><code>Source</code></li> </ul> <p>For example, the <code>Image</code> view derives from <code>View</code> and stores image-specific information:</p> <pre><code>from datetime import datetime\nfrom pixano.features import View, ItemRef, ViewRef\n\n\nclass Image(View):\n    id: str\n    created_at: datetime\n    updated_at: datetime\n    item_ref: ItemRef\n    parent_ref: ViewRef\n    url: str\n    width: int\n    height: int\n    format: str\n</code></pre> <p>To define a new schema, Pixano requires two things:</p> <ol> <li>Deriving from <code>BaseSchema</code>, preferably from a group base class.</li> <li>Registering the custom schema using the <code>register_schema</code> function.</li> </ol> <pre><code>from pixano.features import Entity\n\n\nclass MyEntity(Entity):\n    category: str\n    metadata_int: int\n</code></pre>"},{"location":"getting_started/key_concepts/#types","title":"Types","text":"<p>Types hold atomic information within a schema, forming the columns of the table that implements the schema.</p> <p>Pixano supports native Python types with some extensions, such as datetime. It also supports custom types using BaseModel, but it shares the same limitations as Lance.</p> <p>For example, <code>ViewRef</code> is a custom type that defines a reference to a specific ID in a view table with a specific name, as shown below:</p> <pre><code>from pydantic import BaseModel\n\n\nclass ViewRef(BaseModel):\n    name: str\n    id: str\n</code></pre> <p>Currently, it is not possible to register new types for the app. If you need a new type, please open an issue.</p>"},{"location":"getting_started/key_concepts/#creating-a-dataset","title":"Creating a Dataset","text":""},{"location":"getting_started/key_concepts/#defining-your-dataset","title":"Defining Your Dataset","text":"<p>A dataset is a collection of tables from different <code>SchemaGroup</code>s. To generate this collection, you provide a <code>DatasetItem</code>, which is essentially a BaseModel. The attributes of this DatasetItem must be features and are organized as follows:</p> <ul> <li>Schemas are stored in their respective tables.</li> <li>Types are stored in the <code>'item'</code> table.</li> </ul> <p>Features can be a single element or a list.</p> <p>Example:</p> <pre><code>from pixano.features import BBox, Classification, Entity, Image, Text\nfrom pixano.datasets import DatasetItem\n\n\nclass MyEntity(Entity):\n    category: str\n    metadata_int: int\n\n\nclass MyDatasetItem(DatasetItem):\n    item_metadata: str # will be stored in table 'item'\n    image: Image # will be stored in table 'image'\n    texts: list[Text] # will be stored in table 'texts'\n    image_entities: list[MyEntity] # will be stored in table 'image_entities'\n    bboxes: list[BBox] # will be stored in table 'bboxes'\n    text_entities: list[Entity] # will be stored in table 'text_entities'\n    text_classifs: list[Classification] # will be stored in table 'text_classifs'\n</code></pre>"},{"location":"getting_started/key_concepts/#building-the-dataset","title":"Building the Dataset","text":"<p>To build the dataset, Pixano provides a generic class <code>DatasetBuilder</code> and specific classes detailed in the api reference.</p> <p>To construct a dataset builder, derive from <code>DatasetBuilder</code> to properly handle your data and implement the <code>generate_data</code> method. This method returns an iterator of dictionnary whose keys are table_names and values one <code>BaseSchema</code> or a list of <code>BaseSchema</code> to insert into that table.</p> <pre><code>from pixano.datasets.builders import DatasetBuilder\n\n\ninfo = DatasetInfo(\n    name=\"My super dataset\",\n    description=\"This dataset tracks reference to super stuff.\"\n)\n\nclass MyDatasetBuilder(DatasetBuilder):\n    def __init__(\n        target_dir: Path | str,\n    ):\n        super().__init__(\n            target_dir=target_dir,\n            schemas=MyDatasetItem,\n            info=info\n        )\n\n    def generate_data() -&gt; Iterator[dict[str, BaseSchema | list[BaseSchema]]]:\n        ...\n\n        return {\n            \"item\": ...,\n            \"bboxes\": ...,\n            ...\n        }\n</code></pre>"},{"location":"getting_started/key_concepts/#library-media-and-models","title":"Library, media and models","text":"<p>Pixano presumes that datasets are all stored in a library. The path to this library is passed to the app at launch time to allow it to load this datasets.</p> <p>It also expects all media (images, videos, texts, ...) to be available at a location provided at launch time. This media directory should be used as the parent folder to construct url paths for the views (<code>Image</code>, <code>Video</code>, ...).</p> <p>Finally, some functionalities available on the UI such as assisted semantic segmentation by AI might require the use of models available in a directory whose location should be provided at launch time.</p>"},{"location":"getting_started/launching_the_app/","title":"Launching Pixano","text":""},{"location":"getting_started/launching_the_app/#from-a-terminal-locally","title":"From a terminal: locally","text":"<p>You can start the Pixano app with the following command:</p> <pre><code>pixano your_library_directory/ your_media_directory/\n</code></pre> <p>You will then be provided with a URL to open in your browser to use the app.</p>"},{"location":"getting_started/launching_the_app/#from-a-terminal-s3-experimental","title":"From a terminal: S3 (Experimental)","text":"<p>Note that you can also connect to an S3 compatible storage by providing an S3 path instead of a local path to your library of datasets.</p> <p>The following arguments have to be passed:</p> <ul> <li><code>--models_dir</code>: Path to your models.</li> <li><code>--aws_endpoint</code>: S3 endpoint URL, use 'AWS' if not provided.</li> <li><code>--aws_region</code>: S3 region name, not always required for private storages.</li> <li><code>--aws_access_key</code>: S3 AWS access key.</li> <li><code>--aws_secret_key</code>: S3 AWS secret key.</li> </ul> <p>So the command becomes:</p> <pre><code>pixano s3://your_library_directory/ s3://your_media_directory/ \\\n--models_dir=\"your_local_onnx_models/\"\n--aws_endpoint=\"https://your-aws-endpoint.com\" \\\n--aws_region=\"\" \\\n--aws_access_key=\"your_access_key\" \\\n--aws_secret_key=\"your_secret_key\" \\\n</code></pre>"},{"location":"getting_started/launching_the_app/#from-a-notebook","title":"From a notebook","text":"<p>If you are in a Jupyter or Google Colab notebook, you can start the app by running the following cells:</p> <pre><code>from pixano.app import App\napp = App(\"your_library_directory/\", \"your_media_directory\")\n</code></pre> <p>You can then use the apps directly from the notebook in another cell with:</p> <pre><code>app.display()\n</code></pre>"},{"location":"getting_started/launching_the_app/#from-docker","title":"From Docker","text":"<p>To launch the app you have to mount a library directory, a media directory and a model directory (if you want to use a model).</p> <p>Here is an example:</p> <pre><code>docker run -d \\\n    --name pixano \\\n    -p 8000:8000 \\\n    -v ./library:/app/library \\\n    -v ./media:/app/media \\\n    -v ./models:/app/models \\\n    pixano/pixano:stable\n</code></pre>"},{"location":"getting_started/using_the_app/","title":"Using Pixano","text":""},{"location":"getting_started/using_the_app/#home-page","title":"Home page","text":"<p>From the app home page, you will be greeted with a list of all the Pixano format datasets found in the directory you provided.</p>"},{"location":"getting_started/using_the_app/#dataset-page","title":"Dataset page","text":"<p>On the dataset page, you will see a list of all the items it contains, organized in pages.</p> <p></p> <p>When scrolling to the bottom of the page, you will see navigation buttons to move through the pages of your dataset.</p>"},{"location":"getting_started/using_the_app/#dashboard-page","title":"Dashboard page","text":"<p>From the dataset page, you can go to the dashboard page, which contains more information about your datasets and also displays all the computed statistics available.</p>"},{"location":"getting_started/using_the_app/#item-page","title":"Item page","text":"<p>When opening an item, the item media will be displayed in the center on the screen (in case of multi-view datasets, the images will be tiled).</p> <p>On the left, a toolbar is available. On the right, two panels will display information on the item objects and scene.</p>"},{"location":"getting_started/using_the_app/#scene-panel","title":"Scene panel","text":"<p>The scene panel will display all the scene features, like the item label, or any other feature created when importing your dataset, as well as metadata information on all the images in the item.</p> <p>You can edit the scene features and then click the save changes button to write them to the dataset.</p>"},{"location":"getting_started/using_the_app/#object-panel","title":"Object panel","text":"<p>The objects panel will display all the item objects.</p> <p>On the top, you will see the ground truth objects, which are the objects you imported with your dataset, and objects you create within the app. On the bottom, a dropdown menu will let you go through all the objects created by models like the ones available in Pixano Inference.</p> <p>You have visibility toggles for objects and object group, and when hovering on an object, you will have access to an edit tool and a delete tool.</p> <p>If you have used an inference model for pre-annotating the dataset, a \"Pre-annotation\" toggle will also appear above the ground truth section. Activating this toggle will let you go through each object and accept or reject them individually. You will also be able to edit the object features before accepting it.</p> <p></p> <p>The edit tool will allow you to edit the object features, for example its category and category ID, and also allow you to edit the object bounding box and mask on the image. For text features, auto-completion based on existing feature values in the dataset is available.</p> <p>To create new objects, you have multiple tools at your disposal on the left toolbar.</p>"},{"location":"getting_started/using_the_app/#toolbar","title":"Toolbar","text":""},{"location":"getting_started/using_the_app/#pan-tool","title":"Pan tool","text":"<p>With the pan tool selected, you can move the image around. This is especially useful for multi-view datasets for organizing multiple images.</p> <p>Moving the images is still possible while any other tools is selected by using your mouse middle click. You can also zoom in and out of an image with the mouse wheel, and double click an image to bring it in front of the others.</p>"},{"location":"getting_started/using_the_app/#bounding-box-tool","title":"Bounding box tool","text":"<p>With the bounding box tool, you can create a bounding box object by click and dragging a rectangle over the image. Once you are done with your selection, you will be prompted to enter values for your object features depending on your dataset (in this case category_id and category), and to confirm the object.</p> <p>Then, click save changes in the object panels to save the created object to your dataset.</p>"},{"location":"getting_started/using_the_app/#polygon-tool","title":"Polygon tool","text":"<p>With the polygon tool, you can create a segmentation mask manually by adding points with the granularity of your choice.</p> <p>Once you save this mask, a matching bounding box will automatically be created.</p>"},{"location":"getting_started/using_the_app/#smart-segmentation-tool","title":"Smart segmentation tool","text":"<p>With Pixano, you can segment with smart segmentation tool like SAM (Segment Anything Model). Please follow our documentation on how to precompute the embeddings required by SAM and export its ONNX model to be able to use it.</p> <p></p> <p>With the positive and negative points, you can inform SAM on which part of the image you are trying to segment, and SAM will generate the mask for you.</p> <p></p> <p>When relevant, you can also use the rectangle tool to select the thing you want SAM to segment.</p> <p>When saving the mask created by SAM, like with the polygon tool, a matching bounding box will automatically be created.</p>"},{"location":"tutorials/","title":"Tutorials","text":"<p>In this section, we provide guides to cover Pixano functionalities.</p> <ul> <li>Create your first library</li> <li>Semantic Search</li> <li>Segmentation powered by SAM</li> </ul>"},{"location":"tutorials/create_your_first_library/","title":"Build a Pixano library","text":""},{"location":"tutorials/create_your_first_library/#context","title":"Context","text":"<p>In this tutorial, we will build a library consisting of one dataset from a folder dataset stored in the <code>./assets/health_images/</code> folder with a unique subfolder <code>all/</code> which will later be considered as a split.</p> <p>It contains 10 images of human parts from several image sources (MRI, microscope, and high-resolution photos). A <code>metadata.jsonl</code> also provides annotations, bounding boxes and keypoints, associated to these images.</p>"},{"location":"tutorials/create_your_first_library/#build-the-dataset","title":"Build the Dataset","text":""},{"location":"tutorials/create_your_first_library/#describe-your-dataset","title":"Describe your dataset","text":"<p>To create a Pixano <code>Dataset</code>, a <code>DatasetBuilder</code> needs a pythonic description of the dataset item based on a Pydantic's BaseModel.</p> <p>To do so, Pixano provides the <code>pixano.datasets.DatasetItem</code> class that already has the attributes <code>id</code> and <code>split</code> to uniquely identify an item and categorize the items respectively.</p> <p>To define a custom <code>DatasetItem</code>, simply create a sublcass of <code>DatasetItem</code> that define all the features of your dataset.</p> <p>In our case we have:</p> <ul> <li><code>image_type</code>: a string metadata.</li> <li><code>image</code>: the unique view of the item that is an Image.</li> <li><code>objects</code>: the entites of an item. Think of it as a common identifier for multiple annotations.</li> <li><code>bbox</code>: the bounding boxes of an item.</li> <li><code>keypoints</code>: the keypoints of an item.</li> </ul> <p>This is how it can be defined in code:</p> <pre><code>from pixano.datasets import DatasetItem\nfrom pixano.features import BBox, Entity, Image, KeyPoints\n\n\nclass EntityWithCategory(Entity):\n    category: str\n\n\nclass HealthDatasetItem(DatasetItem):\n    image: Image\n    objects: list[EntityWithCategory]\n    bbox: list[BBox]\n    keypoints: list[KeyPoints]\n    image_type: str\n</code></pre> <p>Notice that when multiple elements are attached to an item we use the <code>list</code> type.</p>"},{"location":"tutorials/create_your_first_library/#initialize-a-datasetbuilder","title":"Initialize a DatasetBuilder","text":""},{"location":"tutorials/create_your_first_library/#use-a-built-in-builder","title":"Use a built-in builder","text":"<p>The Health dataset follows a folder structure that can be handled by Pixano:</p> <pre><code>root_folder/\n    split1/\n        view0.ext\n        view1.ext\n        ...\n        viewN.ext\n        metadata.jsonl\n    split2/\n        ...\n</code></pre> <p>Therefore the <code>pixano.datasets.builders.ImageFolderBuilder</code> can be used to construct the Pixano dataset as follows:</p> <pre><code>from pathlib import Path\nfrom pixano.datasets import DatasetInfo\nfrom pixano.datasets.builders import ImageFolderBuilder\n\n\nbuilder = ImageFolderBuilder(\n    source_dir=Path(\"./assets/health_images\"),\n    target_dir=Path(\"./pixano_library/health_dataset\"),\n    dataset_item=HealthDatasetItem,\n    info=DatasetInfo(\n        id=\"health_images\",\n        name=\"Health Images\",\n        description=\"A dataset of health images\",\n    ),\n    url_prefix=\"/health_images\"\n    # By default, the images' URLs are relative to the health_images folder.\n    # We assume Pixano will be launched with the \"assets/\" directory as media_dir.\n)\n\ndataset = builder.build(mode=\"create\")\n</code></pre>"},{"location":"tutorials/create_your_first_library/#write-your-own-builder","title":"Write your own builder","text":"<p>While it is convenient to use built-in dataset builders, Pixano do not cover all your use-cases. Fortunatly it is possible to design your own builder by subclassing the <code>pixano.datasets.builders.DatasetBuilder</code> class and implementing the <code>generate_data</code> method.</p> <p>Here is roughly the code for the <code>ImageFolderBuilder</code>:</p> <pre><code>from pixano.datasets.builders import DatasetBuilder\nfrom pixano.features import BaseSchema\n\nclass ImageFolderBuilder(DatasetBuilder):\n    def __init__(\n        self,\n        source_dir: Path | str,\n        target_dir: Path | str,\n        dataset_item: type[DatasetItem],\n        info: DatasetInfo,\n        url_prefix: str,\n    ) -&gt; None:\n        super().__init__(target_dir=target_dir, dataset_item=dataset_item, info=info)\n        self.source_dir = Path(source_dir)\n        self.url_prefix = url_prefix\n\n        self.view_name = \"image\"\n        self.view_schema: type[View] = Image\n        self.entity_name = objects\n        self.entity_schema: type[Entity] = EntityWithCategory\n\n    def generate_data(\n        self,\n    ) -&gt; Iterator[dict[str, BaseSchema | list[BaseSchema]]]:\n        source_id = None\n        for split in self.source_dir.glob(\"*\"):\n            if split.is_dir() and not split.name.startswith(\".\"):\n                metadata = self._read_metadata(split / \"metadata.jsonl\")\n\n                for view_file in split.glob(\"*\"):\n                    # only consider {split}/{item}.{ext} files\n                    if view_file.is_file() and view_file.suffix in self.EXTENSIONS:\n                        # retrieve item metadata in metadata file\n                        item_metadata = {}\n                        for m in metadata:\n                            if m[self.view_name] == view_file.name:\n                                item_metadata = m\n                                break\n                        if not item_metadata:\n                            raise ValueError(f\"Metadata not found for {view_file}\")\n\n                        # extract entity metadata from item metadata\n                        entities_data = item_metadata.pop(self.entity_name, None)\n\n                        # create item\n                        item = self._create_item(split.name, **item_metadata)\n\n                        # create view\n                        view = self._create_view(item, view_file, self.view_schema)\n\n                        if entities_data is None:\n                            yield {\n                                self.item_schema_name: item,\n                                self.view_name: view,\n                            }\n                            continue\n                        elif source_id is None:\n                            source_id = self.add_source(\"Builder\", SourceKind.OTHER)\n\n                        # create entities and their annotations\n                        entities, annotations = self._create_entities(item, view, entities_data, source_id)\n\n                        yield {\n                            self.item_schema_name: item,\n                            self.view_name: view,\n                            self.entity_name: entities,\n                            **annotations,\n                        }\n\nbuilder = ImageFolderBuilder(\n    source_dir=Path(\"./assets/health_images\"),\n    target_dir=Path(\"./pixano_library/health_dataset\"),\n    dataset_item=HealthDatasetItem,\n    info=DatasetInfo(\n        id=\"health_images\",\n        name=\"Health Images\",\n        description=\"A dataset of health images\",\n    ),\n    url_prefix=\"/health_images\"\n    # By default, the images' URLs are relative to the health_images folder.\n    # We assume Pixano will be launched with the \"assets/\" directory as media_dir.\n)\n\ndataset = builder.build(mode=\"create\")\n</code></pre> <p>We recommend that you take a look at the implementation of the class <code>pixano.datasets.builders.FolderBaseBuilder</code> for the complete code to understand how to construct your own builder.</p> <p>Notice that the <code>generate_data</code> is a generator of dictionaries whose keys are the names of the tables to fill and the values one example or a list of <code>pixano.features.BaseSchema</code> to fill these tables. The builder flushes data by chunks of a size configured for every table with the argument <code>flush_every_n_samples</code> in the <code>build</code> method. This offers a trade-off between speed and memory footprint.</p>"},{"location":"tutorials/create_your_first_library/#query-your-dataset","title":"Query your dataset","text":""},{"location":"tutorials/create_your_first_library/#python-api","title":"Python API","text":"<p>To interact with your dataset you can use CRUD (create, read, update, and delete) operations either on a table level or on a complete dataset item with the following methods:</p> operation table dataset item create add_data add_dataset_items read get_data get_dataset_items update update_data update_dataset_items delete delete_data delete_dataset_items <p>Here is an example to read the first two image views:</p> <pre><code>from pixano.datasets import Dataset\n\ndataset = Dataset( # Load the dataset\n    Path(\"./pixano_library/health_dataset\"), media_dir=Path(\"./assets/\")\n)\n\ndataset.get_data(\"image\", limit=2, skip=0) # Fetch images\n\n&gt;&gt;&gt; [Image(id='QmmM6LhwB4uMMCRUjgXejY', created_at=datetime.datetime(2024, 11, 7, 10, 14, 5, 364059), updated_at=datetime.datetime(2024, 11, 7, 10, 14, 5, 364059), item_ref=ItemRef(name='item', id='iyA4tHmGeHPP4N6diSuUXi'), parent_ref=ViewRef(name='', id=''), url='/health_images/all/microcope-red_blood_cells.jpg', width=2560, height=1920, format='JPEG'), Image(id='SNgW9Zk68g7mBW2CuHQQKZ', created_at=datetime.datetime(2024, 11, 7, 10, 14, 5, 367359), updated_at=datetime.datetime(2024, 11, 7, 10, 14, 5, 367359), item_ref=ItemRef(name='item', id='VkBcn4bhgt2RRJNWWjvDN5'), parent_ref=ViewRef(name='', id=''), url='/health_images/all/microscope-peau.jpg', width=896, height=550, format='JPEG')]\n</code></pre> <p>And here is an example to read the dataset item whose id is <code>'iyA4tHmGeHPP4N6diSuUXi'</code>. Beware that because they are generated randomly you won't have the same id in your dataset.</p> <pre><code>dataset.get_dataset_items(\"iyA4tHmGeHPP4N6diSuUXi\")\n\n&gt;&gt;&gt; DatasetItem(id='iyA4tHmGeHPP4N6diSuUXi', split='all', created_at=datetime.datetime(2024, 11, 7, 10, 14, 5, 363831), updated_at=datetime.datetime(2024, 11, 7, 10, 14, 5, 363831), image=Image(id='QmmM6LhwB4uMMCRUjgXejY', created_at=datetime.datetime(2024, 11, 7, 10, 14, 5, 364059), updated_at=datetime.datetime(2024, 11, 7, 10, 14, 5, 364059), item_ref=ItemRef(name='item', id='iyA4tHmGeHPP4N6diSuUXi'), parent_ref=ViewRef(name='', id=''), url='/health_images/all/microcope-red_blood_cells.jpg', width=2560, height=1920, format='JPEG'), objects=[], bbox=[], keypoints=[], image_type='microcope')\n</code></pre>"},{"location":"tutorials/create_your_first_library/#rest-api","title":"REST API","text":"<p>To use the REST API, we first need to launch the Pixano's app.</p> <pre><code>pixano ./pixano_library ./assets --host localhost --port 8000\n</code></pre> <p>Then we can call the endpoints of the REST API. To have the complete list of endpoints, we can have take a look at the Swagger docs http://localhost:8000/docs or look at the relevant documentation.</p> <p>To fetch the first two image views here is the call:</p> <pre><code>curl -X 'GET' \\\n  'http://localhost:8000/views/health_images/image/?limit=2&amp;skip=0' \\\n  -H 'accept: application/json'\n\n&gt;&gt;&gt; [\n  {\n    \"id\": \"QmmM6LhwB4uMMCRUjgXejY\",\n    \"created_at\": \"2024-11-07T10:14:05.364059\",\n    \"updated_at\": \"2024-11-07T10:14:05.364059\",\n    \"table_info\": {\n      \"name\": \"image\",\n      \"group\": \"views\",\n      \"base_schema\": \"Image\"\n    },\n    \"data\": {\n      \"item_ref\": {\n        \"name\": \"item\",\n        \"id\": \"iyA4tHmGeHPP4N6diSuUXi\"\n      },\n      \"parent_ref\": {\n        \"name\": \"\",\n        \"id\": \"\"\n      },\n      \"url\": \"/health_images/all/microcope-red_blood_cells.jpg\",\n      \"width\": 2560,\n      \"height\": 1920,\n      \"format\": \"JPEG\"\n    }\n  },\n  {\n    \"id\": \"SNgW9Zk68g7mBW2CuHQQKZ\",\n    \"created_at\": \"2024-11-07T10:14:05.367359\",\n    \"updated_at\": \"2024-11-07T10:14:05.367359\",\n    \"table_info\": {\n      \"name\": \"image\",\n      \"group\": \"views\",\n      \"base_schema\": \"Image\"\n    },\n    \"data\": {\n      \"item_ref\": {\n        \"name\": \"item\",\n        \"id\": \"VkBcn4bhgt2RRJNWWjvDN5\"\n      },\n      \"parent_ref\": {\n        \"name\": \"\",\n        \"id\": \"\"\n      },\n      \"url\": \"/health_images/all/microscope-peau.jpg\",\n      \"width\": 896,\n      \"height\": 550,\n      \"format\": \"JPEG\"\n    }\n  }\n]\n</code></pre>"},{"location":"tutorials/segmentation_powered_by_sam/","title":"Segmentation powered by SAM","text":""},{"location":"tutorials/segmentation_powered_by_sam/#context","title":"Context","text":"<p>SAM (Segment Anything Model) is an open-source model proposed by Meta to perform mask segmentation from boxes, keypoints and/or original masks.</p> <p>Pixano's web app integrates SAM to quickly annotate your images. It first requires to pre-compute the embeddings of the images.</p> <p>This tutorial will help you unlock this feature.</p>"},{"location":"tutorials/segmentation_powered_by_sam/#create-image-embeddings-for-sam","title":"Create image embeddings for SAM","text":""},{"location":"tutorials/segmentation_powered_by_sam/#install-requirements","title":"Install requirements","text":"<ol> <li>Pip dependencies</li> </ol> <p>Install the official SAM repo, <code>onnx</code> to export the model and <code>transformers</code> to get the image embeddings.</p> <pre><code>pip install git+https://github.com/facebookresearch/segment-anything.git\npip install onnx transformers\n</code></pre> <ol> <li>Download the model and export it to ONNX format.</li> </ol> <pre><code>git clone https://github.com/facebookresearch/segment-anything.git\n\ncd segment-anything\n\nwget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n\npython segment-anything/scripts/export_onnx_model.py \\\n    --checkpoint sam_vit_h_4b8939.pth \\\n    --model-type vit_h \\\n    --output sam_h.onnx\n\ncp sam_h.onnx /path/to/pixano/models/\n# Defaults is models/ under the library\n</code></pre>"},{"location":"tutorials/segmentation_powered_by_sam/#create-the-embeddings","title":"Create the embeddings","text":"<p>The following suppose the library tutorial has been followed previously to initialize the library containing the <code>health_dataset</code>.</p> <ol> <li>Load the model and the dataset.</li> </ol> <pre><code>import torch\nfrom transformers import SamModel, SamProcessor\nfrom pixano.datasets import Dataset\nfrom pixano.features import Image\nfrom pathlib import Path\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = SamModel.from_pretrained(\"facebook/sam-vit-huge\").to(device=device)\nprocessor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n\ndataset = Dataset(\n    Path(\"./pixano_library/health_dataset\"),\n    media_dir=Path(\"./assets/\")\n)\n\nimages: list[Image] = dataset.get_data(\"image\", limit=100)\nnum_images  = len(images)\n\nprint(num_images)\n\n&gt;&gt;&gt; 11\n</code></pre> <ol> <li>Create the SAM embeddings table.</li> </ol> <pre><code>from pixano.features import ViewEmbedding, NDArrayFloat\nfrom pixano.datasets.dataset_schema import SchemaRelation\nfrom lancedb.pydantic import Vector\n\nclass SAMViewEmbedding(ViewEmbedding):\n    vector: Vector(1048576)\n\nsam_table = dataset.create_table(\n    name=\"sam_embedding\",\n    schema=SAMViewEmbedding,\n    relation_item=SchemaRelation.ONE_TO_ONE,\n    mode=\"overwrite\"\n)\n</code></pre> <ol> <li>Compute the embeddings</li> </ol> <pre><code>import shortuuid\nfrom pixano.features import ViewRef\n\nembeddings = []\nfor i, image in enumerate(images):\n    pil_image = image.open( # Load the actual image\n            media_dir=dataset.media_dir,\n            output_type=\"image\"\n        ).convert(\"RGB\")\n    with torch.inference_mode():\n        # Compute the embeddings\n        inputs = processor(pil_image, return_tensors=\"pt\").to(device=device)\n        output = model.get_image_embeddings(inputs[\"pixel_values\"])\n    # Validate the output\n    embedding = dataset.schema.schemas[\"sam_embedding\"](\n        id=shortuuid.uuid(),\n        item_ref=image.item_ref,\n        view_ref=ViewRef(id=image.id, name=image.table_name),\n        vector=output.flatten().tolist(),\n        shape=output.squeeze().shape,\n    )\n    embeddings.append(embedding)\n\n# Flush to the table\ndataset.add_data(\"sam_embedding\", embeddings)\n</code></pre>"},{"location":"tutorials/segmentation_powered_by_sam/#use-the-app","title":"Use the app !","text":"<p>Now you are all set to use SAM, follow the using the app guide !</p>"},{"location":"tutorials/semantic_search/","title":"Semantic Search","text":""},{"location":"tutorials/semantic_search/#context","title":"Context","text":"<p>The Pixano's app support semantic search which allows a user to search for a view based on a text content.</p> <p>To do that Pixano requires that the embeddings of the views are pre-computed with the model used for Semantic search. For now, we rely on the Embeddings functions from LanceDB.</p>"},{"location":"tutorials/semantic_search/#open-clip-example","title":"Open-clip example","text":"<p>We will go through the process of semantic search based on the Open-clip model.</p>"},{"location":"tutorials/semantic_search/#pre-compute-the-embeddings","title":"Pre-compute the embeddings","text":"<p>First, we need to pre-compute the embeddings using LanceDB and Pixano. We will use the Health Images dataset defined in the library tutorial.</p> <ol> <li>Install open-clip</li> </ol> <p>For this tutorial, we will use open-clip embedding function and therefore need it to be installed.</p> <pre><code>pip install open_clip_torch\n</code></pre> <ol> <li>Create the Image View Embedding table:</li> </ol> <pre><code>from pathlib import Path\nfrom pixano.datasets import Dataset\nfrom pixano.datasets.dataset_schema import SchemaRelation\nfrom pixano.features import ViewEmbedding\n\nlancedb_embedding_fn = \"open-clip\"\ntable_name = \"emb_open-clip\"\n\ndataset = Dataset( # Load the dataset\n    Path(\"./pixano_library/health_dataset\"), media_dir=Path(\"./assets/\")\n)\nembedding_schema = ViewEmbedding.create_schema( # Create the ViewEmbeddingSchema\n    embedding_fn=lancedb_embedding_fn, # For LanceDB\n    table_name=table_name,\n    dataset=dataset\n)\ndataset.create_table( # Create the table\n    name=table_name,\n    schema=embedding_schema,\n    relation_item=SchemaRelation.ONE_TO_ONE, # Only one view per item\n    mode=\"create\"\n)\n\n&gt;&gt;&gt; LanceTable(connection=LanceDBConnection(.../pixano/docs/tutorials/pixano_library/health_dataset/db), name=\"emb_open-clip\")\n</code></pre> <p>The <code>pixano.features.ViewEmbedding</code>'s method <code>create_schema</code> create a schema that contains a LanceDB embedding function compatible with Pixano.</p> <ol> <li>Compute the embeddings</li> </ol> <p>To compute the embeddings, Pixano needs to access the references to the views. Then, based on these information, it can use the LanceDB embedding function on the views.</p> <pre><code>import shortuuid\n\nviews = dataset.get_data(table_name=\"image\", limit=100) # Get all views from the dataset's table \"image\".\n\ndata = [] # List of dictionnary of ViewEmbedding's model dump without the vector field.\nfor view in views:\n    data.append(\n        {\n            \"id\": shortuuid.uuid(),\n            \"item_ref\": {\n                \"id\": view.item_ref.id,\n                \"name\": view.item_ref.name,\n            },\n            \"view_ref\": { # Reference to the table \"image\"\n                \"id\": view.id,\n                \"name\": \"image\",\n            },\n        }\n    )\n\ndataset.compute_view_embeddings(table_name=table_name, data=data)\n</code></pre> <ol> <li>Perform semantic search (Python API)</li> </ol> <p>To perform semantic search, simply call the dataset's <code>semantic_search</code> method with the text query. It will return the items with the closest view semantically to the query and the distance.</p> <pre><code>query = \"microscope\"\n\ndataset.semantic_search(query, table_name, limit=5, skip=0)\n\n&gt;&gt;&gt;(\n    [\n        Item(id='bFPEPGYaSmJGPakiaPctfF', ..., split='all', image_type='microscope'),\n        Item(id='VkBcn4bhgt2RRJNWWjvDN5', ..., split='all', image_type='microscope'),\n        Item(id='5XFPk5qwFL5xWhLHzGXLeV', ..., split='all', image_type='microscope'),\n        Item(id='A7BXLwmXWRAypbqxd5KqzK', ..., split='all', image_type='peau'),\n        Item(id='iyA4tHmGeHPP4N6diSuUXi', ..., split='all', image_type='microcope')\n    ],\n    [1.5589371919631958, 1.5611850023269653, 1.5707159042358398, 1.5987659692764282, 1.605470895767212]\n)\n</code></pre> <ol> <li>Use the REST API or the UI to browse through your items with semantic search.</li> </ol> <p>You first need to launch the Pixano's app to interact with the UI or the REST API.</p> <p>Then you can curl the REST API to navigate through your items:</p> <pre><code>curl -X 'GET' \\\n  'http://localhost:8000/browser/health_images?limit=5&amp;skip=0&amp;query=microscope&amp;embedding_table=emb_open-clip' \\\n  -H 'accept: application/json'\n\n&gt;&gt;&gt; {\n  \"id\": \"health_images\",\n  \"name\": \"Health Images\",\n  \"table_data\": {\n    \"columns\": [\n      {\n        \"name\": \"image\",\n        \"type\": \"image\"\n      },\n      {\n        \"name\": \"id\",\n        \"type\": \"str\"\n      },\n      {\n        \"name\": \"created_at\",\n        \"type\": \"datetime\"\n      },\n      {\n        \"name\": \"updated_at\",\n        \"type\": \"datetime\"\n      },\n      {\n        \"name\": \"split\",\n        \"type\": \"str\"\n      },\n      {\n        \"name\": \"image_type\",\n        \"type\": \"str\"\n      },\n      {\n        \"name\": \"distance\",\n        \"type\": \"float\"\n      }\n    ],\n    \"rows\": [\n      {\n        \"image\": \"\",\n        \"id\": \"bFPEPGYaSmJGPakiaPctfF\",\n        \"created_at\": \"2024-11-07T10:14:05.396010\",\n        \"updated_at\": \"2024-11-07T10:14:05.396010\",\n        \"split\": \"all\",\n        \"image_type\": \"microscope\",\n        \"distance\": 1.5589371919631958\n      },\n      {\n        \"image\": \"\",\n        \"id\": \"VkBcn4bhgt2RRJNWWjvDN5\",\n        \"created_at\": \"2024-11-07T10:14:05.367159\",\n        \"updated_at\": \"2024-11-07T10:14:05.367159\",\n        \"split\": \"all\",\n        \"image_type\": \"microscope\",\n        \"distance\": 1.5611850023269653\n      },\n      {\n        \"image\": \"\",\n        \"id\": \"5XFPk5qwFL5xWhLHzGXLeV\",\n        \"created_at\": \"2024-11-07T10:14:05.402816\",\n        \"updated_at\": \"2024-11-07T10:14:05.402816\",\n        \"split\": \"all\",\n        \"image_type\": \"microscope\",\n        \"distance\": 1.5707159042358398\n      },\n      {\n        \"image\": \"\",\n        \"id\": \"A7BXLwmXWRAypbqxd5KqzK\",\n        \"created_at\": \"2024-11-07T10:14:05.409434\",\n        \"updated_at\": \"2024-11-07T10:14:05.409434\",\n        \"split\": \"all\",\n        \"image_type\": \"peau\",\n        \"distance\": 1.5987659692764282\n      },\n      {\n        \"image\": \"\",\n        \"id\": \"iyA4tHmGeHPP4N6diSuUXi\",\n        \"created_at\": \"2024-11-07T10:14:05.363831\",\n        \"updated_at\": \"2024-11-07T10:14:05.363831\",\n        \"split\": \"all\",\n        \"image_type\": \"microcope\",\n        \"distance\": 1.605470895767212\n      }\n    ]\n  },\n  \"pagination\": {\n    \"current_page\": 0,\n    \"page_size\": 5,\n    \"total_size\": 11\n  },\n  \"semantic_search\": [\n    \"emb_open-clip\"\n  ]\n}\n</code></pre>"}]}