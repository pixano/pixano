{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"api_reference/","title":"Pixano API reference","text":"<p>Here you will find the documentation for all of our Python API.</p> <ul> <li>The analytics module contains useful functions for computing statistics on a dataset.</li> <li>The app module contains the Pixano app and its API.</li> <li>The core module contains the Pixano custom data types for storing data in the PyArrow tabular format.</li> <li>The data module contains classes like for interfacing data with the API, as well as the classes for importing and exporting datasets.</li> <li>The models module contains the base class for inference generation and embedding precomputing models.</li> <li>The utils module contains useful functions to work with images, bounding boxes, labels, and more.</li> </ul>"},{"location":"api_reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>index</li> <li>analytics<ul> <li>feature_statistics</li> <li>image_statistics</li> </ul> </li> <li>app<ul> <li>api<ul> <li>datasets</li> <li>items</li> <li>models</li> </ul> </li> <li>display</li> <li>main</li> <li>serve</li> </ul> </li> <li>core<ul> <li>bbox</li> <li>camera</li> <li>compressed_rle</li> <li>depth_image</li> <li>gt_info</li> <li>image</li> <li>pixano_type</li> <li>pose</li> <li>utils</li> </ul> </li> <li>data<ul> <li>dataset<ul> <li>dataset</li> <li>dataset_info</li> <li>dataset_item</li> <li>dataset_stat</li> <li>dataset_table</li> </ul> </li> <li>exporters<ul> <li>coco_exporter</li> <li>exporter</li> </ul> </li> <li>fields</li> <li>importers<ul> <li>coco_importer</li> <li>dota_importer</li> <li>image_importer</li> <li>importer</li> </ul> </li> <li>item<ul> <li>item_embedding</li> <li>item_feature</li> <li>item_object</li> <li>item_view</li> </ul> </li> <li>settings</li> </ul> </li> <li>models<ul> <li>inference_model</li> </ul> </li> <li>utils<ul> <li>boxes</li> <li>image</li> <li>labels</li> <li>python</li> </ul> </li> </ul>"},{"location":"api_reference/analytics/feature_statistics/","title":"feature_statistics","text":""},{"location":"api_reference/analytics/feature_statistics/#pixano.analytics.feature_statistics","title":"<code>pixano.analytics.feature_statistics</code>","text":""},{"location":"api_reference/analytics/feature_statistics/#pixano.analytics.feature_statistics.categorical_stats","title":"<code>categorical_stats(df, split, field_name)</code>","text":"<p>Compute feature categorical statistics</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame</p> required <code>split</code> <code>str</code> <p>DataFrame split</p> required <code>field_name</code> <code>str</code> <p>Selected field</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>Feature statistics</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def categorical_stats(df: pd.DataFrame, split: str, field_name: str) -&gt; list[dict]:\n    \"\"\"Compute feature categorical statistics\n\n    Args:\n        df (pd.DataFrame): Input DataFrame\n        split (str): DataFrame split\n        field_name (str): Selected field\n\n    Returns:\n        list[dict]: Feature statistics\n    \"\"\"\n\n    counts = df.value_counts(subset=field_name)\n    return [{field_name: k, \"counts\": v, \"split\": split} for k, v in counts.items()]\n</code></pre>"},{"location":"api_reference/analytics/feature_statistics/#pixano.analytics.feature_statistics.compute_additional_data","title":"<code>compute_additional_data(data_table)</code>","text":"<p>Convert Table to DataFrame and add resolution and aspect ratio</p> <p>Parameters:</p> Name Type Description Default <code>data_table</code> <code>Table</code> <p>Input Table</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with added resolution and aspect ratio</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def compute_additional_data(data_table: pa.Table) -&gt; pd.DataFrame:\n    \"\"\"Convert Table to DataFrame and add resolution and aspect ratio\n\n    Args:\n        data_table (pa.Table): Input Table\n\n    Returns:\n        pd.DataFrame: DataFrame with added resolution and aspect ratio\n    \"\"\"\n\n    # Take a subset of table without image columns (which can't be converted to pandas)\n    if not all(p in data_table.column_names for p in [\"width\", \"height\"]):\n        return None\n    data = data_table.select([\"width\", \"height\"]).to_pandas()\n\n    # Compute additional data\n    data[\"resolution\"] = data.apply(\n        lambda x: str(x[\"width\"]) + \"x\" + str(x[\"height\"]), axis=1\n    )\n    data[\"aspect_ratio\"] = data.apply(\n        lambda x: str(Fraction(x[\"width\"], x[\"height\"])).replace(\"/\", \":\"), axis=1\n    )\n\n    return data\n</code></pre>"},{"location":"api_reference/analytics/feature_statistics/#pixano.analytics.feature_statistics.compute_stats","title":"<code>compute_stats(df, split, feature)</code>","text":"<p>Compute feature statistics</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame</p> required <code>split</code> <code>str</code> <p>DataFrame split</p> required <code>feature</code> <code>dict</code> <p>Selected feature</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>Feature statistics</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def compute_stats(df: pd.DataFrame, split: str, feature: dict[str, Any]) -&gt; list[dict]:\n    \"\"\"Compute feature statistics\n\n    Args:\n        df (pd.DataFrame): Input DataFrame\n        split (str): DataFrame split\n        feature (dict): Selected feature\n\n    Returns:\n        list[dict]: Feature statistics\n    \"\"\"\n\n    # Categorical\n    if feature[\"type\"] == \"categorical\":\n        return categorical_stats(df, split, feature[\"name\"])\n    # Numerical\n    if feature[\"type\"] == \"numerical\":\n        return numerical_stats(df, split, feature[\"name\"], feature.get(\"range\", None))\n    return []\n</code></pre>"},{"location":"api_reference/analytics/feature_statistics/#pixano.analytics.feature_statistics.numerical_stats","title":"<code>numerical_stats(df, split, field_name, field_range=None)</code>","text":"<p>Compute feature numerical statistics</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input DataFrame</p> required <code>split</code> <code>str</code> <p>DataFrame split</p> required <code>field_name</code> <code>str</code> <p>Selected field</p> required <code>field_range</code> <code>list[float]</code> <p>Selected field range. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>Feature statistics</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def numerical_stats(\n    df: pd.DataFrame, split: str, field_name: str, field_range: list[float] = None\n) -&gt; list[dict]:\n    \"\"\"Compute feature numerical statistics\n\n    Args:\n        df (pd.DataFrame): Input DataFrame\n        split (str): DataFrame split\n        field_name (str): Selected field\n        field_range (list[float], optional): Selected field range. Defaults to None.\n\n    Returns:\n        list[dict]: Feature statistics\n    \"\"\"\n\n    counts, bins = np.histogram(df[field_name], range=field_range)\n    return [\n        {\n            \"bin_start\": float(bins[i]),\n            \"bin_end\": float(bins[i + 1]),\n            \"counts\": int(counts[i]),\n            \"split\": split,\n        }\n        for i in range(len(counts))\n    ]\n</code></pre>"},{"location":"api_reference/analytics/feature_statistics/#pixano.analytics.feature_statistics.objects_table_to_df","title":"<code>objects_table_to_df(data_table, field)</code>","text":"<p>Convert a field from the objects column to a DataFrame</p> <p>Parameters:</p> Name Type Description Default <code>data_table</code> <code>Table</code> <p>Table with an objects column</p> required <code>field</code> <code>str</code> <p>Selected field from the objects column</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Selected field as DataFrame</p> Source code in <code>pixano/analytics/feature_statistics.py</code> <pre><code>def objects_table_to_df(data_table: pa.Table, field: str) -&gt; pd.DataFrame:\n    \"\"\"Convert a field from the objects column to a DataFrame\n\n    Args:\n        data_table (pa.Table): Table with an objects column\n        field (str): Selected field from the objects column\n\n    Returns:\n        pd.DataFrame: Selected field as DataFrame\n    \"\"\"\n\n    try:\n        df_objs = data_table.select([\"objects\"]).to_pandas()\n        sel = [{field: d[field]} for objs in df_objs[\"objects\"] for d in objs]\n        return pd.DataFrame.from_dict(sel)\n    except ValueError as e:\n        raise ValueError(\"Unable to convert table Pandas DataFrame\") from e\n</code></pre>"},{"location":"api_reference/analytics/image_statistics/","title":"image_statistics","text":""},{"location":"api_reference/analytics/image_statistics/#pixano.analytics.image_statistics","title":"<code>pixano.analytics.image_statistics</code>","text":""},{"location":"api_reference/analytics/image_statistics/#pixano.analytics.image_statistics.compute_image_stats","title":"<code>compute_image_stats(ds)</code>","text":"<p>Compute image stats, save them to stats.json</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>Dataset</code> <p>Dataset</p> required Source code in <code>pixano/analytics/image_statistics.py</code> <pre><code>def compute_image_stats(ds: Dataset):\n    \"\"\"Compute image stats, save them to stats.json\n\n    Args:\n        ds (Dataset): Dataset\n    \"\"\"\n\n    tables = ds.open_tables()\n\n    for view in tables[\"media\"]:\n        # will be flattened, so don't treat it as a real loop (only one elem)\n        # tt = tables[\"media\"][view].to_lance()\n        # print(duckdb.sql(\"select * from tt\"))\n        data_table = tables[\"media\"][view].to_arrow()\n\n        # Take a subset of table without image columns (which can't be converted to pandas)\n        if not all(p in data_table.column_names for p in [\"width\", \"height\"]):\n            print(\n                \"INFO: 'width' and 'height' not found in media table, get it from image\"\n            )\n            images = data_table.select([view]).to_pylist()\n            sizes = []\n            for image in images:\n                # im = image[view].as_pillow() ne marche plus car uri_prefix vide (pb avec Image.get_uri())\n                im = PILImage.open(ds.media_dir / image[view].uri)\n                sizes.append({\"width\": im.width, \"height\": im.height})\n            data = pa.Table.from_pylist(sizes).to_pandas()\n        else:\n            print(\"INFO: 'width' and 'height' found in media table, use it\")\n            data = data_table.select([\"width\", \"height\"]).to_pandas()\n\n        # Compute additional data\n        data[\"resolution\"] = data.apply(\n            lambda x: str(x[\"width\"]) + \"x\" + str(x[\"height\"]), axis=1\n        )\n        data[\"aspect_ratio\"] = data.apply(\n            lambda x: str(Fraction(x[\"width\"], x[\"height\"])).replace(\"/\", \":\"), axis=1\n        )\n        return data\n</code></pre>"},{"location":"api_reference/app/display/","title":"display","text":""},{"location":"api_reference/app/display/#pixano.app.display","title":"<code>pixano.app.display</code>","text":""},{"location":"api_reference/app/display/#pixano.app.display.display_cli","title":"<code>display_cli(url, port)</code>","text":"<p>Display a Pixano app inside a command line interface</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Pixano app URL</p> required <code>port</code> <code>int</code> <p>Pixano app port</p> required Source code in <code>pixano/app/display.py</code> <pre><code>def display_cli(url: str, port: int):\n    \"\"\"Display a Pixano app inside a command line interface\n\n    Args:\n        url (str): Pixano app URL\n        port (int): Pixano app port\n    \"\"\"\n\n    print(f\"Please visit {url}:{port} in a web browser.\")\n</code></pre>"},{"location":"api_reference/app/display/#pixano.app.display.display_colab","title":"<code>display_colab(url, port, height)</code>","text":"<p>Display a Pixano app inside a Google Colab</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Pixano app URL</p> required <code>port</code> <code>int</code> <p>Pixano app port</p> required <code>height</code> <code>int</code> <p>Frame height</p> required Source code in <code>pixano/app/display.py</code> <pre><code>def display_colab(url: str, port: int, height: int):\n    \"\"\"Display a Pixano app inside a Google Colab\n\n    Args:\n        url (str): Pixano app URL\n        port (int): Pixano app port\n        height (int): Frame height\n    \"\"\"\n\n    # Define frame template\n    shell = \"\"\"\n        (() =&gt; {\n            const url = new URL(%URL%);\n            const port = %PORT%;\n            if (port) {\n                url.port = port;\n            }\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '%HEIGHT%');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    \"\"\"\n\n    # Replace variables in template\n    replacements = [\n        (\"%HEIGHT%\", f\"{height}\"),\n        (\"%PORT%\", f\"{port}\"),\n        (\"%URL%\", json.dumps(url)),\n    ]\n    for k, v in replacements:\n        shell = shell.replace(k, v)\n\n    # Display frame\n    script = IPython.display.Javascript(shell)\n    IPython.display.display(script)\n</code></pre>"},{"location":"api_reference/app/display/#pixano.app.display.display_ipython","title":"<code>display_ipython(url, port, height)</code>","text":"<p>Display a Pixano app inside a Jupyter notebook</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>Pixano app URL</p> required <code>port</code> <code>int</code> <p>Pixano app port</p> required <code>height</code> <code>int</code> <p>Frame height</p> required Source code in <code>pixano/app/display.py</code> <pre><code>def display_ipython(url: str, port: int, height: int):\n    \"\"\"Display a Pixano app inside a Jupyter notebook\n\n    Args:\n        url (str): Pixano app URL\n        port (int): Pixano app port\n        height (int): Frame height\n    \"\"\"\n\n    # Define frame template\n    shell = \"\"\"\n        &lt;iframe id=\"%HTML_ID%\" width=\"100%\" height=\"%HEIGHT%\" frameborder=\"0\"&gt;\n        &lt;/iframe&gt;\n        &lt;script&gt;\n            (function() {\n                const frame = document.getElementById(%JSON_ID%);\n                const url = new URL(%URL%, window.location);\n                const port = %PORT%;\n                if (port) {\n                    url.port = port;\n                }\n                frame.src = url;\n            })();\n        &lt;/script&gt;\n    \"\"\"\n\n    # Replace variables in template\n    frame_id = f\"frame-{shortuuid.uuid()}\"\n    replacements = [\n        (\"%HTML_ID%\", html.escape(frame_id, quote=True)),\n        (\"%JSON_ID%\", json.dumps(frame_id)),\n        (\"%HEIGHT%\", f\"{height}\"),\n        (\"%PORT%\", f\"{port}\"),\n        (\"%URL%\", json.dumps(url)),\n    ]\n    for k, v in replacements:\n        shell = shell.replace(k, v)\n\n    # Display frame\n    iframe = IPython.display.HTML(shell)\n    IPython.display.display(iframe)\n</code></pre>"},{"location":"api_reference/app/main/","title":"main","text":""},{"location":"api_reference/app/main/#pixano.app.main","title":"<code>pixano.app.main</code>","text":""},{"location":"api_reference/app/main/#pixano.app.main.create_app","title":"<code>create_app(settings=Settings())</code>","text":"<p>Run Pixano app</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>App settings</p> <code>Settings()</code> <p>Returns:</p> Type Description <code>FastAPI</code> <p>Pixano app</p> Source code in <code>pixano/app/main.py</code> <pre><code>def create_app(settings: Settings = Settings()) -&gt; FastAPI:\n    \"\"\"Run Pixano app\n\n    Args:\n        settings (Settings): App settings\n\n    Returns:\n        FastAPI: Pixano app\n    \"\"\"\n\n    # Create app\n    app = FastAPI()\n    app.add_middleware(\n        CORSMiddleware,\n        allow_credentials=True,\n        allow_methods=[\"*\"],\n        allow_headers=[\"*\"],\n    )\n\n    # Mount folders\n    if isinstance(settings.data_dir, S3Path):\n        # If S3, mount models parent folder\n        # Check if folder exists\n        if not settings.model_dir.exists():\n            raise FileNotFoundError(\n                f\"Local model directory '{settings.model_dir.absolute()}' not found\"\n            )\n        # Mount\n        app.mount(\n            \"/data\",\n            StaticFiles(directory=settings.model_dir.parent),\n            name=\"data\",\n        )\n    else:\n        # If local, mount datasets folder with models subfolder\n        # Check if folder exists\n        if not settings.data_dir.exists():\n            raise FileNotFoundError(\n                f\"Dataset library '{settings.data_dir.absolute()}' not found\"\n            )\n        # Create models subfolder in case it doesn't exist yet\n        settings.model_dir.mkdir(exist_ok=True)\n        # Mount\n        app.mount(\n            \"/data\",\n            StaticFiles(directory=settings.data_dir),\n            name=\"data\",\n        )\n\n    app.include_router(datasets.router)\n    app.include_router(items.router)\n    app.include_router(models.router)\n\n    add_pagination(app)\n    return app\n</code></pre>"},{"location":"api_reference/app/serve/","title":"serve","text":""},{"location":"api_reference/app/serve/#pixano.app.serve","title":"<code>pixano.app.serve</code>","text":""},{"location":"api_reference/app/serve/#pixano.app.serve.App","title":"<code>App(library_dir, aws_endpoint=None, aws_region=None, aws_access_key=None, aws_secret_key=None, local_model_dir=None, host='127.0.0.1', port=8000)</code>","text":"<p>Pixano app</p> <p>Attributes:</p> Name Type Description <code>app</code> <code>FastAPI</code> <p>FastAPI App</p> <code>config</code> <code>Config</code> <p>App config</p> <code>server</code> <code>Server</code> <p>App server</p> <p>Parameters:</p> Name Type Description Default <code>library_dir</code> <code>str</code> <p>Local or S3 path to dataset library</p> required <code>aws_endpoint</code> <code>str</code> <p>S3 endpoint URL, use 'AWS' if not provided. Used if library_dir is an S3 path. Defaults to None.</p> <code>None</code> <code>aws_region</code> <code>str</code> <p>S3 region name, not always required for private storages. Used if library_dir is an S3 path. Defaults to None.</p> <code>None</code> <code>aws_access_key</code> <code>str</code> <p>S3 AWS access key. Used if library_dir is an S3 path. Defaults to None.</p> <code>None</code> <code>aws_secret_key</code> <code>str</code> <p>S3 AWS secret key. Used if library_dir is an S3 path. Defaults to None.</p> <code>None</code> <code>local_model_dir</code> <code>str</code> <p>Local path to models. Used if library_dir is an S3 path. Defaults to None.</p> <code>None</code> <code>host</code> <code>str</code> <p>App host. Defaults to \"127.0.0.1\".</p> <code>'127.0.0.1'</code> <code>port</code> <code>int</code> <p>App port. Defaults to 8000.</p> <code>8000</code> Source code in <code>pixano/app/serve.py</code> <pre><code>def __init__(\n    self,\n    library_dir: str,\n    aws_endpoint: str = None,\n    aws_region: str = None,\n    aws_access_key: str = None,\n    aws_secret_key: str = None,\n    local_model_dir: str = None,\n    host: str = \"127.0.0.1\",\n    port: int = 8000,\n):\n    \"\"\"Initialize and run Pixano app\n\n    Args:\n        library_dir (str): Local or S3 path to dataset library\n        aws_endpoint (str, optional): S3 endpoint URL, use 'AWS' if not provided. Used if library_dir is an S3 path. Defaults to None.\n        aws_region (str, optional): S3 region name, not always required for private storages. Used if library_dir is an S3 path. Defaults to None.\n        aws_access_key (str, optional): S3 AWS access key. Used if library_dir is an S3 path. Defaults to None.\n        aws_secret_key (str, optional): S3 AWS secret key. Used if library_dir is an S3 path. Defaults to None.\n        local_model_dir (str, optional): Local path to models. Used if library_dir is an S3 path. Defaults to None.\n        host (str, optional): App host. Defaults to \"127.0.0.1\".\n        port (int, optional): App port. Defaults to 8000.\n    \"\"\"\n\n    # Override app settings\n    @lru_cache\n    def get_settings_override():\n        return Settings(\n            library_dir=library_dir,\n            aws_endpoint=aws_endpoint,\n            aws_region=aws_region,\n            aws_access_key=aws_access_key,\n            aws_secret_key=aws_secret_key,\n            local_model_dir=local_model_dir,\n        )\n\n    # Create app\n    templates = Jinja2Templates(directory=TEMPLATE_PATH)\n    self.app = create_app(settings=get_settings_override())\n    self.app.dependency_overrides[get_settings] = get_settings_override\n\n    @self.app.get(\"/\", response_class=HTMLResponse)\n    def main_page(request: fastapi.Request):\n        return templates.TemplateResponse(\"index.html\", {\"request\": request})\n\n    @self.app.get(\"/{ds_id}/dataset\", response_class=HTMLResponse)\n    async def dataset_page(request: fastapi.Request):\n        return templates.TemplateResponse(\"index.html\", {\"request\": request})\n\n    @self.app.get(\"/{ds_id}/dashboard\", response_class=HTMLResponse)\n    async def dashboard_page(request: fastapi.Request):\n        return templates.TemplateResponse(\"index.html\", {\"request\": request})\n\n    @self.app.get(\"/{ds_id}/dataset/{item_id}\", response_class=HTMLResponse)\n    async def item_page(request: fastapi.Request):\n        return templates.TemplateResponse(\"index.html\", {\"request\": request})\n\n    self.app.mount(\"/_app\", StaticFiles(directory=ASSETS_PATH), name=\"assets\")\n    self.config = uvicorn.Config(self.app, host=host, port=port)\n    self.server = uvicorn.Server(self.config)\n\n    # Serve app\n    task_functions[self.get_env()](self.server.serve())\n</code></pre>"},{"location":"api_reference/app/serve/#pixano.app.serve.App.display","title":"<code>display(height=1000)</code>","text":"<p>Display Pixano app</p> <p>Parameters:</p> Name Type Description Default <code>height</code> <code>int</code> <p>Frame height. Defaults to 1000.</p> <code>1000</code> Source code in <code>pixano/app/serve.py</code> <pre><code>def display(self, height: int = 1000) -&gt; None:\n    \"\"\"Display Pixano app\n\n    Args:\n        height (int, optional): Frame height. Defaults to 1000.\n    \"\"\"\n\n    # Wait for app to be online\n    while not self.server.started:\n        task_functions[self.get_env()](asyncio.wait(0.1))\n\n    # Display app\n    for server in self.server.servers:\n        for socket in server.sockets:\n            address = socket.getsockname()\n            display_functions[self.get_env()](\n                url=f\"http://{address[0]}\", port=address[1], height=height\n            )\n</code></pre>"},{"location":"api_reference/app/serve/#pixano.app.serve.App.get_env","title":"<code>get_env()</code>","text":"<p>Get the app's current running environment</p> <p>Returns:</p> Type Description <code>str</code> <p>Running environment</p> Source code in <code>pixano/app/serve.py</code> <pre><code>def get_env(self) -&gt; str:\n    \"\"\"Get the app's current running environment\n\n    Returns:\n        str: Running environment\n    \"\"\"\n\n    # If Google colab import succeeds\n    try:\n        # pylint: disable=import-outside-toplevel, unused-import\n        import google.colab\n        import IPython\n    except ImportError:\n        pass\n    else:\n        if IPython.get_ipython() is not None:\n            return \"colab\"\n\n    # If IPython import succeeds\n    try:\n        # pylint: disable=import-outside-toplevel\n        import IPython\n    except ImportError:\n        pass\n    else:\n        ipython = IPython.get_ipython()\n        if ipython is not None and ipython.has_trait(\"kernel\"):\n            return \"ipython\"\n\n    # Else\n    return \"none\"\n</code></pre>"},{"location":"api_reference/app/serve/#pixano.app.serve.main","title":"<code>main(library_dir, aws_endpoint, aws_region, aws_access_key, aws_secret_key, local_model_dir, host, port)</code>","text":"<p>Launch Pixano App in LIBRARY_DIR</p> <p>LIBRARY_DIR is the local or S3 path to your dataset library</p> Source code in <code>pixano/app/serve.py</code> <pre><code>@click.command(context_settings={\"auto_envvar_prefix\": \"UVICORN\"})\n@click.argument(\"library_dir\", type=str)\n@click.option(\n    \"--aws_endpoint\",\n    type=str,\n    help=\"S3 endpoint URL, use 'AWS' if not provided. Used if library_dir is an S3 path\",\n)\n@click.option(\n    \"--aws_region\",\n    type=str,\n    help=\"S3 region name, not always required for private storages. Used if library_dir is an S3 path\",\n)\n@click.option(\n    \"--aws_access_key\",\n    type=str,\n    help=\"S3 AWS access key. Used if library_dir is an S3 path\",\n)\n@click.option(\n    \"--aws_secret_key\",\n    type=str,\n    help=\"S3 AWS secret key. Used if library_dir is an S3 path\",\n)\n@click.option(\n    \"--local_model_dir\",\n    type=str,\n    help=\"Local path to your models. Used if library_dir is an S3 path\",\n)\n@click.option(\n    \"--host\",\n    type=str,\n    default=\"127.0.0.1\",\n    help=\"Pixano app URL host\",\n    show_default=True,\n)\n@click.option(\n    \"--port\",\n    type=int,\n    default=0,\n    help=\"Pixano app URL port\",\n    show_default=True,\n)\ndef main(\n    library_dir: str,\n    aws_endpoint: str,\n    aws_region: str,\n    aws_access_key: str,\n    aws_secret_key: str,\n    local_model_dir: str,\n    host: str,\n    port: int,\n):\n    \"\"\"Launch Pixano App in LIBRARY_DIR\n\n    LIBRARY_DIR is the local or S3 path to your dataset library\n    \"\"\"\n\n    App(\n        library_dir,\n        aws_endpoint,\n        aws_region,\n        aws_access_key,\n        aws_secret_key,\n        local_model_dir,\n        host,\n        port,\n    )\n</code></pre>"},{"location":"api_reference/app/api/datasets/","title":"datasets","text":""},{"location":"api_reference/app/api/datasets/#pixano.app.api.datasets","title":"<code>pixano.app.api.datasets</code>","text":""},{"location":"api_reference/app/api/datasets/#pixano.app.api.datasets.get_dataset","title":"<code>get_dataset(ds_id, settings)</code>  <code>async</code>","text":"<p>Load dataset</p> <p>Parameters:</p> Name Type Description Default <code>ds_id</code> <code>str</code> <p>Dataset ID</p> required <code>settings</code> <code>Settings</code> <p>App settings</p> required <p>Returns:</p> Type Description <code>DatasetInfo</code> <p>Dataset info</p> Source code in <code>pixano/app/api/datasets.py</code> <pre><code>@router.get(\"/datasets/{ds_id}\", response_model=DatasetInfo)\nasync def get_dataset(\n    ds_id: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; DatasetInfo:\n    \"\"\"Load dataset\n\n    Args:\n        ds_id (str): Dataset ID\n        settings (Settings): App settings\n\n    Returns:\n        DatasetInfo: Dataset info\n    \"\"\"\n\n    # Load dataset\n    dataset = Dataset.find(ds_id, settings.data_dir)\n\n    # Return dataset info\n    if dataset:\n        return dataset.load_info(load_stats=True, load_features_values=True)\n    raise HTTPException(\n        status_code=404,\n        detail=f\"Dataset {ds_id} not found in {settings.data_dir.absolute()}\",\n    )\n</code></pre>"},{"location":"api_reference/app/api/datasets/#pixano.app.api.datasets.get_datasets","title":"<code>get_datasets(settings)</code>  <code>async</code>","text":"<p>Load dataset list</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>App settings</p> required <p>Returns:</p> Type Description <code>list[DatasetInfo]</code> <p>List of dataset infos</p> Source code in <code>pixano/app/api/datasets.py</code> <pre><code>@router.get(\"/datasets\", response_model=list[DatasetInfo])\nasync def get_datasets(\n    settings: Annotated[Settings, Depends(get_settings)]\n) -&gt; list[DatasetInfo]:\n    \"\"\"Load dataset list\n\n    Args:\n        settings (Settings): App settings\n\n    Returns:\n        list[DatasetInfo]: List of dataset infos\n    \"\"\"\n\n    # Load datasets\n    infos = DatasetInfo.load_directory(directory=settings.data_dir, load_thumbnail=True)\n\n    # Return datasets\n    if infos:\n        return infos\n    raise HTTPException(\n        status_code=404,\n        detail=f\"No datasets found in {settings.data_dir.absolute()}\",\n    )\n</code></pre>"},{"location":"api_reference/app/api/items/","title":"items","text":""},{"location":"api_reference/app/api/items/#pixano.app.api.items","title":"<code>pixano.app.api.items</code>","text":""},{"location":"api_reference/app/api/items/#pixano.app.api.items.get_dataset_item","title":"<code>get_dataset_item(ds_id, item_id, settings)</code>  <code>async</code>","text":"<p>Load dataset item</p> <p>Parameters:</p> Name Type Description Default <code>ds_id</code> <code>str</code> <p>Dataset ID</p> required <code>item_id</code> <code>str</code> <p>Item ID</p> required <p>Returns:</p> Type Description <code>DatasetItem</code> <p>Dataset item</p> Source code in <code>pixano/app/api/items.py</code> <pre><code>@router.get(\"/items/{item_id}\", response_model=DatasetItem)\nasync def get_dataset_item(\n    ds_id: str,\n    item_id: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; DatasetItem:\n    \"\"\"Load dataset item\n\n    Args:\n        ds_id (str): Dataset ID\n        item_id (str): Item ID\n\n    Returns:\n        DatasetItem: Dataset item\n    \"\"\"\n\n    # Load dataset\n    dataset = Dataset.find(ds_id, settings.data_dir)\n\n    if dataset:\n        # Load dataset item\n        item = dataset.load_item(item_id, load_objects=True)\n\n        # Return dataset item\n        if item:\n            return item\n        raise HTTPException(\n            status_code=404,\n            detail=f\"Item '{item_id}' not found in dataset\",\n        )\n    raise HTTPException(\n        status_code=404,\n        detail=f\"Dataset {ds_id} not found in {settings.data_dir.absolute()}\",\n    )\n</code></pre>"},{"location":"api_reference/app/api/items/#pixano.app.api.items.get_dataset_items","title":"<code>get_dataset_items(ds_id, settings, params=Depends())</code>  <code>async</code>","text":"<p>Load dataset items</p> <p>Parameters:</p> Name Type Description Default <code>ds_id</code> <code>str</code> <p>Dataset ID</p> required <code>params</code> <code>Params</code> <p>Pagination parameters (offset and limit). Defaults to Depends().</p> <code>Depends()</code> <p>Returns:</p> Type Description <code>Page[DatasetItem]</code> <p>Dataset items page</p> Source code in <code>pixano/app/api/items.py</code> <pre><code>@router.get(\"/items\", response_model=Page[DatasetItem])\nasync def get_dataset_items(\n    ds_id: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n    params: Params = Depends(),\n) -&gt; Page[DatasetItem]:\n    \"\"\"Load dataset items\n\n    Args:\n        ds_id (str): Dataset ID\n        params (Params, optional): Pagination parameters (offset and limit). Defaults to Depends().\n\n    Returns:\n        Page[DatasetItem]: Dataset items page\n    \"\"\"\n\n    # Load dataset\n    dataset = Dataset.find(ds_id, settings.data_dir)\n\n    if dataset:\n        # Get page parameters\n        params = resolve_params(params)\n        raw_params = params.to_raw_params()\n        total = dataset.num_rows\n\n        # Check page parameters\n        start = raw_params.offset\n        stop = min(raw_params.offset + raw_params.limit, total)\n        if start &gt;= stop:\n            raise HTTPException(\n                status_code=404,\n                detail=f\"Invalid page parameters (start {start}, stop {stop})\",\n            )\n\n        # Load dataset items\n        items = dataset.load_items(raw_params.limit, raw_params.offset)\n\n        # Return dataset items\n        if items:\n            return create_page(items, total=total, params=params)\n        raise HTTPException(\n            status_code=404,\n            detail=f\"No items found with page parameters (start {start}, stop {stop}) in dataset\",\n        )\n    raise HTTPException(\n        status_code=404,\n        detail=f\"Dataset {ds_id} not found in {settings.data_dir.absolute()}\",\n    )\n</code></pre>"},{"location":"api_reference/app/api/items/#pixano.app.api.items.get_item_embeddings","title":"<code>get_item_embeddings(ds_id, item_id, model_id, settings)</code>  <code>async</code>","text":"<p>Load dataset item embeddings</p> <p>Parameters:</p> Name Type Description Default <code>ds_id</code> <code>str</code> <p>Dataset ID</p> required <code>item_id</code> <code>str</code> <p>Item ID</p> required <code>model_id</code> <code>str</code> <p>Model ID (ONNX file path)</p> required Source code in <code>pixano/app/api/items.py</code> <pre><code>@router.get(\n    \"/items/{item_id}/embeddings/{model_id}\",\n    response_model=DatasetItem,\n)\nasync def get_item_embeddings(\n    ds_id: str,\n    item_id: str,\n    model_id: str,\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; DatasetItem:\n    \"\"\"Load dataset item embeddings\n\n    Args:\n        ds_id (str): Dataset ID\n        item_id (str): Item ID\n        model_id (str): Model ID (ONNX file path)\n    \"\"\"\n\n    # Load dataset\n    dataset = Dataset.find(ds_id, settings.data_dir)\n\n    if dataset:\n        item = dataset.load_item(\n            item_id,\n            load_media=False,\n            load_active_learning=False,\n            load_embeddings=True,\n            model_id=model_id,\n        )\n\n        # Return dataset item embeddings\n        if item:\n            return item\n        raise HTTPException(\n            status_code=404,\n            detail=f\"No embeddings found for item '{item_id}' with model '{model_id}' in dataset\",\n        )\n    raise HTTPException(\n        status_code=404,\n        detail=f\"Dataset {ds_id} not found in {settings.data_dir.absolute()}\",\n    )\n</code></pre>"},{"location":"api_reference/app/api/items/#pixano.app.api.items.post_dataset_item","title":"<code>post_dataset_item(ds_id, item, settings)</code>  <code>async</code>","text":"<p>Save dataset item</p> <p>Parameters:</p> Name Type Description Default <code>ds_id</code> <code>str</code> <p>Dataset ID</p> required <code>item</code> <code>DatasetItem</code> <p>Item to save</p> required Source code in <code>pixano/app/api/items.py</code> <pre><code>@router.post(\"/items/{item_id}\", response_model=DatasetItem)\nasync def post_dataset_item(\n    ds_id: str,\n    item: DatasetItem,\n    settings: Annotated[Settings, Depends(get_settings)],\n):\n    \"\"\"Save dataset item\n\n    Args:\n        ds_id (str): Dataset ID\n        item (DatasetItem): Item to save\n    \"\"\"\n\n    # Load dataset\n    dataset = Dataset.find(ds_id, settings.data_dir)\n\n    if dataset:\n        # Save dataset item\n        dataset.save_item(item)\n\n        # Return response\n        return Response()\n    raise HTTPException(\n        status_code=404,\n        detail=f\"Dataset {ds_id} not found in {settings.data_dir.absolute()}\",\n    )\n</code></pre>"},{"location":"api_reference/app/api/items/#pixano.app.api.items.search_dataset_items","title":"<code>search_dataset_items(ds_id, query, settings, params=Depends())</code>  <code>async</code>","text":"<p>Load dataset items with a query</p> <p>Parameters:</p> Name Type Description Default <code>ds_id</code> <code>str</code> <p>Dataset ID</p> required <code>query</code> <code>dict[str, str]</code> <p>Search query</p> required <code>params</code> <code>Params</code> <p>Pagination parameters (offset and limit). Defaults to Depends().</p> <code>Depends()</code> <p>Returns:</p> Type Description <code>Page[DatasetItem]</code> <p>Dataset items page</p> Source code in <code>pixano/app/api/items.py</code> <pre><code>@router.post(\"/search\", response_model=Page[DatasetItem])\nasync def search_dataset_items(\n    ds_id: str,\n    query: dict[str, str],\n    settings: Annotated[Settings, Depends(get_settings)],\n    params: Params = Depends(),\n) -&gt; Page[DatasetItem]:\n    \"\"\"Load dataset items with a query\n\n    Args:\n        ds_id (str): Dataset ID\n        query (dict[str, str]): Search query\n        params (Params, optional): Pagination parameters (offset and limit). Defaults to Depends().\n\n    Returns:\n        Page[DatasetItem]: Dataset items page\n    \"\"\"\n\n    # Load dataset\n    dataset = Dataset.find(ds_id, settings.data_dir)\n\n    if dataset:\n        # Get page parameters\n        params = resolve_params(params)\n        raw_params = params.to_raw_params()\n        total = dataset.num_rows\n\n        # Check page parameters\n        start = raw_params.offset\n        stop = min(raw_params.offset + raw_params.limit, total)\n        if start &gt;= stop:\n            raise HTTPException(status_code=404, detail=\"Invalid page parameters\")\n\n        # Load dataset items\n        items = dataset.search_items(raw_params.limit, raw_params.offset, query)\n\n        # Return dataset items\n        if items:\n            return create_page(items, total=total, params=params)\n        raise HTTPException(\n            status_code=404, detail=f\"No items found for query '{query}' in dataset\"\n        )\n    raise HTTPException(\n        status_code=404,\n        detail=f\"Dataset {ds_id} not found in {settings.data_dir.absolute()}\",\n    )\n</code></pre>"},{"location":"api_reference/app/api/models/","title":"models","text":""},{"location":"api_reference/app/api/models/#pixano.app.api.models","title":"<code>pixano.app.api.models</code>","text":""},{"location":"api_reference/app/api/models/#pixano.app.api.models.get_models","title":"<code>get_models(settings)</code>  <code>async</code>","text":"<p>Load models</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of models</p> Source code in <code>pixano/app/api/models.py</code> <pre><code>@router.get(\"/models\", response_model=list[str])\nasync def get_models(\n    settings: Annotated[Settings, Depends(get_settings)],\n) -&gt; list[str]:\n    \"\"\"Load models\n\n    Returns:\n        list[str]: List of models\n    \"\"\"\n\n    # Load list of models\n    models = []\n    for model_path in settings.model_dir.glob(\"*.onnx\"):\n        models.append(model_path.name)\n\n    # Return list of models\n    if models:\n        return models\n    raise HTTPException(\n        status_code=404,\n        detail=f\"No models found in {settings.model_dir.absolute()}\",\n    )\n</code></pre>"},{"location":"api_reference/core/bbox/","title":"bbox","text":""},{"location":"api_reference/core/bbox/#pixano.core.bbox","title":"<code>pixano.core.bbox</code>","text":""},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox","title":"<code>BBox(coords, format, is_normalized=True, confidence=None)</code>","text":"<p>               Bases: <code>PixanoType</code>, <code>BaseModel</code></p> <p>Bounding box type using coordinates in xyxy or xywh format</p> <p>Attributes:</p> Name Type Description <code>coords</code> <code>list[float]</code> <p>List of coordinates in given format</p> <code>format</code> <code>str</code> <p>Coordinates format, 'xyxy' or 'xywh'</p> <code>is_normalized</code> <code>bool</code> <p>True if coordinates are normalized to image size</p> <code>confidence</code> <code>float</code> <p>Bounding box confidence if predicted</p> <p>Parameters:</p> Name Type Description Default <code>coords</code> <code>list[float]</code> <p>List of coordinates in given format</p> required <code>format</code> <code>str</code> <p>Coordinates format, 'xyxy' or 'xywh'</p> required <code>is_normalized</code> <code>bool</code> <p>True if coordinates are normalized to image size. Defaults to True.</p> <code>True</code> <code>confidence</code> <code>float</code> <p>Bounding box confidence if predicted. Defaults to None.</p> <code>None</code> Source code in <code>pixano/core/bbox.py</code> <pre><code>def __init__(\n    self,\n    coords: list[float],\n    format: str,\n    is_normalized: bool = True,\n    confidence: float = None,\n):\n    \"\"\"Initialize Bounding box\n\n    Args:\n        coords (list[float]): List of coordinates in given format\n        format (str): Coordinates format, 'xyxy' or 'xywh'\n        is_normalized (bool, optional): True if coordinates are normalized to image size. Defaults to True.\n        confidence (float, optional): Bounding box confidence if predicted. Defaults to None.\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__()\n\n    # Define private attributes manually\n    self._coords = coords\n    self._format = format\n    self._is_normalized = is_normalized\n    self._confidence = confidence\n</code></pre>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.confidence","title":"<code>confidence: float</code>  <code>property</code>","text":"<p>Return bounding box confidence</p> <p>Returns:</p> Type Description <code>float</code> <p>Bounding box confidence if predicted, else None</p>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.coords","title":"<code>coords: list[float]</code>  <code>property</code>","text":"<p>Return bounding box coordinates</p> <p>Returns:</p> Type Description <code>list[float]</code> <p>Coordinates</p>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.format","title":"<code>format: str</code>  <code>property</code>","text":"<p>Return bounding box coordinates format</p> <p>Returns:</p> Type Description <code>str</code> <p>Coordinates format, 'xyxy' or 'xywh'</p>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.is_normalized","title":"<code>is_normalized: bool</code>  <code>property</code>","text":"<p>Return bounding box normalization information</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if coordinates are normalized to image size</p>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.is_predicted","title":"<code>is_predicted: bool</code>  <code>property</code>","text":"<p>Return True if bounding box is predicted and has a confidence value</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if bounding box is predicted and has a confidence value</p>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.xywh_coords","title":"<code>xywh_coords: list[float]</code>  <code>property</code>","text":"<p>Return bounding box xywh coordinates</p> <p>Returns:</p> Type Description <code>list[float]</code> <p>Coordinates in xywh format</p>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.xyxy_coords","title":"<code>xyxy_coords: list[float]</code>  <code>property</code>","text":"<p>Return bounding box xyxy coordinates</p> <p>Returns:</p> Type Description <code>list[float]</code> <p>Coordinates in xyxy format</p>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.denormalize","title":"<code>denormalize(height, width)</code>","text":"<p>Return bounding box with coordinates denormalized from image size</p> <p>Parameters:</p> Name Type Description Default <code>height</code> <code>int</code> <p>Image height</p> required <code>width</code> <code>int</code> <p>Image width</p> required <p>Returns:</p> Type Description <code>BBox</code> <p>Bounding box with coordinates denormalized from image size</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>def denormalize(self, height: int, width: int) -&gt; \"BBox\":\n    \"\"\"Return bounding box with coordinates denormalized from image size\n\n    Args:\n        height (int): Image height\n        width (int): Image width\n\n    Returns:\n        BBox: Bounding box with coordinates denormalized from image size\n    \"\"\"\n\n    return BBox(\n        denormalize_coords(self.coords, height, width),\n        self.format,\n        False,\n        self.confidence,\n    )\n</code></pre>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.from_mask","title":"<code>from_mask(mask)</code>  <code>staticmethod</code>","text":"<p>Create bounding box using a NumPy array mask</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>NumPy array mask</p> required <p>Returns:</p> Type Description <code>Bbox</code> <p>Bounding box</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>@staticmethod\ndef from_mask(mask: np.ndarray) -&gt; \"BBox\":\n    \"\"\"Create bounding box using a NumPy array mask\n\n    Args:\n        mask (np.ndarray): NumPy array mask\n\n    Returns:\n        Bbox: Bounding box\n    \"\"\"\n\n    return BBox.from_xywh(mask_to_bbox(mask))\n</code></pre>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.from_rle","title":"<code>from_rle(rle)</code>  <code>staticmethod</code>","text":"<p>Create bounding box using a RLE mask</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>CompressedRLE</code> <p>RLE mask</p> required <p>Returns:</p> Type Description <code>Bbox</code> <p>Bounding box</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>@staticmethod\ndef from_rle(rle: CompressedRLE) -&gt; \"BBox\":\n    \"\"\"Create bounding box using a RLE mask\n\n    Args:\n        rle (CompressedRLE): RLE mask\n\n    Returns:\n        Bbox: Bounding box\n    \"\"\"\n\n    return BBox.from_mask(rle.to_mask())\n</code></pre>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.from_xywh","title":"<code>from_xywh(xywh, confidence=None)</code>  <code>staticmethod</code>","text":"<p>Create bounding box using normalized xywh coordinates</p> <p>Parameters:</p> Name Type Description Default <code>xywh</code> <code>list[float]</code> <p>List of coordinates in xywh format</p> required <code>confidence</code> <code>float</code> <p>Bounding box confidence if predicted. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Bbox</code> <p>Bounding box</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>@staticmethod\ndef from_xywh(xywh: list[float], confidence: float = None) -&gt; \"BBox\":\n    \"\"\"Create bounding box using normalized xywh coordinates\n\n    Args:\n        xywh (list[float]): List of coordinates in xywh format\n        confidence (float, optional): Bounding box confidence if predicted. Defaults to None.\n\n    Returns:\n        Bbox: Bounding box\n    \"\"\"\n\n    return BBox(xywh, \"xywh\", confidence=confidence)\n</code></pre>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.from_xyxy","title":"<code>from_xyxy(xyxy, confidence=None)</code>  <code>staticmethod</code>","text":"<p>Create bounding box using normalized xyxy coordinates</p> <p>Parameters:</p> Name Type Description Default <code>xyxy</code> <code>list[float]</code> <p>List of coordinates in xyxy format</p> required <code>confidence</code> <code>float</code> <p>Bounding box confidence if predicted. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Bbox</code> <p>Bounding box</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>@staticmethod\ndef from_xyxy(xyxy: list[float], confidence: float = None) -&gt; \"BBox\":\n    \"\"\"Create bounding box using normalized xyxy coordinates\n\n    Args:\n        xyxy (list[float]): List of coordinates in xyxy format\n        confidence (float, optional): Bounding box confidence if predicted. Defaults to None.\n\n    Returns:\n        Bbox: Bounding box\n    \"\"\"\n\n    return BBox(xyxy, \"xyxy\", confidence=confidence)\n</code></pre>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.normalize","title":"<code>normalize(height, width)</code>","text":"<p>Return bounding box with coordinates normalized to image size</p> <p>Parameters:</p> Name Type Description Default <code>height</code> <code>int</code> <p>Image height</p> required <code>width</code> <code>int</code> <p>Image width</p> required <p>Returns:</p> Type Description <code>BBox</code> <p>Bounding box with coordinates normalized to image size</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>def normalize(self, height: int, width: int) -&gt; \"BBox\":\n    \"\"\"Return bounding box with coordinates normalized to image size\n\n    Args:\n        height (int): Image height\n        width (int): Image width\n\n    Returns:\n        BBox: Bounding box with coordinates normalized to image size\n    \"\"\"\n\n    return BBox(\n        normalize_coords(self.coords, height, width),\n        self.format,\n        True,\n        self.confidence,\n    )\n</code></pre>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.to_struct","title":"<code>to_struct()</code>  <code>staticmethod</code>","text":"<p>Return BBox type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>@staticmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return BBox type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    return pa.struct(\n        [\n            pa.field(\"coords\", pa.list_(pa.float32(), list_size=4)),\n            pa.field(\"is_normalized\", pa.bool_()),\n            pa.field(\"format\", pa.string()),\n            pa.field(\"confidence\", pa.float32()),\n        ]\n    )\n</code></pre>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.to_xywh","title":"<code>to_xywh()</code>","text":"<p>Return bounding box in xywh format</p> <p>Returns:</p> Type Description <code>BBox</code> <p>Bounding box in xyxy format</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>def to_xywh(self) -&gt; \"BBox\":\n    \"\"\"Return bounding box in xywh format\n\n    Returns:\n        BBox: Bounding box in xyxy format\n    \"\"\"\n\n    return BBox(self.xywh_coords, \"xywh\", self.is_normalized, self.confidence)\n</code></pre>"},{"location":"api_reference/core/bbox/#pixano.core.bbox.BBox.to_xyxy","title":"<code>to_xyxy()</code>","text":"<p>Return bounding box in xyxy format</p> <p>Returns:</p> Type Description <code>BBox</code> <p>Bounding box in xyxy format</p> Source code in <code>pixano/core/bbox.py</code> <pre><code>def to_xyxy(self) -&gt; \"BBox\":\n    \"\"\"Return bounding box in xyxy format\n\n    Returns:\n        BBox: Bounding box in xyxy format\n    \"\"\"\n\n    return BBox(self.xyxy_coords, \"xyxy\", self.is_normalized, self.confidence)\n</code></pre>"},{"location":"api_reference/core/camera/","title":"camera","text":""},{"location":"api_reference/core/camera/#pixano.core.camera","title":"<code>pixano.core.camera</code>","text":""},{"location":"api_reference/core/camera/#pixano.core.camera.Camera","title":"<code>Camera(depth_scale, cam_k, cam_r_w2c=None, cam_t_w2c=None)</code>","text":"<p>               Bases: <code>PixanoType</code>, <code>BaseModel</code></p> <p>Camera type</p> <p>Attributes:</p> Name Type Description <code>depth_scale</code> <code>float</code> <p>Depth scale</p> <code>cam_k</code> <code>list[float]</code> <p>Camera matrix K</p> <code>cam_r_w2c</code> <code>list[float]</code> <p>3*3 orientation matrix</p> <code>cam_t_w2c</code> <code>list[float]</code> <p>3*1 translation matrix</p> <p>Parameters:</p> Name Type Description Default <code>depth_scale</code> <code>float</code> <p>Depth scale</p> required <code>cam_k</code> <code>list[float]</code> <p>Camera matrix K</p> required <code>cam_r_w2c</code> <code>list[float]</code> <p>3*3 orientation matrix. Defaults to None.</p> <code>None</code> <code>cam_t_w2c</code> <code>list[float]</code> <p>3*1 translation matrix. Defaults to None.</p> <code>None</code> Source code in <code>pixano/core/camera.py</code> <pre><code>def __init__(\n    self,\n    depth_scale: float,\n    cam_k: list[float],\n    cam_r_w2c: list[float] = None,\n    cam_t_w2c: list[float] = None,\n):\n    \"\"\"Initialize Camera\n\n    Args:\n        depth_scale (float): Depth scale\n        cam_k (list[float]): Camera matrix K\n        cam_r_w2c (list[float], optional): 3*3 orientation matrix. Defaults to None.\n        cam_t_w2c (list[float], optional): 3*1 translation matrix. Defaults to None.\n    \"\"\"\n\n    if cam_r_w2c is None:\n        cam_r_w2c = [0.0] * 9\n    if cam_t_w2c is None:\n        cam_t_w2c = [0.0] * 3\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__(\n        depth_scale=depth_scale,\n        cam_k=cam_k,\n        cam_r_w2c=cam_r_w2c,\n        cam_t_w2c=cam_t_w2c,\n    )\n</code></pre>"},{"location":"api_reference/core/camera/#pixano.core.camera.Camera.to_struct","title":"<code>to_struct()</code>  <code>staticmethod</code>","text":"<p>Return Camera type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/camera.py</code> <pre><code>@staticmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return Camera type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    return pa.struct(\n        [\n            pa.field(\"depth_scale\", pa.float64()),\n            pa.field(\"cam_k\", pa.list_(pa.float64())),\n            pa.field(\"cam_r_w2c\", pa.list_(pa.float64())),\n            pa.field(\"cam_t_w2c\", pa.list_(pa.float64())),\n        ]\n    )\n</code></pre>"},{"location":"api_reference/core/compressed_rle/","title":"compressed_rle","text":""},{"location":"api_reference/core/compressed_rle/#pixano.core.compressed_rle","title":"<code>pixano.core.compressed_rle</code>","text":""},{"location":"api_reference/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE","title":"<code>CompressedRLE(size, counts)</code>","text":"<p>               Bases: <code>PixanoType</code>, <code>BaseModel</code></p> <p>Compressed RLE mask type</p> <p>Attributes:</p> Name Type Description <code>_size</code> <code>list[int]</code> <p>Mask size</p> <code>_counts</code> <code>bytes</code> <p>Mask RLE encoding</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>list[int]</code> <p>Mask size</p> required <code>counts</code> <code>bytes</code> <p>Mask RLE encoding</p> required Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>def __init__(self, size: list[int], counts: bytes):\n    \"\"\"Initalize compressed RLE mask\n\n    Args:\n        size (list[int]): Mask size\n        counts (bytes): Mask RLE encoding\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__()\n\n    # Define private attributes manually\n    self._size = size\n    self._counts = counts\n</code></pre>"},{"location":"api_reference/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.counts","title":"<code>counts: bytes</code>  <code>property</code>","text":"<p>Return mask RLE encoding</p> <p>Returns:</p> Type Description <code>bytes</code> <p>Mask RLE encoding</p>"},{"location":"api_reference/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.size","title":"<code>size: list[int]</code>  <code>property</code>","text":"<p>Return mask size</p> <p>Returns:</p> Type Description <code>list[int]</code> <p>Mask size</p>"},{"location":"api_reference/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.encode","title":"<code>encode(mask, height, width)</code>  <code>staticmethod</code>","text":"<p>Create compressed RLE mask from polygons / uncompressed RLE / compressed RLE</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>list[list] | dict[str, list[int]]</code> <p>Mask as polygons / uncompressed RLE / compressed RLE</p> required <code>height</code> <code>int</code> <p>Image height</p> required <code>width</code> <code>int</code> <p>Image width</p> required <p>Returns:</p> Type Description <code>CompressedRLE</code> <p>Compressed RLE mask</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>@staticmethod\ndef encode(\n    mask: list[list] | dict[str, list[int]], height: int, width: int\n) -&gt; \"CompressedRLE\":\n    \"\"\"Create compressed RLE mask from polygons / uncompressed RLE / compressed RLE\n\n    Args:\n        mask (list[list] | dict[str, list[int]]): Mask as polygons / uncompressed RLE / compressed RLE\n        height (int): Image height\n        width (int): Image width\n\n    Returns:\n        CompressedRLE: Compressed RLE mask\n    \"\"\"\n\n    return CompressedRLE.from_dict(encode_rle(mask, height, width))\n</code></pre>"},{"location":"api_reference/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.from_mask","title":"<code>from_mask(mask)</code>  <code>staticmethod</code>","text":"<p>Create compressed RLE mask from NumPy array</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>Image | ndarray</code> <p>Mask as NumPy array</p> required <p>Returns:</p> Type Description <code>CompressedRLE</code> <p>Compressed RLE mask</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>@staticmethod\ndef from_mask(mask: Image.Image | np.ndarray) -&gt; \"CompressedRLE\":\n    \"\"\"Create compressed RLE mask from NumPy array\n\n    Args:\n        mask (Image.Image | np.ndarray): Mask as NumPy array\n\n    Returns:\n        CompressedRLE: Compressed RLE mask\n    \"\"\"\n\n    return CompressedRLE.from_dict(mask_to_rle(mask))\n</code></pre>"},{"location":"api_reference/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.from_polygons","title":"<code>from_polygons(polygons, height, width)</code>  <code>staticmethod</code>","text":"<p>Create compressed RLE mask from polygons</p> <p>Parameters:</p> Name Type Description Default <code>polygons</code> <code>list[list]</code> <p>Mask as polygons</p> required <code>height</code> <code>int</code> <p>Image height</p> required <code>width</code> <code>int</code> <p>Image width</p> required <p>Returns:</p> Type Description <code>CompressedRLE</code> <p>Compressed RLE mask</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>@staticmethod\ndef from_polygons(\n    polygons: list[list],\n    height: int,\n    width: int,\n) -&gt; \"CompressedRLE\":\n    \"\"\"Create compressed RLE mask from polygons\n\n    Args:\n        polygons (list[list]): Mask as polygons\n        height (int): Image height\n        width (int): Image width\n\n    Returns:\n        CompressedRLE: Compressed RLE mask\n    \"\"\"\n\n    return CompressedRLE.from_dict(polygons_to_rle(polygons, height, width))\n</code></pre>"},{"location":"api_reference/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.from_urle","title":"<code>from_urle(urle)</code>  <code>staticmethod</code>","text":"<p>Create compressed RLE mask from uncompressed RLE</p> <p>Parameters:</p> Name Type Description Default <code>urle</code> <code>dict[str, list[int]]</code> <p>Mask as uncompressed RLE</p> required <p>Returns:</p> Type Description <code>CompressedRLE</code> <p>Compressed RLE mask</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>@staticmethod\ndef from_urle(urle: dict[str, list[int]]) -&gt; \"CompressedRLE\":\n    \"\"\"Create compressed RLE mask from uncompressed RLE\n\n    Args:\n        urle (dict[str, list[int]]): Mask as uncompressed RLE\n\n    Returns:\n        CompressedRLE: Compressed RLE mask\n    \"\"\"\n\n    return CompressedRLE.from_dict(urle_to_rle(urle))\n</code></pre>"},{"location":"api_reference/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.to_mask","title":"<code>to_mask()</code>","text":"<p>Convert compressed RLE mask to NumPy array</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Mask as NumPy array</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>def to_mask(self) -&gt; np.ndarray:\n    \"\"\"Convert compressed RLE mask to NumPy array\n\n    Returns:\n        np.ndarray: Mask as NumPy array\n    \"\"\"\n\n    return rle_to_mask(self.to_dict())\n</code></pre>"},{"location":"api_reference/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.to_polygons","title":"<code>to_polygons()</code>","text":"<p>Convert compressed RLE mask to poylgons</p> <p>Returns:</p> Type Description <code>list[list]</code> <p>Mask as polygons</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>def to_polygons(self) -&gt; list[list]:\n    \"\"\"Convert compressed RLE mask to poylgons\n\n    Returns:\n        list[list]: Mask as polygons\n    \"\"\"\n\n    return rle_to_polygons(self.to_dict())\n</code></pre>"},{"location":"api_reference/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.to_struct","title":"<code>to_struct()</code>  <code>staticmethod</code>","text":"<p>Return CompressedRLE type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>@staticmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return CompressedRLE type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    return pa.struct(\n        [\n            pa.field(\"size\", pa.list_(pa.int32(), list_size=2)),\n            pa.field(\"counts\", pa.binary()),\n        ]\n    )\n</code></pre>"},{"location":"api_reference/core/compressed_rle/#pixano.core.compressed_rle.CompressedRLE.to_urle","title":"<code>to_urle()</code>","text":"<p>Convert compressed RLE mask to uncompressed RLE</p> <p>Returns:</p> Type Description <code>dict[str, list[int]]</code> <p>Mask as uncompressed RLE</p> Source code in <code>pixano/core/compressed_rle.py</code> <pre><code>def to_urle(self) -&gt; dict[str, list[int]]:\n    \"\"\"Convert compressed RLE mask to uncompressed RLE\n\n    Returns:\n        dict[str, list[int]]: Mask as uncompressed RLE\n    \"\"\"\n\n    return rle_to_urle(self.to_dict())\n</code></pre>"},{"location":"api_reference/core/depth_image/","title":"depth_image","text":""},{"location":"api_reference/core/depth_image/#pixano.core.depth_image","title":"<code>pixano.core.depth_image</code>","text":""},{"location":"api_reference/core/depth_image/#pixano.core.depth_image.DepthImage","title":"<code>DepthImage(depth_map=None, bytes=None, shape=None)</code>","text":"<p>               Bases: <code>PixanoType</code>, <code>BaseModel</code></p> <p>Depth image type</p> <p>Attributes:</p> Name Type Description <code>_depth_map</code> <code>ndarray</code> <p>Depth image as NumPy array</p> <code>_bytes</code> <code>bytes</code> <p>Depth image as bytes</p> <code>_shape</code> <code>list[int]</code> <p>Depth image shape</p> <p>Parameters:</p> Name Type Description Default <code>depth_map</code> <code>ndarray</code> <p>Depth image as NumPy array. Defaults to None.</p> <code>None</code> <code>bytes</code> <code>bytes</code> <p>Depth image as bytes. Defaults to None.</p> <code>None</code> <code>shape</code> <code>list[int]</code> <p>Depth image shape. Defaults to None.</p> <code>None</code> Source code in <code>pixano/core/depth_image.py</code> <pre><code>def __init__(\n    self,\n    depth_map: np.ndarray = None,\n    bytes: bytes = None,\n    shape: list[int] = None,\n):\n    \"\"\"Initialize Depth image\n\n    Args:\n        depth_map (np.ndarray, optional): Depth image as NumPy array. Defaults to None.\n        bytes (bytes, optional): Depth image as bytes. Defaults to None.\n        shape (list[int], optional): Depth image shape. Defaults to None.\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__()\n\n    # Define private attributes manually\n    self._depth_map = depth_map\n    self._bytes = bytes\n    self._shape = shape\n</code></pre>"},{"location":"api_reference/core/depth_image/#pixano.core.depth_image.DepthImage.bytes","title":"<code>bytes: bytes</code>  <code>property</code>","text":"<p>Return Depth image as bytes</p> <p>Returns:</p> Type Description <code>bytes</code> <p>Depth image as bytes</p>"},{"location":"api_reference/core/depth_image/#pixano.core.depth_image.DepthImage.depth_map","title":"<code>depth_map: np.ndarray</code>  <code>property</code>","text":"<p>Returns Depth image as NumPy array</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Depth image as NumPy array</p>"},{"location":"api_reference/core/depth_image/#pixano.core.depth_image.DepthImage.shape","title":"<code>shape: list[int]</code>  <code>property</code>","text":"<p>Return Depth image shape</p> <p>Returns:</p> Type Description <code>list[int]</code> <p>Depth image shape</p>"},{"location":"api_reference/core/depth_image/#pixano.core.depth_image.DepthImage.display","title":"<code>display()</code>","text":"<p>Display Depth image with matplotlib</p> <p>Returns:</p> Type Description <code>Figure</code> <p>Plotted image</p> Source code in <code>pixano/core/depth_image.py</code> <pre><code>def display(self):\n    \"\"\"Display Depth image with matplotlib\n\n    Returns:\n        plt.Figure: Plotted image\n    \"\"\"\n\n    fig, ax = plt.subplots(figsize=self._shape)\n    ax.imshow(self.depth_map.astype(np.int8), cmap=\"gray\", vmin=0, vmax=255)\n    ax.axis(\"off\")\n\n    plt.ion()\n    plt.show()\n\n    return fig\n</code></pre>"},{"location":"api_reference/core/depth_image/#pixano.core.depth_image.DepthImage.load","title":"<code>load(path)</code>  <code>staticmethod</code>","text":"<p>Create depth image from 16-bit .png file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path of .png file of depth image</p> required <p>Returns:</p> Type Description <code>DepthImage</code> <p>Depth image</p> Source code in <code>pixano/core/depth_image.py</code> <pre><code>@staticmethod\ndef load(path: str) -&gt; \"DepthImage\":\n    \"\"\"Create depth image from 16-bit .png file\n\n    Args:\n        path (str): Path of .png file of depth image\n\n    Returns:\n        DepthImage: Depth image\n    \"\"\"\n\n    depth_map = imageio.v3.imread(path).astype(np.uint16)\n    return DepthImage(depth_map=depth_map, shape=depth_map.shape)\n</code></pre>"},{"location":"api_reference/core/depth_image/#pixano.core.depth_image.DepthImage.load_npy","title":"<code>load_npy(path)</code>  <code>staticmethod</code>","text":"<p>Create depth image from .npy file</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to .npy file containing depth image as NumPy Array.</p> required <p>Returns:</p> Type Description <code>DepthImage</code> <p>Depth image</p> Source code in <code>pixano/core/depth_image.py</code> <pre><code>@staticmethod\ndef load_npy(path: str) -&gt; \"DepthImage\":\n    \"\"\"Create depth image from .npy file\n\n    Args:\n        path (str): Path to .npy file containing depth image as NumPy Array.\n\n    Returns:\n        DepthImage: Depth image\n    \"\"\"\n\n    depth_map = np.load(path)\n    return DepthImage(depth_map=depth_map, shape=depth_map.shape)\n</code></pre>"},{"location":"api_reference/core/depth_image/#pixano.core.depth_image.DepthImage.open","title":"<code>open()</code>","text":"<p>Open depth image</p> <p>Returns:</p> Type Description <code>IO</code> <p>Opened depth image</p> Source code in <code>pixano/core/depth_image.py</code> <pre><code>def open(self) -&gt; IO:\n    \"\"\"Open depth image\n\n    Returns:\n        IO: Opened depth image\n    \"\"\"\n\n    return io.BytesIO(self.bytes)\n</code></pre>"},{"location":"api_reference/core/depth_image/#pixano.core.depth_image.DepthImage.save","title":"<code>save(path)</code>","text":"<p>Save depth image to .png file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to .png file to save</p> required Source code in <code>pixano/core/depth_image.py</code> <pre><code>def save(self, path):\n    \"\"\"Save depth image to .png file.\n\n    Args:\n        path (str): Path to .png file to save\n    \"\"\"\n\n    depth_image = self.depth_map.astype(np.uint16)\n    imageio.v3.imwrite(path, depth_image)\n</code></pre>"},{"location":"api_reference/core/depth_image/#pixano.core.depth_image.DepthImage.to_grayscale","title":"<code>to_grayscale()</code>","text":"<p>Transform Depth image to 8-bit grayscale depth image</p> <p>Returns:</p> Type Description <code>DepthImage</code> <p>8-bit grayscale depth image</p> Source code in <code>pixano/core/depth_image.py</code> <pre><code>def to_grayscale(\n    self,\n) -&gt; \"DepthImage\":\n    \"\"\"Transform Depth image to 8-bit grayscale depth image\n\n    Returns:\n        DepthImage: 8-bit grayscale depth image\n    \"\"\"\n\n    depth = self.depth_map\n    d_min, d_max = depth.min(), depth.max()\n    depth_n: np.ndarray = ((depth - d_min) / (d_max - d_min)) * 255\n    return DepthImage(depth_map=depth_n.astype(np.uint8), shape=depth.shape)\n</code></pre>"},{"location":"api_reference/core/depth_image/#pixano.core.depth_image.DepthImage.to_struct","title":"<code>to_struct()</code>  <code>staticmethod</code>","text":"<p>Return DepthImage type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/depth_image.py</code> <pre><code>@staticmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return DepthImage type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    return pa.struct(\n        [\n            pa.field(\"bytes\", pa.binary()),\n            pa.field(\"shape\", pa.list_(pa.int32(), list_size=2)),\n        ]\n    )\n</code></pre>"},{"location":"api_reference/core/gt_info/","title":"gt_info","text":""},{"location":"api_reference/core/gt_info/#pixano.core.gt_info","title":"<code>pixano.core.gt_info</code>","text":""},{"location":"api_reference/core/gt_info/#pixano.core.gt_info.GtInfo","title":"<code>GtInfo(bbox_obj, bbox_visib, px_count_all, px_count_valid, px_count_visib, visib_fract)</code>","text":"<p>               Bases: <code>PixanoType</code>, <code>BaseModel</code></p> <p>GtInfo type</p> <p>Attributes:</p> Name Type Description <code>bbox_obj</code> <code>BBox</code> <p>bbox_obj</p> <code>bbox_visib</code> <code>BBox</code> <p>bbox_visib</p> <code>px_count_all</code> <code>int</code> <p>px_count_all</p> <code>px_count_valid</code> <code>int</code> <p>px_count_valid</p> <code>px_count_visib</code> <code>int</code> <p>px_count_visib</p> <code>visib_fract</code> <code>float</code> <p>visib_fract</p> <p>Parameters:</p> Name Type Description Default <code>bbox_obj</code> <code>BBox</code> <p>bbox_obj</p> required <code>bbox_visib</code> <code>BBox</code> <p>bbox_visib</p> required <code>px_count_all</code> <code>int</code> <p>px_count_all</p> required <code>px_count_valid</code> <code>int</code> <p>px_count_valid</p> required <code>px_count_visib</code> <code>int</code> <p>px_count_visib</p> required <code>visib_fract</code> <code>float</code> <p>visib_fract</p> required Source code in <code>pixano/core/gt_info.py</code> <pre><code>def __init__(\n    self,\n    bbox_obj: BBox,\n    bbox_visib: BBox,\n    px_count_all: int,\n    px_count_valid: int,\n    px_count_visib: int,\n    visib_fract: float,\n):\n    \"\"\"Initialize GtInfo\n\n    Args:\n        bbox_obj (BBox): bbox_obj\n        bbox_visib (BBox): bbox_visib\n        px_count_all (int): px_count_all\n        px_count_valid (int): px_count_valid\n        px_count_visib (int): px_count_visib\n        visib_fract (float): visib_fract\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__(\n        bbox_obj=bbox_obj,\n        bbox_visib=bbox_visib,\n        px_count_all=px_count_all,\n        px_count_valid=px_count_valid,\n        px_count_visib=px_count_visib,\n        visib_fract=visib_fract,\n    )\n</code></pre>"},{"location":"api_reference/core/gt_info/#pixano.core.gt_info.GtInfo.to_struct","title":"<code>to_struct()</code>  <code>staticmethod</code>","text":"<p>Return GtInfo type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/gt_info.py</code> <pre><code>@staticmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return GtInfo type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    return pa.struct(\n        [\n            pa.field(\"bbox_obj\", BBoxType),\n            pa.field(\"bbox_visib\", BBoxType),\n            pa.field(\"px_count_all\", pa.int64()),\n            pa.field(\"px_count_valid\", pa.int64()),\n            pa.field(\"px_count_visib\", pa.int64()),\n            pa.field(\"visib_fract\", pa.float64()),\n        ]\n    )\n</code></pre>"},{"location":"api_reference/core/image/","title":"image","text":""},{"location":"api_reference/core/image/#pixano.core.image","title":"<code>pixano.core.image</code>","text":""},{"location":"api_reference/core/image/#pixano.core.image.Image","title":"<code>Image(uri, bytes=None, preview_bytes=None, uri_prefix=None)</code>","text":"<p>               Bases: <code>PixanoType</code>, <code>BaseModel</code></p> <p>Image type using URI or bytes</p> <p>Attributes:</p> Name Type Description <code>uri</code> <code>str</code> <p>Image URI</p> <code>bytes</code> <code>bytes</code> <p>Image bytes</p> <code>preview_bytes</code> <code>bytes</code> <p>Image preview bytes</p> <code>uri_prefix</code> <code>str</code> <p>URI prefix for relative URIs</p> <p>Attributes:</p> Name Type Description <code>uri</code> <code>str</code> <p>Image URI</p> <code>bytes</code> <code>bytes</code> <p>Image bytes. Defaults to None.</p> <code>preview_bytes</code> <code>bytes</code> <p>Image preview bytes. Defaults to None.</p> <code>uri_prefix</code> <code>str</code> <p>URI prefix for relative URIs. Defaults to None.</p> Source code in <code>pixano/core/image.py</code> <pre><code>def __init__(\n    self,\n    uri: str,\n    bytes: bytes = None,\n    preview_bytes: bytes = None,\n    uri_prefix: str = None,\n):\n    \"\"\"Initialize Image\n\n    Attributes:\n        uri (str): Image URI\n        bytes (bytes, optional): Image bytes. Defaults to None.\n        preview_bytes (bytes, optional): Image preview bytes. Defaults to None.\n        uri_prefix (str, optional): URI prefix for relative URIs. Defaults to None.\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__(\n        uri=uri,\n        bytes=bytes,\n        preview_bytes=preview_bytes,\n        uri_prefix=uri_prefix,\n    )\n</code></pre>"},{"location":"api_reference/core/image/#pixano.core.image.Image.complete_uri","title":"<code>complete_uri: str</code>  <code>property</code>","text":"<p>Return complete image URI using URI and URI prefix</p> <p>Returns:</p> Type Description <code>str</code> <p>Image URI</p>"},{"location":"api_reference/core/image/#pixano.core.image.Image.file_name","title":"<code>file_name: str</code>  <code>property</code>","text":"<p>Return image file name from URI</p> <p>Returns:</p> Type Description <code>str</code> <p>Image file name</p>"},{"location":"api_reference/core/image/#pixano.core.image.Image.height","title":"<code>height: int</code>  <code>property</code>","text":"<p>Return image height</p> <p>Returns:</p> Type Description <code>int</code> <p>Image height</p>"},{"location":"api_reference/core/image/#pixano.core.image.Image.path","title":"<code>path: Path</code>  <code>property</code>","text":"<p>Return image path using URI and URI prefix</p> <p>Returns:</p> Type Description <code>Path</code> <p>Image path</p>"},{"location":"api_reference/core/image/#pixano.core.image.Image.preview_url","title":"<code>preview_url: str</code>  <code>property</code>","text":"<p>Return image preview base 64 URL</p> <p>Returns:</p> Type Description <code>str</code> <p>Image preview base 64 URL</p>"},{"location":"api_reference/core/image/#pixano.core.image.Image.size","title":"<code>size: list[int]</code>  <code>property</code>","text":"<p>Return image size</p> <p>Returns:</p> Type Description <code>list[int]</code> <p>Image size</p>"},{"location":"api_reference/core/image/#pixano.core.image.Image.url","title":"<code>url: str</code>  <code>property</code>","text":"<p>Return image base 64 URL</p> <p>Returns:</p> Type Description <code>str</code> <p>Image base 64 URL</p>"},{"location":"api_reference/core/image/#pixano.core.image.Image.width","title":"<code>width: int</code>  <code>property</code>","text":"<p>Return image width</p> <p>Returns:</p> Type Description <code>int</code> <p>Image width</p>"},{"location":"api_reference/core/image/#pixano.core.image.Image.as_cv2","title":"<code>as_cv2()</code>","text":"<p>Open image as OpenCV</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Image as OpenCV</p> Source code in <code>pixano/core/image.py</code> <pre><code>def as_cv2(self) -&gt; np.ndarray:\n    \"\"\"Open image as OpenCV\n\n    Returns:\n        np.ndarray: Image as OpenCV\n    \"\"\"\n\n    im_arr = np.frombuffer(self.open().read(), dtype=np.uint8)\n    return cv2.imdecode(im_arr, cv2.IMREAD_COLOR)\n</code></pre>"},{"location":"api_reference/core/image/#pixano.core.image.Image.as_pillow","title":"<code>as_pillow()</code>","text":"<p>Open image as Pillow</p> <p>Returns:</p> Type Description <code>Image</code> <p>Image as Pillow</p> Source code in <code>pixano/core/image.py</code> <pre><code>def as_pillow(self) -&gt; PILImage.Image:\n    \"\"\"Open image as Pillow\n\n    Returns:\n        PIL.Image.Image: Image as Pillow\n    \"\"\"\n\n    return PILImage.open(self.open()).convert(\"RGB\")\n</code></pre>"},{"location":"api_reference/core/image/#pixano.core.image.Image.display","title":"<code>display(preview=False)</code>","text":"<p>Display image</p> <p>Parameters:</p> Name Type Description Default <code>preview</code> <code>bool</code> <p>True to display image preview instead of full image. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Image</code> <p>Image as IPython Display</p> Source code in <code>pixano/core/image.py</code> <pre><code>def display(self, preview=False) -&gt; IPyImage:\n    \"\"\"Display image\n\n    Args:\n        preview (bool, optional): True to display image preview instead of full image. Defaults to False.\n\n    Returns:\n        IPython.core.display.Image: Image as IPython Display\n    \"\"\"\n\n    im_bytes = self.preview_bytes if preview else self.get_bytes()\n    return IPyImage(url=binary_to_url(im_bytes), format=IPyImage(im_bytes).format)\n</code></pre>"},{"location":"api_reference/core/image/#pixano.core.image.Image.get_bytes","title":"<code>get_bytes()</code>","text":"<p>Get image bytes from attribute or from reading file from URI</p> <p>Returns:</p> Type Description <code>bytes</code> <p>Image bytes</p> Source code in <code>pixano/core/image.py</code> <pre><code>def get_bytes(self) -&gt; bytes:\n    \"\"\"Get image bytes from attribute or from reading file from URI\n\n    Returns:\n        bytes: Image bytes\n    \"\"\"\n\n    if self.bytes is not None:\n        return self.bytes\n    if self.uri is not None:\n        with self.open() as f:\n            return f.read()\n    return None\n</code></pre>"},{"location":"api_reference/core/image/#pixano.core.image.Image.open","title":"<code>open()</code>","text":"<p>Open image</p> <p>Returns:</p> Type Description <code>IO</code> <p>Opened image</p> Source code in <code>pixano/core/image.py</code> <pre><code>def open(self) -&gt; IO:\n    \"\"\"Open image\n\n    Returns:\n        IO: Opened image\n    \"\"\"\n\n    complete_uri = self.complete_uri\n    if urlparse(complete_uri).scheme == \"s3\":\n        presigned_url = S3Path.from_uri(complete_uri).get_presigned_url()\n        return urlopen(presigned_url)\n    return urlopen(complete_uri)\n</code></pre>"},{"location":"api_reference/core/image/#pixano.core.image.Image.to_struct","title":"<code>to_struct()</code>  <code>staticmethod</code>","text":"<p>Return Image type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/image.py</code> <pre><code>@staticmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return Image type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    return pa.struct(\n        [\n            pa.field(\"uri\", pa.utf8()),\n            pa.field(\"bytes\", pa.binary()),\n            pa.field(\"preview_bytes\", pa.binary()),\n        ]\n    )\n</code></pre>"},{"location":"api_reference/core/pixano_type/","title":"pixano_type","text":""},{"location":"api_reference/core/pixano_type/#pixano.core.pixano_type","title":"<code>pixano.core.pixano_type</code>","text":""},{"location":"api_reference/core/pixano_type/#pixano.core.pixano_type.PixanoType","title":"<code>PixanoType(**data)</code>","text":"<p>               Bases: <code>ABC</code>, <code>BaseModel</code></p> <p>Base class for all Pixano custom types</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            category=None,\n        )\n</code></pre>"},{"location":"api_reference/core/pixano_type/#pixano.core.pixano_type.PixanoType.from_dict","title":"<code>from_dict(data)</code>  <code>classmethod</code>","text":"<p>Instance custom type from dict</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type[PixanoType]</code> <p>Pixano custom type to instance</p> required <code>data</code> <code>dict[str, Any]</code> <p>Data to instance from</p> required <p>Returns:</p> Type Description <code>PixanoType</code> <p>New instance of Pixano custom type</p> Source code in <code>pixano/core/pixano_type.py</code> <pre><code>@classmethod\ndef from_dict(cls: Type[\"PixanoType\"], data: dict[str, Any]) -&gt; \"PixanoType\":\n    \"\"\"Instance custom type from dict\n\n    Args:\n        cls (Type[PixanoType]): Pixano custom type to instance\n        data (dict[str, Any]): Data to instance from\n\n    Returns:\n        PixanoType: New instance of Pixano custom type\n    \"\"\"\n\n    return cls(**data)\n</code></pre>"},{"location":"api_reference/core/pixano_type/#pixano.core.pixano_type.PixanoType.to_dict","title":"<code>to_dict()</code>","text":"<p>Return custom type as dict based on corresponding PyArrow Struct</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Custom type as dict</p> Source code in <code>pixano/core/pixano_type.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Return custom type as dict based on corresponding PyArrow Struct\n\n    Returns:\n        dict[str, Any]: Custom type as dict\n    \"\"\"\n\n    def _convert_value_as_dict(value):\n        \"\"\"Recursively convert value to dict if possible\"\"\"\n\n        if isinstance(value, PixanoType):\n            return value.to_dict()\n        if isinstance(value, dict):\n            return {k: _convert_value_as_dict(v) for k, v in value.items()}\n        if isinstance(value, (list, tuple)):\n            return [_convert_value_as_dict(item) for item in value]\n        return value\n\n    struct_fields = self.to_struct()\n    return {\n        field.name: _convert_value_as_dict(getattr(self, field.name))\n        for field in struct_fields\n    }\n</code></pre>"},{"location":"api_reference/core/pixano_type/#pixano.core.pixano_type.PixanoType.to_struct","title":"<code>to_struct()</code>  <code>abstractmethod</code> <code>staticmethod</code>","text":"<p>Return custom type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/pixano_type.py</code> <pre><code>@staticmethod\n@abstractmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return custom type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n</code></pre>"},{"location":"api_reference/core/pixano_type/#pixano.core.pixano_type.convert_field","title":"<code>convert_field(field_name, field_type, field_data)</code>","text":"<p>Convert PyArrow ExtensionTypes properly</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name</p> required <code>field_type</code> <code>DataType</code> <p>Target PyArrow format</p> required <code>field_data</code> <code>list</code> <p>Data in Python format</p> required <p>Returns:</p> Type Description <code>Array</code> <p>Data in target PyArrow format</p> Source code in <code>pixano/core/pixano_type.py</code> <pre><code>def convert_field(\n    field_name: str, field_type: pa.DataType, field_data: list\n) -&gt; pa.Array:\n    \"\"\"Convert PyArrow ExtensionTypes properly\n\n    Args:\n        field_name (str): Name\n        field_type (pa.DataType): Target PyArrow format\n        field_data (list): Data in Python format\n\n    Returns:\n        pa.Array: Data in target PyArrow format\n    \"\"\"\n\n    # If target format is an ExtensionType\n    if isinstance(field_type, pa.ExtensionType):\n        storage = pa.array(field_data, type=field_type.storage_type)\n        return pa.ExtensionArray.from_storage(field_type, storage)\n\n    # If target format is an extension of ListType\n    if pa.types.is_list(field_type):\n        native_arr = pa.array(field_data)\n        if isinstance(native_arr, pa.NullArray):\n            return pa.nulls(len(native_arr), field_type)\n        offsets = native_arr.offsets\n        values = native_arr.values.to_numpy(zero_copy_only=False)\n        return pa.ListArray.from_arrays(\n            offsets,\n            convert_field(f\"{field_name}.elements\", field_type.value_type, values),\n        )\n\n    # If target format is an extension of StructType\n    if pa.types.is_struct(field_type):\n        native_arr = pa.array(field_data)\n        if isinstance(native_arr, pa.NullArray):\n            return pa.nulls(len(native_arr), field_type)\n        arrays = []\n        for subfield in field_type:\n            sub_arr = native_arr.field(subfield.name)\n            converted = convert_field(\n                f\"{field_name}.{subfield.name}\",\n                subfield.type,\n                sub_arr.to_numpy(zero_copy_only=False),\n            )\n            arrays.append(converted)\n        return pa.StructArray.from_arrays(arrays, fields=field_type)\n\n    # For other target formats\n    return pa.array(field_data, type=field_type)\n</code></pre>"},{"location":"api_reference/core/pixano_type/#pixano.core.pixano_type.create_pyarrow_type","title":"<code>create_pyarrow_type(struct_type, name, python_type)</code>","text":"<p>Create PyArrow ExtensionType for Pixano custom type</p> <p>Parameters:</p> Name Type Description Default <code>struct_type</code> <code>StructType</code> <p>Pixano custom type as PyArrow Struct</p> required <code>name</code> <code>str</code> <p>Pixano custom type name</p> required <code>python_type</code> <code>type</code> <p>Pixano custom type Python type</p> required <p>Returns:</p> Type Description <code>ExtensionType</code> <p>PyArrow ExtensionType</p> Source code in <code>pixano/core/pixano_type.py</code> <pre><code>def create_pyarrow_type(\n    struct_type: pa.StructType,\n    name: str,\n    python_type: type,\n) -&gt; pa.ExtensionType:\n    \"\"\"Create PyArrow ExtensionType for Pixano custom type\n\n    Args:\n        struct_type (pa.StructType): Pixano custom type as PyArrow Struct\n        name (str): Pixano custom type name\n        python_type (type): Pixano custom type Python type\n\n    Returns:\n        pa.ExtensionType: PyArrow ExtensionType\n    \"\"\"\n\n    class CustomExtensionType(pa.ExtensionType):\n        \"\"\"PyArrow CustomExtensionType\"\"\"\n\n        # pylint: disable=unused-argument\n        @classmethod\n        def __arrow_ext_deserialize__(cls, storage_type, serialized):\n            return cls(struct_type, name)\n\n        def __arrow_ext_serialize__(self):\n            return b\"\"\n\n        def __arrow_ext_scalar_class__(self):\n            return self.Scalar\n\n        def __arrow_ext_class__(self):\n            return self.Array\n\n        def __repr__(self):\n            return f\"ExtensionType&lt;{name}Type&gt;\"\n\n        class Scalar(pa.ExtensionScalar):\n            \"\"\"PyArrow ExtensionScalar\"\"\"\n\n            def as_py(self):\n                \"\"\"Create Python PixanoType from ExtensionScalar dictionary of PyArrow objects\"\"\"\n\n                def as_py_dict(pa_dict: dict[str, Any]) -&gt; dict[str, Any]:\n                    \"\"\"Recusively convert dictionary of PyArrow objects to dictionary of Python objects\n\n                    Args:\n                        pa_dict (dict[str, Any]): Dictionary of PyArrow objects\n\n                    Returns:\n                        dict[str, Any]: Dictionary of Python objects\n                    \"\"\"\n\n                    py_dict = {}\n                    for key, value in pa_dict.items():\n                        if hasattr(value, \"as_py\") and callable(\n                            getattr(value, \"as_py\")\n                        ):\n                            py_dict[key] = value.as_py()\n                        elif isinstance(value, dict):\n                            py_dict[key] = as_py_dict(value)\n                    return py_dict\n\n                return python_type.from_dict(as_py_dict(self.value))\n\n        class Array(pa.ExtensionArray):\n            \"\"\"PyArrow ExtensionArray\"\"\"\n\n            def __repr__(self):\n                return f\"&lt;{name}Array object at {hex(id(self))}&gt;\\n{self}\"\n\n            @staticmethod\n            def from_pylist(lst: list) -&gt; pa.ExtensionArray | pa.ListArray:\n                \"\"\"Create PyArrow list of objects from Python list\n\n\n                Args:\n                    lst (list): Python list\n\n                Returns:\n                    pa.ExtensionArray | pa.ListArray: PyArrow list\n                \"\"\"\n\n                def from_list(lst: list) -&gt; pa.ExtensionArray:\n                    \"\"\"Return ExtensionArray from Python list\n\n                    Args:\n                        lst (list): Python list\n\n                    Returns:\n                        pa.ExtensionArray: ExtensionArray\n                    \"\"\"\n\n                    fields = struct_type\n                    arrays = []\n\n                    for field in fields:\n                        data = []\n                        for obj in lst:\n                            if obj is not None:\n                                if hasattr(obj, \"to_dict\") and callable(\n                                    getattr(obj, \"to_dict\")\n                                ):\n                                    data.append(obj.to_dict().get(field.name))\n                                elif isinstance(obj, dict):\n                                    data.append(obj.get(field.name))\n                                else:\n                                    data.append(obj)\n                            else:\n                                data.append(None)\n\n                        arrays.append(\n                            convert_field(\n                                field.name,\n                                field.type,\n                                data,\n                            )\n                        )\n                    sto = pa.StructArray.from_arrays(arrays, fields=fields)\n                    return pa.ExtensionArray.from_storage(pyarrow_type, sto)\n\n                def from_lists(lsts: list[list]) -&gt; pa.ListArray:\n                    \"\"\"Return ListArray from Python list of lists\n\n                    Args:\n                        lsts (list[list]): Python list of lists\n\n                    Returns:\n                        pa.ListArray: ListArray\n                    \"\"\"\n\n                    offset = [0]\n                    for sub_list in lsts:\n                        offset.append(len(sub_list) + offset[-1])\n\n                    flat_list = [item for sublist in lsts for item in sublist]\n                    flat_array = from_list(flat_list)\n\n                    return pa.ListArray.from_arrays(\n                        offset, flat_array, type=pa.list_(pyarrow_type)\n                    )\n\n                def is_nested(lst: list) -&gt; bool:\n                    \"\"\"Check if list contains only sublists\n\n                    Args:\n                        lst (list): List to check\n\n                    Returns:\n                        bool: True if list contains only sublists\n                    \"\"\"\n\n                    return all(isinstance(item, list) for item in lst)\n\n                def is_flat(lst: list) -&gt; bool:\n                    \"\"\"Check if list does not contain sublists\n\n                    Args:\n                        lst (list): List to check\n\n                    Returns:\n                        bool: True if list does not contains sublists\n                    \"\"\"\n\n                    return all(not isinstance(item, list) for item in lst)\n\n                if is_nested(lst):\n                    return from_lists(lst)\n                if is_flat(lst):\n                    return from_list(lst)\n                raise ValueError(\n                    \"Input list must be either a nested list or a flat list\"\n                )\n\n    # Create ExtensionType\n    pyarrow_type = CustomExtensionType(struct_type, name)\n\n    # Try and register ExtensionType\n    try:\n        pa.register_extension_type(pyarrow_type)\n    # If ExtensionType is already registered\n    except pa.ArrowKeyError:\n        pass\n\n    return pyarrow_type\n</code></pre>"},{"location":"api_reference/core/pose/","title":"pose","text":""},{"location":"api_reference/core/pose/#pixano.core.pose","title":"<code>pixano.core.pose</code>","text":""},{"location":"api_reference/core/pose/#pixano.core.pose.Pose","title":"<code>Pose(cam_r_m2c, cam_t_m2c)</code>","text":"<p>               Bases: <code>PixanoType</code>, <code>BaseModel</code></p> <p>Pose type using orientation and translation matrices</p> <p>Attributes:</p> Name Type Description <code>_cam_r_m2c</code> <code>list[float]</code> <p>3*3 orientation matrix</p> <code>_cam_t_m2c</code> <code>list[float]</code> <p>3*1 translation matrix</p> <p>Parameters:</p> Name Type Description Default <code>cam_r_m2c</code> <code>list[float]</code> <p>3*3 orientation matrix</p> required <code>cam_t_m2c</code> <code>list[float]</code> <p>3*1 translation matrix</p> required Source code in <code>pixano/core/pose.py</code> <pre><code>def __init__(self, cam_r_m2c: list[float], cam_t_m2c: list[float]):\n    \"\"\"Initialize pose from orientation and translation matrices\n\n    Args:\n        cam_r_m2c (list[float]): 3*3 orientation matrix\n        cam_t_m2c (list[float]): 3*1 translation matrix\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__()\n\n    # Define private attributes manually\n    self._cam_r_m2c = cam_r_m2c\n    self._cam_t_m2c = cam_t_m2c\n</code></pre>"},{"location":"api_reference/core/pose/#pixano.core.pose.Pose.cam_r_m2c","title":"<code>cam_r_m2c: list[float]</code>  <code>property</code>","text":"<p>Return Pose orientation matrix</p> <p>Returns:</p> Type Description <code>list[float]</code> <p>3*3 orientation matrix</p>"},{"location":"api_reference/core/pose/#pixano.core.pose.Pose.cam_t_m2c","title":"<code>cam_t_m2c: list[float]</code>  <code>property</code>","text":"<p>Return Pose translation matrix</p> <p>Returns:</p> Type Description <code>list[float]</code> <p>1*3 translation matrix</p>"},{"location":"api_reference/core/pose/#pixano.core.pose.Pose.to_struct","title":"<code>to_struct()</code>  <code>staticmethod</code>","text":"<p>Return Pose type as PyArrow Struct</p> <p>Returns:</p> Type Description <code>StructType</code> <p>Custom type corresponding PyArrow Struct</p> Source code in <code>pixano/core/pose.py</code> <pre><code>@staticmethod\ndef to_struct() -&gt; pa.StructType:\n    \"\"\"Return Pose type as PyArrow Struct\n\n    Returns:\n        pa.StructType: Custom type corresponding PyArrow Struct\n    \"\"\"\n\n    return pa.struct(\n        [\n            pa.field(\"cam_r_m2c\", pa.list_(pa.float64(), list_size=9)),\n            pa.field(\"cam_t_m2c\", pa.list_(pa.float64(), list_size=3)),\n        ]\n    )\n</code></pre>"},{"location":"api_reference/core/utils/","title":"utils","text":""},{"location":"api_reference/core/utils/#pixano.core.utils","title":"<code>pixano.core.utils</code>","text":""},{"location":"api_reference/core/utils/#pixano.core.utils.is_binary","title":"<code>is_binary(t)</code>","text":"<p>Check if DataType is binary</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>DataType</code> <p>DataType to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if DataType is binary</p> Source code in <code>pixano/core/utils.py</code> <pre><code>def is_binary(t: pa.DataType) -&gt; bool:\n    \"\"\"Check if DataType is binary\n\n    Args:\n        t (pa.DataType): DataType to check\n\n    Returns:\n        bool: True if DataType is binary\n    \"\"\"\n\n    return pa.types.is_binary(t)\n</code></pre>"},{"location":"api_reference/core/utils/#pixano.core.utils.is_boolean","title":"<code>is_boolean(t)</code>","text":"<p>Check if DataType is boolean</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>DataType</code> <p>DataType to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if DataType is boolean</p> Source code in <code>pixano/core/utils.py</code> <pre><code>def is_boolean(t: pa.DataType) -&gt; bool:\n    \"\"\"Check if DataType is boolean\n\n    Args:\n        t (pa.DataType): DataType to check\n\n    Returns:\n        bool: True if DataType is boolean\n    \"\"\"\n\n    return pa.types.is_boolean(t)\n</code></pre>"},{"location":"api_reference/core/utils/#pixano.core.utils.is_float","title":"<code>is_float(t)</code>","text":"<p>Check if DataType is a float</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>DataType</code> <p>DataType to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if DataType is a float</p> Source code in <code>pixano/core/utils.py</code> <pre><code>def is_float(t: pa.DataType) -&gt; bool:\n    \"\"\"Check if DataType is a float\n\n    Args:\n        t (pa.DataType): DataType to check\n\n    Returns:\n        bool: True if DataType is a float\n    \"\"\"\n\n    return pa.types.is_floating(t)\n</code></pre>"},{"location":"api_reference/core/utils/#pixano.core.utils.is_image_type","title":"<code>is_image_type(t)</code>","text":"<p>Check if DataType is an Image</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>DataType</code> <p>DataType to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if DataType is an Image</p> Source code in <code>pixano/core/utils.py</code> <pre><code>def is_image_type(t: pa.DataType) -&gt; bool:\n    \"\"\"Check if DataType is an Image\n\n    Args:\n        t (pa.DataType): DataType to check\n\n    Returns:\n        bool: True if DataType is an Image\n    \"\"\"\n\n    return (\n        ImageType.equals(t)\n        or str(t) == \"struct&lt;uri: string, bytes: binary, preview_bytes: binary&gt;\"\n    )\n</code></pre>"},{"location":"api_reference/core/utils/#pixano.core.utils.is_integer","title":"<code>is_integer(t)</code>","text":"<p>Check if DataType is an integer</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>DataType</code> <p>DataType to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if DataType is an integer</p> Source code in <code>pixano/core/utils.py</code> <pre><code>def is_integer(t: pa.DataType) -&gt; bool:\n    \"\"\"Check if DataType is an integer\n\n    Args:\n        t (pa.DataType): DataType to check\n\n    Returns:\n        bool: True if DataType is an integer\n    \"\"\"\n\n    return pa.types.is_integer(t)\n</code></pre>"},{"location":"api_reference/core/utils/#pixano.core.utils.is_string","title":"<code>is_string(t)</code>","text":"<p>Check if DataType is a string</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>DataType</code> <p>DataType to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if DataType is a string</p> Source code in <code>pixano/core/utils.py</code> <pre><code>def is_string(t: pa.DataType) -&gt; bool:\n    \"\"\"Check if DataType is a string\n\n    Args:\n        t (pa.DataType): DataType to check\n\n    Returns:\n        bool: True if DataType is a string\n    \"\"\"\n\n    return pa.types.is_string(t) or pa.types.is_large_string(t)\n</code></pre>"},{"location":"api_reference/data/fields/","title":"fields","text":""},{"location":"api_reference/data/fields/#pixano.data.fields","title":"<code>pixano.data.fields</code>","text":""},{"location":"api_reference/data/fields/#pixano.data.fields.Fields","title":"<code>Fields(field_dict)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Dataset PyArrow fields as string dictionary</p> <p>Attributes:</p> Name Type Description <code>field_dict</code> <code>dict[str, str]</code> <p>PyArrow fields as string dictionary</p> <p>Parameters:</p> Name Type Description Default <code>field_dict</code> <code>dict[str, str]</code> <p>PyArrow fields as string dictionary</p> required Source code in <code>pixano/data/fields.py</code> <pre><code>def __init__(self, field_dict: dict[str, str]) -&gt; None:\n    \"\"\"Create Fields from string dictionary\n\n    Args:\n        field_dict (dict[str, str]): PyArrow fields as string dictionary\n    \"\"\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__(field_dict=field_dict)\n</code></pre>"},{"location":"api_reference/data/fields/#pixano.data.fields.Fields.to_schema","title":"<code>to_schema()</code>","text":"<p>Convert Fields string dictionary to PyArrow schema</p> <p>Returns:</p> Type Description <code>schema</code> <p>Fields as PyArrow schema</p> Source code in <code>pixano/data/fields.py</code> <pre><code>def to_schema(self) -&gt; pa.schema:\n    \"\"\"Convert Fields string dictionary to PyArrow schema\n\n    Returns:\n        pa.schema: Fields as PyArrow schema\n    \"\"\"\n    fields = []\n    for field_name, field_type in self.field_dict.items():\n        # Convert the field type to PyArrow type\n        field = pa.field(field_name, field_to_pyarrow(field_type), nullable=True)\n        fields.append(field)\n    return pa.schema(fields)\n</code></pre>"},{"location":"api_reference/data/fields/#pixano.data.fields.field_to_pyarrow","title":"<code>field_to_pyarrow(field)</code>","text":"<p>Return PyArrpw type from string field</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>str</code> <p>String field</p> required <p>Returns:</p> Type Description <code>DataType</code> <p>PyArrow type</p> Source code in <code>pixano/data/fields.py</code> <pre><code>def field_to_pyarrow(field: str) -&gt; pa.DataType:\n    \"\"\"Return PyArrpw type from string field\n\n    Args:\n        field (str): String field\n\n    Returns:\n        pa.DataType: PyArrow type\n    \"\"\"\n\n    pyarrow_dict = {\n        \"int\": pa.int64(),\n        \"float\": pa.float32(),\n        \"bool\": pa.bool_(),\n        \"str\": pa.string(),\n        \"bytes\": pa.binary(),\n        \"np.ndarray\": pa.list_(pa.float32()),\n        \"image\": ImageType,\n        \"depthimage\": DepthImageType,\n        \"camera\": CameraType,\n        \"compressedrle\": CompressedRLEType,\n        \"pose\": PoseType,\n        \"bbox\": BBoxType,\n        \"gtinfo\": GtInfoType,\n    }\n\n    if isinstance(field, str):\n        if field.startswith(\"[\") and field.endswith(\"]\"):\n            return pa.list_(\n                pyarrow_dict[field.removeprefix(\"[\").removesuffix(\"]\").lower()]\n            )\n        if field.startswith(\"vector(\") and field.endswith(\")\"):\n            size_str = field.removeprefix(\"vector(\").removesuffix(\")\")\n            if size_str.isnumeric():\n                return pa.list_(pa.float32(), list_size=int(size_str))\n        return pyarrow_dict[field.lower()]\n    return None\n</code></pre>"},{"location":"api_reference/data/fields/#pixano.data.fields.field_to_python","title":"<code>field_to_python(field)</code>","text":"<p>Return Python type from string field</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>str</code> <p>String field</p> required <p>Returns:</p> Type Description <code>type</code> <p>Python type</p> Source code in <code>pixano/data/fields.py</code> <pre><code>def field_to_python(field: str) -&gt; type:\n    \"\"\"Return Python type from string field\n\n    Args:\n        field (str): String field\n\n    Returns:\n        type: Python type\n    \"\"\"\n\n    python_dict = {\n        \"int\": int,\n        \"float\": float,\n        \"bool\": bool,\n        \"str\": str,\n        \"bytes\": bytes,\n        \"np.ndarray\": np.ndarray,\n        \"image\": Image,\n        \"depthimage\": DepthImage,\n        \"camera\": Camera,\n        \"compressedrle\": CompressedRLE,\n        \"pose\": Pose,\n        \"bbox\": BBox,\n        \"gtinfo\": GtInfo,\n    }\n\n    if isinstance(field, str):\n        if field.startswith(\"[\") and field.endswith(\"]\"):\n            return list\n        if field.startswith(\"vector(\") and field.endswith(\")\"):\n            return np.ndarray\n        return python_dict[field.lower()]\n    return None\n</code></pre>"},{"location":"api_reference/data/settings/","title":"settings","text":""},{"location":"api_reference/data/settings/#pixano.data.settings","title":"<code>pixano.data.settings</code>","text":""},{"location":"api_reference/data/settings/#pixano.data.settings.Settings","title":"<code>Settings(*args, **kwargs)</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Pixano app settings</p> <p>Attributes:</p> Name Type Description <code>library_dir</code> <code>str</code> <p>Local or S3 path to dataset library</p> <code>aws_endpoint</code> <code>str</code> <p>S3 endpoint URL, use 'AWS' if not provided. Used if library_dir is an S3 path</p> <code>aws_region</code> <code>str</code> <p>S3 region name, not always required for private storages. Used if library_dir is an S3 path</p> <code>aws_access_key</code> <code>str</code> <p>S3 AWS access key. Used if library_dir is an S3 path</p> <code>aws_secret_key</code> <code>str</code> <p>S3 AWS secret key. Used if library_dir is an S3 path</p> <code>local_model_dir</code> <code>str</code> <p>Local path to models. Used if library_dir is an S3 path</p> <code>data_dir</code> <code>Path | S3Path</code> <p>Dataset directory as Path | S3Path</p> <code>model_dir</code> <code>Path</code> <p>Model directory as Path</p> Source code in <code>pixano/data/settings.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    \"\"\"Initialize settings\"\"\"\n\n    super().__init__(*args, **kwargs)\n\n    # Setup data directory\n    if urlparse(self.library_dir).scheme == \"s3\":\n        # S3 library\n        try:\n            self.data_dir = S3Path.from_uri(self.library_dir)\n            register_configuration_parameter(\n                self.data_dir,\n                resource=boto3.resource(\n                    \"s3\",\n                    endpoint_url=self.aws_endpoint,\n                    region_name=self.aws_region,\n                    aws_access_key_id=self.aws_access_key,\n                    aws_secret_access_key=self.aws_secret_key,\n                ),\n            )\n        except Exception as e:\n            raise ValueError(\n                \"ERROR: Could not register S3 dataset library.\\n\"\n                \"You have to set the following environment variables:\\n\"\n                \"- AWS_ENDPOINT: S3 endpoint URL, use 'AWS' if not provided\\n\"\n                \"- AWS_REGION: S3 region name, not always required for private storages\\n\"\n                \"- AWS_ACCESS_KEY: S3 AWS access key\\n\"\n                \"- AWS_SECRET_KEY: S3 AWS secret key\"\n            ) from e\n\n        # Check if local model directory is provided\n        if self.local_model_dir is None:\n            raise AttributeError(\n                \"When using S3 storage, runtime models (.onnx files) must be stored locally and their directory must be provided with LOCAL_MODEL_DIR.\"\n            )\n        self.model_dir = Path(self.local_model_dir)\n\n    else:\n        # Local library\n        self.data_dir = Path(self.library_dir)\n        self.model_dir = self.data_dir / \"models\"\n</code></pre>"},{"location":"api_reference/data/settings/#pixano.data.settings.get_settings","title":"<code>get_settings()</code>  <code>cached</code>","text":"<p>Get app settings</p> <p>Returns:</p> Type Description <code>Settings</code> <p>App settings</p> Source code in <code>pixano/data/settings.py</code> <pre><code>@lru_cache\ndef get_settings() -&gt; Settings:\n    \"\"\"Get app settings\n\n    Returns:\n        Settings: App settings\n    \"\"\"\n\n    return Settings()\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/","title":"dataset","text":""},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset","title":"<code>pixano.data.dataset.dataset</code>","text":""},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset","title":"<code>Dataset(path)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Dataset</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>Path | S3Path</code> <p>Dataset path</p> <code>info</code> <code>DatasetInfo</code> <p>Dataset info</p> <code>stats</code> <code>list[DatasetStat]</code> <p>Dataset stats</p> <code>thumbnail</code> <code>str</code> <p>Dataset thumbnail base 64 URL</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | S3Path</code> <p>Dataset path</p> required Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>def __init__(\n    self,\n    path: Path | S3Path,\n):\n    \"\"\"Initialize dataset\n\n    Args:\n        path (Path | S3Path): Dataset path\n    \"\"\"\n\n    info_file = path / \"db.json\"\n    stats_file = path / \"stats.json\"\n    thumb_file = path / \"preview.png\"\n\n    # Define public attributes through Pydantic BaseModel\n    super().__init__(\n        path=path,\n        info=DatasetInfo.from_json(info_file),\n        stats=DatasetStat.from_json(stats_file) if stats_file.is_file() else None,\n        thumbnail=(\n            Image(uri=thumb_file.absolute().as_uri()).url\n            if thumb_file.is_file()\n            else None\n        ),\n    )\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.media_dir","title":"<code>media_dir: Path | S3Path</code>  <code>property</code>","text":"<p>Return dataset media directory</p> <p>Returns:</p> Type Description <code>Path | S3Path</code> <p>Dataset media directory</p>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.num_rows","title":"<code>num_rows: int</code>  <code>property</code>","text":"<p>Return number of rows in dataset</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of rows</p>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.connect","title":"<code>connect()</code>","text":"<p>Connect to dataset with LanceDB</p> <p>Returns:</p> Type Description <code>DBConnection</code> <p>Dataset LanceDB connection</p> Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>def connect(self) -&gt; lancedb.db.DBConnection:\n    \"\"\"Connect to dataset with LanceDB\n\n    Returns:\n        lancedb.db.DBConnection: Dataset LanceDB connection\n    \"\"\"\n\n    if isinstance(self.path, S3Path):\n        return lancedb.connect(self.path.as_uri())\n    return lancedb.connect(self.path)\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.create","title":"<code>create(path, info)</code>  <code>staticmethod</code>","text":"<p>Create dataset</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | S3Path</code> <p>Path to create dataset in</p> required <code>info</code> <code>DatasetInfo</code> <p>Dataset info</p> required <p>Returns:</p> Type Description <code>Dataset</code> <p>Created dataset</p> Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>@staticmethod\ndef create(path: Path | S3Path, info: DatasetInfo) -&gt; \"Dataset\":\n    \"\"\"Create dataset\n\n    Args:\n        path (Path | S3Path): Path to create dataset in\n        info (DatasetInfo): Dataset info\n\n    Returns:\n        Dataset: Created dataset\n    \"\"\"\n\n    # Create DatasetInfo file\n    path.mkdir(parents=True, exist_ok=True)\n    info.save(path)\n\n    # Load dataset\n    dataset = Dataset(path)\n\n    # Create dataset tables\n    for group_name, table_group in dataset.info.tables.items():\n        for table in table_group:\n            dataset.create_table(table, group_name, add_to_info=False)\n\n    return dataset\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.create_table","title":"<code>create_table(table, table_group, add_to_info=True)</code>","text":"<p>Create a new table in the dataset</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>DatasetTable</code> <p>Table to create</p> required <code>table_group</code> <code>str</code> <p>Table group</p> required <code>add_to_info</code> <code>bool</code> <p>Add table to DatasetInfo. Defaults to True.</p> <code>True</code> Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>def create_table(\n    self,\n    table: DatasetTable,\n    table_group: str,\n    add_to_info: bool = True,\n):\n    \"\"\"Create a new table in the dataset\n\n    Args:\n        table (DatasetTable): Table to create\n        table_group (str): Table group\n        add_to_info (bool, optional): Add table to DatasetInfo. Defaults to True.\n    \"\"\"\n\n    # Create Lance table\n    ds = self.connect()\n    # pylint: disable=unexpected-keyword-arg\n    ds.create_table(\n        table.name,\n        schema=Fields(table.fields).to_schema(),\n        mode=\"overwrite\",\n    )\n\n    # Save table to DatasetInfo\n    if add_to_info:\n        if table_group in self.info.tables:\n            self.info.tables[table_group].append(table)\n        else:\n            self.info.tables[table_group] = [table]\n        self.save_info()\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.find","title":"<code>find(dataset_id, directory)</code>  <code>staticmethod</code>","text":"<p>Find Dataset in directory</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Dataset ID</p> required <code>directory</code> <code>Path</code> <p>Directory to search in</p> required <p>Returns:</p> Type Description <code>Dataset</code> <p>Dataset</p> Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>@staticmethod\ndef find(\n    dataset_id: str,\n    directory: Path | S3Path,\n) -&gt; \"Dataset\":\n    \"\"\"Find Dataset in directory\n\n    Args:\n        dataset_id (str): Dataset ID\n        directory (Path): Directory to search in\n\n    Returns:\n        Dataset: Dataset\n    \"\"\"\n\n    # Browse directory\n    for json_fp in directory.glob(\"*/db.json\"):\n        info = DatasetInfo.from_json(json_fp)\n        if info.id == dataset_id:\n            # Return dataset\n            return Dataset(json_fp.parent)\n    return None\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.get_features_values","title":"<code>get_features_values(config_values)</code>","text":"<p>get config values    merge with distinct existing values for each scene and object string features, if not restricted</p> <p>Parameters:</p> Name Type Description Default <code>config_values</code> <code>FeaturesValues</code> <p>features values from db.json</p> required <p>Returns:     FeaturesValues: existing values for each scene and object string feature</p> Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>def get_features_values(self, config_values: FeaturesValues) -&gt; FeaturesValues:\n    \"\"\"get config values\n       merge with distinct existing values for each scene and object string features, if not restricted\n\n    Args:\n        config_values (FeaturesValues): features values from db.json\n    Returns:\n        FeaturesValues: existing values for each scene and object string feature\n    \"\"\"\n\n    # Load tables\n    ds_tables = self.open_tables()\n\n    def get_distinct_values(\n        table_name: str,\n        ignore_list: list[str],\n        config_vals: dict[str, FeatureValues],\n    ) -&gt; dict[str, FeatureValues]:\n        avail_values = defaultdict(FeatureValues)\n        for table in ds_tables[table_name].values():\n            table_arrow = table.to_arrow()\n            feats = [f for f in table_arrow.column_names if f not in ignore_list]\n            for feat in feats:\n                if feat not in avail_values:\n                    avail_values[feat] = FeatureValues(restricted=False, values=[])\n                if config_vals and feat in config_vals:\n                    avail_values[feat].restricted = config_vals[feat].restricted\n                    avail_values[feat].values.extend(config_vals[feat].values)\n                if not avail_values[feat].restricted:\n                    v = (\n                        duckdb.sql(f\"select DISTINCT {feat} from table_arrow\")\n                        .to_arrow_table()\n                        .to_pydict()\n                    )\n                    if v[feat] is not None and v[feat] != [None]:\n                        avail_values[feat].values.extend(\n                            [\n                                val\n                                for val in v[feat]\n                                if val is not None\n                                and isinstance(val, str)\n                                and val not in avail_values[feat].values\n                            ]\n                        )\n        return avail_values\n\n    return FeaturesValues(\n        main=get_distinct_values(\n            \"main\",\n            [\"id\", \"split\", \"views\", \"original_id\"],\n            config_values.main if config_values else None,\n        ),\n        objects=get_distinct_values(\n            \"objects\",\n            [\"id\", \"item_id\", \"view_id\", \"bbox\", \"mask\", \"review_state\"],\n            config_values.objects if config_values else None,\n        ),\n    )\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.get_item_uuid","title":"<code>get_item_uuid(original_id)</code>","text":"<p>Get id (uuid) from original data item id, if exist</p> <p>Parameters:</p> Name Type Description Default <code>original_id</code> <code>str</code> <p>original data item id</p> required <p>Returns:</p> Type Description <code>str</code> <p>unique item id, or original_id if not found</p> Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>def get_item_uuid(self, original_id: str) -&gt; str:\n    \"\"\"Get id (uuid) from original data item id, if exist\n\n    Args:\n        original_id (str): original data item id\n\n    Returns:\n        str: unique item id, or original_id if not found\n    \"\"\"\n    ds_tables = self.open_tables()\n    # pylint: disable=unused-variable\n    lance_table = ds_tables[\"main\"][\"db\"].to_lance()\n    result = (\n        duckdb.query(\n            f\"SELECT id FROM lance_table WHERE original_id = '{original_id}'\"\n        )\n        .to_arrow_table()\n        .to_pylist()\n    )\n    if result and len(result) == 1:\n        return result[0][\"id\"]\n    return original_id\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.get_object_uuid","title":"<code>get_object_uuid(original_id)</code>","text":"<p>Get id (uuid) from original data object id, if exist</p> <p>Parameters:</p> Name Type Description Default <code>original_id</code> <code>str</code> <p>original data object id</p> required <p>Returns:</p> Type Description <code>str</code> <p>unique item id, or original_id if not found</p> Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>def get_object_uuid(self, original_id: str) -&gt; str:\n    \"\"\"Get id (uuid) from original data object id, if exist\n\n    Args:\n        original_id (str): original data object id\n\n    Returns:\n        str: unique item id, or original_id if not found\n    \"\"\"\n    ds_tables = self.open_tables()\n    # pylint: disable=unused-variable\n    lance_table = ds_tables[\"objects\"][\"objects\"].to_lance()\n    result = (\n        duckdb.query(\n            f\"SELECT id FROM lance_table WHERE original_id = '{original_id}'\"\n        )\n        .to_arrow_table()\n        .to_pylist()\n    )\n    if result and len(result) == 1:\n        return result[0][\"id\"]\n    return original_id\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.load_info","title":"<code>load_info(load_stats=False, load_thumbnail=False, load_features_values=False)</code>","text":"<p>Return dataset info with thumbnail and stats inside</p> <p>Parameters:</p> Name Type Description Default <code>load_stats</code> <code>bool</code> <p>Load dataset stats. Defaults to False.</p> <code>False</code> <code>load_thumbnail</code> <code>bool</code> <p>Load dataset thumbnail. Defaults to False.</p> <code>False</code> <code>load_features_values</code> <code>bool</code> <p>Load available values. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>DatasetInfo</code> <p>Dataset info</p> Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>def load_info(\n    self,\n    load_stats: bool = False,\n    load_thumbnail: bool = False,\n    load_features_values: bool = False,\n) -&gt; DatasetInfo:\n    \"\"\"Return dataset info with thumbnail and stats inside\n\n    Args:\n        load_stats (bool, optional): Load dataset stats. Defaults to False.\n        load_thumbnail (bool, optional): Load dataset thumbnail. Defaults to False.\n        load_features_values (bool, optional): Load available values. Defaults to False.\n\n    Returns:\n        DatasetInfo: Dataset info\n    \"\"\"\n\n    info = DatasetInfo.from_json(\n        self.path / \"db.json\",\n        load_stats=load_stats,\n        load_thumbnail=load_thumbnail,\n    )\n    if load_features_values:\n        info.features_values = self.get_features_values(info.features_values)\n\n    return info\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.load_item","title":"<code>load_item(item_id, load_media=True, load_objects=False, load_active_learning=True, load_embeddings=False, model_id=None)</code>","text":"<p>Find dataset item in selected tables</p> <p>Parameters:</p> Name Type Description Default <code>item_id</code> <code>str</code> <p>Dataset item ID</p> required <code>load_media</code> <code>bool</code> <p>Load item media. Defaults to True.</p> <code>True</code> <code>load_objects</code> <code>bool</code> <p>Load item objects. Defaults to False.</p> <code>False</code> <code>load_active_learning</code> <code>bool</code> <p>Load item active learning info. Defaults to True.</p> <code>True</code> <code>load_embeddings</code> <code>bool</code> <p>Load item embeddings. Defaults to False.</p> <code>False</code> <code>model_id</code> <code>str</code> <p>Model ID (ONNX file path) of embeddings to load. Defaults to None.</p> <code>None</code> <p>Returns:     DatasetItem: Dataset item</p> Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>def load_item(\n    self,\n    item_id: str,\n    load_media: bool = True,\n    load_objects: bool = False,\n    load_active_learning: bool = True,\n    load_embeddings: bool = False,\n    model_id: str = None,\n) -&gt; DatasetItem:\n    \"\"\"Find dataset item in selected tables\n\n    Args:\n        item_id (str): Dataset item ID\n        load_media (bool, optional): Load item media. Defaults to True.\n        load_objects (bool, optional): Load item objects. Defaults to False.\n        load_active_learning (bool, optional): Load item active learning info. Defaults to True.\n        load_embeddings (bool, optional): Load item embeddings. Defaults to False.\n        model_id (str, optional): Model ID (ONNX file path) of embeddings to load. Defaults to None.\n    Returns:\n        DatasetItem: Dataset item\n    \"\"\"\n\n    # Update info in case of change\n    self.info = self.load_info()\n\n    # Load tables\n    ds_tables = self.open_tables()\n\n    # Load PyArrow item from tables\n    pyarrow_item: dict[str, dict[str, pa.Table]] = defaultdict(dict)\n\n    # Load PyArrow item from main table\n    lance_scanner = (\n        ds_tables[\"main\"][\"db\"].to_lance().scanner(filter=f\"id in ('{item_id}')\")\n    )\n    pyarrow_item[\"main\"][\"db\"] = lance_scanner.to_table()\n\n    # Load PyArrow item from media tables\n    if load_media:\n        for table_name, media_table in ds_tables[\"media\"].items():\n            lance_scanner = media_table.to_lance().scanner(\n                filter=f\"id in ('{item_id}')\"\n            )\n            pyarrow_item[\"media\"][table_name] = lance_scanner.to_table()\n\n    # Load PyArrow item from objects tables\n    if load_objects:\n        for table_name, obj_table in ds_tables[\"objects\"].items():\n            lance_scanner = obj_table.to_lance().scanner(\n                filter=f\"item_id in ('{item_id}')\"\n            )\n            pyarrow_item[\"objects\"][table_name] = lance_scanner.to_table()\n\n    # Load PyArrow item from active learning tables\n    if load_active_learning:\n        for table_name, al_table in ds_tables[\"active_learning\"].items():\n            lance_scanner = al_table.to_lance().scanner(\n                filter=f\"id in ('{item_id}')\"\n            )\n            pyarrow_item[\"active_learning\"][table_name] = lance_scanner.to_table()\n\n    # Load PyArrow item from segmentation embeddings tables\n    found_embeddings = not load_embeddings\n    if load_embeddings and \"embeddings\" in self.info.tables:\n        for table in self.info.tables[\"embeddings\"]:\n            if table.source.lower() in model_id.lower():\n                found_embeddings = True\n                emb_table = ds_tables[\"embeddings\"][table.name]\n                lance_scanner = emb_table.to_lance().scanner(\n                    filter=f\"id in ('{item_id}')\"\n                )\n                pyarrow_item[\"embeddings\"][table.name] = lance_scanner.to_table()\n\n    if pyarrow_item[\"main\"][\"db\"].num_rows &gt; 0 and found_embeddings:\n        return DatasetItem.from_pyarrow(\n            pyarrow_item,\n            self.info,\n            self.media_dir,\n            media_features=True,\n            model_id=model_id,\n        )\n    return None\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.load_items","title":"<code>load_items(limit, offset, load_active_learning=True)</code>","text":"<p>Load dataset items in selected tables</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int</code> <p>Items limit</p> required <code>offset</code> <code>int</code> <p>Items offset</p> required <code>load_active_learning</code> <code>bool</code> <p>Load items active learning info. Defaults to True.</p> <code>True</code> <p>Returns:     list[DatasetItem]: List of dataset items</p> Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>def load_items(\n    self,\n    limit: int,\n    offset: int,\n    load_active_learning: bool = True,\n) -&gt; list[DatasetItem]:\n    \"\"\"Load dataset items in selected tables\n\n    Args:\n        limit (int): Items limit\n        offset (int): Items offset\n        load_active_learning (bool, optional): Load items active learning info. Defaults to True.\n    Returns:\n        list[DatasetItem]: List of dataset items\n    \"\"\"\n\n    # Update info in case of change\n    self.info = self.load_info()\n\n    # Load tables\n    ds_tables = self.open_tables()\n\n    # Load PyArrow items from tables\n    pyarrow_items: dict[str, dict[str, pa.Table]] = defaultdict(dict)\n\n    # Load PyArrow items from main table\n    # pylint: disable=unused-variable\n    lance_table = ds_tables[\"main\"][\"db\"].to_lance()\n    id_field = \"original_id\" if \"original_id\" in lance_table.schema.names else \"id\"\n    pyarrow_items[\"main\"][\"db\"] = duckdb.query(\n        f\"SELECT * FROM lance_table ORDER BY len({id_field}), {id_field} LIMIT {limit} OFFSET {offset}\"\n    ).to_arrow_table()\n    id_list = tuple(pyarrow_items[\"main\"][\"db\"].to_pydict()[\"id\"])\n\n    # Media tables\n    for media_source, media_table in ds_tables[\"media\"].items():\n        lance_table = media_table.to_lance()\n        pyarrow_items[\"media\"][media_source] = duckdb.query(\n            f\"SELECT * FROM lance_table WHERE id IN {id_list}\"\n        ).to_arrow_table()\n\n    # Active Learning tables\n    if load_active_learning:\n        for al_source, al_table in ds_tables[\"active_learning\"].items():\n            lance_table = al_table.to_lance()\n            pyarrow_items[\"active_learning\"][al_source] = duckdb.query(\n                f\"SELECT * FROM lance_table  WHERE id IN {id_list}\"\n            ).to_arrow_table()\n\n    if pyarrow_items[\"main\"][\"db\"].num_rows &gt; 0:\n        # Split results\n        pyarrow_item_list = self._split_items(pyarrow_items, load_active_learning)\n\n        return [\n            DatasetItem.from_pyarrow(pyarrow_item, self.info, self.media_dir)\n            for pyarrow_item in pyarrow_item_list\n        ]\n    return None\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.open_tables","title":"<code>open_tables()</code>","text":"<p>Open dataset tables with LanceDB</p> <p>Returns:</p> Type Description <code>dict[str, dict[str, LanceTable]]</code> <p>Dataset tables</p> Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>def open_tables(self) -&gt; dict[str, dict[str, lancedb.db.LanceTable]]:\n    \"\"\"Open dataset tables with LanceDB\n\n    Returns:\n        dict[str, dict[str, lancedb.db.LanceTable]]: Dataset tables\n    \"\"\"\n\n    ds = self.connect()\n\n    ds_tables: dict[str, dict[str, lancedb.db.LanceTable]] = defaultdict(dict)\n\n    for group_name, table_group in self.info.tables.items():\n        for table in table_group:\n            try:\n                ds_tables[group_name][table.name] = ds.open_table(table.name)\n            except FileNotFoundError as e:\n                # If optional table, remove from DatasetInfo\n                if group_name in [\"objects\", \"embeddings\", \"active_learning\"]:\n                    self.info.tables[group_name].remove(table)\n                    self.save_info()\n                else:\n                    raise FileNotFoundError from e\n\n    return ds_tables\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.save_info","title":"<code>save_info()</code>","text":"<p>Save updated dataset info</p> Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>def save_info(self):\n    \"\"\"Save updated dataset info\"\"\"\n\n    self.info.save(self.path)\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.save_item","title":"<code>save_item(item)</code>","text":"<p>Save dataset item features and objects</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>DatasetItem</code> <p>Item to save</p> required Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>def save_item(self, item: DatasetItem):\n    \"\"\"Save dataset item features and objects\n\n    Args:\n        item (DatasetItem): Item to save\n    \"\"\"\n\n    # Local utility function to convert objects to pyarrow format\n    def convert_to_pyarrow(obj_table, objs):\n        # Convert objects to PyArrow\n        pyarrow_objs = [obj.to_pyarrow() for obj in objs]\n        return pa.Table.from_pylist(\n            pyarrow_objs,\n            schema=obj_table.schema,\n        )\n\n    # Update info in case of change\n    self.info = self.load_info()\n\n    # Load dataset tables\n    ds_tables = self.open_tables()\n    main_table = ds_tables[\"main\"][\"db\"]\n\n    # Add new item columns\n    self.update_table(item, main_table, \"main\", \"db\")\n\n    # Reload dataset tables\n    ds_tables = self.open_tables()\n    main_table = ds_tables[\"main\"][\"db\"]\n\n    # Update item\n    item.update(main_table)\n\n    # dispatch objects by table name\n    if \"objects\" in self.info.tables:\n        table_source_name_map = {\n            table.source: table.name for table in self.info.tables[\"objects\"]\n        }\n    else:\n        table_source_name_map = {}\n    objects_by_table = defaultdict(list)\n    non_existing_table_objects = []\n    for obj in item.objects.values():\n        if obj.source_id in table_source_name_map:\n            objects_by_table[table_source_name_map[obj.source_id]].append(obj)\n        else:\n            non_existing_table_objects.append(obj)\n\n    for table_name, objs in objects_by_table.items():\n        obj_table = ds_tables[\"objects\"][table_name]\n        str_obj_ids = [f\"'{obj.id}'\" for obj in objs]\n        str_obj_ids = \"(\" + \", \".join(str_obj_ids) + \")\"\n        scanner = obj_table.to_lance().scanner(filter=f\"id in {str_obj_ids}\")\n        existing_objs = scanner.to_table()\n        update_ids = existing_objs.to_pydict()[\"id\"]\n        new_objs_ids = [obj.id for obj in objs if obj.id not in update_ids]\n\n        # ADD\n        if new_objs_ids:\n            new_objs = [obj for obj in objs if obj.id in new_objs_ids]\n            obj_table.add(convert_to_pyarrow(obj_table, new_objs))\n\n        # UPDATE\n        if update_ids:\n            upd_objs = [obj for obj in objs if obj.id in update_ids]\n            str_obj_ids = [f\"'{id}'\" for id in update_ids]\n            str_obj_ids = \"(\" + \", \".join(str_obj_ids) + \")\"\n            obj_table.delete(f\"id in {str_obj_ids}\")\n            obj_table.add(convert_to_pyarrow(obj_table, upd_objs))\n\n        # Clear change history to prevent dataset from becoming too large\n        obj_table.to_lance().cleanup_old_versions()\n\n    if non_existing_table_objects:\n        # Create table\n        new_table = DatasetTable(\n            name=\"objects\",\n            source=\"Ground Truth\",\n            fields={\n                \"id\": \"str\",\n                \"item_id\": \"str\",\n                \"view_id\": \"str\",\n                \"bbox\": \"bbox\",\n                \"mask\": \"compressedrle\",\n            },\n        )\n        for obj in non_existing_table_objects:\n            for feat in obj.features.values():\n                new_table.fields[feat.name] = feat.dtype\n\n        self.create_table(new_table, \"objects\")\n\n        # Reload dataset tables\n        ds_tables = self.open_tables()\n        new_obj_table = ds_tables[\"objects\"][new_table.name]\n\n        new_obj_table.add(\n            convert_to_pyarrow(new_obj_table, non_existing_table_objects)\n        )\n\n    # Objects to delete\n    item.delete_objects(ds_tables)\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.search_items","title":"<code>search_items(limit, offset, query, load_active_learning=True)</code>","text":"<p>Search for dataset items in selected tables</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int</code> <p>Items limit</p> required <code>offset</code> <code>int</code> <p>Items offset</p> required <code>query</code> <code>dict[str, str]</code> <p>Search query</p> required <code>load_active_learning</code> <code>bool</code> <p>Load items active learning info. Defaults to True.</p> <code>True</code> <p>Returns:     list[DatasetItem]: List of dataset items</p> Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>def search_items(\n    self,\n    limit: int,\n    offset: int,\n    query: dict[str, str],\n    load_active_learning: bool = True,\n):\n    \"\"\"Search for dataset items in selected tables\n\n    Args:\n        limit (int): Items limit\n        offset (int): Items offset\n        query (dict[str, str]): Search query\n        load_active_learning (bool, optional): Load items active learning info. Defaults to True.\n    Returns:\n        list[DatasetItem]: List of dataset items\n    \"\"\"\n\n    # Update info in case of change\n    self.info = self.load_info()\n\n    # Load PyArrow items from tables\n    pyarrow_items: dict[str, dict[str, pa.Table]] = defaultdict(dict)\n\n    # Search items with selected method\n    if query[\"model\"] in [\"CLIP\"]:\n        pyarrow_items = self._embeddings_search(limit, offset, query)\n    # NOTE: metadata search could go here\n\n    if pyarrow_items is not None and pyarrow_items[\"main\"][\"db\"].num_rows &gt; 0:\n        # Split results\n        pyarrow_item_list = self._split_items(pyarrow_items, load_active_learning)\n\n        return [\n            DatasetItem.from_pyarrow(pyarrow_item, self.info, self.media_dir)\n            for pyarrow_item in pyarrow_item_list\n        ]\n    return None\n</code></pre>"},{"location":"api_reference/data/dataset/dataset/#pixano.data.dataset.dataset.Dataset.update_table","title":"<code>update_table(element, table, table_group, table_name)</code>","text":"<p>Update a table with new features or base fields</p> <p>Parameters:</p> Name Type Description Default <code>element</code> <code>DatasetItem | ItemObject</code> <p>Table element (item or object)</p> required <code>table</code> <code>LanceTable</code> <p>Table to update</p> required <code>table_group</code> <code>str</code> <p>Table group</p> required <code>table_name</code> <code>str</code> <p>Table name</p> required Source code in <code>pixano/data/dataset/dataset.py</code> <pre><code>def update_table(\n    self,\n    element: DatasetItem | ItemObject,\n    table: lancedb.db.LanceTable,\n    table_group: str,\n    table_name: str,\n):\n    \"\"\"Update a table with new features or base fields\n\n    Args:\n        element (DatasetItem | ItemObject): Table element (item or object)\n        table (lancedb.db.LanceTable): Table to update\n        table_group (str): Table group\n        table_name (str): Table name\n    \"\"\"\n\n    new_columns: list[ItemFeature] = []\n\n    # Check for new base fields\n    base_fields = {\"review_state\": \"str\", \"bbox\": \"bbox\", \"mask\": \"compressedrle\"}\n    new_columns.extend(\n        [\n            ItemFeature(name=field_name, dtype=field_type, value=None)\n            for field_name, field_type in base_fields.items()\n            if hasattr(element, field_name) and field_name not in table.schema.names\n        ]\n    )\n    # Check for new features\n    if element.features is not None:\n        new_columns.extend(\n            [\n                feat\n                for feat in element.features.values()\n                if feat.name not in table.schema.names\n            ]\n        )\n    # Add new columns\n    if len(new_columns) &gt; 0:\n        new_columns_table = table.to_lance().to_table(columns=[\"id\"])\n        for col in new_columns:\n            # None should be suported for booleans with pylance 0.9.1\n            # None is not supported for integers and floats yet\n            none_value = (\n                False\n                if col.dtype == \"bool\"\n                else 0 if col.dtype in (\"int\", \"float\") else None\n            )\n            col_array = pa.array(\n                [none_value] * len(table),\n                type=field_to_pyarrow(col.dtype),\n            )\n            new_columns_table = new_columns_table.append_column(\n                pa.field(col.name, field_to_pyarrow(col.dtype)), col_array\n            )\n            # Update DatasetInfo\n            for info_table in self.info.tables[table_group]:\n                if info_table.name == table_name:\n                    info_table.fields[col.name] = col.dtype\n\n        # Merge with main table\n        if len(new_columns_table) &gt; 0:\n            table.to_lance().merge(new_columns_table, \"id\")\n        self.save_info()\n</code></pre>"},{"location":"api_reference/data/dataset/dataset_info/","title":"dataset_info","text":""},{"location":"api_reference/data/dataset/dataset_info/#pixano.data.dataset.dataset_info","title":"<code>pixano.data.dataset.dataset_info</code>","text":""},{"location":"api_reference/data/dataset/dataset_info/#pixano.data.dataset.dataset_info.DatasetInfo","title":"<code>DatasetInfo(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>DatasetInfo</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Dataset ID</p> <code>name</code> <code>str</code> <p>Dataset name</p> <code>description</code> <code>str</code> <p>Dataset description</p> <code>estimated_size</code> <code>str</code> <p>Dataset estimated size</p> <code>num_elements</code> <code>int</code> <p>Number of elements in dataset</p> <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> <code>tables</code> <code>dict[str, list[DatasetTable]]</code> <p>Dataset tables</p> <code>features_values</code> <code>Optional[FeaturesValues]</code> <p>(FeaturesValues, optional): existing values for each custom feature</p> <code>preview</code> <code>str</code> <p>Dataset preview</p> <code>stats</code> <code>list[DatasetStat]</code> <p>Dataset stats</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            category=None,\n        )\n</code></pre>"},{"location":"api_reference/data/dataset/dataset_info/#pixano.data.dataset.dataset_info.DatasetInfo.from_json","title":"<code>from_json(json_fp, load_stats=False, load_thumbnail=False)</code>  <code>staticmethod</code>","text":"<p>Read DatasetInfo from JSON file</p> <p>Parameters:</p> Name Type Description Default <code>json_fp</code> <code>Path | S3Path</code> <p>JSON file path</p> required <code>load_stats</code> <code>bool</code> <p>Load dataset stats. Defaults to False.</p> <code>False</code> <code>load_thumbnail</code> <code>bool</code> <p>Load dataset thumbnail. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>DatasetInfo</code> <p>DatasetInfo</p> Source code in <code>pixano/data/dataset/dataset_info.py</code> <pre><code>@staticmethod\ndef from_json(\n    json_fp: Path | S3Path,\n    load_stats: bool = False,\n    load_thumbnail: bool = False,\n) -&gt; \"DatasetInfo\":\n    \"\"\"Read DatasetInfo from JSON file\n\n    Args:\n        json_fp (Path | S3Path): JSON file path\n        load_stats (bool, optional): Load dataset stats. Defaults to False.\n        load_thumbnail (bool, optional): Load dataset thumbnail. Defaults to False.\n\n    Returns:\n        DatasetInfo: DatasetInfo\n    \"\"\"\n\n    if isinstance(json_fp, S3Path):\n        with json_fp.open(encoding=\"utf-8\") as json_file:\n            info_json = json.load(json_file)\n    else:\n        with open(json_fp, encoding=\"utf-8\") as json_file:\n            info_json = json.load(json_file)\n\n    info = DatasetInfo.model_validate(info_json)\n\n    # Load dataset stats file\n    if load_stats:\n        stats_fp = json_fp.parent / \"stats.json\"\n        if stats_fp.is_file():\n            info.stats = DatasetStat.from_json(stats_fp)\n\n    # Load thumbnail\n    if load_thumbnail:\n        thumb_fp = json_fp.parent / \"preview.png\"\n        if thumb_fp.is_file():\n            if isinstance(json_fp, S3Path):\n                info.preview = thumb_fp.get_presigned_url()\n            else:\n                im = Image(uri=thumb_fp.absolute().as_uri())\n                info.preview = im.url\n\n    return info\n</code></pre>"},{"location":"api_reference/data/dataset/dataset_info/#pixano.data.dataset.dataset_info.DatasetInfo.load_directory","title":"<code>load_directory(directory, load_thumbnail=False, load_stats=False)</code>  <code>staticmethod</code>","text":"<p>Load list of DatasetInfo from directory</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>Path | S3Path</code> <p>Directory to load</p> required <code>load_thumbnail</code> <code>bool</code> <p>Load dataset thumbnail. Defaults to False.</p> <code>False</code> <code>load_stats</code> <code>bool</code> <p>Load dataset stats. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[DatasetInfo]</code> <p>List of DatasetInfo</p> Source code in <code>pixano/data/dataset/dataset_info.py</code> <pre><code>@staticmethod\ndef load_directory(\n    directory: Path | S3Path,\n    load_thumbnail: bool = False,\n    load_stats: bool = False,\n) -&gt; list[\"DatasetInfo\"]:\n    \"\"\"Load list of DatasetInfo from directory\n\n    Args:\n        directory (Path | S3Path): Directory to load\n        load_thumbnail (bool, optional): Load dataset thumbnail. Defaults to False.\n        load_stats (bool, optional): Load dataset stats. Defaults to False.\n\n    Returns:\n        list[DatasetInfo]: List of DatasetInfo\n    \"\"\"\n\n    infos = []\n\n    # Browse directory\n    for json_fp in sorted(directory.glob(\"*/db.json\")):\n        # Add dataset info to list\n        infos.append(\n            DatasetInfo.from_json(\n                json_fp,\n                load_thumbnail=load_thumbnail,\n                load_stats=load_stats,\n            )\n        )\n\n    return infos\n</code></pre>"},{"location":"api_reference/data/dataset/dataset_info/#pixano.data.dataset.dataset_info.DatasetInfo.save","title":"<code>save(save_dir)</code>","text":"<p>Save DatasetInfo to json file</p> <p>Parameters:</p> Name Type Description Default <code>save_dir</code> <code>Path | S3Path</code> <p>Save directory</p> required Source code in <code>pixano/data/dataset/dataset_info.py</code> <pre><code>def save(self, save_dir: Path | S3Path):\n    \"\"\"Save DatasetInfo to json file\n\n    Args:\n        save_dir (Path | S3Path): Save directory\n    \"\"\"\n    if isinstance(save_dir, S3Path):\n        with (save_dir / \"db.json\").open(encoding=\"utf-8\") as f:\n            json.dump(self.model_dump(), f)\n    else:\n        with open(save_dir / \"db.json\", \"w\", encoding=\"utf-8\") as f:\n            json.dump(self.model_dump(), f)\n</code></pre>"},{"location":"api_reference/data/dataset/dataset_item/","title":"dataset_item","text":""},{"location":"api_reference/data/dataset/dataset_item/#pixano.data.dataset.dataset_item","title":"<code>pixano.data.dataset.dataset_item</code>","text":""},{"location":"api_reference/data/dataset/dataset_item/#pixano.data.dataset.dataset_item.DatasetItem","title":"<code>DatasetItem(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>DatasetItem</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Item ID</p> <code>original_id</code> <code>str</code> <p>Item original ID</p> <code>split</code> <code>str</code> <p>Item split</p> <code>features</code> <code>dict[str, ItemFeature]</code> <p>Item features</p> <code>views</code> <code>dict[str, ItemView]</code> <p>Item views</p> <code>objects</code> <code>dict[str, ItemObject]</code> <p>Item objects</p> <code>embeddings</code> <code>dict[str, ItemEmbedding]</code> <p>Item embeddings</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            category=None,\n        )\n</code></pre>"},{"location":"api_reference/data/dataset/dataset_item/#pixano.data.dataset.dataset_item.DatasetItem.delete_objects","title":"<code>delete_objects(ds_tables)</code>","text":"<p>Delete remove objects from dataset item</p> <p>Parameters:</p> Name Type Description Default <code>ds_tables</code> <code>dict[str, dict[str, LanceTable]]</code> <p>Dataset tables</p> required Source code in <code>pixano/data/dataset/dataset_item.py</code> <pre><code>def delete_objects(\n    self,\n    ds_tables: dict[str, dict[str, lancedb.db.LanceTable]],\n):\n    \"\"\"Delete remove objects from dataset item\n\n    Args:\n        ds_tables (dict[str, dict[str, lancedb.db.LanceTable]]): Dataset tables\n    \"\"\"\n\n    # Get current item objects\n    current_obj_tables = {}\n    for table_name, table in ds_tables[\"objects\"].items():\n        media_scanner = table.to_lance().scanner(filter=f\"item_id in ('{self.id}')\")\n        current_obj_tables[table_name] = media_scanner.to_table().to_pylist()\n\n    # Check if objects have been deleted\n    for table_name, current_obj_table in current_obj_tables.items():\n        for current_obj in current_obj_table:\n            # If object has been deleted\n            if not any(\n                obj_id == current_obj[\"id\"] for obj_id in self.objects.keys()\n            ):\n                # Remove object from table\n                ds_tables[\"objects\"][table_name].delete(\n                    f\"id in ('{current_obj['id']}')\"\n                )\n\n                # Clear change history to prevent dataset from becoming too large\n                ds_tables[\"objects\"][table_name].to_lance().cleanup_old_versions()\n</code></pre>"},{"location":"api_reference/data/dataset/dataset_item/#pixano.data.dataset.dataset_item.DatasetItem.from_pyarrow","title":"<code>from_pyarrow(pyarrow_item, info, media_dir, media_features=False, model_id=None)</code>  <code>staticmethod</code>","text":"<p>Format PyArrow item</p> <p>Parameters:</p> Name Type Description Default <code>pyarrow_item</code> <code>dict[str, dict[str, Table]]</code> <p>PyArrow item</p> required <code>info</code> <code>DatasetInfo</code> <p>Dataset info</p> required <code>media_dir</code> <code>Path</code> <p>Dataset media directory</p> required <code>media_features</code> <code>bool</code> <p>Load media features like image width and height (slow for large item batches)</p> <code>False</code> <code>model_id</code> <code>str</code> <p>Model ID (ONNX file path) of embeddings to load. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DatasetItem</code> <p>Formatted item</p> Source code in <code>pixano/data/dataset/dataset_item.py</code> <pre><code>@staticmethod\ndef from_pyarrow(\n    pyarrow_item: dict[str, dict[str, pa.Table]],\n    info: DatasetInfo,\n    media_dir: Path,\n    media_features: bool = False,\n    model_id: str = None,\n) -&gt; \"DatasetItem\":\n    \"\"\"Format PyArrow item\n\n    Args:\n        pyarrow_item (dict[str, dict[str, pa.Table]]): PyArrow item\n        info (DatasetInfo): Dataset info\n        media_dir (Path): Dataset media directory\n        media_features (bool, optional): Load media features like image width and height (slow for large item batches)\n        model_id (str, optional): Model ID (ONNX file path) of embeddings to load. Defaults to None.\n\n    Returns:\n        DatasetItem: Formatted item\n    \"\"\"\n\n    item_info = pyarrow_item[\"main\"][\"db\"].to_pylist()[0]\n\n    # Create item\n    item = DatasetItem(\n        id=item_info[\"id\"],\n        split=item_info[\"split\"],\n    )\n\n    for group_name, table_group in info.tables.items():\n        # Main table\n        if group_name == \"main\":\n            # Item features\n            item.features = ItemFeature.from_pyarrow(\n                pyarrow_item[\"main\"][\"db\"],\n                Fields(table_group[0].fields).to_schema(),\n            )\n\n        # Media tables\n        if group_name == \"media\" and \"media\" in pyarrow_item:\n            item.views = {}\n            for table in table_group:\n                item.views = item.views | ItemView.from_pyarrow(\n                    pyarrow_item[\"media\"][table.name],\n                    Fields(table.fields).to_schema(),\n                    media_dir,\n                    media_features,\n                )\n\n        # Objects\n        if group_name == \"objects\" and \"objects\" in pyarrow_item:\n            item.objects = {}\n            for table in table_group:\n                item.objects = item.objects | ItemObject.from_pyarrow(\n                    pyarrow_item[\"objects\"][table.name],\n                    Fields(table.fields).to_schema(),\n                    table.source,\n                )\n\n        # Active Learning\n        if group_name == \"active_learning\" and \"active_learning\" in pyarrow_item:\n            for table in table_group:\n                al_features = ItemFeature.from_pyarrow(\n                    pyarrow_item[\"active_learning\"][table.name],\n                    Fields(table.fields).to_schema(),\n                )\n                item.features = item.features | al_features\n\n        # Segmentation embeddings\n        if group_name == \"embeddings\" and \"embeddings\" in pyarrow_item:\n            item.embeddings = {}\n            for table in table_group:\n                if table.source.lower() in model_id.lower():\n                    item.embeddings = item.embeddings | ItemEmbedding.from_pyarrow(\n                        pyarrow_item[\"embeddings\"][table.name],\n                        Fields(table.fields).to_schema(),\n                    )\n\n    return item\n</code></pre>"},{"location":"api_reference/data/dataset/dataset_item/#pixano.data.dataset.dataset_item.DatasetItem.to_pyarrow","title":"<code>to_pyarrow()</code>","text":"<p>Return DatasetItem in PyArrow format</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Item in PyArrow format</p> Source code in <code>pixano/data/dataset/dataset_item.py</code> <pre><code>def to_pyarrow(self) -&gt; dict[str, Any]:\n    \"\"\"Return DatasetItem in PyArrow format\n\n    Returns:\n        dict[str, Any]: Item in PyArrow format\n    \"\"\"\n\n    pyarrow_item = {}\n\n    # ID\n    pyarrow_item[\"id\"] = self.id\n    pyarrow_item[\"split\"] = self.split\n\n    # Features\n    if self.features is not None:\n        # Add features\n        for feat in self.features.values():\n            pyarrow_item[feat.name] = (\n                field_to_python(feat.dtype)(feat.value)\n                if feat.value is not None\n                else None\n            )\n\n        # Check feature types\n        for feat in self.features.values():\n            if pyarrow_item[feat.name] is not None and not isinstance(\n                pyarrow_item[feat.name], field_to_python(feat.dtype)\n            ):\n                raise ValueError(\n                    f\"Feature {feat.name} of object {self.id} is of type {type(self.features[feat.name].value)} instead of type {field_to_python(feat.dtype)}\"\n                )\n\n    return pyarrow_item\n</code></pre>"},{"location":"api_reference/data/dataset/dataset_item/#pixano.data.dataset.dataset_item.DatasetItem.update","title":"<code>update(ds_table)</code>","text":"<p>Update dataset item</p> <p>Parameters:</p> Name Type Description Default <code>ds_table</code> <code>LanceTable</code> <p>Item table</p> required Source code in <code>pixano/data/dataset/dataset_item.py</code> <pre><code>def update(\n    self,\n    ds_table: lancedb.db.LanceTable,\n):\n    \"\"\"Update dataset item\n\n    Args:\n        ds_table (lancedb.db.LanceTable): Item table\n    \"\"\"\n\n    # Convert item to PyArrow\n    pyarrow_item = self.to_pyarrow()\n    table_item = pa.Table.from_pylist(\n        [pyarrow_item],\n        schema=ds_table.schema,\n    )\n\n    # Update item\n    ds_table.delete(f\"id in ('{self.id}')\")\n    ds_table.add(table_item, mode=\"append\")\n\n    # Clear change history to prevent dataset from becoming too large\n    ds_table.to_lance().cleanup_old_versions()\n</code></pre>"},{"location":"api_reference/data/dataset/dataset_stat/","title":"dataset_stat","text":""},{"location":"api_reference/data/dataset/dataset_stat/#pixano.data.dataset.dataset_stat","title":"<code>pixano.data.dataset.dataset_stat</code>","text":""},{"location":"api_reference/data/dataset/dataset_stat/#pixano.data.dataset.dataset_stat.DatasetStat","title":"<code>DatasetStat(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>DatasetStat</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Stats name</p> <code>type</code> <code>str</code> <p>Stats type ('numerical' or 'categorical')</p> <code>histogram</code> <code>str</code> <p>Stats histogram data</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            category=None,\n        )\n</code></pre>"},{"location":"api_reference/data/dataset/dataset_stat/#pixano.data.dataset.dataset_stat.DatasetStat.from_json","title":"<code>from_json(json_fp)</code>  <code>staticmethod</code>","text":"<p>Read list of DatasetStats from JSON file</p> <p>Parameters:</p> Name Type Description Default <code>json_fp</code> <code>Path | S3Path</code> <p>JSON file path</p> required <p>Returns:</p> Type Description <code>list[DatasetStats]</code> <p>List of DatasetStat</p> Source code in <code>pixano/data/dataset/dataset_stat.py</code> <pre><code>@staticmethod\ndef from_json(json_fp: Path | S3Path) -&gt; list[\"DatasetStat\"]:\n    \"\"\"Read list of DatasetStats from JSON file\n\n    Args:\n        json_fp (Path | S3Path): JSON file path\n\n    Returns:\n        list[DatasetStats]: List of DatasetStat\n    \"\"\"\n\n    if isinstance(json_fp, S3Path):\n        with json_fp.open(encoding=\"utf-8\") as json_file:\n            stats_json = json.load(json_file)\n    else:\n        with open(json_fp, encoding=\"utf-8\") as json_file:\n            stats_json = json.load(json_file)\n\n    return [DatasetStat.model_validate(stat) for stat in stats_json]\n</code></pre>"},{"location":"api_reference/data/dataset/dataset_stat/#pixano.data.dataset.dataset_stat.DatasetStat.save","title":"<code>save(save_dir)</code>","text":"<p>Save DatasetInfo to json file    replace existing histogram with same name in json_fp</p> <p>Parameters:</p> Name Type Description Default <code>save_dir</code> <code>Path | S3Path</code> <p>Save directory</p> required Source code in <code>pixano/data/dataset/dataset_stat.py</code> <pre><code>def save(self, save_dir: Path | S3Path):\n    \"\"\"Save DatasetInfo to json file\n       replace existing histogram with same name in json_fp\n\n    Args:\n        save_dir (Path | S3Path): Save directory\n    \"\"\"\n\n    try:\n        if isinstance(save_dir, S3Path):\n            with (save_dir / \"stats.json\").open(encoding=\"utf-8\") as json_file:\n                json_stats = json.load(json_file)\n        else:\n            with open(save_dir / \"stats.json\", \"r\", encoding=\"utf-8\") as json_file:\n                json_stats = json.load(json_file)\n    except FileNotFoundError:\n        json_stats = []\n    # keep all stats except the one with same name, we replace it if exist\n    json_stats = [stat for stat in json_stats if stat[\"name\"] != self.name]\n    json_stats.append(\n        {\"name\": self.name, \"type\": self.type, \"histogram\": self.histogram}\n    )\n\n    if isinstance(save_dir, S3Path):\n        with (save_dir / \"stats.json\").open(\"w\", encoding=\"utf-8\") as f:\n            json.dump(json_stats, f, indent=\"\\t\")\n    else:\n        with open(save_dir / \"stats.json\", \"w\", encoding=\"utf-8\") as f:\n            json.dump(json_stats, f, indent=\"\\t\")\n</code></pre>"},{"location":"api_reference/data/dataset/dataset_table/","title":"dataset_table","text":""},{"location":"api_reference/data/dataset/dataset_table/#pixano.data.dataset.dataset_table","title":"<code>pixano.data.dataset.dataset_table</code>","text":""},{"location":"api_reference/data/dataset/dataset_table/#pixano.data.dataset.dataset_table.DatasetTable","title":"<code>DatasetTable(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>DatasetTable</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Table name</p> <code>fields</code> <code>dict[str, str]</code> <p>Table fields</p> <code>source</code> <code>str</code> <p>Table source</p> <code>type</code> <code>str</code> <p>Table type</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            category=None,\n        )\n</code></pre>"},{"location":"api_reference/data/exporters/coco_exporter/","title":"coco_exporter","text":""},{"location":"api_reference/data/exporters/coco_exporter/#pixano.data.exporters.coco_exporter","title":"<code>pixano.data.exporters.coco_exporter</code>","text":""},{"location":"api_reference/data/exporters/coco_exporter/#pixano.data.exporters.coco_exporter.COCOExporter","title":"<code>COCOExporter(input_dir)</code>","text":"<p>               Bases: <code>Exporter</code></p> <p>Exporter class for COCO instances dataset</p> <p>Attributes:</p> Name Type Description <code>dataset</code> <code>Dataset</code> <p>Dataset to export</p> <code>coco_json</code> <code>dict[str, Any]</code> <p>Dataset split in COCO format</p> <p>Parameters:</p> Name Type Description Default <code>input_dir</code> <code>Path</code> <p>Input dataset directory</p> required Source code in <code>pixano/data/exporters/exporter.py</code> <pre><code>def __init__(\n    self,\n    input_dir: Path,\n):\n    \"\"\"Initialize Exporter\n\n    Args:\n        input_dir (Path): Input dataset directory\n    \"\"\"\n\n    # Dataset to export\n    self.dataset = Dataset(input_dir)\n</code></pre>"},{"location":"api_reference/data/exporters/coco_exporter/#pixano.data.exporters.coco_exporter.COCOExporter.export_dataset","title":"<code>export_dataset(export_dir, splits=None, objects_sources=None, copy=True)</code>","text":"<p>Export dataset back to original format</p> <p>Parameters:</p> Name Type Description Default <code>export_dir</code> <code>Path</code> <p>Export directory</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits to export, all if None. Defaults to None.</p> <code>None</code> <code>objects_sources</code> <code>list[str]</code> <p>Objects sources to export, all if None. Defaults to None.</p> <code>None</code> <code>copy</code> <code>bool</code> <p>True to copy files to export directory. Defaults to True.</p> <code>True</code> Source code in <code>pixano/data/exporters/coco_exporter.py</code> <pre><code>def export_dataset(\n    self,\n    export_dir: Path,\n    splits: list[str] = None,\n    objects_sources: list[str] = None,\n    copy: bool = True,\n):\n    \"\"\"Export dataset back to original format\n\n    Args:\n        export_dir (Path): Export directory\n        splits (list[str], optional): Dataset splits to export, all if None. Defaults to None.\n        objects_sources (list[str], optional): Objects sources to export, all if None. Defaults to None.\n        copy (bool, optional): True to copy files to export directory. Defaults to True.\n    \"\"\"\n\n    # If no splits provided, select all splits\n    if splits is None:\n        splits = self.dataset.info.splits\n        # If no splits, there is nothing to export\n        if not splits:\n            raise ValueError(\"Dataset has no splits to export.\")\n\n    # If no object sources provided, select all object tables\n    if objects_sources is None:\n        objects_sources = list(\n            table.source for table in self.dataset.info.tables[\"objects\"]\n        )\n        # If no object tables, there is nothing to export\n        if not objects_sources:\n            raise ValueError(\"Dataset has no objects tables to export.\")\n\n    # Create export directory\n    ann_dir = export_dir / f\"annotations [{', '.join(objects_sources)}]\"\n    ann_dir.mkdir(parents=True, exist_ok=True)\n\n    self._category_id_count = 0  # used if no category_id in dataset (TODO: get from prebuilt coco id/name mapping)\n\n    # Iterate on splits\n    with tqdm(desc=\"Processing dataset\", total=self.dataset.num_rows) as progress:\n        for split in splits:\n            # build categories field from features_values\n            if (\n                self.dataset.info.features_values\n                and self.dataset.info.features_values.objects\n                and \"category\" in self.dataset.info.features_values.objects\n            ):\n                if \"category_id\" in self.dataset.info.features_values.objects:\n                    categories = [\n                        {\"id\": id, \"name\": name, \"supercategory\": \"\"}\n                        for id, name in zip(\n                            self.dataset.info.features_values.objects[\n                                \"category_id\"\n                            ].values,\n                            self.dataset.info.features_values.objects[\n                                \"category\"\n                            ].values,\n                        )\n                    ]\n                else:\n                    for i, val in enumerate(\n                        self.dataset.info.features_values.objects[\"category\"].values\n                    ):\n                        categories.append({\"id\": i, \"name\": val})\n\n            else:\n                categories = []\n\n            # Create COCO json\n            self.coco_json = {\n                \"info\": {\n                    \"description\": self.dataset.info.name,\n                    \"url\": \"N/A\",\n                    \"version\": f\"v{datetime.datetime.now().strftime('%y%m%d.%H%M%S')}\",\n                    \"year\": datetime.date.today().year,\n                    \"contributor\": \"Exported from Pixano\",\n                    \"date_created\": datetime.date.today().isoformat(),\n                },\n                \"licences\": [\n                    {\n                        \"url\": \"N/A\",\n                        \"id\": 1,\n                        \"name\": \"Unknown\",\n                    },\n                ],\n                \"images\": [],\n                \"annotations\": [],\n                \"categories\": categories,\n            }\n\n            batch_size = 1024\n\n            for batch_index in range(ceil(self.dataset.num_rows / batch_size)):\n                # Load items\n                items = self.dataset.load_items(\n                    limit=min(\n                        self.dataset.num_rows,\n                        (batch_index + 1) * batch_size,\n                    ),\n                    offset=batch_index * batch_size,\n                )\n\n                # Iterate on items\n                for item in items:\n                    # Filter on split\n                    if item.split == split:\n                        # Export item\n                        self._export_item(item, objects_sources)\n                        # Update progress bar\n                        progress.update(1)\n\n            # Save COCO format .json file\n            with open(\n                ann_dir / f\"instances_{split}.json\", \"w\", encoding=\"utf-8\"\n            ) as f:\n                json.dump(self.coco_json, f)\n\n    # Copy media directory\n    if copy:\n        if (\n            self.dataset.media_dir.exists()\n            and self.dataset.media_dir != export_dir / \"media\"\n        ):\n            shutil.copytree(\n                self.dataset.media_dir, export_dir / \"media\", dirs_exist_ok=True\n            )\n</code></pre>"},{"location":"api_reference/data/exporters/exporter/","title":"exporter","text":""},{"location":"api_reference/data/exporters/exporter/#pixano.data.exporters.exporter","title":"<code>pixano.data.exporters.exporter</code>","text":""},{"location":"api_reference/data/exporters/exporter/#pixano.data.exporters.exporter.Exporter","title":"<code>Exporter(input_dir)</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract Data Exporter class</p> <p>Attributes:</p> Name Type Description <code>dataset</code> <code>Dataset</code> <p>Dataset to export</p> <p>Parameters:</p> Name Type Description Default <code>input_dir</code> <code>Path</code> <p>Input dataset directory</p> required Source code in <code>pixano/data/exporters/exporter.py</code> <pre><code>def __init__(\n    self,\n    input_dir: Path,\n):\n    \"\"\"Initialize Exporter\n\n    Args:\n        input_dir (Path): Input dataset directory\n    \"\"\"\n\n    # Dataset to export\n    self.dataset = Dataset(input_dir)\n</code></pre>"},{"location":"api_reference/data/exporters/exporter/#pixano.data.exporters.exporter.Exporter.export_dataset","title":"<code>export_dataset(export_dir)</code>  <code>abstractmethod</code>","text":"<p>Export dataset back to original format</p> <p>Parameters:</p> Name Type Description Default <code>export_dir</code> <code>Path</code> <p>Export directory</p> required Source code in <code>pixano/data/exporters/exporter.py</code> <pre><code>@abstractmethod\ndef export_dataset(self, export_dir: Path):\n    \"\"\"Export dataset back to original format\n\n    Args:\n        export_dir (Path): Export directory\n    \"\"\"\n</code></pre>"},{"location":"api_reference/data/importers/coco_importer/","title":"coco_importer","text":""},{"location":"api_reference/data/importers/coco_importer/#pixano.data.importers.coco_importer","title":"<code>pixano.data.importers.coco_importer</code>","text":""},{"location":"api_reference/data/importers/coco_importer/#pixano.data.importers.coco_importer.COCOImporter","title":"<code>COCOImporter(name, description, input_dirs, splits, media_fields=None)</code>","text":"<p>               Bases: <code>Importer</code></p> <p>Importer class for COCO instances format datasets</p> <p>Attributes:</p> Name Type Description <code>info</code> <code>DatasetInfo</code> <p>Dataset information</p> <code>input_dirs</code> <code>dict[str, Path]</code> <p>Dataset input directories</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>input_dirs</code> <code>dict[str, Path]</code> <p>Dataset input directories</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> required <code>media_fields</code> <code>dict[str, str]</code> <p>Dataset media fields, with field names as keys and field types as values. Default to None.</p> <code>None</code> Source code in <code>pixano/data/importers/coco_importer.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    input_dirs: dict[str, Path],\n    splits: list[str],\n    media_fields: dict[str, str] = None,\n):\n    \"\"\"Initialize COCO Importer\n\n    Args:\n        name (str): Dataset name\n        description (str): Dataset description\n        input_dirs (dict[str, Path]): Dataset input directories\n        splits (list[str]): Dataset splits\n        media_fields (dict[str, str]): Dataset media fields, with field names as keys and field types as values. Default to None.\n    \"\"\"\n\n    # Object fields\n    object_fields = {\n        \"original_id\": \"str\",\n        \"bbox\": \"bbox\",\n        \"mask\": \"compressedrle\",\n        \"category\": \"str\",\n        \"category_id\": \"int\",\n        \"supercategory\": \"str\",\n    }\n\n    # Create features_values\n    features_values = FeaturesValues(\n        objects={\n            \"category\": FeatureValues(restricted=False, values=[]),\n            \"category_id\": FeatureValues(restricted=False, values=[]),\n            \"supercategory\": FeatureValues(restricted=False, values=[]),\n        }\n    )\n    for split in splits:\n        with open(\n            input_dirs[\"objects\"] / f\"instances_{split}.json\", \"r\", encoding=\"utf-8\"\n        ) as f:\n            coco_instances = json.load(f)\n            if \"categories\" in coco_instances:\n                for category in coco_instances[\"categories\"]:\n                    features_values.objects[\"category\"].values.append(\n                        category[\"name\"]\n                    )\n                    features_values.objects[\"category_id\"].values.append(\n                        category[\"id\"]\n                    )\n                    if \"supercategory\" in category:\n                        features_values.objects[\"supercategory\"].values.append(\n                            category[\"supercategory\"]\n                        )\n    if len(features_values.objects[\"supercategory\"].values) == 0:\n        features_values.objects.pop(\"supercategory\")\n        object_fields.pop(\"supercategory\")\n    else:\n        features_values.objects[\"supercategory\"].values = list(\n            set(features_values.objects[\"supercategory\"].values)\n        )\n    FeaturesValues.model_validate(features_values)\n\n    # Create tables\n    tables = super().create_tables(\n        media_fields,\n        object_fields,\n    )\n\n    # Initialize Importer\n    self.input_dirs = input_dirs\n    super().__init__(name, description, tables, splits, features_values)\n</code></pre>"},{"location":"api_reference/data/importers/coco_importer/#pixano.data.importers.coco_importer.COCOImporter.import_rows","title":"<code>import_rows()</code>","text":"<p>Process dataset rows for import</p> <p>Yields:</p> Type Description <code>Iterator</code> <p>Processed rows</p> Source code in <code>pixano/data/importers/coco_importer.py</code> <pre><code>def import_rows(self) -&gt; Iterator:\n    \"\"\"Process dataset rows for import\n\n    Yields:\n        Iterator: Processed rows\n    \"\"\"\n\n    # Iterate on splits\n    for split in self.info.splits:\n        # Open annotation files\n        with open(\n            self.input_dirs[\"objects\"] / f\"instances_{split}.json\",\n            \"r\",\n            encoding=\"utf-8\",\n        ) as f:\n            coco_instances = json.load(f)\n\n        # Group annotations by image ID\n        annotations = defaultdict(list)\n        for ann in coco_instances[\"annotations\"]:\n            annotations[ann[\"image_id\"]].append(ann)\n\n        # Create a COCO category id to COCO category name and supercategory dictionary\n        categories = {}\n        supercategories = {}\n        for cat in coco_instances[\"categories\"]:\n            categories[cat[\"id\"]] = cat[\"name\"]\n            supercategories[cat[\"id\"]] = (\n                cat[\"supercategory\"] if \"supercategory\" in cat else None\n            )\n\n        # Process rows\n        for im in sorted(\n            coco_instances[\"images\"], key=lambda x: natural_key(str(x[\"id\"]))\n        ):\n            # Load image annotations\n            im_anns = annotations[im[\"id\"]]\n            # Load image\n            file_name_uri = urlparse(im[\"file_name\"])\n            if file_name_uri.scheme == \"\":\n                im_path = self.input_dirs[\"image\"] / split / im[\"file_name\"]\n            else:\n                im_path = Path(file_name_uri.path)\n\n            # Create image thumbnail\n            im_thumb = image_to_thumbnail(im_path.read_bytes())\n\n            # Set image URI\n            im_uri = f\"image/{split}/{im_path.name}\"\n\n            # Set unique id\n            item_id = shortuuid.uuid()\n\n            # Return rows\n            rows = {\n                \"main\": {\n                    \"db\": [\n                        {\n                            \"id\": item_id,\n                            \"original_id\": str(im[\"id\"]),\n                            \"views\": [\"image\"],\n                            \"split\": split,\n                        }\n                    ]\n                },\n                \"media\": {\n                    \"image\": [\n                        {\n                            \"id\": item_id,\n                            \"image\": Image(im_uri, None, im_thumb).to_dict(),\n                        }\n                    ]\n                },\n                \"objects\": {\n                    \"objects\": [\n                        {\n                            \"id\": shortuuid.uuid(),\n                            \"original_id\": str(ann[\"id\"]),\n                            \"item_id\": item_id,\n                            \"view_id\": \"image\",\n                            \"bbox\": (\n                                BBox.from_xywh(ann[\"bbox\"])\n                                .normalize(im[\"height\"], im[\"width\"])\n                                .to_dict()\n                                if ann[\"bbox\"]\n                                else None\n                            ),\n                            \"mask\": (\n                                CompressedRLE.encode(\n                                    ann[\"segmentation\"], im[\"height\"], im[\"width\"]\n                                ).to_dict()\n                                if ann[\"segmentation\"]\n                                else None\n                            ),\n                            \"category\": str(categories[ann[\"category_id\"]]),\n                            \"category_id\": ann[\"category_id\"],\n                            \"supercategory\": supercategories[ann[\"category_id\"]],\n                        }\n                        for ann in im_anns\n                    ]\n                },\n            }\n\n            # Remove supercategory if empty\n            for obj in rows[\"objects\"][\"objects\"]:\n                if obj[\"supercategory\"] is None:\n                    obj.pop(\"supercategory\")\n\n            yield rows\n</code></pre>"},{"location":"api_reference/data/importers/dota_importer/","title":"dota_importer","text":""},{"location":"api_reference/data/importers/dota_importer/#pixano.data.importers.dota_importer","title":"<code>pixano.data.importers.dota_importer</code>","text":""},{"location":"api_reference/data/importers/dota_importer/#pixano.data.importers.dota_importer.DOTAImporter","title":"<code>DOTAImporter(name, description, input_dirs, splits)</code>","text":"<p>               Bases: <code>Importer</code></p> <p>Importer class for DOTA dataset</p> <p>Attributes:</p> Name Type Description <code>info</code> <code>DatasetInfo</code> <p>Dataset information</p> <code>input_dirs</code> <code>dict[str, Path]</code> <p>Dataset input directories</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>input_dirs</code> <code>dict[str, Path]</code> <p>Dataset input directories</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> required Source code in <code>pixano/data/importers/dota_importer.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    input_dirs: dict[str, Path],\n    splits: list[str],\n):\n    \"\"\"Initialize DOTA Importer\n\n    Args:\n        name (str): Dataset name\n        description (str): Dataset description\n        input_dirs (dict[str, Path]): Dataset input directories\n        splits (list[str]): Dataset splits\n    \"\"\"\n\n    # Create tables\n    tables = super().create_tables(\n        media_fields={\"image\": \"image\"},\n        object_fields={\n            \"original_id\": \"str\",\n            \"bbox\": \"bbox\",\n            \"category\": \"str\",\n        },\n    )\n\n    # Create categories\n    features_values = FeaturesValues(\n        objects={\n            \"category\": FeatureValues(\n                restricted=False,\n                values=[\n                    \"plane\",  # id=1\n                    \"ship\",  # id=2\n                    \"storage tank\",  # id=3\n                    \"baseball diamond\",  # id=4\n                    \"tennis court\",  # id=5\n                    \"basketball court\",  # id=6\n                    \"ground track field\",  # id=7\n                    \"harbor\",  # id=8\n                    \"bridge\",  # id=9\n                    \"large vehicle\",  # id=10\n                    \"small vehicle\",  # id=11\n                    \"helicopter\",  # id=12\n                    \"roundabout\",  # id=13\n                    \"soccer ball field\",  # id=14\n                    \"swimming pool\",  # id=15\n                    \"container crane\",  # id=16\n                    \"airport\",  # id=17\n                    \"helipad\",  # id=18\n                ],\n            )\n        }\n    )\n\n    # Initialize Importer\n    self.input_dirs = input_dirs\n    super().__init__(name, description, tables, splits, features_values)\n</code></pre>"},{"location":"api_reference/data/importers/dota_importer/#pixano.data.importers.dota_importer.DOTAImporter.import_rows","title":"<code>import_rows()</code>","text":"<p>Process dataset rows for import</p> <p>Yields:</p> Type Description <code>Iterator</code> <p>Processed rows</p> Source code in <code>pixano/data/importers/dota_importer.py</code> <pre><code>def import_rows(self) -&gt; Iterator:\n    \"\"\"Process dataset rows for import\n\n    Yields:\n        Iterator: Processed rows\n    \"\"\"\n    for split in self.info.splits:\n        # Get images paths\n        image_paths = glob.glob(str(self.input_dirs[\"image\"] / split / \"*.png\"))\n        image_paths = [Path(p) for p in sorted(image_paths, key=natural_key)]\n\n        # Process rows\n        for im_path in image_paths:\n            # Load image annotations\n            im_anns_file = (\n                self.input_dirs[\"objects\"]\n                / split\n                / \"hbb\"\n                / im_path.name.replace(\"png\", \"txt\")\n            )\n            with open(im_anns_file, encoding=\"utf-8\") as f:\n                im_anns = [line.strip().split() for line in f]\n\n            # Allow DOTA largest images\n            PILImage.MAX_IMAGE_PIXELS = 806504000\n\n            # Get image dimensions and thumbnail\n            with PILImage.open(im_path) as im:\n                im_w, im_h = im.size\n                im_thumb = image_to_thumbnail(im)\n\n            # Set image URI\n            im_uri = f\"image/{split}/{im_path.name}\"\n\n            # Set unique item id\n            item_id = shortuuid.uuid()\n\n            # Return rows\n            rows = {\n                \"main\": {\n                    \"db\": [\n                        {\n                            \"id\": item_id,\n                            \"original_id\": im_path.stem,\n                            \"views\": [\"image\"],\n                            \"split\": split,\n                        }\n                    ]\n                },\n                \"media\": {\n                    \"image\": [\n                        {\n                            \"id\": item_id,\n                            \"image\": Image(im_uri, None, im_thumb).to_dict(),\n                        }\n                    ]\n                },\n                \"objects\": {\n                    \"objects\": [\n                        {\n                            \"id\": shortuuid.uuid(),\n                            \"item_id\": item_id,\n                            \"view_id\": \"image\",\n                            \"bbox\": BBox.from_xyxy(\n                                [\n                                    float(ann[0]),\n                                    float(ann[1]),\n                                    float(ann[4]),\n                                    float(ann[5]),\n                                ]\n                            )\n                            .normalize(im_h, im_w)\n                            .to_dict(),\n                            \"category\": str(ann[8]).replace(\"-\", \" \"),\n                        }\n                        for ann in im_anns\n                    ]\n                },\n            }\n\n            yield rows\n</code></pre>"},{"location":"api_reference/data/importers/image_importer/","title":"image_importer","text":""},{"location":"api_reference/data/importers/image_importer/#pixano.data.importers.image_importer","title":"<code>pixano.data.importers.image_importer</code>","text":""},{"location":"api_reference/data/importers/image_importer/#pixano.data.importers.image_importer.ImageImporter","title":"<code>ImageImporter(name, description, input_dirs, splits=None, media_fields=None)</code>","text":"<p>               Bases: <code>Importer</code></p> <p>Importer class for image datasets</p> <p>Attributes:</p> Name Type Description <code>info</code> <code>DatasetInfo</code> <p>Dataset information</p> <code>input_dirs</code> <code>dict[str, Path]</code> <p>Dataset input directories</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>input_dirs</code> <code>dict[str, Path]</code> <p>Dataset input directories</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits. Defaults to None for datasets with no subfolders for splits.</p> <code>None</code> <code>media_fields</code> <code>dict[str, str]</code> <p>Dataset media fields, with field names as keys and field types as values. Default to None.</p> <code>None</code> Source code in <code>pixano/data/importers/image_importer.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    input_dirs: dict[str, Path],\n    splits: list[str] = None,\n    media_fields: dict[str, str] = None,\n):\n    \"\"\"Initialize Image Importer\n\n    Args:\n        name (str): Dataset name\n        description (str): Dataset description\n        input_dirs (dict[str, Path]): Dataset input directories\n        splits (list[str], optional): Dataset splits. Defaults to None for datasets with no subfolders for splits.\n        media_fields (dict[str, str]): Dataset media fields, with field names as keys and field types as values. Default to None.\n    \"\"\"\n\n    # Create dataset tables\n    tables = super().create_tables(media_fields)\n\n    # Create splits\n    if splits is None:\n        splits = [\"dataset\"]\n\n    # Initialize Importer\n    self.input_dirs = input_dirs\n    super().__init__(name, description, tables, splits)\n</code></pre>"},{"location":"api_reference/data/importers/image_importer/#pixano.data.importers.image_importer.ImageImporter.import_rows","title":"<code>import_rows()</code>","text":"<p>Process dataset rows for import</p> <p>Yields:</p> Type Description <code>Iterator</code> <p>Processed rows</p> Source code in <code>pixano/data/importers/image_importer.py</code> <pre><code>def import_rows(self) -&gt; Iterator:\n    \"\"\"Process dataset rows for import\n\n    Yields:\n        Iterator: Processed rows\n    \"\"\"\n\n    for split in self.info.splits:\n        # Get images paths\n        image_paths = []\n        for ftype in [\"*.png\", \"*.jpg\", \"*.jpeg\"]:\n            if split == \"dataset\":\n                image_paths.extend(glob.glob(str(self.input_dirs[\"image\"] / ftype)))\n            else:\n                image_paths.extend(\n                    glob.glob(str(self.input_dirs[\"image\"] / split / ftype))\n                )\n        image_paths = [Path(p) for p in sorted(image_paths, key=natural_key)]\n\n        # Process rows\n        for im_path in image_paths:\n            # Create image thumbnail\n            im_thumb = image_to_thumbnail(im_path.read_bytes())\n\n            # Set image URI\n            im_uri = (\n                f\"image/{im_path.name}\"\n                if split == \"dataset\"\n                else f\"image/{split}/{im_path.name}\"\n            )\n\n            # Set unique item id\n            item_id = shortuuid.uuid()\n\n            # Return rows\n            rows = {\n                \"main\": {\n                    \"db\": [\n                        {\n                            \"id\": item_id,\n                            \"original_id\": im_path.name,\n                            \"views\": [\"image\"],\n                            \"split\": split,\n                            \"label\": \"\",\n                        }\n                    ]\n                },\n                \"media\": {\n                    \"image\": [\n                        {\n                            \"id\": item_id,\n                            \"image\": Image(im_uri, None, im_thumb).to_dict(),\n                        }\n                    ]\n                },\n            }\n            yield rows\n</code></pre>"},{"location":"api_reference/data/importers/importer/","title":"importer","text":""},{"location":"api_reference/data/importers/importer/#pixano.data.importers.importer","title":"<code>pixano.data.importers.importer</code>","text":""},{"location":"api_reference/data/importers/importer/#pixano.data.importers.importer.Importer","title":"<code>Importer(name, description, tables, splits, features_values=None)</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Dataset Importer class</p> <p>Attributes:</p> Name Type Description <code>info</code> <code>DatasetInfo</code> <p>Dataset information</p> <code>input_dirs</code> <code>dict[str, Path]</code> <p>Dataset input directories</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Dataset name</p> required <code>description</code> <code>str</code> <p>Dataset description</p> required <code>tables</code> <code>dict[str, list[DatasetTable]]</code> <p>Dataset tables</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits</p> required <code>features_values</code> <code>FeaturesValues</code> <p>Values for features</p> <code>None</code> Source code in <code>pixano/data/importers/importer.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    description: str,\n    tables: dict[str, list[DatasetTable]],\n    splits: list[str],\n    features_values: FeaturesValues = None,\n):\n    \"\"\"Initialize Importer\n\n    Args:\n        name (str): Dataset name\n        description (str): Dataset description\n        tables (dict[str, list[DatasetTable]]): Dataset tables\n        splits (list[str]): Dataset splits\n        features_values (FeaturesValues, optional): Values for features\n    \"\"\"\n\n    # Check input directories\n    for source_path in self.input_dirs.values():\n        if not source_path.exists():\n            raise FileNotFoundError(f\"{source_path} does not exist.\")\n        if not any(source_path.iterdir()):\n            raise FileNotFoundError(f\"{source_path} is empty.\")\n\n    # Create DatasetInfo\n    self.info = DatasetInfo(\n        id=shortuuid.uuid(),\n        name=name,\n        description=description,\n        estimated_size=\"N/A\",\n        num_elements=0,\n        splits=splits,\n        tables=tables,\n        features_values=features_values,\n    )\n</code></pre>"},{"location":"api_reference/data/importers/importer/#pixano.data.importers.importer.Importer.copy_or_move_files","title":"<code>copy_or_move_files(import_dir, ds_tables, copy)</code>","text":"<p>Copy or move dataset files</p> <p>Parameters:</p> Name Type Description Default <code>import_dir</code> <code>Path</code> <p>Import directory</p> required <code>ds_tables</code> <code>dict[str, dict[str, LanceTable]]</code> <p>Dataset tables</p> required <code>copy</code> <code>bool</code> <p>True to copy files, False to move them</p> required Source code in <code>pixano/data/importers/importer.py</code> <pre><code>def copy_or_move_files(\n    self,\n    import_dir: Path,\n    ds_tables: dict[str, dict[str, lancedb.db.LanceTable]],\n    copy: bool,\n):\n    \"\"\"Copy or move dataset files\n\n    Args:\n        import_dir (Path): Import directory\n        ds_tables (dict[str, dict[str, lancedb.db.LanceTable]]): Dataset tables\n        copy (bool): True to copy files, False to move them\n    \"\"\"\n\n    if copy:\n        for table in tqdm(\n            ds_tables[\"media\"].values(), desc=\"Copying media directories\"\n        ):\n            for field in table.schema:\n                if field.name in self.input_dirs:\n                    field_dir = import_dir / \"media\" / field.name\n                    field_dir.mkdir(parents=True, exist_ok=True)\n                    if self.input_dirs[field.name] != field_dir:\n                        shutil.copytree(\n                            self.input_dirs[field.name],\n                            field_dir,\n                            dirs_exist_ok=True,\n                        )\n    else:\n        for table in tqdm(\n            ds_tables[\"media\"].values(), desc=\"Moving media directories\"\n        ):\n            for field in table.schema:\n                if field.name in self.input_dirs:\n                    field_dir = import_dir / \"media\" / field.name\n                    if self.input_dirs[field.name] != field_dir:\n                        self.input_dirs[field.name].rename(field_dir)\n</code></pre>"},{"location":"api_reference/data/importers/importer/#pixano.data.importers.importer.Importer.create_preview","title":"<code>create_preview(import_dir, ds_tables)</code>","text":"<p>Create dataset preview image</p> <p>Parameters:</p> Name Type Description Default <code>import_dir</code> <code>Path</code> <p>Import directory</p> required <code>ds_tables</code> <code>dict[str, dict[str, LanceTable]]</code> <p>Dataset tables</p> required Source code in <code>pixano/data/importers/importer.py</code> <pre><code>def create_preview(\n    self,\n    import_dir: Path,\n    ds_tables: dict[str, dict[str, lancedb.db.LanceTable]],\n):\n    \"\"\"Create dataset preview image\n\n    Args:\n        import_dir (Path): Import directory\n        ds_tables (dict[str, dict[str, lancedb.db.LanceTable]]): Dataset tables\n    \"\"\"\n\n    # Get list of image fields\n    if \"media\" in ds_tables:\n        if \"image\" in ds_tables[\"media\"]:\n            image_table = ds_tables[\"media\"][\"image\"]\n            if len(image_table) &gt; 0:\n                image_fields = [\n                    field.name for field in image_table.schema if field.name != \"id\"\n                ]\n                with tqdm(desc=\"Creating dataset thumbnail\", total=1) as progress:\n                    tile_w = 64\n                    tile_h = 64\n                    preview = Image.new(\"RGB\", (4 * tile_w, 2 * tile_h))\n                    for i in range(8):\n                        field = image_fields[i % len(image_fields)]\n                        item_id = random.randrange(len(image_table))\n                        item = image_table.to_lance().take([item_id]).to_pylist()[0]\n                        with Image.open(BytesIO(item[field].preview_bytes)) as im:\n                            preview.paste(\n                                im,\n                                ((i % 4) * tile_w, (int(i / 4) % 2) * tile_h),\n                            )\n                    preview.save(import_dir / \"preview.png\")\n                    progress.update(1)\n</code></pre>"},{"location":"api_reference/data/importers/importer/#pixano.data.importers.importer.Importer.create_tables","title":"<code>create_tables(media_fields=None, object_fields=None)</code>","text":"<p>Create dataset tables</p> <p>Parameters:</p> Name Type Description Default <code>media_fields</code> <code>dict[str, str]</code> <p>Media fields. Defaults to None.</p> <code>None</code> <code>object_fields</code> <code>dict[str, str]</code> <p>Object fields. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, list[DatasetTable]]</code> <p>Tables</p> Source code in <code>pixano/data/importers/importer.py</code> <pre><code>def create_tables(\n    self, media_fields: dict[str, str] = None, object_fields: dict[str, str] = None\n):\n    \"\"\"Create dataset tables\n\n    Args:\n        media_fields (dict[str, str], optional): Media fields. Defaults to None.\n        object_fields (dict[str, str], optional): Object fields. Defaults to None.\n\n    Returns:\n        dict[str, list[DatasetTable]]: Tables\n    \"\"\"\n\n    if media_fields is None:\n        media_fields = {\"image\": \"image\"}\n\n    tables: dict[str, list[DatasetTable]] = {\n        \"main\": [\n            DatasetTable(\n                name=\"db\",\n                fields={\n                    \"id\": \"str\",\n                    \"original_id\": \"str\",\n                    \"views\": \"[str]\",\n                    \"split\": \"str\",\n                },\n            )\n        ],\n        \"media\": [],\n    }\n\n    # Add media fields\n    for field_name, field_type in media_fields.items():\n        table_exists = False\n        # If table for given field type exists\n        for media_table in tables[\"media\"]:\n            if field_type == media_table.name and not table_exists:\n                media_table.fields[field_name] = field_type\n                table_exists = True\n        # Else, create that table\n        if not table_exists:\n            tables[\"media\"].append(\n                DatasetTable(\n                    name=field_type,\n                    fields={\n                        \"id\": \"str\",\n                        field_name: field_type,\n                    },\n                )\n            )\n\n    # Add object fields\n    if object_fields is not None:\n        tables[\"objects\"] = [\n            DatasetTable(\n                name=\"objects\",\n                fields={\"id\": \"str\", \"item_id\": \"str\", \"view_id\": \"str\"}\n                | object_fields,\n                source=\"Ground Truth\",\n            )\n        ]\n\n    return tables\n</code></pre>"},{"location":"api_reference/data/importers/importer/#pixano.data.importers.importer.Importer.import_dataset","title":"<code>import_dataset(import_dir, copy=True)</code>","text":"<p>Import dataset to Pixano format</p> <p>Parameters:</p> Name Type Description Default <code>import_dir</code> <code>Path</code> <p>Import directory</p> required <code>copy</code> <code>bool</code> <p>True to copy files to the import directory, False to move them. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>Imported dataset</p> Source code in <code>pixano/data/importers/importer.py</code> <pre><code>def import_dataset(\n    self,\n    import_dir: Path,\n    copy: bool = True,\n) -&gt; Dataset:\n    \"\"\"Import dataset to Pixano format\n\n    Args:\n        import_dir (Path): Import directory\n        copy (bool, optional): True to copy files to the import directory, False to move them. Defaults to True.\n\n    Returns:\n        Dataset: Imported dataset\n    \"\"\"\n\n    # Create dataset\n    dataset = Dataset.create(import_dir, self.info)\n\n    # Load dataset tables\n    ds_tables = dataset.open_tables()\n\n    # Initalize batches\n    ds_batches: dict[str, dict[str, list]] = defaultdict(dict)\n    for group_name, table_group in self.info.tables.items():\n        for table in table_group:\n            ds_batches[group_name][table.name] = []\n\n    # Add rows to tables\n    save_batch_size = 1024\n    for rows in tqdm(self.import_rows(), desc=\"Importing dataset\"):\n        for group_name, table_group in self.info.tables.items():\n            for table in table_group:\n                # Store rows in a batch\n                ds_batches[group_name][table.name].extend(\n                    rows[group_name][table.name]\n                )\n                # If batch reaches 1024 rows, store in table\n                if len(ds_batches[group_name][table.name]) &gt;= save_batch_size:\n                    pa_batch = pa.Table.from_pylist(\n                        ds_batches[group_name][table.name],\n                        schema=Fields(table.fields).to_schema(),\n                    )\n                    lance.write_dataset(\n                        pa_batch,\n                        uri=ds_tables[group_name][table.name].to_lance().uri,\n                        mode=\"append\",\n                    )\n                    ds_batches[group_name][table.name] = []\n\n    # Store final batches\n    for group_name, table_group in self.info.tables.items():\n        for table in table_group:\n            if len(ds_batches[group_name][table.name]) &gt; 0:\n                pa_batch = pa.Table.from_pylist(\n                    ds_batches[group_name][table.name],\n                    schema=Fields(table.fields).to_schema(),\n                )\n                lance.write_dataset(\n                    pa_batch,\n                    uri=ds_tables[group_name][table.name].to_lance().uri,\n                    mode=\"append\",\n                )\n                ds_batches[group_name][table.name] = []\n\n    # Optimize and clear creation history\n    for tables in ds_tables.values():\n        for table in tables.values():\n            table.to_lance().optimize.compact_files()\n            table.to_lance().cleanup_old_versions(older_than=timedelta(0))\n\n    # Refresh tables\n    ds_tables = dataset.open_tables()\n\n    # Raise error if generated dataset is empty\n    if len(ds_tables[\"main\"][\"db\"]) == 0:\n        raise FileNotFoundError(\n            \"Generated dataset is empty. Please make sure that the paths to your media files are correct, and that they each contain subfolders for your splits.\"\n        )\n\n    # Create DatasetInfo\n    dataset.info.num_elements = len(ds_tables[\"main\"][\"db\"])\n    dataset.info.estimated_size = estimate_size(import_dir)\n    dataset.save_info()\n\n    # Create thumbnail\n    self.create_preview(import_dir, ds_tables)\n\n    # Copy or move media directories\n    self.copy_or_move_files(import_dir, ds_tables, copy)\n\n    return Dataset(import_dir)\n</code></pre>"},{"location":"api_reference/data/importers/importer/#pixano.data.importers.importer.Importer.import_rows","title":"<code>import_rows()</code>  <code>abstractmethod</code>","text":"<p>Process dataset rows for import</p> <p>Yields:</p> Type Description <code>Iterator</code> <p>Processed rows</p> Source code in <code>pixano/data/importers/importer.py</code> <pre><code>@abstractmethod\ndef import_rows(self) -&gt; Iterator:\n    \"\"\"Process dataset rows for import\n\n    Yields:\n        Iterator: Processed rows\n    \"\"\"\n</code></pre>"},{"location":"api_reference/data/item/item_embedding/","title":"item_embedding","text":""},{"location":"api_reference/data/item/item_embedding/#pixano.data.item.item_embedding","title":"<code>pixano.data.item.item_embedding</code>","text":""},{"location":"api_reference/data/item/item_embedding/#pixano.data.item.item_embedding.ItemEmbedding","title":"<code>ItemEmbedding(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Embedding type for DatasetItem</p> <p>Attributes:</p> Name Type Description <code>view_id</code> <code>str</code> <p>Embedding view ID</p> <code>data</code> <code>str</code> <p>Embedding data in base 64</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            category=None,\n        )\n</code></pre>"},{"location":"api_reference/data/item/item_embedding/#pixano.data.item.item_embedding.ItemEmbedding.from_pyarrow","title":"<code>from_pyarrow(table, schema)</code>  <code>staticmethod</code>","text":"<p>Create dictionary of ItemEmbedding from PyArrow Table</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>dict[str, Any]</code> <p>PyArrow table</p> required <code>schema</code> <code>schema</code> <p>PyArrow schema</p> required <p>Returns:</p> Type Description <code>dict[str, ItemEmbedding]</code> <p>Dictionary of ItemEmbedding</p> Source code in <code>pixano/data/item/item_embedding.py</code> <pre><code>@staticmethod\ndef from_pyarrow(table: pa.Table, schema: pa.schema) -&gt; dict[str, \"ItemEmbedding\"]:\n    \"\"\"Create dictionary of ItemEmbedding from PyArrow Table\n\n    Args:\n        table (dict[str, Any]): PyArrow table\n        schema (pa.schema): PyArrow schema\n\n    Returns:\n        dict[str, ItemEmbedding]: Dictionary of ItemEmbedding\n    \"\"\"\n\n    list_item = table.to_pylist()\n    if len(list_item) == 0:\n        return {}\n    item = list_item[0]\n    embeddings = {}\n\n    # Iterate on fields\n    for field in schema:\n        # Image\n        if is_binary(field.type):\n            embeddings[field.name] = ItemEmbedding(\n                view_id=field.name,\n                data=base64.b64encode(item[field.name]).decode(\"ascii\"),\n            )\n\n    return embeddings\n</code></pre>"},{"location":"api_reference/data/item/item_feature/","title":"item_feature","text":""},{"location":"api_reference/data/item/item_feature/#pixano.data.item.item_feature","title":"<code>pixano.data.item.item_feature</code>","text":""},{"location":"api_reference/data/item/item_feature/#pixano.data.item.item_feature.FeatureValues","title":"<code>FeatureValues(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Feature available values, as a restricted list or open list</p> <p>Attributes:</p> Name Type Description <code>restricted</code> <code>bool</code> <p>restricted list or open list</p> <code>values</code> <code>list[str | int]</code> <p>list of available values</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            category=None,\n        )\n</code></pre>"},{"location":"api_reference/data/item/item_feature/#pixano.data.item.item_feature.FeaturesValues","title":"<code>FeaturesValues(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Features availables values</p> <p>Attributes:</p> Name Type Description <code>main</code> <code>dict[str, FeatureValues]</code> <p>Scene features available values (\"main\" table)</p> <code>objects</code> <code>dict[str, FeatureValues]</code> <p>Objects features available values</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            category=None,\n        )\n</code></pre>"},{"location":"api_reference/data/item/item_feature/#pixano.data.item.item_feature.ItemFeature","title":"<code>ItemFeature(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Feature</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Feature name</p> <code>dtype</code> <code>str</code> <p>Feature type</p> <code>value</code> <code>str | int | float | bool</code> <p>Feature value</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            category=None,\n        )\n</code></pre>"},{"location":"api_reference/data/item/item_feature/#pixano.data.item.item_feature.ItemFeature.from_pyarrow","title":"<code>from_pyarrow(table, schema)</code>  <code>staticmethod</code>","text":"<p>Create dictionary of ItemFeature from PyArrow Table</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table</code> <p>PyArrow table</p> required <code>schema</code> <code>schema</code> <p>PyArrow schema</p> required <p>Returns:</p> Type Description <code>dict[str, ItemFeature]</code> <p>Dictionary of ItemFeature</p> Source code in <code>pixano/data/item/item_feature.py</code> <pre><code>@staticmethod\ndef from_pyarrow(\n    table: pa.Table,\n    schema: pa.schema,\n) -&gt; dict[str, \"ItemFeature\"]:\n    \"\"\"Create dictionary of ItemFeature from PyArrow Table\n\n    Args:\n        table (pa.Table): PyArrow table\n        schema (pa.schema): PyArrow schema\n\n    Returns:\n        dict[str, ItemFeature]: Dictionary of ItemFeature\n    \"\"\"\n\n    item = table.to_pylist()[0]\n    features = {}\n    ignored_fields = [\n        \"id\",\n        \"item_id\",\n        \"view_id\",\n        \"source_id\",\n        \"split\",\n        \"review_state\",\n    ]\n\n    # Iterate on fields\n    for field in schema:\n        if field.name not in ignored_fields:\n            # Integer fields\n            if is_integer(field.type):\n                features[field.name] = ItemFeature(\n                    name=field.name,\n                    dtype=\"int\",\n                    value=item[field.name],\n                )\n\n            # Float fields\n            if is_float(field.type):\n                # Parse float value from string\n                # (Float conversions from PyArrow to Python can currently add a lot of random decimal places)\n                value_as_string: str = table[field.name].to_string()\n                value_as_string = (\n                    value_as_string.replace(\"[\", \"\").replace(\"]\", \"\").strip()\n                )\n                try:\n                    features[field.name] = ItemFeature(\n                        name=field.name,\n                        dtype=\"float\",\n                        value=float(value_as_string),\n                    )\n                except ValueError:\n                    features[field.name] = ItemFeature(\n                        name=field.name,\n                        dtype=\"float\",\n                        value=float(item[field.name]),\n                    )\n\n            # String fields\n            elif is_string(field.type):\n                features[field.name] = ItemFeature(\n                    name=field.name,\n                    dtype=\"str\",\n                    value=str(item[field.name]),\n                )\n\n            # Boolean fields\n            elif is_boolean(field.type):\n                features[field.name] = ItemFeature(\n                    name=field.name,\n                    dtype=\"bool\",\n                    value=bool(item[field.name]),\n                )\n\n    # Additional distance field in case of semantic search\n    for field_name in item.keys():\n        if field_name == \"distance\":\n            features[\"search distance\"] = ItemFeature(\n                name=\"search distance\",\n                dtype=\"float\",\n                value=round(item[field_name], 2),\n            )\n\n    return features\n</code></pre>"},{"location":"api_reference/data/item/item_object/","title":"item_object","text":""},{"location":"api_reference/data/item/item_object/#pixano.data.item.item_object","title":"<code>pixano.data.item.item_object</code>","text":""},{"location":"api_reference/data/item/item_object/#pixano.data.item.item_object.ItemBBox","title":"<code>ItemBBox(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>BBox type for DatasetItem</p> <p>Type for BBox.to_dict()</p> <p>Attributes:</p> Name Type Description <code>coords</code> <code>list[float]</code> <p>List of coordinates in given format</p> <code>format</code> <code>str</code> <p>Coordinates format, 'xyxy' or 'xywh'</p> <code>is_normalized</code> <code>bool</code> <p>True if coordinates are normalized to image size</p> <code>confidence</code> <code>float</code> <p>Bounding box confidence if predicted</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            category=None,\n        )\n</code></pre>"},{"location":"api_reference/data/item/item_object/#pixano.data.item.item_object.ItemBBox.from_pyarrow","title":"<code>from_pyarrow(bbox)</code>  <code>staticmethod</code>","text":"<p>Create ItemBBox from bounding box</p> <p>Parameters:</p> Name Type Description Default <code>bbox</code> <code>BBox</code> <p>Bounding box</p> required <p>Returns:</p> Type Description <code>ItemBBox</code> <p>ItemBBox</p> Source code in <code>pixano/data/item/item_object.py</code> <pre><code>@staticmethod\ndef from_pyarrow(\n    bbox: BBox,\n) -&gt; \"ItemBBox\":\n    \"\"\"Create ItemBBox from bounding box\n\n    Args:\n        bbox (BBox): Bounding box\n\n    Returns:\n        ItemBBox: ItemBBox\n    \"\"\"\n\n    return (\n        ItemBBox.model_validate(bbox.to_xywh().to_dict())\n        if bbox.coords != [0.0, 0.0, 0.0, 0.0]\n        else None\n    )\n</code></pre>"},{"location":"api_reference/data/item/item_object/#pixano.data.item.item_object.ItemBBox.to_pyarrow","title":"<code>to_pyarrow()</code>","text":"<p>Return ItemBbox as BBox</p> <p>Returns:</p> Type Description <code>BBox</code> <p>Bounding box</p> Source code in <code>pixano/data/item/item_object.py</code> <pre><code>def to_pyarrow(self) -&gt; BBox:\n    \"\"\"Return ItemBbox as BBox\n\n    Returns:\n        BBox: Bounding box\n    \"\"\"\n\n    return (\n        BBox.from_dict(self.model_dump())\n        if self.coords != [0.0, 0.0, 0.0, 0.0]\n        else None\n    )\n</code></pre>"},{"location":"api_reference/data/item/item_object/#pixano.data.item.item_object.ItemObject","title":"<code>ItemObject(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Object type for DatasetItem</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Object ID</p> <code>original_id</code> <code>str</code> <p>Object original ID</p> <code>item_id</code> <code>str</code> <p>Object item ID</p> <code>view_id</code> <code>str</code> <p>Object view ID</p> <code>source_id</code> <code>str</code> <p>Object source ID</p> <code>review_state</code> <code>str</code> <p>Object review state (\"accepted\", \"rejected\", None)</p> <code>bbox</code> <code>ItemBBox</code> <p>Object bounding box</p> <code>mask</code> <code>ItemURLE</code> <p>Object mask</p> <code>features</code> <code>dict[str, ItemFeature]</code> <p>Object features</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            category=None,\n        )\n</code></pre>"},{"location":"api_reference/data/item/item_object/#pixano.data.item.item_object.ItemObject.add_or_update","title":"<code>add_or_update(ds_table)</code>","text":"<p>Add or update item object</p> <p>Parameters:</p> Name Type Description Default <code>ds_table</code> <code>LanceTable</code> <p>Object table</p> required Source code in <code>pixano/data/item/item_object.py</code> <pre><code>def add_or_update(\n    self,\n    ds_table: lancedb.db.LanceTable,\n):\n    \"\"\"Add or update item object\n\n    Args:\n        ds_table (lancedb.db.LanceTable): Object table\n    \"\"\"\n\n    # Convert object to PyArrow\n    pyarrow_obj = self.to_pyarrow()\n    table_obj = pa.Table.from_pylist(\n        [pyarrow_obj],\n        schema=ds_table.schema,\n    )\n\n    # Delete object (if it exists)\n    scanner = ds_table.to_lance().scanner(filter=f\"id in ('{self.id}')\")\n    existing_obj = scanner.to_table()\n    if existing_obj.num_rows &gt; 0:\n        ds_table.delete(f\"id in ('{self.id}')\")\n\n    # Add object\n    ds_table.add(table_obj, mode=\"append\")\n\n    # Clear change history to prevent dataset from becoming too large\n    ds_table.to_lance().cleanup_old_versions()\n</code></pre>"},{"location":"api_reference/data/item/item_object/#pixano.data.item.item_object.ItemObject.from_pyarrow","title":"<code>from_pyarrow(table, schema, source_id)</code>  <code>staticmethod</code>","text":"<p>Create dictionary of ItemObject from PyArrow Table</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>dict[str, Any]</code> <p>PyArrow table</p> required <code>schema</code> <code>schema</code> <p>PyArrow schema</p> required <code>source_id</code> <code>str</code> <p>Objects source ID</p> required <p>Returns:</p> Type Description <code>dict[str, ItemObject]</code> <p>Dictionary of ItemObject</p> Source code in <code>pixano/data/item/item_object.py</code> <pre><code>@staticmethod\ndef from_pyarrow(\n    table: pa.Table,\n    schema: pa.schema,\n    source_id: str,\n) -&gt; dict[str, \"ItemObject\"]:\n    \"\"\"Create dictionary of ItemObject from PyArrow Table\n\n    Args:\n        table (dict[str, Any]): PyArrow table\n        schema (pa.schema): PyArrow schema\n        source_id (str): Objects source ID\n\n    Returns:\n        dict[str, ItemObject]: Dictionary of ItemObject\n    \"\"\"\n\n    items = table.to_pylist()\n    objects = {}\n\n    # Iterate on objects\n    for index, item in enumerate(items):\n        # Create object\n        obj = ItemObject(\n            id=item[\"id\"],\n            item_id=item[\"item_id\"],\n            view_id=item[\"view_id\"],\n            source_id=source_id,\n        )\n\n        # Add other base fields (review state, bbox, mask)\n        for field in schema:\n            if field.name == \"review_state\" and item[\"review_state\"]:\n                obj.review_state = item[\"review_state\"]\n            if field.name == \"bbox\" and item[\"bbox\"]:\n                obj.bbox = ItemBBox.from_pyarrow(item[\"bbox\"])\n            elif field.name == \"mask\" and item[\"mask\"]:\n                obj.mask = ItemURLE.from_pyarrow(item[\"mask\"])\n        # Add features\n        obj.features = ItemFeature.from_pyarrow(table.take([index]), schema)\n        # Append object\n        objects[item[\"id\"]] = obj\n\n    return objects\n</code></pre>"},{"location":"api_reference/data/item/item_object/#pixano.data.item.item_object.ItemObject.to_pyarrow","title":"<code>to_pyarrow()</code>","text":"<p>Return ItemObject in PyArrow format</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Object in PyArrow format</p> Source code in <code>pixano/data/item/item_object.py</code> <pre><code>def to_pyarrow(self) -&gt; dict[str, Any]:\n    \"\"\"Return ItemObject in PyArrow format\n\n    Returns:\n        dict[str, Any]: Object in PyArrow format\n    \"\"\"\n\n    pyarrow_object = {}\n\n    # IDs\n    pyarrow_object[\"id\"] = self.id\n    pyarrow_object[\"item_id\"] = self.item_id\n    pyarrow_object[\"view_id\"] = self.view_id\n\n    # Base fields (review state, bbox, mask)\n    if self.review_state is not None:\n        pyarrow_object[\"review_state\"] = self.review_state\n\n    pyarrow_mask = self.mask.to_pyarrow() if self.mask else None\n    pyarrow_bbox = (\n        self.bbox.to_pyarrow()\n        if self.bbox\n        else BBox.from_rle(pyarrow_mask) if pyarrow_mask else None\n    )\n\n    pyarrow_object[\"mask\"] = pyarrow_mask.to_dict() if pyarrow_mask else None\n    pyarrow_object[\"bbox\"] = pyarrow_bbox.to_dict() if pyarrow_bbox else None\n\n    # Features\n    if self.features is not None:\n        # Add features\n        for feat in self.features.values():\n            pyarrow_object[feat.name] = (\n                field_to_python(feat.dtype)(feat.value)\n                if feat.value is not None\n                else None\n            )\n\n        # Check feature types\n        for feat in self.features.values():\n            if pyarrow_object[feat.name] is not None and not isinstance(\n                pyarrow_object[feat.name], field_to_python(feat.dtype)\n            ):\n                raise ValueError(\n                    f\"Feature {feat.name} of object {self.id} is of type {type(self.features[feat.name].value)} instead of type {field_to_python(feat.dtype)}\"\n                )\n\n    return pyarrow_object\n</code></pre>"},{"location":"api_reference/data/item/item_object/#pixano.data.item.item_object.ItemURLE","title":"<code>ItemURLE(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Uncompressed URLE mask type for DatasetItem</p> <p>Type for CompressedRLE.to_urle()</p> <p>Attributes:</p> Name Type Description <code>size</code> <code>list[int]</code> <p>Mask size</p> <code>counts</code> <code>list[int]</code> <p>Mask URLE encoding</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            category=None,\n        )\n</code></pre>"},{"location":"api_reference/data/item/item_object/#pixano.data.item.item_object.ItemURLE.from_pyarrow","title":"<code>from_pyarrow(rle)</code>  <code>staticmethod</code>","text":"<p>Create ItemURLE from compressed RLE</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>CompressedRLE</code> <p>Compressed RLE</p> required <p>Returns:</p> Type Description <code>ItemURLE</code> <p>ItemURLE</p> Source code in <code>pixano/data/item/item_object.py</code> <pre><code>@staticmethod\ndef from_pyarrow(\n    rle: CompressedRLE,\n) -&gt; \"ItemURLE\":\n    \"\"\"Create ItemURLE from compressed RLE\n\n    Args:\n        rle (CompressedRLE): Compressed RLE\n\n    Returns:\n        ItemURLE: ItemURLE\n    \"\"\"\n\n    return ItemURLE.model_validate(rle.to_urle()) if rle.counts else None\n</code></pre>"},{"location":"api_reference/data/item/item_object/#pixano.data.item.item_object.ItemURLE.to_pyarrow","title":"<code>to_pyarrow()</code>","text":"<p>Return ItemURLE as compressed RLE</p> <p>Returns:</p> Type Description <code>CompressedRLE</code> <p>Compressed RLE</p> Source code in <code>pixano/data/item/item_object.py</code> <pre><code>def to_pyarrow(self) -&gt; CompressedRLE:\n    \"\"\"Return ItemURLE as compressed RLE\n\n    Returns:\n        CompressedRLE: Compressed RLE\n    \"\"\"\n\n    return CompressedRLE.from_urle(self.model_dump()) if self.counts else None\n</code></pre>"},{"location":"api_reference/data/item/item_view/","title":"item_view","text":""},{"location":"api_reference/data/item/item_view/#pixano.data.item.item_view","title":"<code>pixano.data.item.item_view</code>","text":""},{"location":"api_reference/data/item/item_view/#pixano.data.item.item_view.ItemView","title":"<code>ItemView(**data)</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>View type for DatasetItem</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>View ID</p> <code>type</code> <code>str</code> <p>View type (\"image\", \"video\", \"point_cloud\")</p> <code>url</code> <code>str</code> <p>View URI</p> <code>thumbnail</code> <code>str</code> <p>View thumbnail as base 64 URL</p> <code>frame_number</code> <code>int</code> <p>View frame number</p> <code>total_frames</code> <code>int</code> <p>View total frames</p> <code>features</code> <code>dict[str, ItemFeature]</code> <p>View features</p> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            category=None,\n        )\n</code></pre>"},{"location":"api_reference/data/item/item_view/#pixano.data.item.item_view.ItemView.from_pyarrow","title":"<code>from_pyarrow(table, schema, media_dir, media_features=False)</code>  <code>staticmethod</code>","text":"<p>Create dictionary of ItemView from PyArrow Table</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>dict[str, Any]</code> <p>PyArrow table</p> required <code>schema</code> <code>schema</code> <p>PyArrow schema</p> required <code>media_dir</code> <code>Path</code> <p>Dataset media directory</p> required <code>media_features</code> <code>bool</code> <p>Load media features like image width and height (slow for large item batches)</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[ItemView]</code> <p>Dictionary of ItemView</p> Source code in <code>pixano/data/item/item_view.py</code> <pre><code>@staticmethod\ndef from_pyarrow(\n    table: pa.Table,\n    schema: pa.schema,\n    media_dir: Path,\n    media_features: bool = False,\n) -&gt; dict[str, \"ItemView\"]:\n    \"\"\"Create dictionary of ItemView from PyArrow Table\n\n    Args:\n        table (dict[str, Any]): PyArrow table\n        schema (pa.schema): PyArrow schema\n        media_dir (Path): Dataset media directory\n        media_features (bool, optional): Load media features like image width and height (slow for large item batches)\n\n    Returns:\n        dict[ItemView]: Dictionary of ItemView\n    \"\"\"\n\n    # NOTE: Potential change to flattened view fields with one row per view\n    item = table.to_pylist()[0] if len(table.to_pylist()) &gt; 0 else None\n    views = {}\n\n    # Iterate on fields\n    for field in schema:\n        # Image\n        if is_image_type(field.type):\n            if item is not None:\n                im = (\n                    item[field.name]\n                    if isinstance(item[field.name], Image)\n                    else Image.from_dict(item[field.name])\n                )\n                im.uri_prefix = media_dir.absolute().as_uri()\n                api_uri = (\n                    (media_dir / im.uri).get_presigned_url()\n                    if isinstance(media_dir, S3Path)\n                    else f\"data/{media_dir.parent.name}/media/{im.uri}\"\n                )\n                image_view = ItemView(\n                    id=field.name,\n                    type=\"image\",\n                    uri=api_uri,\n                    thumbnail=im.preview_url,\n                )\n                image_view.features = {}\n                if media_features:\n                    image_view.features[\"width\"] = ItemFeature(\n                        name=\"width\",\n                        dtype=\"int\",\n                        value=im.width,\n                    )\n\n                    image_view.features[\"height\"] = ItemFeature(\n                        name=\"height\",\n                        dtype=\"int\",\n                        value=im.height,\n                    )\n                views[field.name] = image_view\n            else:\n                views[field.name] = ItemView(id=field.name, type=\"image\", uri=\"\")\n\n        # NOTE: Future support for videos and 3D point clouds\n\n    return views\n</code></pre>"},{"location":"api_reference/models/inference_model/","title":"inference_model","text":""},{"location":"api_reference/models/inference_model/#pixano.models.inference_model","title":"<code>pixano.models.inference_model</code>","text":""},{"location":"api_reference/models/inference_model/#pixano.models.inference_model.InferenceModel","title":"<code>InferenceModel(name, model_id='', device='', description='')</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract parent class for OfflineModel and OnlineModel</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Model name</p> <code>model_id</code> <code>str</code> <p>Model ID</p> <code>device</code> <code>str</code> <p>Model GPU or CPU device</p> <code>description</code> <code>str</code> <p>Model description</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Model name</p> required <code>model_id</code> <code>str</code> <p>Model ID. Defaults to \"\".</p> <code>''</code> <code>device</code> <code>str</code> <p>Model GPU or CPU device. Defaults to \"\".</p> <code>''</code> <code>description</code> <code>str</code> <p>Model description. Defaults to \"\".</p> <code>''</code> Source code in <code>pixano/models/inference_model.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    model_id: str = \"\",\n    device: str = \"\",\n    description: str = \"\",\n) -&gt; None:\n    \"\"\"Initialize model name and ID\n\n    Args:\n        name (str): Model name\n        model_id (str, optional): Model ID. Defaults to \"\".\n        device (str, optional): Model GPU or CPU device. Defaults to \"\".\n        description (str, optional): Model description. Defaults to \"\".\n    \"\"\"\n\n    self.name = name\n    if model_id == \"\":\n        self.model_id = f\"{datetime.now().strftime('%y%m%d_%H%M%S')}_{name}\"\n    else:\n        self.model_id = model_id\n    self.device = device\n    self.description = description\n</code></pre>"},{"location":"api_reference/models/inference_model/#pixano.models.inference_model.InferenceModel.create_table","title":"<code>create_table(process_type, views, dataset)</code>","text":"<p>Create inference table in dataset</p> <p>Parameters:</p> Name Type Description Default <code>process_type</code> <code>str</code> <p>Process type                 - 'pre_ann' for pre-annotations to accept or reject as Ground Truth                 - 'model_run' for annotations to compare to Ground Truth                 - 'segment_emb' for segmentation embeddings                 - 'search_emb' for semantic search embeddings</p> required <code>views</code> <code>list[str]</code> <p>Dataset views</p> required <code>dataset</code> <code>Dataset</code> <p>Dataset</p> required <p>Returns:</p> Type Description <code>DatasetTable</code> <p>Inference table</p> Source code in <code>pixano/models/inference_model.py</code> <pre><code>def create_table(\n    self,\n    process_type: str,\n    views: list[str],\n    dataset: Dataset,\n) -&gt; DatasetTable:\n    \"\"\"Create inference table in dataset\n\n    Args:\n        process_type (str): Process type\n                            - 'pre_ann' for pre-annotations to accept or reject as Ground Truth\n                            - 'model_run' for annotations to compare to Ground Truth\n                            - 'segment_emb' for segmentation embeddings\n                            - 'search_emb' for semantic search embeddings\n        views (list[str]): Dataset views\n        dataset (Dataset): Dataset\n\n    Returns:\n        DatasetTable: Inference table\n    \"\"\"\n    table = None\n    table_group = None\n\n    # Inference table filename\n    table_filename = (\n        f\"emb_{self.model_id}\" if \"emb\" in process_type else f\"obj_{self.model_id}\"\n    )\n\n    # Annotations schema\n    if process_type in [\"pre_ann\", \"model_run\"]:\n        table_group = \"objects\"\n        # Create table\n        table = DatasetTable(\n            name=table_filename,\n            fields={\n                \"id\": \"str\",\n                \"item_id\": \"str\",\n                \"view_id\": \"str\",\n                \"bbox\": \"bbox\",\n                \"mask\": \"compressedrle\",\n                \"category\": \"str\",\n            },\n            source=self.name if process_type == \"model_run\" else \"Pre-annotation\",\n            type=None,\n        )\n    # Segmentation embeddings schema\n    elif process_type == \"segment_emb\":\n        table_group = \"embeddings\"\n        # Add embedding column for each selected view\n        fields = {\"id\": \"str\"}\n        for view in views:\n            fields[view] = \"bytes\"\n        # Create table\n        table = DatasetTable(\n            name=table_filename,\n            fields=fields,\n            source=self.name,\n            type=\"segment\",\n        )\n\n    # Semantic search embeddings schema\n    elif process_type == \"search_emb\":\n        table_group = \"embeddings\"\n        # Add vector column for each selected view\n        fields = {\"id\": \"str\"}\n        for view in views:\n            fields[view] = \"vector(512)\"\n        # Create table\n        table = DatasetTable(\n            name=table_filename,\n            fields=fields,\n            source=self.name,\n            type=\"search\",\n        )\n\n    # Create table\n    if table and table_group:\n        dataset.create_table(table, table_group)\n\n    return table\n</code></pre>"},{"location":"api_reference/models/inference_model/#pixano.models.inference_model.InferenceModel.export_to_onnx","title":"<code>export_to_onnx(library_dir)</code>","text":"<p>Export Torch model to ONNX</p> <p>Parameters:</p> Name Type Description Default <code>library_dir</code> <code>Path</code> <p>Dataset library directory</p> required Source code in <code>pixano/models/inference_model.py</code> <pre><code>def export_to_onnx(self, library_dir: Path):\n    \"\"\"Export Torch model to ONNX\n\n    Args:\n        library_dir (Path): Dataset library directory\n    \"\"\"\n</code></pre>"},{"location":"api_reference/models/inference_model/#pixano.models.inference_model.InferenceModel.preannotate","title":"<code>preannotate(batch, views, uri_prefix, threshold=0.0, prompt='')</code>","text":"<p>Generate annotations for dataset rows</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>RecordBatch</code> <p>Input batch</p> required <code>views</code> <code>list[str]</code> <p>Dataset views</p> required <code>uri_prefix</code> <code>str</code> <p>URI prefix for media files</p> required <code>threshold</code> <code>float</code> <p>Confidence threshold. Defaults to 0.0.</p> <code>0.0</code> <code>prompt</code> <code>str</code> <p>Annotation text prompt. Defaults to \"\".</p> <code>''</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>Annotation rows</p> Source code in <code>pixano/models/inference_model.py</code> <pre><code>def preannotate(\n    self,\n    batch: pa.RecordBatch,\n    views: list[str],\n    uri_prefix: str,\n    threshold: float = 0.0,\n    prompt: str = \"\",\n) -&gt; list[dict]:\n    \"\"\"Generate annotations for dataset rows\n\n    Args:\n        batch (pa.RecordBatch): Input batch\n        views (list[str]): Dataset views\n        uri_prefix (str): URI prefix for media files\n        threshold (float, optional): Confidence threshold. Defaults to 0.0.\n        prompt (str, optional): Annotation text prompt. Defaults to \"\".\n\n    Returns:\n        list[dict]: Annotation rows\n    \"\"\"\n</code></pre>"},{"location":"api_reference/models/inference_model/#pixano.models.inference_model.InferenceModel.precompute_embeddings","title":"<code>precompute_embeddings(batch, views, uri_prefix)</code>","text":"<p>Precompute embeddings for dataset rows</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>RecordBatch</code> <p>Input batch</p> required <code>views</code> <code>list[str]</code> <p>Dataset views</p> required <code>uri_prefix</code> <code>str</code> <p>URI prefix for media files</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>Embedding rows</p> Source code in <code>pixano/models/inference_model.py</code> <pre><code>def precompute_embeddings(\n    self,\n    batch: pa.RecordBatch,\n    views: list[str],\n    uri_prefix: str,\n) -&gt; list[dict]:\n    \"\"\"Precompute embeddings for dataset rows\n\n    Args:\n        batch (pa.RecordBatch): Input batch\n        views (list[str]): Dataset views\n        uri_prefix (str): URI prefix for media files\n\n    Returns:\n        list[dict]: Embedding rows\n    \"\"\"\n</code></pre>"},{"location":"api_reference/models/inference_model/#pixano.models.inference_model.InferenceModel.process_dataset","title":"<code>process_dataset(dataset_dir, views, process_type, splits=None, batch_size=1, threshold=0.0, prompt='')</code>","text":"<p>Process dataset for annotations or embeddings</p> <p>Parameters:</p> Name Type Description Default <code>dataset_dir</code> <code>Path</code> <p>Dataset directory</p> required <code>views</code> <code>list[str]</code> <p>Dataset views</p> required <code>process_type</code> <code>str</code> <p>Process type                 - 'pre_ann' for pre-annotations to accept or reject as Ground Truth                 - 'model_run' for annotations to compare to Ground Truth                 - 'segment_emb' for segmentation embeddings                 - 'search_emb' for semantic search embeddings</p> required <code>splits</code> <code>list[str]</code> <p>Dataset splits, all if None. Defaults to None.</p> <code>None</code> <code>batch_size</code> <code>int</code> <p>Rows per process batch. Defaults to 1.</p> <code>1</code> <code>threshold</code> <code>float</code> <p>Confidence threshold for predictions. Defaults to 0.0.</p> <code>0.0</code> <code>prompt</code> <code>str</code> <p>Annotation text prompt. Defaults to \"\".</p> <code>''</code> <p>Returns:</p> Type Description <code>Dataset</code> <p>Dataset</p> Source code in <code>pixano/models/inference_model.py</code> <pre><code>def process_dataset(\n    self,\n    dataset_dir: Path,\n    views: list[str],\n    process_type: str,\n    splits: list[str] = None,\n    batch_size: int = 1,\n    threshold: float = 0.0,\n    prompt: str = \"\",\n) -&gt; Dataset:\n    \"\"\"Process dataset for annotations or embeddings\n\n    Args:\n        dataset_dir (Path): Dataset directory\n        views (list[str]): Dataset views\n        process_type (str): Process type\n                            - 'pre_ann' for pre-annotations to accept or reject as Ground Truth\n                            - 'model_run' for annotations to compare to Ground Truth\n                            - 'segment_emb' for segmentation embeddings\n                            - 'search_emb' for semantic search embeddings\n        splits (list[str], optional): Dataset splits, all if None. Defaults to None.\n        batch_size (int, optional): Rows per process batch. Defaults to 1.\n        threshold (float, optional): Confidence threshold for predictions. Defaults to 0.0.\n        prompt (str, optional): Annotation text prompt. Defaults to \"\".\n\n    Returns:\n        Dataset: Dataset\n    \"\"\"\n\n    if process_type not in [\n        \"pre_ann\",\n        \"model_run\",\n        \"segment_emb\",\n        \"search_emb\",\n    ]:\n        raise ValueError(\n            \"Please choose a valid process type\"\n            \"('pre_ann' or 'model_run' for for annotations,\"\n            \"'segment_emb' or 'search_emb' for segmentation or semantic search embeddings)\"\n        )\n\n    if not views:\n        raise ValueError(\"Please select which views you want to process on.\")\n\n    # Load dataset\n    dataset = Dataset(dataset_dir)\n\n    # Create inference table\n    table = self.create_table(process_type, views, dataset)\n\n    # Load dataset tables\n    ds_tables = dataset.open_tables()\n\n    # Load inference table\n    table_group = \"embeddings\" if \"emb\" in process_type else \"objects\"\n    table_lance = ds_tables[table_group][table.name].to_lance()\n\n    # Create URI prefix\n    uri_prefix = dataset.media_dir.absolute().as_uri()\n\n    # Add rows to tables\n    save_batch_size = 1024\n    with tqdm(desc=\"Processing dataset\", total=dataset.num_rows) as progress:\n        for save_batch_index in range(ceil(dataset.num_rows / save_batch_size)):\n            # Load rows\n            process_batches = self._load_rows(\n                dataset,\n                ds_tables,\n                splits,\n                batch_size,\n                save_batch_size,\n                save_batch_index,\n            )\n\n            # Process rows\n            save_batch = []\n            for process_batch in process_batches:\n                save_batch.extend(\n                    self.precompute_embeddings(process_batch, views, uri_prefix)\n                    if \"emb\" in process_type\n                    else self.preannotate(\n                        process_batch, views, uri_prefix, threshold, prompt\n                    )\n                )\n                progress.update(batch_size)\n\n            # Save rows\n            pyarrow_save_batch = pa.Table.from_pylist(\n                save_batch,\n                schema=Fields(table.fields).to_schema(),\n            )\n            lance.write_dataset(\n                pyarrow_save_batch,\n                uri=table_lance.uri,\n                mode=\"append\",\n            )\n\n    # Optimize and clear creation history\n    table_lance.optimize.compact_files()\n    table_lance.cleanup_old_versions(older_than=timedelta(0))\n\n    return dataset\n</code></pre>"},{"location":"api_reference/utils/boxes/","title":"boxes","text":""},{"location":"api_reference/utils/boxes/#pixano.utils.boxes","title":"<code>pixano.utils.boxes</code>","text":""},{"location":"api_reference/utils/boxes/#pixano.utils.boxes.denormalize_coords","title":"<code>denormalize_coords(coord, height, width, rounded_int=True)</code>","text":"<p>Denormalize coordinates</p> <p>Parameters:</p> Name Type Description Default <code>coord</code> <code>list[float]</code> <p>Normalized coordinates</p> required <code>height</code> <code>int</code> <p>Height</p> required <code>width</code> <code>int</code> <p>Width</p> required <code>rounded_int</code> <code>bool</code> <p>True to round denormalized float to nearest integer. Default to True</p> <code>True</code> <p>Returns:</p> Type Description <code>list[float]</code> <p>Unnormalized coordinates,</p> Source code in <code>pixano/utils/boxes.py</code> <pre><code>def denormalize_coords(\n    coord: list[float], height: int, width: int, rounded_int=True\n) -&gt; list[float]:\n    \"\"\"Denormalize coordinates\n\n    Args:\n        coord (list[float]): Normalized coordinates\n        height (int): Height\n        width (int): Width\n        rounded_int (bool): True to round denormalized float to nearest integer. Default to True\n\n    Returns:\n        list[float]: Unnormalized coordinates,\n    \"\"\"\n\n    denorm = []\n\n    for i, c in enumerate(coord):\n        if i % 2 == 0:\n            denorm.append(round(c * width) if rounded_int else c * width)\n        else:\n            denorm.append(round(c * height) if rounded_int else c * height)\n\n    return denorm\n</code></pre>"},{"location":"api_reference/utils/boxes/#pixano.utils.boxes.mask_to_bbox","title":"<code>mask_to_bbox(mask)</code>","text":"<p>Return the smallest bounding box containing all the mask pixels</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>Mask as NumPy Array</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>Normalized xywh bounding box</p> Source code in <code>pixano/utils/boxes.py</code> <pre><code>def mask_to_bbox(mask: np.ndarray) -&gt; list[float]:\n    \"\"\"Return the smallest bounding box containing all the mask pixels\n\n    Args:\n        mask (np.ndarray): Mask as NumPy Array\n\n    Returns:\n        list[float]: Normalized xywh bounding box\n    \"\"\"\n\n    height, width = mask.shape\n    bool_mask = np.array(mask).astype(bool)\n\n    # Find all columns and rows that contain ones\n    rows = np.any(bool_mask, axis=1)\n    cols = np.any(bool_mask, axis=0)\n\n    # Find the min and max col/row index that contain ones\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n\n    # Calculate bbox height and width\n    w = (cmax - cmin + 1) / width\n    h = (rmax - rmin + 1) / height\n\n    return [cmin / width, rmin / height, w, h]\n</code></pre>"},{"location":"api_reference/utils/boxes/#pixano.utils.boxes.normalize_coords","title":"<code>normalize_coords(coord, height, width)</code>","text":"<p>Normalize coordinates</p> <p>Parameters:</p> Name Type Description Default <code>coord</code> <code>list[float]</code> <p>Unnormalized coordinates</p> required <code>height</code> <code>int</code> <p>Height</p> required <code>width</code> <code>int</code> <p>Width</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>Normalized coordinates</p> Source code in <code>pixano/utils/boxes.py</code> <pre><code>def normalize_coords(coord: list[float], height: int, width: int) -&gt; list[float]:\n    \"\"\"Normalize coordinates\n\n    Args:\n        coord (list[float]): Unnormalized coordinates\n        height (int): Height\n        width (int): Width\n\n    Returns:\n        list[float]: Normalized coordinates\n    \"\"\"\n\n    norm = []\n\n    for i, c in enumerate(coord):\n        if i % 2 == 0:\n            norm.append(c / width)\n        else:\n            norm.append(c / height)\n\n    return norm\n</code></pre>"},{"location":"api_reference/utils/boxes/#pixano.utils.boxes.urle_to_bbox","title":"<code>urle_to_bbox(urle)</code>","text":"<p>Return the smallest bounding box containing all the mask pixels</p> <p>Parameters:</p> Name Type Description Default <code>urle</code> <code>dict</code> <p>Mask as uncompressed RLE</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>Normalized xywh bounding box</p> Source code in <code>pixano/utils/boxes.py</code> <pre><code>def urle_to_bbox(urle: dict) -&gt; list[float]:\n    \"\"\"Return the smallest bounding box containing all the mask pixels\n\n    Args:\n        urle (dict): Mask as uncompressed RLE\n\n    Returns:\n        list[float]: Normalized xywh bounding box\n    \"\"\"\n\n    return mask_to_bbox(rle_to_mask(urle_to_rle(urle)))\n</code></pre>"},{"location":"api_reference/utils/boxes/#pixano.utils.boxes.xywh_to_xyxy","title":"<code>xywh_to_xyxy(xywh)</code>","text":"<p>Convert bounding box coordinates from xywh (using top left point as reference) to xyxy</p> <p>Parameters:</p> Name Type Description Default <code>xywh</code> <code>list[float]</code> <p>xywh coordinates</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>xyxy coordinates</p> Source code in <code>pixano/utils/boxes.py</code> <pre><code>def xywh_to_xyxy(xywh: list[float]) -&gt; list[float]:\n    \"\"\"Convert bounding box coordinates from xywh (using top left point as reference) to xyxy\n\n    Args:\n        xywh (list[float]): xywh coordinates\n\n    Returns:\n        list[float]: xyxy coordinates\n    \"\"\"\n\n    return [\n        float(xywh[0]),\n        float(xywh[1]),\n        float(xywh[0] + xywh[2]),\n        float(xywh[1] + xywh[3]),\n    ]\n</code></pre>"},{"location":"api_reference/utils/boxes/#pixano.utils.boxes.xyxy_to_xywh","title":"<code>xyxy_to_xywh(xyxy)</code>","text":"<p>Convert bounding box coordinates from xyxy to xywh (using top left point as reference)</p> <p>Parameters:</p> Name Type Description Default <code>xyxy</code> <code>list[float]</code> <p>xyxy coordinates</p> required <p>Returns:</p> Type Description <code>list[float]</code> <p>xywh coordinates</p> Source code in <code>pixano/utils/boxes.py</code> <pre><code>def xyxy_to_xywh(xyxy: list[float]) -&gt; list[float]:\n    \"\"\"Convert bounding box coordinates from xyxy to xywh (using top left point as reference)\n\n    Args:\n        xyxy (list[float]): xyxy coordinates\n\n    Returns:\n        list[float]: xywh coordinates\n    \"\"\"\n\n    return [\n        float(xyxy[0]),\n        float(xyxy[1]),\n        float(xyxy[2] - xyxy[0]),\n        float(xyxy[3] - xyxy[1]),\n    ]\n</code></pre>"},{"location":"api_reference/utils/image/","title":"image","text":""},{"location":"api_reference/utils/image/#pixano.utils.image","title":"<code>pixano.utils.image</code>","text":""},{"location":"api_reference/utils/image/#pixano.utils.image.binary_to_url","title":"<code>binary_to_url(im_bytes)</code>","text":"<p>Encode image from binary to base 64 URL</p> <p>Parameters:</p> Name Type Description Default <code>im_bytes</code> <code>bytes</code> <p>Image as binary</p> required <p>Returns:</p> Type Description <code>str</code> <p>Image base 64 URL</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def binary_to_url(im_bytes: bytes) -&gt; str:\n    \"\"\"Encode image from binary to base 64 URL\n\n    Args:\n        im_bytes (bytes): Image as binary\n\n    Returns:\n        str: Image base 64 URL\n    \"\"\"\n\n    if im_bytes is not None:\n        encoded = base64.b64encode(im_bytes).decode(\"utf-8\")\n        return f\"data:image;base64,{encoded}\"\n    return \"\"\n</code></pre>"},{"location":"api_reference/utils/image/#pixano.utils.image.depth_array_to_gray","title":"<code>depth_array_to_gray(depth, valid_start=0.2, valid_end=1, scale=1.0)</code>","text":"<p>Encode depth array to gray levels</p> <p>Parameters:</p> Name Type Description Default <code>depth</code> <code>ndarray</code> <p>Depth array</p> required <code>valid_start</code> <code>float</code> <p>Valid start. Defaults to 0.2.</p> <code>0.2</code> <code>valid_end</code> <code>float</code> <p>Valid end. Defaults to 1.</p> <code>1</code> <code>scale</code> <code>float</code> <p>Scale. Defaults to 1.0.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Depth array in gray levels</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def depth_array_to_gray(\n    depth: np.ndarray,\n    valid_start: float = 0.2,\n    valid_end: float = 1,\n    scale: float = 1.0,\n) -&gt; np.ndarray:\n    \"\"\"Encode depth array to gray levels\n\n    Args:\n        depth (np.ndarray): Depth array\n        valid_start (float, optional): Valid start. Defaults to 0.2.\n        valid_end (float, optional): Valid end. Defaults to 1.\n        scale (float, optional): Scale. Defaults to 1.0.\n\n    Returns:\n        np.ndarray: Depth array in gray levels\n    \"\"\"\n\n    mask = depth &gt; 1\n\n    # Scale gives depth in mm\n    depth_n = depth * scale * 0.001\n\n    if mask.sum() &gt; 0:\n        depth_n[mask] -= depth_n[mask].min()\n        depth_n[mask] /= depth_n[mask].max() / (valid_end - valid_start)\n        depth_n[mask] += valid_start\n\n    depth_n *= 255\n    depth_n = cv2.applyColorMap(\n        depth_n[:, :, np.newaxis].astype(np.uint8), cv2.COLORMAP_PLASMA\n    )\n\n    return depth_n\n</code></pre>"},{"location":"api_reference/utils/image/#pixano.utils.image.depth_file_to_binary","title":"<code>depth_file_to_binary(depth_path)</code>","text":"<p>Encode depth file to RGB image in binary</p> <p>Parameters:</p> Name Type Description Default <code>depth_path</code> <code>str</code> <p>Depth file path</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>Depth file as RGB image in binary</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def depth_file_to_binary(depth_path: str) -&gt; bytes:\n    \"\"\"Encode depth file to RGB image in binary\n\n    Args:\n        depth_path (str): Depth file path\n\n    Returns:\n        bytes: Depth file as RGB image in binary\n    \"\"\"\n\n    depth = cv2.imread(depth_path, cv2.IMREAD_ANYDEPTH).astype(np.float32)\n    depth = depth_array_to_gray(depth)\n    depth_rgb = Image.fromarray(depth)\n\n    return image_to_binary(depth_rgb)\n</code></pre>"},{"location":"api_reference/utils/image/#pixano.utils.image.encode_rle","title":"<code>encode_rle(mask, height, width)</code>","text":"<p>Encode mask from polygons / uncompressed RLE / RLE to RLE</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>list[list] | dict</code> <p>Mask as polygons / uncompressed RLE / RLE</p> required <code>height</code> <code>int</code> <p>Image height</p> required <code>width</code> <code>int</code> <p>Image width</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Mask as RLE</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def encode_rle(mask: list[list] | dict, height: int, width: int) -&gt; dict:\n    \"\"\"Encode mask from polygons / uncompressed RLE / RLE to RLE\n\n    Args:\n        mask (list[list] | dict): Mask as polygons / uncompressed RLE / RLE\n        height (int): Image height\n        width (int): Image width\n\n    Returns:\n        dict: Mask as RLE\n    \"\"\"\n\n    if isinstance(mask, list):\n        return polygons_to_rle(mask, height, width)\n    if isinstance(mask, dict):\n        if isinstance(mask[\"counts\"], list):\n            return urle_to_rle(mask)\n        return mask\n    return None\n</code></pre>"},{"location":"api_reference/utils/image/#pixano.utils.image.image_to_binary","title":"<code>image_to_binary(image, im_format='PNG')</code>","text":"<p>Encode image from Pillow to binary</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Image</code> <p>Image as Pillow</p> required <code>im_format</code> <code>str</code> <p>Image file extension. Defaults to \"PNG\".</p> <code>'PNG'</code> <p>Returns:</p> Type Description <code>bytes</code> <p>Image as binary</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def image_to_binary(image: Image.Image, im_format: str = \"PNG\") -&gt; bytes:\n    \"\"\"Encode image from Pillow to binary\n\n    Args:\n        image (Image.Image): Image as Pillow\n        im_format (str, optional): Image file extension. Defaults to \"PNG\".\n\n    Returns:\n        bytes: Image as binary\n    \"\"\"\n\n    if image is None:\n        return None\n\n    with BytesIO() as output_bytes:\n        image.save(output_bytes, im_format)\n        im_bytes = output_bytes.getvalue()\n\n    return im_bytes\n</code></pre>"},{"location":"api_reference/utils/image/#pixano.utils.image.image_to_thumbnail","title":"<code>image_to_thumbnail(image)</code>","text":"<p>Generate image thumbnail</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>bytes | Image</code> <p>Image as binary or as Pillow</p> required <p>Returns:</p> Type Description <code>bytes</code> <p>Image thumbnail as binary</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def image_to_thumbnail(image: bytes | Image.Image) -&gt; bytes:\n    \"\"\"Generate image thumbnail\n\n    Args:\n        image (bytes | Image.Image): Image as binary or as Pillow\n\n    Returns:\n        bytes: Image thumbnail as binary\n    \"\"\"\n\n    if isinstance(image, bytes):\n        image = Image.open(BytesIO(image))\n\n    image.thumbnail((128, 128))\n    return image_to_binary(image)\n</code></pre>"},{"location":"api_reference/utils/image/#pixano.utils.image.mask_to_polygons","title":"<code>mask_to_polygons(mask)</code>","text":"<p>Encode mask from NumPy array to polygons</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>ndarray</code> <p>Mask as NumPy array</p> required <p>Returns:</p> Type Description <code>list[list]</code> <p>Mask as polygons</p> <code>bool</code> <p>True if mask has holes</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def mask_to_polygons(mask: np.ndarray) -&gt; tuple[list[list], bool]:\n    \"\"\"Encode mask from NumPy array to polygons\n\n    Args:\n        mask (np.ndarray): Mask as NumPy array\n\n    Returns:\n        list[list]: Mask as polygons\n        bool: True if mask has holes\n    \"\"\"\n\n    if mask is not None:\n        # Some versions of cv2 does not support incontiguous arr\n        mask = np.ascontiguousarray(mask)\n\n        # cv2.RETR_CCOMP flag retrieves all the contours and arranges them to a 2-level hierarchy.\n        # External contours (boundary) of the object are placed in hierarchy-1.\n        # Internal contours (holes) are placed in hierarchy-2.\n        # cv2.CHAIN_APPROX_NONE flag gets vertices of polygons from contours.\n        res = cv2.findContours(\n            mask.astype(\"uint8\"), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE\n        )\n        hierarchy = res[-1]\n\n        # If mask is empty\n        if hierarchy is None:\n            return [], False\n\n        # Check if mask has holes\n        has_holes = (hierarchy.reshape(-1, 4)[:, 3] &gt;= 0).sum() &gt; 0\n\n        res = res[-2]\n        res = [x.flatten() for x in res]\n\n        # The coordinates from OpenCV are integers in range [0, W-1 or H-1].\n        # We add 0.5 to turn them into real-value coordinate space. A better solution\n        # would be to first +0.5 and then dilate the returned polygon by 0.5.\n        res = [x + 0.5 for x in res if len(x) &gt;= 6]\n\n        # Convert np.array to lists\n        res = [x.tolist() for x in res]\n\n        return res, has_holes\n\n    return [], False\n</code></pre>"},{"location":"api_reference/utils/image/#pixano.utils.image.mask_to_rle","title":"<code>mask_to_rle(mask)</code>","text":"<p>Encode mask from Pillow or NumPy array to RLE</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>Image</code> <p>Mask as Pillow or NumPy array</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Mask as RLE</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def mask_to_rle(mask: Image.Image) -&gt; dict:\n    \"\"\"Encode mask from Pillow or NumPy array to RLE\n\n    Args:\n        mask (Image.Image): Mask as Pillow or NumPy array\n\n    Returns:\n        dict: Mask as RLE\n    \"\"\"\n\n    if mask is not None:\n        mask_array = np.asfortranarray(mask)\n        return mask_api.encode(mask_array)\n    return None\n</code></pre>"},{"location":"api_reference/utils/image/#pixano.utils.image.polygons_to_rle","title":"<code>polygons_to_rle(polygons, height, width)</code>","text":"<p>Encode mask from polygons to RLE</p> <p>Parameters:</p> Name Type Description Default <code>polygons</code> <code>list[list]</code> <p>Mask as polygons</p> required <code>height</code> <code>int</code> <p>Image height</p> required <code>width</code> <code>int</code> <p>Image width</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Mask as RLE</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def polygons_to_rle(polygons: list[list], height: int, width: int) -&gt; dict:\n    \"\"\"Encode mask from polygons to RLE\n\n    Args:\n        polygons (list[list]): Mask as polygons\n        height (int): Image height\n        width (int): Image width\n\n    Returns:\n        dict: Mask as RLE\n    \"\"\"\n\n    if polygons is not None:\n        rles = mask_api.frPyObjects(polygons, height, width)\n        return mask_api.merge(rles)\n    return None\n</code></pre>"},{"location":"api_reference/utils/image/#pixano.utils.image.rle_to_mask","title":"<code>rle_to_mask(rle)</code>","text":"<p>Decode mask from RLE to NumPy array</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>dict[str, list[int] | bytes]</code> <p>Mask as RLE</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Mask as NumPy array</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def rle_to_mask(rle: dict[str, list[int] | bytes]) -&gt; np.ndarray:\n    \"\"\"Decode mask from RLE to NumPy array\n\n    Args:\n        rle (dict[str, list[int] | bytes]): Mask as RLE\n\n    Returns:\n        np.ndarray: Mask as NumPy array\n    \"\"\"\n\n    if rle is not None:\n        return mask_api.decode(rle)\n    return None\n</code></pre>"},{"location":"api_reference/utils/image/#pixano.utils.image.rle_to_polygons","title":"<code>rle_to_polygons(rle)</code>","text":"<p>Encode mask from RLE to polygons</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>dict[str, list[int] | bytes]</code> <p>Mask as RLE</p> required <p>Returns:</p> Type Description <code>list[list]</code> <p>Mask as polygons</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def rle_to_polygons(rle: dict[str, list[int] | bytes]) -&gt; list[list]:\n    \"\"\"Encode mask from RLE to polygons\n\n    Args:\n        rle (dict[str, list[int] | bytes]): Mask as RLE\n\n    Returns:\n        list[list]: Mask as polygons\n    \"\"\"\n\n    if rle is not None and \"size\" in rle:\n        h, w = rle[\"size\"]\n        polygons, _ = mask_to_polygons(rle_to_mask(rle))\n\n        # Normalize point coordinates\n        for p in polygons:\n            p[::2] = [x / w for x in p[::2]]\n            p[1::2] = [y / h for y in p[1::2]]\n\n        return polygons\n    return None\n</code></pre>"},{"location":"api_reference/utils/image/#pixano.utils.image.rle_to_urle","title":"<code>rle_to_urle(rle)</code>","text":"<p>Encode mask from RLE to uncompressed RLE</p> <p>Parameters:</p> Name Type Description Default <code>rle</code> <code>dict[str, list[int] | bytes]</code> <p>Mask as RLE</p> required <p>Returns:</p> Type Description <code>dict[str, list[int]]</code> <p>Mask as uncompressed RLE</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def rle_to_urle(rle: dict[str, list[int] | bytes]) -&gt; dict[str, list[int]]:\n    \"\"\"Encode mask from RLE to uncompressed RLE\n\n    Args:\n        rle (dict[str, list[int] | bytes]): Mask as RLE\n\n    Returns:\n        dict[str, list[int]]: Mask as uncompressed RLE\n    \"\"\"\n\n    if rle is not None and rle[\"counts\"] is not None:\n        mask = rle_to_mask(rle)\n        urle = {\"counts\": [], \"size\": list(mask.shape)}\n\n        for i, (value, elements) in enumerate(groupby(mask.ravel(order=\"F\"))):\n            urle[\"counts\"].append(0 if i == 0 and value == 1 else len(list(elements)))\n\n        return urle\n    return None\n</code></pre>"},{"location":"api_reference/utils/image/#pixano.utils.image.urle_to_rle","title":"<code>urle_to_rle(urle)</code>","text":"<p>Encode mask from uncompressed RLE to RLE</p> <p>Parameters:</p> Name Type Description Default <code>urle</code> <code>dict[str, list[int]]</code> <p>Mask as uncompressed RLE</p> required <p>Returns:</p> Type Description <code>dict[str, list[int] | bytes]</code> <p>Mask as RLE</p> Source code in <code>pixano/utils/image.py</code> <pre><code>def urle_to_rle(urle: dict[str, list[int]]) -&gt; dict[str, list[int] | bytes]:\n    \"\"\"Encode mask from uncompressed RLE to RLE\n\n    Args:\n        urle (dict[str, list[int]]): Mask as uncompressed RLE\n\n    Returns:\n        dict[str, list[int] | bytes]: Mask as RLE\n    \"\"\"\n\n    if urle is not None:\n        height, width = urle[\"size\"]\n        return mask_api.frPyObjects(urle, height, width)\n    return None\n</code></pre>"},{"location":"api_reference/utils/labels/","title":"labels","text":""},{"location":"api_reference/utils/labels/#pixano.utils.labels","title":"<code>pixano.utils.labels</code>","text":""},{"location":"api_reference/utils/labels/#pixano.utils.labels.coco_ids_80to91","title":"<code>coco_ids_80to91(cat_id)</code>","text":"<p>Return COCO category ID (80 to 91 classes)</p> <p>Parameters:</p> Name Type Description Default <code>cat_id</code> <code>int</code> <p>Category ID (80 classes)</p> required <p>Returns:</p> Type Description <code>int</code> <p>Category ID (91 classes)</p> Source code in <code>pixano/utils/labels.py</code> <pre><code>def coco_ids_80to91(cat_id: int) -&gt; int:\n    \"\"\"Return COCO category ID (80 to 91 classes)\n\n    Args:\n        cat_id (int): Category ID (80 classes)\n\n    Returns:\n        int: Category ID (91 classes)\n    \"\"\"\n\n    coco_dict = {\n        1: 1,\n        2: 2,\n        3: 3,\n        4: 4,\n        5: 5,\n        6: 6,\n        7: 7,\n        8: 8,\n        9: 9,\n        10: 10,\n        11: 11,\n        12: 13,\n        13: 14,\n        14: 15,\n        15: 16,\n        16: 17,\n        17: 18,\n        18: 19,\n        19: 20,\n        20: 21,\n        21: 22,\n        22: 23,\n        23: 24,\n        24: 25,\n        25: 27,\n        26: 28,\n        27: 31,\n        28: 32,\n        29: 33,\n        30: 34,\n        31: 35,\n        32: 36,\n        33: 37,\n        34: 38,\n        35: 39,\n        36: 40,\n        37: 41,\n        38: 42,\n        39: 43,\n        40: 44,\n        41: 46,\n        42: 47,\n        43: 48,\n        44: 49,\n        45: 50,\n        46: 51,\n        47: 52,\n        48: 53,\n        49: 54,\n        50: 55,\n        51: 56,\n        52: 57,\n        53: 58,\n        54: 59,\n        55: 60,\n        56: 61,\n        57: 62,\n        58: 63,\n        59: 64,\n        60: 65,\n        61: 67,\n        62: 70,\n        63: 72,\n        64: 73,\n        65: 74,\n        66: 75,\n        67: 76,\n        68: 77,\n        69: 78,\n        70: 79,\n        71: 80,\n        72: 81,\n        73: 82,\n        74: 84,\n        75: 85,\n        76: 86,\n        77: 87,\n        78: 88,\n        79: 89,\n        80: 90,\n    }\n\n    return coco_dict[int(cat_id)]\n</code></pre>"},{"location":"api_reference/utils/labels/#pixano.utils.labels.coco_names_80","title":"<code>coco_names_80(cat_id)</code>","text":"<p>Return COCO category name (80 classes)</p> <p>Parameters:</p> Name Type Description Default <code>cat_id</code> <code>int</code> <p>Category ID</p> required <p>Returns:</p> Type Description <code>str</code> <p>Category name</p> Source code in <code>pixano/utils/labels.py</code> <pre><code>def coco_names_80(cat_id: int) -&gt; str:\n    \"\"\"Return COCO category name (80 classes)\n\n    Args:\n        cat_id (int): Category ID\n\n    Returns:\n        str: Category name\n    \"\"\"\n\n    coco_dict = {\n        1: \"person\",\n        2: \"bicycle\",\n        3: \"car\",\n        4: \"motorcycle\",\n        5: \"airplane\",\n        6: \"bus\",\n        7: \"train\",\n        8: \"truck\",\n        9: \"boat\",\n        10: \"traffic light\",\n        11: \"fire hydrant\",\n        12: \"stop sign\",\n        13: \"parking meter\",\n        14: \"bench\",\n        15: \"bird\",\n        16: \"cat\",\n        17: \"dog\",\n        18: \"horse\",\n        19: \"sheep\",\n        20: \"cow\",\n        21: \"elephant\",\n        22: \"bear\",\n        23: \"zebra\",\n        24: \"giraffe\",\n        25: \"backpack\",\n        26: \"umbrella\",\n        27: \"handbag\",\n        28: \"tie\",\n        29: \"suitcase\",\n        30: \"frisbee\",\n        31: \"skis\",\n        32: \"snowboard\",\n        33: \"sports ball\",\n        34: \"kite\",\n        35: \"baseball bat\",\n        36: \"baseball glove\",\n        37: \"skateboard\",\n        38: \"surfboard\",\n        39: \"tennis racket\",\n        40: \"bottle\",\n        41: \"wine glass\",\n        42: \"cup\",\n        43: \"fork\",\n        44: \"knife\",\n        45: \"spoon\",\n        46: \"bowl\",\n        47: \"banana\",\n        48: \"apple\",\n        49: \"sandwich\",\n        50: \"orange\",\n        51: \"broccoli\",\n        52: \"carrot\",\n        53: \"hot dog\",\n        54: \"pizza\",\n        55: \"donut\",\n        56: \"cake\",\n        57: \"chair\",\n        58: \"couch\",\n        59: \"potted plant\",\n        60: \"bed\",\n        61: \"dining table\",\n        62: \"toilet\",\n        63: \"tv\",\n        64: \"laptop\",\n        65: \"mouse\",\n        66: \"remote\",\n        67: \"keyboard\",\n        68: \"cell phone\",\n        69: \"microwave\",\n        70: \"oven\",\n        71: \"toaster\",\n        72: \"sink\",\n        73: \"refrigerator\",\n        74: \"book\",\n        75: \"clock\",\n        76: \"vase\",\n        77: \"scissors\",\n        78: \"teddy bear\",\n        79: \"hair drier\",\n        80: \"toothbrush\",\n    }\n\n    return coco_dict[int(cat_id)]\n</code></pre>"},{"location":"api_reference/utils/labels/#pixano.utils.labels.coco_names_91","title":"<code>coco_names_91(cat_id)</code>","text":"<p>Return COCO category name (91 classes)</p> <p>Parameters:</p> Name Type Description Default <code>cat_id</code> <code>int</code> <p>Category ID</p> required <p>Returns:</p> Type Description <code>str</code> <p>Category name</p> Source code in <code>pixano/utils/labels.py</code> <pre><code>def coco_names_91(cat_id: int) -&gt; str:\n    \"\"\"Return COCO category name (91 classes)\n\n    Args:\n        cat_id (int): Category ID\n\n    Returns:\n        str: Category name\n    \"\"\"\n\n    coco_dict = {\n        1: \"person\",\n        2: \"bicycle\",\n        3: \"car\",\n        4: \"motorcycle\",\n        5: \"airplane\",\n        6: \"bus\",\n        7: \"train\",\n        8: \"truck\",\n        9: \"boat\",\n        10: \"traffic light\",\n        11: \"fire hydrant\",\n        12: \"street sign\",\n        13: \"stop sign\",\n        14: \"parking meter\",\n        15: \"bench\",\n        16: \"bird\",\n        17: \"cat\",\n        18: \"dog\",\n        19: \"horse\",\n        20: \"sheep\",\n        21: \"cow\",\n        22: \"elephant\",\n        23: \"bear\",\n        24: \"zebra\",\n        25: \"giraffe\",\n        26: \"hat\",\n        27: \"backpack\",\n        28: \"umbrella\",\n        29: \"shoe\",\n        30: \"eye glasses\",\n        31: \"handbag\",\n        32: \"tie\",\n        33: \"suitcase\",\n        34: \"frisbee\",\n        35: \"skis\",\n        36: \"snowboard\",\n        37: \"sports ball\",\n        38: \"kite\",\n        39: \"baseball bat\",\n        40: \"baseball glove\",\n        41: \"skateboard\",\n        42: \"surfboard\",\n        43: \"tennis racket\",\n        44: \"bottle\",\n        45: \"plate\",\n        46: \"wine glass\",\n        47: \"cup\",\n        48: \"fork\",\n        49: \"knife\",\n        50: \"spoon\",\n        51: \"bowl\",\n        52: \"banana\",\n        53: \"apple\",\n        54: \"sandwich\",\n        55: \"orange\",\n        56: \"broccoli\",\n        57: \"carrot\",\n        58: \"hot dog\",\n        59: \"pizza\",\n        60: \"donut\",\n        61: \"cake\",\n        62: \"chair\",\n        63: \"couch\",\n        64: \"potted plant\",\n        65: \"bed\",\n        66: \"mirror\",\n        67: \"dining table\",\n        68: \"window\",\n        69: \"desk\",\n        70: \"toilet\",\n        71: \"door\",\n        72: \"tv\",\n        73: \"laptop\",\n        74: \"mouse\",\n        75: \"remote\",\n        76: \"keyboard\",\n        77: \"cell phone\",\n        78: \"microwave\",\n        79: \"oven\",\n        80: \"toaster\",\n        81: \"sink\",\n        82: \"refrigerator\",\n        83: \"blender\",\n        84: \"book\",\n        85: \"clock\",\n        86: \"vase\",\n        87: \"scissors\",\n        88: \"teddy bear\",\n        89: \"hair drier\",\n        90: \"toothbrush\",\n        91: \"hair brush\",\n    }\n\n    return coco_dict[int(cat_id)]\n</code></pre>"},{"location":"api_reference/utils/labels/#pixano.utils.labels.dota_ids","title":"<code>dota_ids(name)</code>","text":"<p>Return DOTAv2 category ID (18 classes)</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>int</code> <p>Category name</p> required <p>Returns:</p> Type Description <code>str</code> <p>Category ID</p> Source code in <code>pixano/utils/labels.py</code> <pre><code>def dota_ids(name: str) -&gt; int:\n    \"\"\"Return DOTAv2 category ID (18 classes)\n\n    Args:\n        name (int): Category name\n\n    Returns:\n        str: Category ID\n    \"\"\"\n\n    dota_dict = {\n        \"plane\": 1,\n        \"ship\": 2,\n        \"storage tank\": 3,\n        \"baseball diamond\": 4,\n        \"tennis court\": 5,\n        \"basketball court\": 6,\n        \"ground track field\": 7,\n        \"harbor\": 8,\n        \"bridge\": 9,\n        \"large vehicle\": 10,\n        \"small vehicle\": 11,\n        \"helicopter\": 12,\n        \"roundabout\": 13,\n        \"soccer ball field\": 14,\n        \"swimming pool\": 15,\n        \"container crane\": 16,\n        \"airport\": 17,\n        \"helipad\": 18,\n    }\n\n    return dota_dict[str(name).replace(\"-\", \" \")]\n</code></pre>"},{"location":"api_reference/utils/labels/#pixano.utils.labels.voc_names","title":"<code>voc_names(cat_id)</code>","text":"<p>Return VOC category name (20 classes)</p> <p>Parameters:</p> Name Type Description Default <code>cat_id</code> <code>int</code> <p>Category ID</p> required <p>Returns:</p> Type Description <code>str</code> <p>Category name</p> Source code in <code>pixano/utils/labels.py</code> <pre><code>def voc_names(cat_id: int) -&gt; str:\n    \"\"\"Return VOC category name (20 classes)\n\n    Args:\n        cat_id (int): Category ID\n\n    Returns:\n        str: Category name\n    \"\"\"\n\n    voc_dict = {\n        1: \"aeroplane\",\n        2: \"bicycle\",\n        3: \"bird\",\n        4: \"boat\",\n        5: \"bottle\",\n        6: \"bus\",\n        7: \"car\",\n        8: \"cat\",\n        9: \"chair\",\n        10: \"cow\",\n        11: \"dining table\",\n        12: \"dog\",\n        13: \"horse\",\n        14: \"motorbike\",\n        15: \"person\",\n        16: \"potted plant\",\n        17: \"sheep\",\n        18: \"sofa\",\n        19: \"train\",\n        20: \"tv / monitor\",\n    }\n\n    return voc_dict[int(cat_id)]\n</code></pre>"},{"location":"api_reference/utils/python/","title":"python","text":""},{"location":"api_reference/utils/python/#pixano.utils.python","title":"<code>pixano.utils.python</code>","text":""},{"location":"api_reference/utils/python/#pixano.utils.python.estimate_size","title":"<code>estimate_size(folder_path)</code>","text":"<p>Estimate folder size and return it as a human-readable string</p> <p>Parameters:</p> Name Type Description Default <code>folder_path</code> <code>Path</code> <p>Folder path</p> required <p>Returns:</p> Type Description <code>str</code> <p>Folder size as a human-readable string</p> Source code in <code>pixano/utils/python.py</code> <pre><code>def estimate_size(folder_path: Path) -&gt; str:\n    \"\"\"Estimate folder size and return it as a human-readable string\n\n    Args:\n        folder_path (Path): Folder path\n\n    Returns:\n        str: Folder size as a human-readable string\n    \"\"\"\n\n    # Estimate size\n    total_size = 0\n    for dirpath, _, filenames in os.walk(folder_path):\n        for f in filenames:\n            fp = os.path.join(dirpath, f)\n            # skip if it is symbolic link\n            if not os.path.islink(fp):\n                total_size += os.path.getsize(fp)\n\n    # Format size\n    i = 0\n    suffixes = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n    while total_size &gt;= 1024 and i &lt; len(suffixes) - 1:\n        total_size /= 1024.0\n        i += 1\n    f = (f\"{total_size:.2f}\").rstrip(\"0\").rstrip(\".\")\n    readable_size = f\"{f} {suffixes[i]}\"\n\n    return readable_size\n</code></pre>"},{"location":"api_reference/utils/python/#pixano.utils.python.natural_key","title":"<code>natural_key(string)</code>","text":"<p>Return key for string natural sort</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <code>str</code> <p>Input string</p> required <p>Returns:</p> Type Description <code>list</code> <p>Sort key</p> Source code in <code>pixano/utils/python.py</code> <pre><code>def natural_key(string: str) -&gt; list:\n    \"\"\"Return key for string natural sort\n\n    Args:\n        string (str): Input string\n\n    Returns:\n        list: Sort key\n    \"\"\"\n\n    return [int(s) if s.isdecimal() else s for s in re.split(r\"(\\d+)\", string)]\n</code></pre>"},{"location":"getting_started/","title":"Getting started with Pixano","text":"<ul> <li>Installing Pixano</li> <li>Importing your datasets</li> <li>Exporting your datasets</li> <li>Launching the app</li> <li>Using the app</li> </ul>"},{"location":"getting_started/exporting_datasets/","title":"Exporting datasets","text":"<p>Please refer to this Jupyter notebook for information on how to export your datasets.</p>"},{"location":"getting_started/importing_datasets/","title":"Importing datasets","text":"<p>Please refer to this Jupyter notebook for information on how to import your datasets.</p>"},{"location":"getting_started/installing_pixano/","title":"Installing Pixano","text":"<p>As Pixano requires specific versions for its dependencies, we recommend creating a new Python virtual environment to install it.</p> <p>For example, with conda:</p> <pre><code>conda create -n pixano_env python=3.10\nconda activate pixano_env\n</code></pre> <p>Then, you can install the Pixano package inside that environment with pip:</p> <pre><code>pip install pixano\n</code></pre>"},{"location":"getting_started/launching_the_app/","title":"Launching the app","text":""},{"location":"getting_started/launching_the_app/#from-a-terminal","title":"From a terminal","text":"<p>You can start the Pixano app with the following command:</p> <pre><code>pixano your_dataset_directory/\n</code></pre> <p>You will then be provided with a URL to open in your browser to use the app.</p> <p>Note that you can also connect to an S3 compatible storage by providing an S3 path instead of a local path to your datasets.</p> <p>The following arguments have to be passed:</p> <ul> <li><code>--aws_endpoint</code>: S3 endpoint URL, use 'AWS' if not provided.</li> <li><code>--aws_region</code>: S3 region name, not always required for private storages.</li> <li><code>--aws_access_key</code>: S3 AWS access key.</li> <li><code>--aws_secret_key</code>: S3 AWS secret key.</li> <li><code>--local_model_dir</code>: Local path to your models.</li> </ul> <p>So the command becomes:</p> <pre><code>pixano s3://your_dataset_directory/ \\\n--aws_endpoint=\"https://your-aws-endpoint.com\" \\\n--aws_region=\"\" \\\n--aws_access_key=\"your_access_key\" \\\n--aws_secret_key=\"your_secret_key\" \\\n--local_model_dir=\"your_local_onnx_models/\"\n</code></pre>"},{"location":"getting_started/launching_the_app/#from-a-notebook","title":"From a notebook","text":"<p>If you are in a Jupyter or Google Colab notebook, you can start the app by running the following cells:</p> <pre><code>from pixano.app import App\napp = App(\"your_dataset_directory/\")\n</code></pre> <p>You can then use the apps directly from the notebook in another cell with:</p> <pre><code>app.display()\n</code></pre>"},{"location":"getting_started/using_the_app/","title":"Using the app","text":""},{"location":"getting_started/using_the_app/#home-page","title":"Home page","text":"<p>From the app home page, you will be greeted with a list of all the Pixano format datasets found in the directory you provided.</p>"},{"location":"getting_started/using_the_app/#dataset-page","title":"Dataset page","text":"<p>On the dataset page, you will see a list of all the items it contains, organized in pages.</p> <p></p> <p>When scrolling to the bottom of the page, you will see navigation buttons to move through the pages of your dataset.</p>"},{"location":"getting_started/using_the_app/#dashboard-page","title":"Dashboard page","text":"<p>From the dataset page, you can go to the dashboard page, which contains more information about your datasets and also displays all the computed statistics available.</p>"},{"location":"getting_started/using_the_app/#item-page","title":"Item page","text":"<p>When opening an item, the item media will be displayed in the center on the screen (in case of multi-view datasets, the images will be tiled).</p> <p>On the left, a toolbar is available. On the right, two panels will display information on the item objects and scene.</p>"},{"location":"getting_started/using_the_app/#scene-panel","title":"Scene panel","text":"<p>The scene panel will display all the scene features, like the item label, or any other feature created when importing your dataset, as well as metadata information on all the images in the item.</p> <p>You can edit the scene features and then click the save changes button to write them to the dataset.</p>"},{"location":"getting_started/using_the_app/#object-panel","title":"Object panel","text":"<p>The objects panel will display all the item objects.</p> <p>On the top, you will see the ground truth objects, which are the objects you imported with your dataset, and objects you create within the app. On the bottom, a dropdown menu will let you go through all the objects created by models like the ones available in Pixano Inference.</p> <p>You have visibility toggles for objects and object group, and when hovering on an object, you will have access to an edit tool and a delete tool.</p> <p>If you have used an inference model for pre-annotating the dataset, a \"Pre-annotation\" toggle will also appear above the ground truth section. Activating this toggle will let you go through each object and accept or reject them individually. You will also be able to edit the object features before accepting it.</p> <p></p> <p>The edit tool will allow you to edit the object features, for example its category and category ID, and also allow you to edit the object bounding box and mask on the image. For text features, auto-completion based on existing feature values in the dataset is available.</p> <p>To create new objects, you have multiple tools at your disposal on the left toolbar.</p>"},{"location":"getting_started/using_the_app/#toolbar","title":"Toolbar","text":""},{"location":"getting_started/using_the_app/#pan-tool","title":"Pan tool","text":"<p>With the pan tool selected, you can move the image around. This is especially useful for multi-view datasets for organizing multiple images.</p> <p>Moving the images is still possible while any other tools is selected by using your mouse middle click. You can also zoom in and out of an image with the mouse wheel, and double click an image to bring it in front of the others.</p>"},{"location":"getting_started/using_the_app/#bounding-box-tool","title":"Bounding box tool","text":"<p>With the bounding box tool, you can create a bounding box object by click and dragging a rectangle over the image. Once you are done with your selection, you will be prompted to enter values for your object features depending on your dataset (in this case category_id and category), and to confirm the object.</p> <p>Then, click save changes in the object panels to save the created object to your dataset.</p>"},{"location":"getting_started/using_the_app/#polygon-tool","title":"Polygon tool","text":"<p>With the polygon tool, you can create a segmentation mask manually by adding points with the granularity of your choice.</p> <p>Once you save this mask, a matching bounding box will automatically be created.</p>"},{"location":"getting_started/using_the_app/#smart-segmentation-tool","title":"Smart segmentation tool","text":"<p>With Pixano, you can segment with smart segmentation tool like SAM (Segment Anything Model). Please follow our documentation on how to precompute the embeddings required by SAM and export its ONNX model to be able to use it.</p> <p></p> <p>With the positive and negative points, you can inform SAM on which part of the image you are trying to segment, and SAM will generate the mask for you.</p> <p></p> <p>When relevant, you can also use the rectangle tool to select the thing you want SAM to segment.</p> <p>When saving the mask created by SAM, like with the polygon tool, a matching bounding box will automatically be created.</p>"}]}