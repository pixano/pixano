{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interactive annotation with Pixano [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pixano/pixano/blob/main/notebooks/annotation/interactive_annotation.ipynb)\n",
        "\n",
        "This notebook allows you to pre-compute embeddings for a whole Pixano dataset using a deep learning model, and convert the model to ONNX.\n",
        "\n",
        "You can then interactively annotate your dataset using that model in the Pixano Annotator.\n",
        "\n",
        "## 1. Setting up\n",
        "\n",
        "### Install dependencies\n",
        "\n",
        "This notebook requires installing `pixano` as well the models from the complementary [`pixano-inference`](https://github.com/pixano/pixano-inference) module.\n",
        "\n",
        "If you are running this notebook on your computer, we strongly recommend creating a virtual environment for using Pixano like so:\n",
        "\n",
        "```shell\n",
        "conda create -n pixano_env python=3.10\n",
        "conda activate pixano_env\n",
        "```\n",
        "\n",
        "```shell\n",
        "pip install pixano\n",
        "pip install pixano-inference@git+https://github.com/pixano/pixano-inference\n",
        "```\n",
        "\n",
        "If you are running this notebook in Google Colab, run the cell below to install `pixano` and `pixano-inference`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  ENV = \"colab\"\n",
        "  !pip install pixano\n",
        "  !pip install pixano-inference@git+https://github.com/pixano/pixano-inference\n",
        "except:\n",
        "  ENV = \"jupyter\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from pixano_inference import segment_anything\n",
        "\n",
        "from pixano.apps import AnnotatorApp\n",
        "from pixano.models import InferenceModel"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download checkpoints\n",
        "- Segment Anything Model:\n",
        "    - `default` or `vit_h`: [ViT-H SAM model](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth).\n",
        "    - `vit_l`: [ViT-L SAM model](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth).\n",
        "    - `vit_b`: [ViT-B SAM model](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth).\n",
        "    \n",
        "## 2. Computing embeddings\n",
        "\n",
        "### Select a model\n",
        "\n",
        "- Loading a model:\n",
        "    - Segment Anything Model\n",
        "        - `model = segment_anything.SAM(checkpoint_path=Path(\"sam_vit_b_01ec64.pth\"), size=\"b\")`\n",
        "        - `model = segment_anything.SAM(checkpoint_path=Path(\"sam_vit_h_4b8939.pth\"), size=\"h\")`\n",
        "- Loading previously computed embeddings with model ID:\n",
        "    - `model = segment_anything.SAM(checkpoint_path=Path(\"sam_vit_h_4b8939.pth\"), size=\"h\", id=\"230414_094523_SAM_ViT_H\")`\n",
        "\n",
        "By default, `device` is equal to `\"cuda\"` for PyTorch models and `\"/GPU:0\"` for TensorFlow models.\n",
        "\n",
        "If you would like to run the model on your CPU, please add `device=\"cpu\"` for PyTorch models or `device=\"/CPU:0\"` for TensorFlow models in the arguments in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = segment_anything.SAM(checkpoint_path=Path(\"sam_vit_b_01ec64.pth\"), size=\"b\", device=\"cpu\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select a Pixano format dataset\n",
        "\n",
        "If you haven't already, please refer to the [dataset notebooks](../dataset/) for information on how to import your dataset to Pixano format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "library_dir = Path(\"datasets/\")\n",
        "dataset_dir = library_dir / \"coco_instances\"\n",
        "\n",
        "views = [\"image\"]\n",
        "splits = []"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "help(InferenceModel.process_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_dir = model.process_dataset(\n",
        "    input_dir=dataset_dir,\n",
        "    process_type=\"embed\",\n",
        "    views=views,\n",
        "    splits=splits,\n",
        "    batch_size=2,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exporting model to ONNX\n",
        "\n",
        "To use your model inside Pixano Annotator, you will need to convert it to ONNX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.export_to_onnx(library_dir)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Annotating the dataset\n",
        "\n",
        "With the generation complete, you can now browse your dataset with the Pixano Annotator and start annotating.\n",
        "\n",
        "You can stop the Annotator app by restarting the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "annotator = AnnotatorApp(library_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "annotator.display()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "px-next-4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
