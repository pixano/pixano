{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pre-annotation with Pixano [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pixano/pixano/blob/main/notebooks/models/pre_annotation.ipynb)\n",
        "\n",
        "This notebook allows you to preannotate a whole Pixano dataset using a deep learning model.\n",
        "\n",
        "You can then browse the inferences and compare them to ground truths in the Pixano app.\n",
        "\n",
        "## 1. Setting up\n",
        "\n",
        "### Install dependencies\n",
        "\n",
        "This notebook requires installing `pixano` and `pixano-inference`.\n",
        "\n",
        "If you are running this notebook on your computer, we strongly recommend creating a virtual environment for using Pixano like so:\n",
        "\n",
        "```shell\n",
        "conda create -n pixano_env python=3.10\n",
        "conda activate pixano_env\n",
        "```\n",
        "\n",
        "```shell\n",
        "pip install pixano\n",
        "pip install pixano-inference\n",
        "```\n",
        "\n",
        "If you are running this notebook in Google Colab, run the cell below to install `pixano` and `pixano-inference`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "\n",
        "    ENV = \"colab\"\n",
        "    %pip install pixano\n",
        "    %pip install pixano-inference\n",
        "except:\n",
        "    ENV = \"jupyter\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you plan to use some of the GitHub models available in Pixano Inference, you will also need to install them separately:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install segment-anything@git+https://github.com/facebookresearch/segment-anything\n",
        "%pip install mobile-sam@git+https://github.com/ChaoningZhang/MobileSAM\n",
        "%pip install groundingdino@git+https://github.com/IDEA-Research/GroundingDINO"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from pixano_inference import pytorch, github, tensorflow\n",
        "\n",
        "from pixano.app import App"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download checkpoints and configs\n",
        "\n",
        "- GroundingDINO:\n",
        "  - SwinT checkpoint: [groundingdino_swint_ogc.pth](https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth)\n",
        "  - SwinT config: [GroundingDINO_SwinT_OGC.py](https://raw.githubusercontent.com/IDEA-Research/GroundingDINO/main/groundingdino/config/GroundingDINO_SwinT_OGC.py)\n",
        "  - SwinB checkpoint: [groundingdino_swinb_cogcoor.pth](https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha2/groundingdino_swinb_cogcoor.pth)\n",
        "  - SwinB config: [GroundingDINO_SwinB_cfg.py](https://raw.githubusercontent.com/IDEA-Research/GroundingDINO/main/groundingdino/config/GroundingDINO_SwinB_cfg.py)\n",
        "- Segment Anything Model:\n",
        "  - ViT-H checkpoint: [sam_vit_h_4b8939.pth](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth)\n",
        "  - ViT-L checkpoint: [sam_vit_l_0b3195.pth](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth)\n",
        "  - ViT-B checkpoint: [sam_vit_b_01ec64.pth](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth)\n",
        "- MobileSAM:\n",
        "  - ViT-T checkpoint: [mobile_sam.pt](https://github.com/ChaoningZhang/MobileSAM/raw/master/weights/mobile_sam.pt)\n",
        "\n",
        "## 2. Genererating inferences\n",
        "\n",
        "With the Pixano Inference module, we provide some useful models from the PyTorch and TensorFlow model hubs as well as models from GitHub repositories.\n",
        "\n",
        "You can take a look at how they are implemented to add your own, or reach out to us if you think Pixano Inference could benefit from it, and we will try to add it in a future version.\n",
        "\n",
        "### Select a model\n",
        "\n",
        "- Object Detection (COCO labels):\n",
        "\n",
        "```python\n",
        "model = pytorch.YOLOv5(size=\"m\")\n",
        "model = tensorflow.FasterRCNN()\n",
        "model = tensorflow.EfficientDet()\n",
        "```\n",
        "\n",
        "- Instance Segmentation (COCO labels):\n",
        "\n",
        "```python\n",
        "model = pytorch.MaskRCNNv2()\n",
        "```\n",
        "\n",
        "- Semantic Segmentation (VOC labels):\n",
        "\n",
        "```python\n",
        "model = pytorch.DeepLabV3()\n",
        "```\n",
        "\n",
        "- Semantic Segmentation (text prompts):\n",
        "\n",
        "```python\n",
        "model = github.GroundingDINO(\n",
        "    checkpoint_path=Path(\"my_datasets/models/groundingdino_swint_ogc.pth\"),\n",
        "    config_path=Path(\"my_datasets/models/GroundingDINO_SwinT_OGC.py\")\n",
        ")\n",
        "```\n",
        "\n",
        "- Segment Anything (no labels):\n",
        "\n",
        "```python\n",
        "model = github.SAM(\n",
        "    checkpoint_path=Path(\"my_datasets/models/sam_vit_b_01ec64.pth\"),\n",
        "    size=\"b\"\n",
        ")\n",
        "model = github.MobileSAM(\n",
        "    checkpoint_path=Path(\"my_datasets/models/mobile_sam.pt\"),\n",
        ")\n",
        "```\n",
        "\n",
        "By default, `device` is equal to `\"cuda\"` (PyTorch) or `\"/GPU:0\"` (TensorFlow) for most models.\n",
        "\n",
        "If you would like to run the model on your CPU, please add `device=\"cpu\"` (PyTorch) or `device=\"/CPU:0\"` (TensorFlow) in the arguments in the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = pytorch.MaskRCNNv2()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select a Pixano format dataset\n",
        "\n",
        "If you haven't already, please refer to the [dataset notebooks](../datasets/) for information on how to import your dataset to Pixano format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "library_dir = Path(\"my_datasets/\")\n",
        "dataset_dir = library_dir / \"coco_instances\"\n",
        "\n",
        "views = [\"image\"]\n",
        "splits = []"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate inferences\n",
        "\n",
        "You have two options when generating inferences.\n",
        "\n",
        "- With `process_type=\"pre_ann\"`, the annotations will show up in the Pixano app as pre-annotations that you can individually accept as Ground Truth or reject.\n",
        "- With `process_type=\"model_run\"`, the annotations will instead be displayed in \"Model run\", a separate category that you can use to visualize the model's predictions and compare them to existing Ground Truth.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "help(model.process_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For prompt dependant models like GroundingDINO, don't forget to add the `prompt` argument in `process_dataset`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = model.process_dataset(\n",
        "    dataset_dir=dataset_dir,\n",
        "    process_type=\"model_run\",\n",
        "    views=views,\n",
        "    splits=splits,\n",
        "    batch_size=1,\n",
        "    threshold=0.1,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Browsing the dataset\n",
        "\n",
        "With the generation complete, you can now browse your dataset with the Pixano app and compare your inferences with ground truths.\n",
        "\n",
        "You can stop the app by restarting the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "app = App(library_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "app.display()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "px-next-4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f623b0e0a6a406195aec46cc280f4376049e0849fb0bfdc719d0238ed961bcbb"
      }
    }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ENV = \"colab\"\n",
    "    %pip install pixano\n",
    "    %pip install pixano-inference\n",
    "except:  # noqa: E722\n",
    "    ENV = \"jupyter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to install SAM and MobileSAM separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install segment-anything@git+https://github.com/facebookresearch/segment-anything\n",
    "%pip install mobile-sam@git+https://github.com/ChaoningZhang/MobileSAM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from pixano_inference import pytorch\n",
    "\n",
    "from pixano.app import App"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download checkpoints\n",
    "- Segment Anything Model:\n",
    "    - ViT-H checkpoint: [sam_vit_h_4b8939.pth](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth)\n",
    "    - ViT-L checkpoint: [sam_vit_l_0b3195.pth](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth)\n",
    "    - ViT-B checkpoint: [sam_vit_b_01ec64.pth](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth)\n",
    "- MobileSAM:\n",
    "    - ViT-T checkpoint: [mobile_sam.pt](https://github.com/ChaoningZhang/MobileSAM/raw/master/weights/mobile_sam.pt)\n",
    "\n",
    "## 2. Genererating inferences\n",
    "\n",
    "With the Pixano Inference module, we provide some useful models from the PyTorch and TensorFlow model hubs as well as models from GitHub repositories.\n",
    "\n",
    "You can take a look at how they are implemented to add your own, or reach out to us if you think Pixano Inference could benefit from it, and we will try to add it in a future version. \n",
    "\n",
    "### Select a model\n",
    "- Object Detection (COCO labels):\n",
    "```python\n",
    "model = pytorch.YOLOv5(size=\"m\")\n",
    "model = tensorflow.FasterRCNN()\n",
    "model = tensorflow.EfficientDet()\n",
    "```\n",
    "- Instance Segmentation (COCO labels):\n",
    "```python\n",
    "model = pytorch.MaskRCNNv2()\n",
    "```\n",
    "- Semantic Segmentation (VOC labels):\n",
    "```python\n",
    "model = pytorch.DeepLabV3()\n",
    "```\n",
    "- Semantic Segmentation (text prompts):\n",
    "```python\n",
    "model = github.GroundingDINO(\n",
    "    checkpoint_path=Path(\"my_datasets/models/groundingdino_swint_ogc.pth\"),\n",
    "    config_path=Path(\"my_datasets/models/GroundingDINO_SwinT_OGC.py\")\n",
    ")\n",
    "```\n",
    "- Segment Anything (no labels):\n",
    "```python\n",
    "model = github.SAM(\n",
    "    checkpoint_path=Path(\"my_datasets/models/sam_vit_b_01ec64.pth\"),\n",
    "    size=\"b\"\n",
    ")\n",
    "model = github.MobileSAM(\n",
    "    checkpoint_path=Path(\"my_datasets/models/mobile_sam.pt\"),\n",
    ")\n",
    "```\n",
    "\n",
    "By default, `device` is equal to `\"cuda\"` (PyTorch) or `\"/GPU:0\"` (TensorFlow) for most models.\n",
    "\n",
    "If you would like to run the model on your CPU, please add `device=\"cpu\"` (PyTorch) or `device=\"/CPU:0\"` (TensorFlow) in the arguments in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pytorch.MaskRCNNv2()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a Pixano format dataset\n",
    "\n",
    "If you haven't already, please refer to the [dataset notebooks](../datasets/) for information on how to import your dataset to Pixano format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_dir = Path(\"my_datasets/\")\n",
    "dataset_dir = library_dir / \"coco_instances\"\n",
    "\n",
    "views = [\"image\"]\n",
    "splits = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate inferences\n",
    "\n",
    "You have two options when generating inferences.\n",
    "- With `process_type=\"pre_ann\"`, the annotations will show up in the Pixano app as pre-annotations that you can individually accept as Ground Truth or reject.\n",
    "- With `process_type=\"model_run\"`, the annotations will instead be displayed in \"Model run\", a separate category that you can use to visualize the model's predictions and compare them to existing Ground Truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model.process_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = model.process_dataset(\n",
    "    dataset_dir=dataset_dir,\n",
    "    process_type=\"model_run\",\n",
    "    views=views,\n",
    "    splits=splits,\n",
    "    batch_size=1,\n",
    "    threshold=0.1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Browsing the dataset\n",
    "\n",
    "With the generation complete, you can now browse your dataset with the Pixano app and compare your inferences with ground truths.\n",
    "\n",
    "You can stop the app by restarting the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = App(library_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "px-next-4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f623b0e0a6a406195aec46cc280f4376049e0849fb0bfdc719d0238ed961bcbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
