{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interactive annotation with Pixano [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pixano/pixano/blob/main/notebooks/models/interactive_annotation.ipynb)\n",
        "\n",
        "This notebook allows you to pre-compute embeddings for a whole Pixano dataset using a deep learning model, and convert the model to ONNX.\n",
        "\n",
        "You can then interactively annotate your dataset using that model in the Pixano app.\n",
        "\n",
        "## 1. Setting up\n",
        "\n",
        "### Install dependencies\n",
        "\n",
        "This notebook requires installing `pixano` as well the models from the complementary [`pixano-inference`](https://github.com/pixano/pixano-inference) module.\n",
        "\n",
        "If you are running this notebook on your computer, we strongly recommend creating a virtual environment for using Pixano like so:\n",
        "\n",
        "```shell\n",
        "conda create -n pixano_env python=3.10\n",
        "conda activate pixano_env\n",
        "```\n",
        "\n",
        "```shell\n",
        "pip install pixano\n",
        "pip install pixano-inference@git+https://github.com/pixano/pixano-inference\n",
        "```\n",
        "\n",
        "If you are running this notebook in Google Colab, run the cell below to install `pixano` and `pixano-inference`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "\n",
        "    ENV = \"colab\"\n",
        "    %pip install pixano\n",
        "    %pip install pixano-inference@git+https://github.com/pixano/pixano-inference\n",
        "except:\n",
        "    ENV = \"jupyter\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from pixano_inference import segment_anything\n",
        "\n",
        "from pixano.app import App"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download checkpoints\n",
        "- Segment Anything Model:\n",
        "    - `default` or `vit_h`: [ViT-H SAM model](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth).\n",
        "    - `vit_l`: [ViT-L SAM model](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth).\n",
        "    - `vit_b`: [ViT-B SAM model](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth).\n",
        "- MobileSAM:\n",
        "    - `vit_t`: [ViT-T model](https://github.com/ChaoningZhang/MobileSAM/raw/master/weights/mobile_sam.pt)\n",
        "    \n",
        "## 2. Computing embeddings\n",
        "\n",
        "### Select a model\n",
        "\n",
        "- Loading a model:\n",
        "    - Segment Anything Model\n",
        "        - `model = segment_anything.SAM(checkpoint_path=Path(\"my_datasets/models/sam_vit_b_01ec64.pth\"), size=\"b\")`\n",
        "        - `model = segment_anything.SAM(checkpoint_path=Path(\"my_datasets/models/sam_vit_h_4b8939.pth\"), size=\"h\")`\n",
        "    - MobileSAM\n",
        "        - `model = segment_anything.MobileSAM(checkpoint_path=Path(\"my_datasets/models/mobile_sam.pt\"))`\n",
        "\n",
        "By default, `device` is equal to `\"cuda\"` for SAM and `\"cpu\"` for MobileSAM.\n",
        "\n",
        "If you would like to run the model on a different device, please add `device=\"cuda\"` or `device=\"cpu\"` in the arguments in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = segment_anything.SAM(\n",
        "    checkpoint_path=Path(\"my_datasets/models/sam_vit_h_4b8939.pth\"), size=\"h\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Select a Pixano format dataset\n",
        "\n",
        "If you haven't already, please refer to the [dataset notebooks](../datasets/) for information on how to import your dataset to Pixano format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "library_dir = Path(\"my_datasets/\")\n",
        "dataset_dir = library_dir / \"coco_instances\"\n",
        "\n",
        "views = [\"image\"]\n",
        "splits = []"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "help(model.process_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = model.process_dataset(\n",
        "    dataset_dir=dataset_dir,\n",
        "    process_type=\"segment_emb\",\n",
        "    views=views,\n",
        "    splits=splits,\n",
        "    batch_size=2,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exporting model to ONNX\n",
        "\n",
        "To use your model inside Pixano app, you will need to convert it to ONNX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.export_to_onnx(library_dir)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Annotating the dataset\n",
        "\n",
        "With the generation complete, you can now browse your dataset with the Pixano app and start annotating.\n",
        "\n",
        "You can stop the app by restarting the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "app = App(library_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "app.display()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "px-next-4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
